mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Check dimensions of pima_pca$x and pima_pca$rotation
class(pima_pca$x)
class(pima_pca$rotation)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Apply KLT to PCA results
pima_klt_result <- pima_pca$x %*% pima_pca$rotation
lisbon_klt_result <- t(lisbon_pca$x) %*% lisbon_pca$rotation
#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Check dimensions of pima_pca$x and pima_pca$rotation
class(pima_pca$x)
class(pima_pca$rotation)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Apply KLT to PCA results
pima_klt_result <- pima_pca$x %*% pima_pca$rotation
pima_klt_result
lisbon_klt_result <- t(lisbon_pca$x) %*% lisbon_pca$rotation
#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance <- cumsum(pima_eigenvalues) / sum(pima_eigenvalues)
# Find the number of components that explain at least 90% of the variance
num_components <- which(cumulative_variance >= 0.9)[1]
# Retain the selected number of components
selected_pcs <- pima_pca$x[, 1:num_components]
selected_pcs
#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance <- cumsum(pima_eigenvalues) / sum(pima_eigenvalues)
# Find the number of components that explain at least 90% of the variance
num_components <- which(cumulative_variance >= 0.95)[1]
# Retain the selected number of components
selected_pcs <- pima_pca$x[, 1:num_components]
selected_pcs
#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance_pima <- cumsum(pima_pca$sdev^2 / sum(pima_pca$sdev^2))
cumulative_variance_lisbon <- cumsum(lisbon_pca$sdev^2 / sum(lisbon_pca$sdev^2))
# Find the number of components that explain at least 90% of the variance
k_pima <- which(cumulative_variance_pima >= 0.9)[1]
k_lisbon <- which(cumulative_variance_lisbon >= 0.9)[1]
# Retain the selected number of components
selected_pcs_pima <- pima_pca$x[, 1:k_pima]
selected_pcs_lisbon <- lisbon_pca$x[, 1:k_lisbon]
# Show selected components in terminal
selected_pcs_pima
selected_pcs_lisbon
#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance_pima <- cumsum(pima_pca$sdev^2 / sum(pima_pca$sdev^2))
cumulative_variance_lisbon <- cumsum(lisbon_pca$sdev^2 / sum(lisbon_pca$sdev^2))
# Find the number of components that explain at least 90% of the variance
k_pima <- which(cumulative_variance_pima >= 0.9)[1]
k_lisbon <- which(cumulative_variance_lisbon >= 0.9)[1]
# Retain the selected number of components
selected_pcs_pima <- pima_pca$x[, 1:k_pima]
selected_pcs_lisbon <- lisbon_pca$x[, 1:k_lisbon]
# Show selected components in terminal
ncol(selected_pcs_pima)
ncol(selected_pcs_lisbon)
#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance_pima <- cumsum(pima_pca$sdev^2 / sum(pima_pca$sdev^2))
cumulative_variance_lisbon <- cumsum(lisbon_pca$sdev^2 / sum(lisbon_pca$sdev^2))
# Find the number of components that explain at least 90% of the variance
k_pima <- which(cumulative_variance_pima >= 0.9)[1]
k_lisbon <- which(cumulative_variance_lisbon >= 0.95)[1]
# Retain the selected number of components
selected_pcs_pima <- pima_pca$x[, 1:k_pima]
selected_pcs_lisbon <- lisbon_pca$x[, 1:k_lisbon]
# Show selected components in terminal
ncol(selected_pcs_pima)
ncol(selected_pcs_lisbon)
#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance_pima <- cumsum(pima_pca$sdev^2 / sum(pima_pca$sdev^2))
cumulative_variance_lisbon <- cumsum(lisbon_pca$sdev^2 / sum(lisbon_pca$sdev^2))
# Find the number of components that explain at least 90% of the variance
k_pima <- which(cumulative_variance_pima >= 0.9)[1]
k_lisbon <- which(cumulative_variance_lisbon >= 0.9)[1]
# Retain the selected number of components
selected_pcs_pima <- pima_pca$x[, 1:k_pima]
selected_pcs_lisbon <- lisbon_pca$x[, 1:k_lisbon]
# Show selected components in terminal
ncol(selected_pcs_pima)
ncol(selected_pcs_lisbon)
#Ex b
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Function to handle missing or infinite values
handle_missing_infinite <- function(data) {
for (col in names(data)){
data[[col]][is.infinite(data[[col]])] <- NA
data[[col]][is.nan(data[[col]])] <- NA
}
data <- na.omit(data)
return(data)
}
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Apply the function to handle missing or infinite values
lisbon_encoded <- handle_missing_infinite(lisbon_encoded)
# Compute SVD for Pima dataset
pima_svd <- svd(scale(pima_encoded[, -ncol(pima_encoded)]))
# Compute SVD for Lisbon dataset
lisbon_svd <- svd(scale(lisbon_encoded[, -c(1, 2, 22, 23, 24)]))
# Plot singular values for Pima dataset
plot(pima_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Pima Dataset")
# Plot singular values for Lisbon dataset
plot(lisbon_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Lisbon Dataset")
# Determine a proporção acumulada da variância explicada por cada componente
cumulative_variance_svd_pima <- cumsum(pima_svd$d^2 / sum(pima_svd$d^2))
cumulative_variance_svd_lisbon <- cumsum(lisbon_svd$d^2 / sum(lisbon_svd$d^2))
# Encontre o número de componentes que explicam pelo menos 90% da variância
k_svd_pima <- which(cumulative_variance_svd_pima >= 0.9)[1]
k_svd_lisbon <- which(cumulative_variance_svd_lisbon >= 0.9)[1]
# Retenha o número selecionado de componentes
selected_svd_pcs_pima <- pima_svd$u[, 1:k_svd_pima] %*% diag(pima_svd$d[1:k_svd_pima])
selected_svd_pcs_lisbon <- lisbon_svd$u[, 1:k_svd_lisbon] %*% diag(lisbon_svd$d[1:k_svd_lisbon])
# Mostrar os componentes selecionados no terminal
selected_svd_pcs_pima
selected_svd_pcs_lisbon
#Ex b
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Function to handle missing or infinite values
handle_missing_infinite <- function(data) {
for (col in names(data)){
data[[col]][is.infinite(data[[col]])] <- NA
data[[col]][is.nan(data[[col]])] <- NA
}
data <- na.omit(data)
return(data)
}
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Apply the function to handle missing or infinite values
lisbon_encoded <- handle_missing_infinite(lisbon_encoded)
# Compute SVD for Pima dataset
pima_svd <- svd(scale(pima_encoded[, -ncol(pima_encoded)]))
# Compute SVD for Lisbon dataset
lisbon_svd <- svd(scale(lisbon_encoded[, -c(1, 2, 22, 23, 24)]))
# Plot singular values for Pima dataset
plot(pima_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Pima Dataset")
# Plot singular values for Lisbon dataset
plot(lisbon_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Lisbon Dataset")
# Determine a proporção acumulada da variância explicada por cada componente
cumulative_variance_svd_pima <- cumsum(pima_svd$d^2 / sum(pima_svd$d^2))
cumulative_variance_svd_lisbon <- cumsum(lisbon_svd$d^2 / sum(lisbon_svd$d^2))
# Encontre o número de componentes que explicam pelo menos 90% da variância
k_svd_pima <- which(cumulative_variance_svd_pima >= 0.9)[1]
k_svd_lisbon <- which(cumulative_variance_svd_lisbon >= 0.9)[1]
# Retenha o número selecionado de componentes
selected_svd_pcs_pima <- pima_svd$u[, 1:k_svd_pima] %*% diag(pima_svd$d[1:k_svd_pima])
selected_svd_pcs_lisbon <- lisbon_svd$u[, 1:k_svd_lisbon] %*% diag(lisbon_svd$d[1:k_svd_lisbon])
# Mostrar os componentes selecionados no terminal
ncol(selected_svd_pcs_pima)
ncol(selected_svd_pcs_lisbon)
################# Preparation ################
library(dplyr) #data manipulation
library(sparklyr) #spark
library(smotefamily) #For SMOTE sampling
library(data.table) #To be used when possible, as a more performant data.frame
setwd("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab03/AP3")
if(!exists("printConfusionMatrix", mode="function"))
source("helperfunctions.R")
################# Spark setup ################
spark_disconnect_all() #just preventive code
sc <- spark_connect('local', version = '3.4.2', hadoop_version = '3', config = list())
################# Load data ################
basepath <- "../data"
tr.data <- c("train_data_25.csv","train_data_30.csv") #The data to use
labels<- c("train_labels_25.csv","train_labels_30.csv") #the lables for the data
fun1 <- function(i) { #read CSV data
read.csv(paste(basepath,"train",i,sep = "/"), header=FALSE,stringsAsFactors = FALSE)
}
fun2 <- function(i) { #read and transpose CSV data
read.csv(paste(basepath,"train",i,sep = "/"), header=FALSE,stringsAsFactors = FALSE) %>% t %>% as.data.table
}
df<-do.call(rbind, lapply(tr.data, fun1 )) #bind csv together
df.l<-do.call(rbind, lapply(labels, fun2 )) #bind class together
names(df.l) <-c("CLASS") #rename dependent variable
df.local<- cbind(df.l,df) #bind them together
df <- copy_to(sc, df.local)
################# G2 #######################
#Glimpse of the data set
#TODO
sdf <- sdf_schema(df)
head(sdf)
stopifnot(
ncol(sdf)==545,
nrow(sdf)==2190)
################# G3 #######################
#Feature Selection
idx <- c(1,2,5,6,9,10,11,14,16,17,19,21,24,25,26,31,32,33,34,35,41,44,49,50,54)
#TODO
df.sel <- df %>% select(all_of(idx))
head(df.sel)
################# G4 #######################
#Generating train and test data
set.seed(123)
df.split <- sdf_random_split(df, fractions = c("training" = 2/3, "testing" = 1/3))
df.split <- sdf_random_split(df, fractions = c("training" = 0.67, "testing" = 0.33))
df.split <- sdf_random_split(df, fractions = c("training" = 0.67, "testing" = 0.33))
df.split <- sdf_random_split(df, fractions = c(training = 0.67, testing = 0.33))
help("sdf_random_split")
df.split <- df %>%
sdf_random_split(df, fractions = c(training = 0.67, testing = 0.33))
df.split <- df %>% sdf_random_split(training = 0.67, testing = 0.33)
df.train <- df.split$training
df.test <-  df.split$testing
#TODO Baseline
# Collect the data from Spark DataFrame to local R environment
train_data_local <- collect(df.train)
test_data_local <- collect(df.test)
# Use the table function to determine the number of instances for each class
train_class_counts <- table(train_data_local$CLASS)
test_class_counts <- table(test_data_local$CLASS)
# Display the class counts
print("Train Data Class Counts:")
print(train_class_counts)
print("Test Data Class Counts:")
print(test_class_counts)
help("ml_random_forest")
random_forest_model <- ml_random_forest(df.train, formula = ("CLASS ~ ."))
summary(random_forest_model)
help("mdle.printConfusionMatrix")
help("ml_predict")
mdle.printConfusionMatrix <- function(actual, predicted) {
conf_matrix <- table(Actual = actual, Predicted = predicted)
print(conf_matrix)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy:", accuracy, "\n")
}
# Make predictions on the test data using the trained model
predictions <- ml_predict(rf_model, df.test)
mdle.printConfusionMatrix <- function(actual, predicted) {
conf_matrix <- table(Actual = actual, Predicted = predicted)
print(conf_matrix)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy:", accuracy, "\n")
}
# Make predictions on the test data using the trained model
predictions <- ml_predict(random_forest_model, df.test)
# Extract the predicted labels from the predictions
predicted_labels <- collect(predictions) %>%
select(Predicted) %>%
as.vector()
# Extract the predicted labels from the predictions
predicted_labels <- collect(predictions) %>%
select(predictions) %>%
as.vector()
# Make predictions on the test data using the trained model
predictions <- ml_predict(random_forest_model, df.test)
predictions
# Make predictions on the test data using the trained model
predictions <- ml_predict(random_forest_model, df.test)
predictions
# Extract the predicted labels from the predictions
predicted_labels <- collect(predictions) %>%
select(predictions) %>%
as.vector()
mdle.printConfusionMatrix <- function(actual, predicted) {
conf_matrix <- table(Actual = actual, Predicted = predicted)
print(conf_matrix)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy:", accuracy, "\n")
}
# Make predictions on the test data using the trained model
predictions <- ml_predict(random_forest_model, test_class_counts)
mdle.printConfusionMatrix <- function(actual, predicted) {
conf_matrix <- table(Actual = actual, Predicted = predicted)
print(conf_matrix)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy:", accuracy, "\n")
}
# Make predictions on the test data using the trained model
predictions <- ml_predict(random_forest_model, df.test)
predictions
# Extract the predicted labels from the predictions
predicted_labels <- collect(predictions) %>%
select(predictions) %>%
as.vector()
mdle.printConfusionMatrix <- function(actual, predicted) {
conf_matrix <- table(Actual = actual, Predicted = predicted)
print(conf_matrix)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy:", accuracy, "\n")
}
# Make predictions on the test data using the trained model
predictions <- ml_predict(random_forest_model, df.test)
predictions
# Extract the predicted labels from the predictions
predicted_labels <- collect(predictions) %>%
select(CLASS) %>%
as.vector()
# Extract the actual labels from the test data
actual_labels <- collect(df.test) %>%
select(CLASS) %>%
as.vector()
# Print confusion matrix and performance metrics
mdle.printConfusionMatrix(actual_labels, predicted_labels)
