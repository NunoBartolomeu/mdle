#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance_pima <- cumsum(pima_pca$sdev^2 / sum(pima_pca$sdev^2))
cumulative_variance_lisbon <- cumsum(lisbon_pca$sdev^2 / sum(lisbon_pca$sdev^2))
# Find the number of components that explain at least 90% of the variance
k_pima <- which(cumulative_variance_pima >= 0.9)[1]
k_lisbon <- which(cumulative_variance_lisbon >= 0.9)[1]
# Retain the selected number of components
selected_pcs_pima <- pima_pca$x[, 1:k_pima]
selected_pcs_lisbon <- lisbon_pca$x[, 1:k_lisbon]
# Show selected components in terminal
selected_pcs_pima
selected_pcs_lisbon
#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance_pima <- cumsum(pima_pca$sdev^2 / sum(pima_pca$sdev^2))
cumulative_variance_lisbon <- cumsum(lisbon_pca$sdev^2 / sum(lisbon_pca$sdev^2))
# Find the number of components that explain at least 90% of the variance
k_pima <- which(cumulative_variance_pima >= 0.9)[1]
k_lisbon <- which(cumulative_variance_lisbon >= 0.9)[1]
# Retain the selected number of components
selected_pcs_pima <- pima_pca$x[, 1:k_pima]
selected_pcs_lisbon <- lisbon_pca$x[, 1:k_lisbon]
# Show selected components in terminal
ncol(selected_pcs_pima)
ncol(selected_pcs_lisbon)
#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance_pima <- cumsum(pima_pca$sdev^2 / sum(pima_pca$sdev^2))
cumulative_variance_lisbon <- cumsum(lisbon_pca$sdev^2 / sum(lisbon_pca$sdev^2))
# Find the number of components that explain at least 90% of the variance
k_pima <- which(cumulative_variance_pima >= 0.9)[1]
k_lisbon <- which(cumulative_variance_lisbon >= 0.95)[1]
# Retain the selected number of components
selected_pcs_pima <- pima_pca$x[, 1:k_pima]
selected_pcs_lisbon <- lisbon_pca$x[, 1:k_lisbon]
# Show selected components in terminal
ncol(selected_pcs_pima)
ncol(selected_pcs_lisbon)
#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance_pima <- cumsum(pima_pca$sdev^2 / sum(pima_pca$sdev^2))
cumulative_variance_lisbon <- cumsum(lisbon_pca$sdev^2 / sum(lisbon_pca$sdev^2))
# Find the number of components that explain at least 90% of the variance
k_pima <- which(cumulative_variance_pima >= 0.9)[1]
k_lisbon <- which(cumulative_variance_lisbon >= 0.9)[1]
# Retain the selected number of components
selected_pcs_pima <- pima_pca$x[, 1:k_pima]
selected_pcs_lisbon <- lisbon_pca$x[, 1:k_lisbon]
# Show selected components in terminal
ncol(selected_pcs_pima)
ncol(selected_pcs_lisbon)
#Ex b
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Function to handle missing or infinite values
handle_missing_infinite <- function(data) {
for (col in names(data)){
data[[col]][is.infinite(data[[col]])] <- NA
data[[col]][is.nan(data[[col]])] <- NA
}
data <- na.omit(data)
return(data)
}
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Apply the function to handle missing or infinite values
lisbon_encoded <- handle_missing_infinite(lisbon_encoded)
# Compute SVD for Pima dataset
pima_svd <- svd(scale(pima_encoded[, -ncol(pima_encoded)]))
# Compute SVD for Lisbon dataset
lisbon_svd <- svd(scale(lisbon_encoded[, -c(1, 2, 22, 23, 24)]))
# Plot singular values for Pima dataset
plot(pima_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Pima Dataset")
# Plot singular values for Lisbon dataset
plot(lisbon_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Lisbon Dataset")
# Determine a proporção acumulada da variância explicada por cada componente
cumulative_variance_svd_pima <- cumsum(pima_svd$d^2 / sum(pima_svd$d^2))
cumulative_variance_svd_lisbon <- cumsum(lisbon_svd$d^2 / sum(lisbon_svd$d^2))
# Encontre o número de componentes que explicam pelo menos 90% da variância
k_svd_pima <- which(cumulative_variance_svd_pima >= 0.9)[1]
k_svd_lisbon <- which(cumulative_variance_svd_lisbon >= 0.9)[1]
# Retenha o número selecionado de componentes
selected_svd_pcs_pima <- pima_svd$u[, 1:k_svd_pima] %*% diag(pima_svd$d[1:k_svd_pima])
selected_svd_pcs_lisbon <- lisbon_svd$u[, 1:k_svd_lisbon] %*% diag(lisbon_svd$d[1:k_svd_lisbon])
# Mostrar os componentes selecionados no terminal
selected_svd_pcs_pima
selected_svd_pcs_lisbon
#Ex b
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Function to handle missing or infinite values
handle_missing_infinite <- function(data) {
for (col in names(data)){
data[[col]][is.infinite(data[[col]])] <- NA
data[[col]][is.nan(data[[col]])] <- NA
}
data <- na.omit(data)
return(data)
}
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Apply the function to handle missing or infinite values
lisbon_encoded <- handle_missing_infinite(lisbon_encoded)
# Compute SVD for Pima dataset
pima_svd <- svd(scale(pima_encoded[, -ncol(pima_encoded)]))
# Compute SVD for Lisbon dataset
lisbon_svd <- svd(scale(lisbon_encoded[, -c(1, 2, 22, 23, 24)]))
# Plot singular values for Pima dataset
plot(pima_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Pima Dataset")
# Plot singular values for Lisbon dataset
plot(lisbon_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Lisbon Dataset")
# Determine a proporção acumulada da variância explicada por cada componente
cumulative_variance_svd_pima <- cumsum(pima_svd$d^2 / sum(pima_svd$d^2))
cumulative_variance_svd_lisbon <- cumsum(lisbon_svd$d^2 / sum(lisbon_svd$d^2))
# Encontre o número de componentes que explicam pelo menos 90% da variância
k_svd_pima <- which(cumulative_variance_svd_pima >= 0.9)[1]
k_svd_lisbon <- which(cumulative_variance_svd_lisbon >= 0.9)[1]
# Retenha o número selecionado de componentes
selected_svd_pcs_pima <- pima_svd$u[, 1:k_svd_pima] %*% diag(pima_svd$d[1:k_svd_pima])
selected_svd_pcs_lisbon <- lisbon_svd$u[, 1:k_svd_lisbon] %*% diag(lisbon_svd$d[1:k_svd_lisbon])
# Mostrar os componentes selecionados no terminal
ncol(selected_svd_pcs_pima)
ncol(selected_svd_pcs_lisbon)
# Set the working directory to the 'src' directory
#setwd("D:/Cadeiras/MDLE/mdle/project1/src")
setwd("C:/Users/pedro/Desktop/mestradoLab/mdle/project1/src")
# List of filenames
filenames <- c(
"Lisbon_2023-01-01_2023-01-31.csv",
"Lisbon_2022-12-01_2022-12-31.csv",
"Lisbon_2023-02-01_2023-02-28.csv",
"Lisbon_2023-03-01_2023-03-31.csv",
"Lisbon_2023-04-01_2023-04-30.csv",
"Lisbon_2023-05-01_2023-05-31.csv",
"Lisbon_2023-06-01_2023-06-30.csv",
"Lisbon_2023-07-01_2023-07-31.csv",
"Lisbon_2023-08-01_2023-08-31.csv",
"Lisbon_2023-09-01_2023-09-30.csv",
"Lisbon_2023-10-01_2023-10-31.csv",
"Lisbon_2023-11-01_2023-11-30.csv",
"Lisbon_2023-12-01_2023-12-31.csv"
)
# Initialize an empty data frame to store merged data
merged_data <- data.frame()
# Loop through each file, read it, and append to merged_data
for (filename in filenames) {
file_path <- paste("../mdle_data/Weather/", filename, sep="")
data <- read.csv(file_path, header=TRUE)
merged_data <- rbind(merged_data, data)
}
# Write merged data to a new CSV file
write.csv(merged_data, file="../mdle_data/Weather/Lisbon_2022-12-01_2023-12-31_full.csv", row.names = FALSE)
################################################################################
# Read the merged data file
merged_data <- read.csv("../mdle_data/Weather/Lisbon_2022-12-01_2023-12-31_full.csv")
#
variance_lisbon <- apply(merged_data, 2, function(x) var(x, na.rm = TRUE))
# Combine relevance measures for each dataset
relevance_lisbon <- data.frame(features = colnames(merged_data), variance = variance_lisbon)
print("Lisbon Dataset:")
print(relevance_lisbon)
# Remove columns with 0 variance
valid_indices <- which(relevance_lisbon$variance > 0 || relevance_lisbon$features == "datetime")
# Remove columns with 0 variance
valid_indices <- which(relevance_lisbon$variance > 0 | relevance_lisbon$features == "datetime")
# Remove the specified columns
filtered_merged_data <- merged_data[, valid_indices]
print("Lisbon Dataset (filtered):")
print(filtered_merged_data)
# Write the filtered data to a new CSV file
write.csv(filtered_merged_data, file="../mdle_data/Weather/Lisbon_2022-12-01_2023-12-31_filtered.csv", row.names=FALSE)
source("C:/Users/pedro/Desktop/mestradoLab/mdle/project1/src/filter_make_weather_massive_file.R")
# Set the working directory to the 'src' directory
#setwd("D:/Cadeiras/MDLE/mdle/project1/src")
setwd("C:/Users/pedro/Desktop/mestradoLab/mdle/project1/src")
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
head(data)
lisbon_census <- subset(data, data$X.6 = "Lisboa")
lisbon_census <- subset(data, data$X.6 == "Lisboa")
lisbon_census <- subset(data, data$X.6 == "Área Metropolitana de Lisboa")
head(lisbon_census)
# Set the working directory to the 'src' directory
#setwd("D:/Cadeiras/MDLE/mdle/project1/src")
setwd("C:/Users/pedro/Desktop/mestradoLab/mdle/project1/src")
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
lisbon_census <- subset(data, data$X.6 == "Área Metropolitana de Lisboa")
head(lisbon_census)
lisbon_census
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
lisbon_census <- subset(data, data$X.6 == "Área Metropolitana de Lisboa")
lisbon_census
# Set the working directory to the 'src' directory
#setwd("D:/Cadeiras/MDLE/mdle/project1/src")
setwd("C:/Users/pedro/Desktop/mestradoLab/mdle/project1/src")
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
lisbon_census <- subset(data, data$X.6 == "Área Metropolitana de Lisboa")
lisbon_census
data <- read_excel("../mdle_data/INE/FS-2021-Secção-Tot.csv")
data <- read_excel("../mdle_data/INE/FS 2021 Secção Tot.xlsx")
data <- read_excel("../mdle_data/INE/FS 2021 Secção Tot.xlsx")
data <- read_excel("../mdle_data/INE/FS 2021 Secção Tot.xlsx")
data <- read_excel("../mdle_data/INE/FS_2021_Secção_Tot.xlsx")
install.packages("readxl")
install.packages("readxl")
install.packages("readxl")
data <- read_excel("../mdle_data/INE/FS_2021_Secção_Tot.xlsx")
help("read_excel")
??read_excel
library(readxl)
data <- read_excel("../mdle_data/INE/FS_2021_Secção_Tot.xlsx")
lisbon_census
lisbon_census <- subset(data, data$X.6 == "Área Metropolitana de Lisboa")
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
lisbon_census <- subset(data, data$X.6 == "Área Metropolitana de Lisboa")
lisbon_census
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
lisbon_census <- subset(data, data$X.6 == "Área Metropolitana de Lisboa")
lisbon_census
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
lisbon_census <- subset(data, data$MUNICIPIO == "Área Metropolitana de Lisboa")
lisbon_census
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
head(data)
lisbon_census <- subset(data, data$MUNICIPIO.DSG == "Área Metropolitana de Lisboa")
head(lisbon_census)
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
head(data)
lisbon_indices <- which(data$MUNICIPIO.DSG == "Área Metropolitana de Lisboa")
lisbon_census <- data[, lisbon_indices]
head(lisbon_census)
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
lisbon_census <- subset(data, data$NUTS2.DSG == "Área Metropolitana de Lisboa")
head(lisbon_census)
range(lisbon_census$MUNICIPIO)
max(lisbon_census$MUNICIPIO)
class(lisbon_census)
for (col in colnames(lisbon_census)) {
print(typeof(col))
}
for (col in colnames(lisbon_census)) {
lisbon_census$col <- as.integer(lisbon_census$col)
}
lisbon_census <- as.data.frame(lapply(lisbon_census, as.integer))
str(lisbon_census)
variance_lisbon_census <- apply(lisbon_census, 2, function(x) var(x, na.rm = TRUE))
relevance_lisbon_census <- data.frame(features = colnames(variance_lisbon_census), variance = variance_lisbon)
relevance_lisbon_census <- data.frame(features = colnames(variance_lisbon_census), variance = variance_lisbon_census)
relevance_lisbon_census <- data.frame(variance = variance_lisbon_census)
print("Lisbon Dataset:")
print(relevance_lisbon_census)
min(lisbon_census$MUNICIPIO)
max(lisbon_census$MUNICIPIO)
# Encontrar o maior valor
maior_valor <- max(lisbon_census$MUNICIPIO)
# Encontrar o menor valor
menor_valor <- min(lisbon_census$MUNICIPIO)
# Imprimir os resultados
print(paste("Maior valor:", maior_valor))
print(paste("Menor valor:", menor_valor))
print(lisbon_census$MUNICIPIO)
print(mean(lisbon_census$MUNICIPIO))
print(str(lisbon_census$MUNICIPIO))
valid_indices <- which(relevance_lisbon_census$variance > 0)
# Remove the specified columns
filtered_relevance_lisbon_census <- merged_data[, valid_indices]
# Remove the specified columns
filtered_relevance_lisbon_census <- lisbon_census[, valid_indices]
head(filtered_relevance_lisbon_census)
filtered_relevance_lisbon_census <- filtered_relevance_lisbon_census[, !("ORD") %in% names(filtered_relevance_lisbon_census)]
head(filtered_relevance_lisbon_census)
valid_indices <- which(relevance_lisbon_census$variance > 0)
# Remove the specified columns
filtered_relevance_lisbon_census <- lisbon_census[, valid_indices]
filtered_relevance_lisbon_census <- filtered_relevance_lisbon_census[, !("ORD") %in% names(filtered_relevance_lisbon_census)]
head(filtered_relevance_lisbon_census)
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
head(data)
lisbon_census <- subset(data, data$NUTS2.DSG == "Área Metropolitana de Lisboa")
head(lisbon_census)
lisbon_census <- as.data.frame(lapply(lisbon_census, as.integer))
variance_lisbon_census <- apply(lisbon_census, 2, function(x) var(x, na.rm = TRUE))
relevance_lisbon_census <- data.frame(variance = variance_lisbon_census)
valid_indices <- which(relevance_lisbon_census$variance > 0)
# Remove the specified columns
filtered_relevance_lisbon_census <- lisbon_census[, valid_indices]
filtered_relevance_lisbon_census <- filtered_relevance_lisbon_census[, !("ORD") %in% names(filtered_relevance_lisbon_census)]
head(filtered_relevance_lisbon_census)
# Set the working directory to the 'src' directory
#setwd("D:/Cadeiras/MDLE/mdle/project1/src")
setwd("C:/Users/pedro/Desktop/mestradoLab/mdle/project1/src")
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/INE/FS-2021-Secção-Tot.csv", sep = ",")
head(data)
lisbon_census <- subset(data, data$NUTS2.DSG == "Área Metropolitana de Lisboa")
head(lisbon_census)
lisbon_census <- as.data.frame(lapply(lisbon_census, as.integer))
variance_lisbon_census <- apply(lisbon_census, 2, function(x) var(x, na.rm = TRUE))
relevance_lisbon_census <- data.frame(features = colnames(lisbon_census), variance = variance_lisbon_census)
valid_indices <- which(relevance_lisbon_census$variance > 0 & relevance_lisbon_census != "ORD")
# Remove the specified columns
filtered_relevance_lisbon_census <- lisbon_census[, valid_indices]
valid_indices
valid_indices <- which(relevance_lisbon_census$variance > 0 & relevance_lisbon_census$features != "ORD")
# Remove the specified columns
filtered_relevance_lisbon_census <- lisbon_census[, valid_indices]
head(filtered_relevance_lisbon_census)
################################################################################
# Write the filtered data to a new CSV file
write.csv(data, file="../mdle_data/INE/Censos_2021_Lisbon_filtered.csv", row.names=FALSE)
################################################################################
# Write the filtered data to a new CSV file
write.csv(filtered_relevance_lisbon_census, file="../mdle_data/INE/Censos_2021_Lisbon_filtered.csv", row.names=FALSE)
# Set the working directory to the 'src' directory
#setwd("D:/Cadeiras/MDLE/mdle/project1/src")
setwd("C:/Users/pedro/Desktop/mestradoLab/mdle/project1/src")
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/consumos_horario_codigo_postal.csv", sep = ";")
# Set the working directory to the 'src' directory
#setwd("D:/Cadeiras/MDLE/mdle/project1/src")
setwd("C:/Users/pedro/Desktop/mestradoLab/mdle/project1/src")
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/consumos_horario_codigo_postal.csv", sep = ";")
# Read the CSV file using a relative path
data <- read.csv("../consumos_horario_codigo_postal.csv", sep = ";")
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/consumos_horario_codigo_postal.csv", sep = ";")
# Set the working directory to the 'src' directory
#setwd("D:/Cadeiras/MDLE/mdle/project1/src")
setwd("C:/Users/pedro/Desktop/mestradoLab/mdle/project1/src")
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/consumos_horario_codigo_postal.csv", sep = ";")
# Read the CSV file using a relative path
data <- read.csv("../mdle_data/consumos_horario_codigo_postal.csv", sep = ";")
# Remove the 'Date' and 'Hour' columns
data <- subset(data, select = -c(Date, Hour))
# Filter the 'Zip Code' column to contain only numbers between 1000 and 1990
data <- subset(data, Zip.Code >= 1105 & Zip.Code <= 1512)
# Write the filtered data to a new CSV file
write.csv(data, file = "../mdle_data/consumos_horario_codigo_postal_lisboa.csv", row.names = FALSE)
# Set the working directory to the 'src' directory
#setwd("D:/Cadeiras/MDLE/mdle/project1/src")
setwd("C:/Users/pedro/Desktop/mestradoLab/mdle/project1/src")
# List of filenames
filenames <- c(
"Lisbon_2023-01-01_2023-01-31.csv",
"Lisbon_2022-12-01_2022-12-31.csv",
"Lisbon_2023-02-01_2023-02-28.csv",
"Lisbon_2023-03-01_2023-03-31.csv",
"Lisbon_2023-04-01_2023-04-30.csv",
"Lisbon_2023-05-01_2023-05-31.csv",
"Lisbon_2023-06-01_2023-06-30.csv",
"Lisbon_2023-07-01_2023-07-31.csv",
"Lisbon_2023-08-01_2023-08-31.csv",
"Lisbon_2023-09-01_2023-09-30.csv",
"Lisbon_2023-10-01_2023-10-31.csv",
"Lisbon_2023-11-01_2023-11-30.csv",
"Lisbon_2023-12-01_2023-12-31.csv"
)
# Initialize an empty data frame to store merged data
merged_data <- data.frame()
# Loop through each file, read it, and append to merged_data
for (filename in filenames) {
file_path <- paste("../mdle_data/Weather/", filename, sep="")
data <- read.csv(file_path, header=TRUE)
merged_data <- rbind(merged_data, data)
}
# Write merged data to a new CSV file
write.csv(merged_data, file="../mdle_data/Weather/Lisbon_2022-12-01_2023-12-31_full.csv", row.names = FALSE)
################################################################################
# Read the merged data file
merged_data <- read.csv("../mdle_data/Weather/Lisbon_2022-12-01_2023-12-31_full.csv")
#
variance_lisbon <- apply(merged_data, 2, function(x) var(x, na.rm = TRUE))
# Combine relevance measures for each dataset
relevance_lisbon <- data.frame(features = colnames(merged_data), variance = variance_lisbon)
print("Lisbon Dataset:")
print(relevance_lisbon)
################################################################################
# Remove columns with 0 variance
valid_indices <- which(relevance_lisbon$variance > 0 | relevance_lisbon$features == "datetime")
# Remove the specified columns
filtered_merged_data <- merged_data[, valid_indices]
print("Lisbon Dataset (filtered):")
print(filtered_merged_data)
# Write the filtered data to a new CSV file
write.csv(filtered_merged_data, file="../mdle_data/Weather/Lisbon_2022-12-01_2023-12-31_filtered.csv", row.names=FALSE)
