24/04/13 12:32:09.292 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 12:32:09.495 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/13 12:32:09.517 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/13 12:32:09.582 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/13 12:32:09.671 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 12:32:09.671 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/13 12:32:09.671 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 12:32:09.672 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/13 12:32:09.698 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/13 12:32:09.709 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/13 12:32:09.710 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/13 12:32:09.765 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/13 12:32:09.766 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/13 12:32:09.766 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/13 12:32:09.766 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/13 12:32:09.767 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/13 12:32:09.853 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 51051.
24/04/13 12:32:09.885 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/13 12:32:09.922 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/13 12:32:09.948 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/13 12:32:09.949 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/13 12:32:09.952 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/13 12:32:09.979 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-d4d5d751-7814-4231-937a-ea20ad54e209
24/04/13 12:32:10.007 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/13 12:32:10.031 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/13 12:32:10.035 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/13 12:32:10.259 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/13 12:32:10.375 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/13 12:32:10.421 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:51051/jars/sparklyr-3.0-2.12.jar with timestamp 1713007929487
24/04/13 12:32:10.497 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/13 12:32:10.504 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/13 12:32:10.516 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:51051/jars/sparklyr-3.0-2.12.jar with timestamp 1713007929487
24/04/13 12:32:10.556 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:51051 after 19 ms (0 ms spent in bootstraps)
24/04/13 12:32:10.564 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:51051/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-101650f1-582e-4fdd-bf19-08341d5f8c0a\userFiles-ab342ec5-0b95-4a76-8390-7e95f99812d1\fetchFileTemp5692991556329080863.tmp
24/04/13 12:32:11.039 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-101650f1-582e-4fdd-bf19-08341d5f8c0a/userFiles-ab342ec5-0b95-4a76-8390-7e95f99812d1/sparklyr-3.0-2.12.jar to class loader
24/04/13 12:32:11.051 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51071.
24/04/13 12:32:11.051 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:51071
24/04/13 12:32:11.053 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/13 12:32:11.064 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 51071, None)
24/04/13 12:32:11.069 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:51071 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 51071, None)
24/04/13 12:32:11.077 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 51071, None)
24/04/13 12:32:11.079 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 51071, None)
24/04/13 12:32:11.382 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/13 12:32:11.390 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/13 12:32:15.041 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/13 12:32:15.170 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 12:32:15.512 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/13 12:32:15.684 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/13 12:32:15.684 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/13 12:32:15.685 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/13 12:32:15.728 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/13 12:32:15.874 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/13 12:32:15.875 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/13 12:32:16.890 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/13 12:32:18.225 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/13 12:32:18.228 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/13 12:32:18.295 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/13 12:32:18.295 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/13 12:32:18.323 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/13 12:32:18.448 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/13 12:32:18.449 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/13 12:32:18.494 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/13 12:32:18.605 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:32:18.607 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:32:18.625 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/13 12:32:18.625 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/13 12:32:18.626 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/13 12:32:18.626 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:32:18.626 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:32:18.628 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:32:18.628 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:32:18.630 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 12:32:18.630 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 12:37:36.480 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/13 12:37:36.480 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/13 12:37:36.497 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/13 12:37:36.523 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/13 12:37:36.536 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/13 12:37:36.536 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/13 12:37:36.545 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/13 12:37:36.548 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/13 12:37:36.554 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/13 12:37:36.554 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/13 12:37:36.554 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-38e02ea2-3a9c-4564-89db-a159bdf738d6
24/04/13 12:37:36.556 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-101650f1-582e-4fdd-bf19-08341d5f8c0a
24/04/13 12:37:48.538 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 12:37:48.725 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/13 12:37:48.744 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/13 12:37:48.792 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/13 12:37:48.876 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 12:37:48.876 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/13 12:37:48.877 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 12:37:48.877 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/13 12:37:48.903 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/13 12:37:48.914 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/13 12:37:48.915 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/13 12:37:48.963 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/13 12:37:48.963 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/13 12:37:48.964 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/13 12:37:48.964 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/13 12:37:48.964 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/13 12:37:49.050 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 51172.
24/04/13 12:37:49.081 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/13 12:37:49.115 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/13 12:37:49.138 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/13 12:37:49.138 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/13 12:37:49.143 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/13 12:37:49.175 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-357d3199-7dc5-4b88-9dc8-93543692c4ef
24/04/13 12:37:49.204 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/13 12:37:49.232 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/13 12:37:49.238 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/13 12:37:49.485 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/13 12:37:49.624 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/13 12:37:49.702 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:51172/jars/sparklyr-3.0-2.12.jar with timestamp 1713008268714
24/04/13 12:37:49.865 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/13 12:37:49.875 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/13 12:37:49.894 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:51172/jars/sparklyr-3.0-2.12.jar with timestamp 1713008268714
24/04/13 12:37:49.969 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:51172 after 33 ms (0 ms spent in bootstraps)
24/04/13 12:37:49.979 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:51172/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e2e3c7da-2871-4979-9b1b-383a58572873\userFiles-c6cd7b0d-dac8-483f-85fc-ee58ec78897d\fetchFileTemp6945004696946724388.tmp
24/04/13 12:37:50.245 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-e2e3c7da-2871-4979-9b1b-383a58572873/userFiles-c6cd7b0d-dac8-483f-85fc-ee58ec78897d/sparklyr-3.0-2.12.jar to class loader
24/04/13 12:37:50.264 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51192.
24/04/13 12:37:50.264 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:51192
24/04/13 12:37:50.267 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/13 12:37:50.279 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 51192, None)
24/04/13 12:37:50.284 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:51192 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 51192, None)
24/04/13 12:37:50.288 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 51192, None)
24/04/13 12:37:50.290 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 51192, None)
24/04/13 12:37:50.613 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/13 12:37:50.623 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/13 12:37:53.811 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/13 12:37:53.965 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 12:37:54.153 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/13 12:37:54.358 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/13 12:37:54.359 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/13 12:37:54.359 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/13 12:37:54.398 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/13 12:37:54.521 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/13 12:37:54.522 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/13 12:37:55.484 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/13 12:37:57.038 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/13 12:37:57.040 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/13 12:37:57.106 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/13 12:37:57.106 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/13 12:37:57.134 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/13 12:37:57.253 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/13 12:37:57.254 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/13 12:37:57.291 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/13 12:37:57.373 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:37:57.376 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:37:57.398 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/13 12:37:57.398 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/13 12:37:57.399 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/13 12:37:57.401 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:37:57.401 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:37:57.404 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:37:57.404 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:37:57.407 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 12:37:57.407 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 12:42:06.191 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/13 12:42:06.194 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/13 12:42:06.217 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/13 12:42:06.243 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/13 12:42:06.263 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/13 12:42:06.263 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/13 12:42:06.276 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/13 12:42:06.280 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/13 12:42:06.285 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/13 12:42:06.286 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/13 12:42:06.287 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-a521caff-e2ca-4e92-980e-bfd38d9c0925
24/04/13 12:42:06.288 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e2e3c7da-2871-4979-9b1b-383a58572873
24/04/13 12:42:18.253 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 12:42:18.482 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/13 12:42:18.508 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/13 12:42:18.574 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/13 12:42:18.658 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 12:42:18.659 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/13 12:42:18.659 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 12:42:18.660 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/13 12:42:18.692 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/13 12:42:18.705 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/13 12:42:18.706 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/13 12:42:18.775 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/13 12:42:18.776 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/13 12:42:18.776 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/13 12:42:18.776 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/13 12:42:18.777 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/13 12:42:18.898 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 51419.
24/04/13 12:42:18.931 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/13 12:42:18.979 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/13 12:42:19.014 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/13 12:42:19.015 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/13 12:42:19.019 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/13 12:42:19.054 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-dbcb9f7a-b8a0-44f2-811b-08001b4bb1e0
24/04/13 12:42:19.075 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/13 12:42:19.096 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/13 12:42:19.100 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/13 12:42:19.273 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/13 12:42:19.363 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/13 12:42:19.415 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:51419/jars/sparklyr-3.0-2.12.jar with timestamp 1713008538475
24/04/13 12:42:19.500 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/13 12:42:19.508 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/13 12:42:19.522 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:51419/jars/sparklyr-3.0-2.12.jar with timestamp 1713008538475
24/04/13 12:42:19.575 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:51419 after 24 ms (0 ms spent in bootstraps)
24/04/13 12:42:19.580 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:51419/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-301e41de-1f6a-4634-811c-dfa73a0ce538\userFiles-079ff47f-098b-4f26-80e5-a0c4b4bd0a42\fetchFileTemp4237697913008202037.tmp
24/04/13 12:42:19.749 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-301e41de-1f6a-4634-811c-dfa73a0ce538/userFiles-079ff47f-098b-4f26-80e5-a0c4b4bd0a42/sparklyr-3.0-2.12.jar to class loader
24/04/13 12:42:19.770 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51439.
24/04/13 12:42:19.771 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:51439
24/04/13 12:42:19.773 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/13 12:42:19.781 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 51439, None)
24/04/13 12:42:19.784 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:51439 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 51439, None)
24/04/13 12:42:19.787 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 51439, None)
24/04/13 12:42:19.788 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 51439, None)
24/04/13 12:42:20.052 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/13 12:42:20.059 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/13 12:42:23.005 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/13 12:42:23.149 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 12:42:23.402 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/13 12:42:23.533 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/13 12:42:23.534 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/13 12:42:23.534 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/13 12:42:23.573 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/13 12:42:23.694 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/13 12:42:23.694 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/13 12:42:24.684 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/13 12:42:26.064 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/13 12:42:26.066 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/13 12:42:26.119 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/13 12:42:26.120 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/13 12:42:26.142 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/13 12:42:26.261 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/13 12:42:26.263 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/13 12:42:26.300 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/13 12:42:26.379 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:42:26.381 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:42:26.400 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/13 12:42:26.400 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/13 12:42:26.401 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/13 12:42:26.402 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:42:26.402 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:42:26.403 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:42:26.403 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:42:26.405 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 12:42:26.405 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 12:43:33.626 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/13 12:43:33.627 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/13 12:43:33.649 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/13 12:43:33.678 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/13 12:43:33.688 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/13 12:43:33.689 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/13 12:43:33.730 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/13 12:43:33.734 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/13 12:43:33.744 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/13 12:43:33.745 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/13 12:43:33.745 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-301e41de-1f6a-4634-811c-dfa73a0ce538
24/04/13 12:43:33.747 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-9a7c49fe-e1b1-40e0-97d9-1b11a50d4515
24/04/13 12:43:45.917 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 12:43:46.102 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/13 12:43:46.121 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/13 12:43:46.172 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/13 12:43:46.246 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 12:43:46.246 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/13 12:43:46.246 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 12:43:46.247 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/13 12:43:46.273 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/13 12:43:46.286 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/13 12:43:46.287 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/13 12:43:46.339 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/13 12:43:46.339 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/13 12:43:46.339 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/13 12:43:46.340 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/13 12:43:46.340 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/13 12:43:46.432 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 51522.
24/04/13 12:43:46.458 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/13 12:43:46.494 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/13 12:43:46.521 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/13 12:43:46.521 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/13 12:43:46.524 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/13 12:43:46.548 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-ac81dfb4-df4d-4a2d-9489-72e6bbfff7dc
24/04/13 12:43:46.565 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/13 12:43:46.579 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/13 12:43:46.582 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/13 12:43:46.726 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/13 12:43:46.801 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/13 12:43:46.847 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:51522/jars/sparklyr-3.0-2.12.jar with timestamp 1713008626097
24/04/13 12:43:46.923 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/13 12:43:46.929 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/13 12:43:46.940 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:51522/jars/sparklyr-3.0-2.12.jar with timestamp 1713008626097
24/04/13 12:43:46.980 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:51522 after 18 ms (0 ms spent in bootstraps)
24/04/13 12:43:46.984 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:51522/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-56aa03a2-fb01-4ac1-b7a0-c323613dc273\userFiles-25cf282e-6753-4e89-a32f-cae39f790783\fetchFileTemp1328904515856139121.tmp
24/04/13 12:43:47.151 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-56aa03a2-fb01-4ac1-b7a0-c323613dc273/userFiles-25cf282e-6753-4e89-a32f-cae39f790783/sparklyr-3.0-2.12.jar to class loader
24/04/13 12:43:47.164 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51544.
24/04/13 12:43:47.164 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:51544
24/04/13 12:43:47.166 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/13 12:43:47.174 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 51544, None)
24/04/13 12:43:47.177 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:51544 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 51544, None)
24/04/13 12:43:47.180 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 51544, None)
24/04/13 12:43:47.181 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 51544, None)
24/04/13 12:43:47.505 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/13 12:43:47.515 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/13 12:43:50.723 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/13 12:43:50.847 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 12:43:51.044 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/13 12:43:51.282 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/13 12:43:51.283 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/13 12:43:51.284 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/13 12:43:51.336 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/13 12:43:51.482 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/13 12:43:51.483 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/13 12:43:52.512 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/13 12:43:54.045 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/13 12:43:54.048 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/13 12:43:54.137 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/13 12:43:54.138 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/13 12:43:54.168 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/13 12:43:54.333 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/13 12:43:54.336 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/13 12:43:54.390 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/13 12:43:54.493 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:43:54.496 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:43:54.515 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/13 12:43:54.515 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/13 12:43:54.516 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/13 12:43:54.517 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:43:54.517 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:43:54.519 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:43:54.520 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:43:54.523 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 12:43:54.523 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 12:43:55.749 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/13 12:43:55.750 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/13 12:43:55.771 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/13 12:43:55.798 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/13 12:43:55.810 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/13 12:43:55.810 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/13 12:43:55.825 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/13 12:43:55.829 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/13 12:43:55.838 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/13 12:43:55.839 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/13 12:43:55.839 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-56aa03a2-fb01-4ac1-b7a0-c323613dc273
24/04/13 12:43:55.841 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-a04a070e-d1e6-47b1-8a95-69505d659bda
24/04/13 12:44:08.078 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 12:44:08.266 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/13 12:44:08.284 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/13 12:44:08.338 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/13 12:44:08.440 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 12:44:08.441 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/13 12:44:08.441 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 12:44:08.442 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/13 12:44:08.471 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/13 12:44:08.483 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/13 12:44:08.483 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/13 12:44:08.535 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/13 12:44:08.535 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/13 12:44:08.536 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/13 12:44:08.536 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/13 12:44:08.536 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/13 12:44:08.636 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 51598.
24/04/13 12:44:08.664 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/13 12:44:08.700 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/13 12:44:08.723 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/13 12:44:08.723 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/13 12:44:08.726 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/13 12:44:08.750 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-7ca1aa6a-1c7d-4f43-89c1-e3a8cfe0dc52
24/04/13 12:44:08.767 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/13 12:44:08.781 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/13 12:44:08.784 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/13 12:44:08.941 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/13 12:44:09.041 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/13 12:44:09.095 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:51598/jars/sparklyr-3.0-2.12.jar with timestamp 1713008648260
24/04/13 12:44:09.188 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/13 12:44:09.197 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/13 12:44:09.211 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:51598/jars/sparklyr-3.0-2.12.jar with timestamp 1713008648260
24/04/13 12:44:09.269 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:51598 after 27 ms (0 ms spent in bootstraps)
24/04/13 12:44:09.275 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:51598/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-36e10d67-cbe0-4a98-a7fe-dfc6296f2653\userFiles-24e5bf15-daff-402c-9931-355a3aad76ae\fetchFileTemp2189255524959162469.tmp
24/04/13 12:44:09.432 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-36e10d67-cbe0-4a98-a7fe-dfc6296f2653/userFiles-24e5bf15-daff-402c-9931-355a3aad76ae/sparklyr-3.0-2.12.jar to class loader
24/04/13 12:44:09.444 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51619.
24/04/13 12:44:09.445 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:51619
24/04/13 12:44:09.446 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/13 12:44:09.463 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 51619, None)
24/04/13 12:44:09.467 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:51619 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 51619, None)
24/04/13 12:44:09.469 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 51619, None)
24/04/13 12:44:09.470 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 51619, None)
24/04/13 12:44:09.725 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/13 12:44:09.733 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/13 12:44:14.341 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/13 12:44:14.484 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 12:44:14.759 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/13 12:44:14.891 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/13 12:44:14.892 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/13 12:44:14.892 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/13 12:44:14.931 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/13 12:44:15.052 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/13 12:44:15.054 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/13 12:44:15.945 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/13 12:44:17.228 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/13 12:44:17.229 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/13 12:44:17.285 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/13 12:44:17.286 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/13 12:44:17.308 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/13 12:44:17.458 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/13 12:44:17.460 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/13 12:44:17.504 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/13 12:44:17.606 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:44:17.609 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:44:17.628 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/13 12:44:17.628 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/13 12:44:17.629 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/13 12:44:17.630 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:44:17.630 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:44:17.632 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:44:17.632 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:44:17.635 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 12:44:17.635 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 12:44:18.521 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 224.2571 ms
24/04/13 12:44:18.683 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 12:44:18.691 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,006993 s
24/04/13 12:44:23.212 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/13 12:44:25.222 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.873 ms
24/04/13 12:44:25.273 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 12:44:25.291 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/13 12:44:25.292 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/13 12:44:25.292 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 12:44:25.293 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 12:44:25.297 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/13 12:44:25.379 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 12:44:25.440 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 12:44:25.443 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:51619 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 12:44:25.448 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/13 12:44:25.465 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 12:44:25.467 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/13 12:44:25.528 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 12:44:25.542 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/13 12:44:26.210 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 241.7076 ms
24/04/13 12:44:26.245 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1559 bytes result sent to driver
24/04/13 12:44:26.258 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 743 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 12:44:26.262 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/13 12:44:26.271 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,954 s
24/04/13 12:44:26.276 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 12:44:26.276 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/13 12:44:26.277 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 1,003541 s
24/04/13 12:44:26.615 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 209.1345 ms
24/04/13 12:44:30.618 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 12:44:30.619 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/13 12:44:30.619 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/13 12:44:30.619 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 12:44:30.619 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 12:44:30.621 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/13 12:44:30.627 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 12:44:30.629 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 12:44:30.630 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:51619 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 12:44:30.630 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/13 12:44:30.631 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 12:44:30.631 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/13 12:44:30.632 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 12:44:30.633 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/13 12:44:30.689 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/13 12:44:30.691 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 59 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 12:44:30.692 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/13 12:44:30.692 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,070 s
24/04/13 12:44:30.692 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 12:44:30.692 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/13 12:44:30.693 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,074967 s
24/04/13 12:44:30.941 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:51619 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 12:44:30.953 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:51619 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 12:44:33.351 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:44:33.352 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:44:33.365 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 12:44:33.365 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 12:44:33.367 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 12:44:33.367 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 12:44:33.450 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 41.7413 ms
24/04/13 12:44:33.485 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.4307 ms
24/04/13 12:44:33.501 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.436 ms
24/04/13 14:12:41.076 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from DESKTOP-LH06ASP:51598 in 10000 milliseconds. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at scala.util.Failure.recover(Try.scala:234)
	at scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from DESKTOP-LH06ASP:51598 in 10000 milliseconds
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)
	... 7 more
24/04/13 14:12:51.090 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from DESKTOP-LH06ASP:51598 in 10000 milliseconds. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at scala.util.Failure.recover(Try.scala:234)
	at scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from DESKTOP-LH06ASP:51598 in 10000 milliseconds
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)
	... 7 more
24/04/13 14:13:01.096 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
24/04/13 14:13:11.099 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from DESKTOP-LH06ASP:51598 in 10000 milliseconds. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at scala.util.Failure.recover(Try.scala:234)
	at scala.concurrent.Future.$anonfun$recover$1(Future.scala:395)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:264)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from DESKTOP-LH06ASP:51598 in 10000 milliseconds
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:265)
	... 7 more
24/04/13 14:13:19.856 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
24/04/13 14:13:19.861 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
24/04/13 14:13:19.862 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
24/04/13 14:13:19.863 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
24/04/13 14:14:52.421 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:14:52.424 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:14:52.424 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/13 14:14:52.425 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:14:52.429 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:14:52.430 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26), which has no missing parents
24/04/13 14:14:52.458 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 107.3 KiB, free 912.2 MiB)
24/04/13 14:14:52.468 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 912.2 MiB)
24/04/13 14:14:52.469 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:51619 (size: 27.1 KiB, free: 912.3 MiB)
24/04/13 14:14:52.469 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/13 14:14:52.470 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:14:52.470 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/13 14:14:52.503 dispatcher-event-loop-0 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/13 14:14:52.504 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/13 14:14:52.506 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/13 14:14:52.788 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 168.3469 ms
24/04/13 14:14:53.233 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 686.4 KiB, free 911.5 MiB)
24/04/13 14:14:53.234 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on DESKTOP-LH06ASP:51619 (size: 686.4 KiB, free: 911.6 MiB)
24/04/13 14:14:53.245 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 3.5557 ms
24/04/13 14:14:53.885 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 626.1107 ms
24/04/13 14:14:53.922 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_13_0]
24/04/13 14:14:53.930 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2528 bytes result sent to driver
24/04/13 14:14:53.931 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1459 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:14:53.932 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/13 14:14:53.932 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 1,500 s
24/04/13 14:14:53.933 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:14:53.933 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/13 14:14:53.933 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 1,510912 s
24/04/13 14:14:54.227 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 181.8932 ms
24/04/13 14:15:09.598 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/13 14:15:09.599 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/13 14:15:09.625 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/13 14:15:09.657 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/13 14:15:09.698 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/13 14:15:09.698 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/13 14:15:09.702 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/13 14:15:09.707 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/13 14:15:09.713 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-36e10d67-cbe0-4a98-a7fe-dfc6296f2653\userFiles-24e5bf15-daff-402c-9931-355a3aad76ae
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-36e10d67-cbe0-4a98-a7fe-dfc6296f2653\userFiles-24e5bf15-daff-402c-9931-355a3aad76ae\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:15:09.715 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/13 14:15:09.715 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/13 14:15:09.716 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-8aa966d2-9fcc-48ba-b4b1-2864df897098
24/04/13 14:15:09.718 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-36e10d67-cbe0-4a98-a7fe-dfc6296f2653\userFiles-24e5bf15-daff-402c-9931-355a3aad76ae
24/04/13 14:15:09.721 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-36e10d67-cbe0-4a98-a7fe-dfc6296f2653\userFiles-24e5bf15-daff-402c-9931-355a3aad76ae
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-36e10d67-cbe0-4a98-a7fe-dfc6296f2653\userFiles-24e5bf15-daff-402c-9931-355a3aad76ae\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:15:09.721 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-36e10d67-cbe0-4a98-a7fe-dfc6296f2653
24/04/13 14:15:09.726 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-36e10d67-cbe0-4a98-a7fe-dfc6296f2653
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-36e10d67-cbe0-4a98-a7fe-dfc6296f2653\userFiles-24e5bf15-daff-402c-9931-355a3aad76ae\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:15:22.029 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 14:15:22.304 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/13 14:15:22.342 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/13 14:15:22.440 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/13 14:15:22.559 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 14:15:22.560 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/13 14:15:22.560 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 14:15:22.561 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/13 14:15:22.591 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/13 14:15:22.603 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/13 14:15:22.604 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/13 14:15:22.666 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/13 14:15:22.666 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/13 14:15:22.666 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/13 14:15:22.667 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/13 14:15:22.668 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/13 14:15:22.785 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 57601.
24/04/13 14:15:22.832 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/13 14:15:22.886 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/13 14:15:22.926 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/13 14:15:22.927 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/13 14:15:22.931 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/13 14:15:22.963 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-33b4db5a-1040-420f-8747-37e8da2e9d1c
24/04/13 14:15:22.990 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/13 14:15:23.013 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/13 14:15:23.016 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/13 14:15:23.297 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/13 14:15:23.393 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/13 14:15:23.450 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:57601/jars/sparklyr-3.0-2.12.jar with timestamp 1713014122293
24/04/13 14:15:23.563 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/13 14:15:23.570 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/13 14:15:23.582 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:57601/jars/sparklyr-3.0-2.12.jar with timestamp 1713014122293
24/04/13 14:15:23.635 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:57601 after 24 ms (0 ms spent in bootstraps)
24/04/13 14:15:23.640 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:57601/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1c94725b-6e57-4d57-9372-2bdcd0a1a667\userFiles-e212d81b-efaa-4a4c-a11e-c5843b8297bf\fetchFileTemp2283290484549399743.tmp
24/04/13 14:15:23.816 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-1c94725b-6e57-4d57-9372-2bdcd0a1a667/userFiles-e212d81b-efaa-4a4c-a11e-c5843b8297bf/sparklyr-3.0-2.12.jar to class loader
24/04/13 14:15:23.833 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57621.
24/04/13 14:15:23.833 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:57621
24/04/13 14:15:23.835 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/13 14:15:23.844 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 57621, None)
24/04/13 14:15:23.849 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:57621 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 57621, None)
24/04/13 14:15:23.854 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 57621, None)
24/04/13 14:15:23.857 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 57621, None)
24/04/13 14:15:24.539 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/13 14:15:24.555 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/13 14:15:32.490 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/13 14:15:32.645 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 14:15:32.938 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/13 14:15:33.276 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/13 14:15:33.277 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/13 14:15:33.277 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/13 14:15:33.333 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/13 14:15:33.493 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/13 14:15:33.494 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/13 14:15:34.955 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/13 14:15:37.313 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/13 14:15:37.318 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/13 14:15:37.406 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/13 14:15:37.406 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/13 14:15:37.455 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/13 14:15:37.784 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/13 14:15:37.787 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/13 14:15:37.870 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/13 14:15:38.078 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:15:38.082 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:15:38.119 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/13 14:15:38.120 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/13 14:15:38.121 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/13 14:15:38.123 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:15:38.123 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:15:38.126 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:15:38.126 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:15:38.131 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 14:15:38.133 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 14:15:39.189 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 222.3137 ms
24/04/13 14:15:39.330 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:15:39.336 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,005068 s
24/04/13 14:15:47.170 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/13 14:15:49.703 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 18.6367 ms
24/04/13 14:15:49.815 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:15:49.847 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:15:49.848 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/13 14:15:49.848 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:15:49.850 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:15:49.856 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/13 14:15:50.082 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 14:15:50.219 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 14:15:50.227 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:57621 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:15:50.240 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/13 14:15:50.277 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:15:50.281 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/13 14:15:50.381 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 14:15:50.405 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/13 14:15:51.619 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 611.1015 ms
24/04/13 14:15:51.716 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1516 bytes result sent to driver
24/04/13 14:15:51.736 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1375 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:15:51.744 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/13 14:15:51.765 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 1,869 s
24/04/13 14:15:51.773 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:15:51.778 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/13 14:15:51.781 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 1,963921 s
24/04/13 14:15:52.862 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:57621 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:15:52.980 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 990.9383 ms
24/04/13 14:16:01.163 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:16:01.167 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:16:01.168 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/13 14:16:01.169 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:16:01.169 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:16:01.175 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/13 14:16:01.183 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 14:16:01.191 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 14:16:01.192 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:57621 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:16:01.193 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/13 14:16:01.194 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:16:01.194 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/13 14:16:01.197 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 14:16:01.199 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/13 14:16:01.435 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1473 bytes result sent to driver
24/04/13 14:16:01.443 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 245 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:16:01.447 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/13 14:16:01.448 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,271 s
24/04/13 14:16:01.449 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:16:01.449 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/13 14:16:01.450 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,286069 s
24/04/13 14:16:05.474 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:16:05.474 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:16:05.492 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:16:05.492 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:16:05.494 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 14:16:05.494 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 14:16:05.662 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 84.5195 ms
24/04/13 14:16:05.730 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.1939 ms
24/04/13 14:16:05.761 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.5047 ms
24/04/13 14:20:27.837 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/13 14:20:27.839 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/13 14:20:28.041 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/13 14:20:28.070 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/13 14:20:28.090 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/13 14:20:28.091 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/13 14:20:28.096 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/13 14:20:28.101 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/13 14:20:28.107 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1c94725b-6e57-4d57-9372-2bdcd0a1a667\userFiles-e212d81b-efaa-4a4c-a11e-c5843b8297bf
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1c94725b-6e57-4d57-9372-2bdcd0a1a667\userFiles-e212d81b-efaa-4a4c-a11e-c5843b8297bf\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:20:28.112 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/13 14:20:28.113 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/13 14:20:28.114 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1c94725b-6e57-4d57-9372-2bdcd0a1a667\userFiles-e212d81b-efaa-4a4c-a11e-c5843b8297bf
24/04/13 14:20:28.118 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1c94725b-6e57-4d57-9372-2bdcd0a1a667\userFiles-e212d81b-efaa-4a4c-a11e-c5843b8297bf
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1c94725b-6e57-4d57-9372-2bdcd0a1a667\userFiles-e212d81b-efaa-4a4c-a11e-c5843b8297bf\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:20:28.118 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-4b3085ef-925b-41df-b035-3288bf1da35f
24/04/13 14:20:28.120 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1c94725b-6e57-4d57-9372-2bdcd0a1a667
24/04/13 14:20:28.123 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1c94725b-6e57-4d57-9372-2bdcd0a1a667
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1c94725b-6e57-4d57-9372-2bdcd0a1a667\userFiles-e212d81b-efaa-4a4c-a11e-c5843b8297bf\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:20:40.358 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 14:20:40.586 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/13 14:20:40.613 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/13 14:20:40.683 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/13 14:20:40.769 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 14:20:40.770 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/13 14:20:40.770 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 14:20:40.771 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/13 14:20:40.809 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/13 14:20:40.823 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/13 14:20:40.824 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/13 14:20:40.902 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/13 14:20:40.903 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/13 14:20:40.903 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/13 14:20:40.904 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/13 14:20:40.905 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/13 14:20:41.035 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 58257.
24/04/13 14:20:41.068 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/13 14:20:41.113 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/13 14:20:41.150 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/13 14:20:41.150 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/13 14:20:41.155 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/13 14:20:41.187 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-e3c4c18e-befb-46aa-bf77-a440ac20fd50
24/04/13 14:20:41.211 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/13 14:20:41.229 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/13 14:20:41.232 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/13 14:20:41.429 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/13 14:20:41.523 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/13 14:20:41.567 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:58257/jars/sparklyr-3.0-2.12.jar with timestamp 1713014440577
24/04/13 14:20:41.652 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/13 14:20:41.660 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/13 14:20:41.671 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:58257/jars/sparklyr-3.0-2.12.jar with timestamp 1713014440577
24/04/13 14:20:41.711 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:58257 after 19 ms (0 ms spent in bootstraps)
24/04/13 14:20:41.716 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:58257/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-47c64739-2b1e-4318-8c06-584f604e396a\userFiles-19bebceb-a721-4b76-a529-70a10efd1697\fetchFileTemp3567781967067454299.tmp
24/04/13 14:20:41.875 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-47c64739-2b1e-4318-8c06-584f604e396a/userFiles-19bebceb-a721-4b76-a529-70a10efd1697/sparklyr-3.0-2.12.jar to class loader
24/04/13 14:20:41.887 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58277.
24/04/13 14:20:41.887 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:58277
24/04/13 14:20:41.889 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/13 14:20:41.897 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 58277, None)
24/04/13 14:20:41.902 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:58277 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 58277, None)
24/04/13 14:20:41.905 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 58277, None)
24/04/13 14:20:41.906 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 58277, None)
24/04/13 14:20:42.172 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/13 14:20:42.180 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/13 14:20:46.381 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/13 14:20:46.511 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 14:20:46.801 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/13 14:20:47.079 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/13 14:20:47.079 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/13 14:20:47.079 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/13 14:20:47.124 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/13 14:20:47.286 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/13 14:20:47.287 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/13 14:20:48.429 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/13 14:20:49.739 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/13 14:20:49.741 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/13 14:20:49.799 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/13 14:20:49.799 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/13 14:20:49.826 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/13 14:20:49.958 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/13 14:20:49.960 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/13 14:20:49.997 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/13 14:20:50.102 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:20:50.104 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:20:50.122 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/13 14:20:50.122 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/13 14:20:50.123 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/13 14:20:50.124 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:20:50.124 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:20:50.126 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:20:50.126 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:20:50.128 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 14:20:50.128 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 14:20:50.824 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 174.9306 ms
24/04/13 14:20:50.942 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:20:50.949 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,005175 s
24/04/13 14:20:55.379 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/13 14:20:57.040 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.3417 ms
24/04/13 14:20:57.126 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:20:57.149 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:20:57.150 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/13 14:20:57.151 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:20:57.153 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:20:57.158 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/13 14:20:57.266 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 14:20:57.341 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 14:20:57.345 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:58277 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:20:57.349 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/13 14:20:57.369 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:20:57.371 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/13 14:20:57.451 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 14:20:57.468 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/13 14:20:58.420 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 400.6442 ms
24/04/13 14:20:58.479 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1559 bytes result sent to driver
24/04/13 14:20:58.526 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1088 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:20:58.530 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/13 14:20:58.538 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 1,354 s
24/04/13 14:20:58.548 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:20:58.549 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/13 14:20:58.552 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 1,424348 s
24/04/13 14:20:59.101 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 335.1959 ms
24/04/13 14:21:02.901 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:21:02.902 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:21:02.902 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/13 14:21:02.902 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:21:02.902 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:21:02.903 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/13 14:21:02.910 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 14:21:02.912 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 14:21:02.913 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:58277 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:21:02.913 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/13 14:21:02.914 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:21:02.915 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/13 14:21:02.916 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 14:21:02.916 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/13 14:21:02.961 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/13 14:21:02.964 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 49 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:21:02.964 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/13 14:21:02.965 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,060 s
24/04/13 14:21:02.965 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:21:02.965 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/13 14:21:02.966 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,064538 s
24/04/13 14:21:03.069 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:58277 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:21:05.909 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:21:05.910 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:21:05.911 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/13 14:21:05.911 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:21:05.914 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:21:05.915 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26), which has no missing parents
24/04/13 14:21:05.944 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 107.3 KiB, free 912.1 MiB)
24/04/13 14:21:05.947 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 912.1 MiB)
24/04/13 14:21:05.948 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:58277 (size: 27.1 KiB, free: 912.3 MiB)
24/04/13 14:21:05.949 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/13 14:21:05.949 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:21:05.949 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/13 14:21:05.966 dispatcher-event-loop-1 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/13 14:21:05.966 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/13 14:21:05.967 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/13 14:21:06.223 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 157.0672 ms
24/04/13 14:21:06.961 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 686.4 KiB, free 911.4 MiB)
24/04/13 14:21:06.966 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on DESKTOP-LH06ASP:58277 (size: 686.4 KiB, free: 911.6 MiB)
24/04/13 14:21:06.981 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 6.059 ms
24/04/13 14:21:07.191 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 189.5375 ms
24/04/13 14:21:07.231 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_13_0]
24/04/13 14:21:07.233 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2399 bytes result sent to driver
24/04/13 14:21:07.235 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1285 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:21:07.235 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/13 14:21:07.236 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 1,319 s
24/04/13 14:21:07.236 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:21:07.237 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/13 14:21:07.237 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 1,327206 s
24/04/13 14:21:07.353 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on DESKTOP-LH06ASP:58277 in memory (size: 27.1 KiB, free: 911.6 MiB)
24/04/13 14:21:07.639 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 239.0039 ms
24/04/13 14:21:10.012 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:21:10.013 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:21:10.015 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:21:10.015 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:21:10.018 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 14:21:10.019 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 14:21:10.073 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 30.0697 ms
24/04/13 14:21:10.108 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.1103 ms
24/04/13 14:21:10.123 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.7561 ms
24/04/13 14:21:40.861 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/13 14:21:40.862 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/13 14:21:40.881 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/13 14:21:40.903 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/13 14:21:40.938 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/13 14:21:40.938 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/13 14:21:40.941 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/13 14:21:40.944 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/13 14:21:40.948 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-47c64739-2b1e-4318-8c06-584f604e396a\userFiles-19bebceb-a721-4b76-a529-70a10efd1697
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-47c64739-2b1e-4318-8c06-584f604e396a\userFiles-19bebceb-a721-4b76-a529-70a10efd1697\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:21:40.950 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/13 14:21:40.951 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/13 14:21:40.952 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-47c64739-2b1e-4318-8c06-584f604e396a\userFiles-19bebceb-a721-4b76-a529-70a10efd1697
24/04/13 14:21:40.955 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-47c64739-2b1e-4318-8c06-584f604e396a\userFiles-19bebceb-a721-4b76-a529-70a10efd1697
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-47c64739-2b1e-4318-8c06-584f604e396a\userFiles-19bebceb-a721-4b76-a529-70a10efd1697\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:21:40.955 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-9ea739dc-8aeb-4057-a69e-b69af2f2493e
24/04/13 14:21:40.957 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-47c64739-2b1e-4318-8c06-584f604e396a
24/04/13 14:21:40.962 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-47c64739-2b1e-4318-8c06-584f604e396a
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-47c64739-2b1e-4318-8c06-584f604e396a\userFiles-19bebceb-a721-4b76-a529-70a10efd1697\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:21:53.487 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 14:21:53.729 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/13 14:21:53.757 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/13 14:21:53.821 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/13 14:21:53.905 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 14:21:53.906 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/13 14:21:53.906 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 14:21:53.907 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/13 14:21:53.937 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/13 14:21:53.951 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/13 14:21:53.952 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/13 14:21:54.019 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/13 14:21:54.020 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/13 14:21:54.020 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/13 14:21:54.021 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/13 14:21:54.021 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/13 14:21:54.148 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 58431.
24/04/13 14:21:54.179 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/13 14:21:54.225 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/13 14:21:54.259 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/13 14:21:54.260 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/13 14:21:54.265 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/13 14:21:54.296 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-4c394c6f-f79f-47d6-878b-02bdbd39422e
24/04/13 14:21:54.318 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/13 14:21:54.334 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/13 14:21:54.338 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/13 14:21:54.523 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/13 14:21:54.678 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/13 14:21:54.753 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:58431/jars/sparklyr-3.0-2.12.jar with timestamp 1713014513720
24/04/13 14:21:54.827 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/13 14:21:54.834 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/13 14:21:54.845 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:58431/jars/sparklyr-3.0-2.12.jar with timestamp 1713014513720
24/04/13 14:21:54.884 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:58431 after 18 ms (0 ms spent in bootstraps)
24/04/13 14:21:54.888 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:58431/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-2a7278c0-6434-4837-af8f-58d8a3a155cc\userFiles-a0a161f4-7fa4-444d-930c-a87a3ace98c3\fetchFileTemp2068621777965906065.tmp
24/04/13 14:21:55.078 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-2a7278c0-6434-4837-af8f-58d8a3a155cc/userFiles-a0a161f4-7fa4-444d-930c-a87a3ace98c3/sparklyr-3.0-2.12.jar to class loader
24/04/13 14:21:55.148 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58456.
24/04/13 14:21:55.149 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:58456
24/04/13 14:21:55.158 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/13 14:21:55.189 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 58456, None)
24/04/13 14:21:55.200 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:58456 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 58456, None)
24/04/13 14:21:55.214 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 58456, None)
24/04/13 14:21:55.217 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 58456, None)
24/04/13 14:21:55.753 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/13 14:21:55.763 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/13 14:22:01.126 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/13 14:22:01.242 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 14:22:01.502 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/13 14:22:01.645 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/13 14:22:01.645 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/13 14:22:01.646 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/13 14:22:01.684 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/13 14:22:01.806 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/13 14:22:01.807 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/13 14:22:02.700 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/13 14:22:04.077 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/13 14:22:04.079 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/13 14:22:04.134 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/13 14:22:04.134 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/13 14:22:04.157 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/13 14:22:04.277 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/13 14:22:04.279 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/13 14:22:04.317 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/13 14:22:04.422 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:22:04.424 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:22:04.440 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/13 14:22:04.440 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/13 14:22:04.441 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/13 14:22:04.442 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:22:04.442 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:22:04.444 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:22:04.444 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:22:04.446 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 14:22:04.446 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 14:22:05.623 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 345.7755 ms
24/04/13 14:22:05.833 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:22:05.843 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,008602 s
24/04/13 14:22:10.421 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/13 14:22:12.263 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.7554 ms
24/04/13 14:22:12.365 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:22:12.387 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:22:12.388 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/13 14:22:12.388 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:22:12.390 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:22:12.394 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/13 14:22:12.482 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 14:22:12.560 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 14:22:12.564 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:58456 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:22:12.569 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/13 14:22:12.590 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:22:12.591 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/13 14:22:12.653 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 14:22:12.671 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/13 14:22:13.311 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 197.8355 ms
24/04/13 14:22:13.332 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1516 bytes result sent to driver
24/04/13 14:22:13.341 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 699 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:22:13.343 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/13 14:22:13.350 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,936 s
24/04/13 14:22:13.354 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:22:13.354 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/13 14:22:13.355 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,989051 s
24/04/13 14:22:13.520 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:58456 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:22:13.977 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 446.1016 ms
24/04/13 14:22:18.933 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:22:18.934 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:22:18.934 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/13 14:22:18.934 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:22:18.934 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:22:18.935 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/13 14:22:18.941 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 14:22:18.943 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 14:22:18.944 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:58456 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:22:18.944 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/13 14:22:18.945 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:22:18.945 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/13 14:22:18.946 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 14:22:18.947 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/13 14:22:19.014 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1473 bytes result sent to driver
24/04/13 14:22:19.016 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 70 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:22:19.016 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/13 14:22:19.017 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,081 s
24/04/13 14:22:19.018 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:22:19.018 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/13 14:22:19.018 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,085411 s
24/04/13 14:22:19.074 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:58456 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:22:22.177 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:22:22.179 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:22:22.180 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/13 14:22:22.180 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:22:22.183 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:22:22.185 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26), which has no missing parents
24/04/13 14:22:22.209 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 107.3 KiB, free 912.2 MiB)
24/04/13 14:22:22.211 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 912.2 MiB)
24/04/13 14:22:22.212 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:58456 (size: 27.1 KiB, free: 912.3 MiB)
24/04/13 14:22:22.213 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/13 14:22:22.214 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:22:22.214 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/13 14:22:22.235 dispatcher-event-loop-0 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/13 14:22:22.235 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/13 14:22:22.236 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/13 14:22:22.441 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 118.6783 ms
24/04/13 14:22:23.338 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 686.4 KiB, free 911.5 MiB)
24/04/13 14:22:23.370 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on DESKTOP-LH06ASP:58456 (size: 686.4 KiB, free: 911.6 MiB)
24/04/13 14:22:23.386 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 9.2981 ms
24/04/13 14:22:23.699 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 294.801 ms
24/04/13 14:22:23.745 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_13_0]
24/04/13 14:22:23.747 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2442 bytes result sent to driver
24/04/13 14:22:23.751 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1535 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:22:23.751 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/13 14:22:23.753 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 1,567 s
24/04/13 14:22:23.755 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:22:23.756 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/13 14:22:23.757 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 1,578888 s
24/04/13 14:22:24.147 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 260.5934 ms
24/04/13 14:22:27.800 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:22:27.802 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:22:27.802 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
24/04/13 14:22:27.803 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:22:27.806 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:22:27.807 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[21] at collect at utils.scala:26), which has no missing parents
24/04/13 14:22:27.816 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 107.3 KiB, free 911.4 MiB)
24/04/13 14:22:27.819 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 911.4 MiB)
24/04/13 14:22:27.820 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-LH06ASP:58456 (size: 27.1 KiB, free: 911.6 MiB)
24/04/13 14:22:27.821 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
24/04/13 14:22:27.821 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[21] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:22:27.822 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/13 14:22:27.837 dispatcher-event-loop-1 WARN TaskSetManager: Stage 3 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/13 14:22:27.837 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/13 14:22:27.838 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/13 14:22:27.847 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO BlockManager: Found block rdd_13_0 locally
24/04/13 14:22:27.855 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: 1 block locks were not released by task 0.0 in stage 3.0 (TID 3)
[rdd_13_0]
24/04/13 14:22:27.856 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2485 bytes result sent to driver
24/04/13 14:22:27.858 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 32 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:22:27.859 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/13 14:22:27.859 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0,051 s
24/04/13 14:22:27.860 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:22:27.860 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/04/13 14:22:27.861 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0,059686 s
24/04/13 14:22:30.303 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:22:30.304 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:22:30.305 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:22:30.306 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:22:30.307 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 14:22:30.307 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 14:22:30.370 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 32.1211 ms
24/04/13 14:22:30.410 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.4084 ms
24/04/13 14:22:30.422 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.5806 ms
24/04/13 14:29:35.212 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/13 14:29:35.212 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/13 14:29:35.244 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/13 14:29:35.263 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/13 14:29:35.297 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/13 14:29:35.298 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/13 14:29:35.300 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/13 14:29:35.305 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/13 14:29:35.309 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-2a7278c0-6434-4837-af8f-58d8a3a155cc\userFiles-a0a161f4-7fa4-444d-930c-a87a3ace98c3
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-2a7278c0-6434-4837-af8f-58d8a3a155cc\userFiles-a0a161f4-7fa4-444d-930c-a87a3ace98c3\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:29:35.311 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/13 14:29:35.311 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/13 14:29:35.311 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-0149c649-a058-48cd-a0dc-ba20ae1d60c4
24/04/13 14:29:35.313 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-2a7278c0-6434-4837-af8f-58d8a3a155cc
24/04/13 14:29:35.316 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-2a7278c0-6434-4837-af8f-58d8a3a155cc
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-2a7278c0-6434-4837-af8f-58d8a3a155cc\userFiles-a0a161f4-7fa4-444d-930c-a87a3ace98c3\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:29:35.317 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-2a7278c0-6434-4837-af8f-58d8a3a155cc\userFiles-a0a161f4-7fa4-444d-930c-a87a3ace98c3
24/04/13 14:29:35.319 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-2a7278c0-6434-4837-af8f-58d8a3a155cc\userFiles-a0a161f4-7fa4-444d-930c-a87a3ace98c3
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-2a7278c0-6434-4837-af8f-58d8a3a155cc\userFiles-a0a161f4-7fa4-444d-930c-a87a3ace98c3\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:29:47.411 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 14:29:47.628 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/13 14:29:47.655 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/13 14:29:47.716 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/13 14:29:47.801 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 14:29:47.802 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/13 14:29:47.802 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 14:29:47.803 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/13 14:29:47.829 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/13 14:29:47.842 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/13 14:29:47.842 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/13 14:29:47.901 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/13 14:29:47.902 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/13 14:29:47.902 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/13 14:29:47.903 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/13 14:29:47.903 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/13 14:29:48.058 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 59009.
24/04/13 14:29:48.092 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/13 14:29:48.129 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/13 14:29:48.152 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/13 14:29:48.153 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/13 14:29:48.155 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/13 14:29:48.178 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-94bfd556-fda5-4031-bda5-72adcb55a48f
24/04/13 14:29:48.196 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/13 14:29:48.211 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/13 14:29:48.214 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/13 14:29:48.356 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/13 14:29:48.505 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/13 14:29:48.575 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:59009/jars/sparklyr-3.0-2.12.jar with timestamp 1713014987622
24/04/13 14:29:48.682 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/13 14:29:48.689 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/13 14:29:48.703 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:59009/jars/sparklyr-3.0-2.12.jar with timestamp 1713014987622
24/04/13 14:29:48.768 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:59009 after 37 ms (0 ms spent in bootstraps)
24/04/13 14:29:48.778 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:59009/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-38e8c421-52c2-4511-a732-95cc5eb2b9d2\userFiles-d9a49146-ceab-403c-a25f-8f95c2d1ed57\fetchFileTemp7782732309141153033.tmp
24/04/13 14:29:48.948 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-38e8c421-52c2-4511-a732-95cc5eb2b9d2/userFiles-d9a49146-ceab-403c-a25f-8f95c2d1ed57/sparklyr-3.0-2.12.jar to class loader
24/04/13 14:29:48.960 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59031.
24/04/13 14:29:48.960 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:59031
24/04/13 14:29:48.962 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/13 14:29:48.970 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 59031, None)
24/04/13 14:29:48.973 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:59031 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 59031, None)
24/04/13 14:29:48.976 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 59031, None)
24/04/13 14:29:48.977 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 59031, None)
24/04/13 14:29:49.294 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/13 14:29:49.303 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/13 14:29:53.787 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/13 14:29:53.920 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 14:29:54.206 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/13 14:29:54.338 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/13 14:29:54.339 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/13 14:29:54.339 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/13 14:29:54.380 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/13 14:29:54.510 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/13 14:29:54.512 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/13 14:29:55.543 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/13 14:29:56.986 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/13 14:29:56.988 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/13 14:29:57.039 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/13 14:29:57.039 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/13 14:29:57.060 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/13 14:29:57.184 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/13 14:29:57.185 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/13 14:29:57.224 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/13 14:29:57.303 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:29:57.305 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:29:57.326 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/13 14:29:57.327 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/13 14:29:57.328 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/13 14:29:57.329 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:29:57.329 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:29:57.331 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:29:57.331 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:29:57.333 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 14:29:57.333 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 14:29:58.060 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 201.3114 ms
24/04/13 14:29:58.195 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:29:58.202 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,005815 s
24/04/13 14:30:02.430 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/13 14:30:03.789 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.2061 ms
24/04/13 14:30:03.843 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:30:03.859 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:30:03.860 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/13 14:30:03.860 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:30:03.861 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:30:03.864 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/13 14:30:03.930 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 14:30:03.986 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 14:30:03.989 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:59031 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:30:03.993 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/13 14:30:04.007 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:30:04.009 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/13 14:30:04.059 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 14:30:04.075 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/13 14:30:04.539 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 159.5234 ms
24/04/13 14:30:04.560 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1516 bytes result sent to driver
24/04/13 14:30:04.569 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 520 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:30:04.571 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/13 14:30:04.576 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,696 s
24/04/13 14:30:04.579 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:30:04.579 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/13 14:30:04.580 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,736672 s
24/04/13 14:30:04.833 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:59031 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:30:04.894 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 237.7769 ms
24/04/13 14:30:09.280 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:30:09.282 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:30:09.282 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/13 14:30:09.282 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:30:09.282 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:30:09.283 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/13 14:30:09.288 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 14:30:09.290 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 14:30:09.291 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:59031 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:30:09.291 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/13 14:30:09.292 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:30:09.292 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/13 14:30:09.293 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 14:30:09.294 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/13 14:30:09.340 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/13 14:30:09.343 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 50 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:30:09.343 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/13 14:30:09.344 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,059 s
24/04/13 14:30:09.344 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:30:09.344 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/13 14:30:09.344 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,063476 s
24/04/13 14:30:11.572 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:59031 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:30:12.037 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:30:12.038 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:30:12.039 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/13 14:30:12.039 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:30:12.041 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:30:12.043 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26), which has no missing parents
24/04/13 14:30:12.064 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 107.3 KiB, free 912.2 MiB)
24/04/13 14:30:12.067 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 912.2 MiB)
24/04/13 14:30:12.069 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:59031 (size: 27.1 KiB, free: 912.3 MiB)
24/04/13 14:30:12.070 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/13 14:30:12.070 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:30:12.071 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/13 14:30:12.089 dispatcher-event-loop-1 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/13 14:30:12.089 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/13 14:30:12.090 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/13 14:30:12.313 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 151.8155 ms
24/04/13 14:30:13.049 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 686.4 KiB, free 911.5 MiB)
24/04/13 14:30:13.050 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on DESKTOP-LH06ASP:59031 (size: 686.4 KiB, free: 911.6 MiB)
24/04/13 14:30:13.066 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 5.2037 ms
24/04/13 14:30:13.208 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 127.3652 ms
24/04/13 14:30:13.237 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_13_0]
24/04/13 14:30:13.238 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2442 bytes result sent to driver
24/04/13 14:30:13.240 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1168 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:30:13.240 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/13 14:30:13.241 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 1,197 s
24/04/13 14:30:13.241 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:30:13.241 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/13 14:30:13.242 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 1,204550 s
24/04/13 14:30:13.514 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 194.584 ms
24/04/13 14:30:16.880 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:30:16.880 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:30:16.884 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:30:16.884 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:30:16.885 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 14:30:16.885 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 14:30:16.939 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 24.8882 ms
24/04/13 14:30:16.965 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.8802 ms
24/04/13 14:30:16.976 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.2181 ms
24/04/13 14:30:33.073 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/13 14:30:33.073 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/13 14:30:33.099 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/13 14:30:33.131 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/13 14:30:33.160 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/13 14:30:33.161 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/13 14:30:33.168 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/13 14:30:33.183 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/13 14:30:33.187 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-38e8c421-52c2-4511-a732-95cc5eb2b9d2\userFiles-d9a49146-ceab-403c-a25f-8f95c2d1ed57
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-38e8c421-52c2-4511-a732-95cc5eb2b9d2\userFiles-d9a49146-ceab-403c-a25f-8f95c2d1ed57\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:30:33.189 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/13 14:30:33.189 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/13 14:30:33.190 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-38e8c421-52c2-4511-a732-95cc5eb2b9d2
24/04/13 14:30:33.193 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-38e8c421-52c2-4511-a732-95cc5eb2b9d2
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-38e8c421-52c2-4511-a732-95cc5eb2b9d2\userFiles-d9a49146-ceab-403c-a25f-8f95c2d1ed57\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:30:33.193 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-97410210-b375-41c9-ac6b-c4fcfaa224ad
24/04/13 14:30:33.195 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-38e8c421-52c2-4511-a732-95cc5eb2b9d2\userFiles-d9a49146-ceab-403c-a25f-8f95c2d1ed57
24/04/13 14:30:33.197 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-38e8c421-52c2-4511-a732-95cc5eb2b9d2\userFiles-d9a49146-ceab-403c-a25f-8f95c2d1ed57
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-38e8c421-52c2-4511-a732-95cc5eb2b9d2\userFiles-d9a49146-ceab-403c-a25f-8f95c2d1ed57\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:30:45.313 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 14:30:45.492 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/13 14:30:45.512 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/13 14:30:45.559 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/13 14:30:45.662 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 14:30:45.662 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/13 14:30:45.663 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/13 14:30:45.664 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/13 14:30:45.691 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/13 14:30:45.702 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/13 14:30:45.702 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/13 14:30:45.750 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/13 14:30:45.751 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/13 14:30:45.751 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/13 14:30:45.752 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/13 14:30:45.752 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/13 14:30:45.835 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 59137.
24/04/13 14:30:45.860 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/13 14:30:45.892 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/13 14:30:45.914 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/13 14:30:45.915 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/13 14:30:45.918 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/13 14:30:45.941 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-4d270396-e767-4537-81b8-0a36185fb9eb
24/04/13 14:30:45.963 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/13 14:30:45.983 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/13 14:30:45.987 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/13 14:30:46.160 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/13 14:30:46.265 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/13 14:30:46.316 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:59137/jars/sparklyr-3.0-2.12.jar with timestamp 1713015045486
24/04/13 14:30:46.403 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/13 14:30:46.412 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/13 14:30:46.423 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:59137/jars/sparklyr-3.0-2.12.jar with timestamp 1713015045486
24/04/13 14:30:46.468 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:59137 after 22 ms (0 ms spent in bootstraps)
24/04/13 14:30:46.473 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:59137/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-0409ad2a-12b6-4fa4-a74d-6f36854a71ce\userFiles-ae1658e1-9644-46e0-bd81-8d9c33cf23dd\fetchFileTemp293355838455235786.tmp
24/04/13 14:30:46.625 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-0409ad2a-12b6-4fa4-a74d-6f36854a71ce/userFiles-ae1658e1-9644-46e0-bd81-8d9c33cf23dd/sparklyr-3.0-2.12.jar to class loader
24/04/13 14:30:46.647 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59157.
24/04/13 14:30:46.647 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:59157
24/04/13 14:30:46.648 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/13 14:30:46.656 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 59157, None)
24/04/13 14:30:46.659 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:59157 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 59157, None)
24/04/13 14:30:46.662 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 59157, None)
24/04/13 14:30:46.663 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 59157, None)
24/04/13 14:30:46.914 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/13 14:30:46.921 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/13 14:30:50.667 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/13 14:30:50.805 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/13 14:30:51.072 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/13 14:30:51.202 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/13 14:30:51.202 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/13 14:30:51.203 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/13 14:30:51.241 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/13 14:30:51.378 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/13 14:30:51.379 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/13 14:30:52.310 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/13 14:30:53.572 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/13 14:30:53.574 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/13 14:30:53.624 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/13 14:30:53.624 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/13 14:30:53.646 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/13 14:30:53.767 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/13 14:30:53.769 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/13 14:30:53.805 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/13 14:30:53.883 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:30:53.885 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:30:53.902 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/13 14:30:53.902 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/13 14:30:53.903 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/13 14:30:53.904 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:30:53.904 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:30:53.906 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:30:53.906 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:30:53.908 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 14:30:53.908 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 14:30:54.704 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 177.2981 ms
24/04/13 14:30:54.814 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:30:54.821 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,005260 s
24/04/13 14:30:59.569 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/13 14:31:01.087 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.8452 ms
24/04/13 14:31:01.151 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:31:01.170 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:31:01.171 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/13 14:31:01.171 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:31:01.172 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:31:01.176 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/13 14:31:01.255 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 14:31:01.312 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 14:31:01.317 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:59157 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:31:01.322 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/13 14:31:01.341 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:31:01.343 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/13 14:31:01.401 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 14:31:01.417 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/13 14:31:02.116 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 208.7345 ms
24/04/13 14:31:02.144 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1559 bytes result sent to driver
24/04/13 14:31:02.156 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 768 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:31:02.159 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/13 14:31:02.165 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,971 s
24/04/13 14:31:02.168 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:31:02.169 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/13 14:31:02.170 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 1,017992 s
24/04/13 14:31:02.574 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 265.4538 ms
24/04/13 14:31:06.425 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/13 14:31:06.426 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/13 14:31:06.426 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/13 14:31:06.426 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/13 14:31:06.426 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/13 14:31:06.427 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/13 14:31:06.433 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/13 14:31:06.435 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/13 14:31:06.436 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:59157 (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:31:06.437 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/13 14:31:06.438 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/13 14:31:06.438 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/13 14:31:06.439 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/13 14:31:06.440 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/13 14:31:06.494 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/13 14:31:06.496 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 57 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/13 14:31:06.496 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/13 14:31:06.497 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,069 s
24/04/13 14:31:06.497 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/13 14:31:06.497 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/13 14:31:06.498 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,072662 s
24/04/13 14:31:06.569 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:59157 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/13 14:31:09.135 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:31:09.136 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:31:09.139 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/13 14:31:09.139 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/13 14:31:09.141 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/13 14:31:09.141 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/13 14:31:09.205 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 34.163 ms
24/04/13 14:31:09.240 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.129 ms
24/04/13 14:31:09.254 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.9453 ms
24/04/13 14:41:10.005 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/13 14:41:10.006 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/13 14:41:10.025 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/13 14:41:10.043 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/13 14:41:10.056 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/13 14:41:10.057 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/13 14:41:10.060 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/13 14:41:10.063 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/13 14:41:10.067 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-0409ad2a-12b6-4fa4-a74d-6f36854a71ce\userFiles-ae1658e1-9644-46e0-bd81-8d9c33cf23dd
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-0409ad2a-12b6-4fa4-a74d-6f36854a71ce\userFiles-ae1658e1-9644-46e0-bd81-8d9c33cf23dd\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:41:10.069 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/13 14:41:10.069 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/13 14:41:10.070 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-6305f741-2bfa-4398-89c9-23b33d43bbfd
24/04/13 14:41:10.072 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-0409ad2a-12b6-4fa4-a74d-6f36854a71ce\userFiles-ae1658e1-9644-46e0-bd81-8d9c33cf23dd
24/04/13 14:41:10.074 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-0409ad2a-12b6-4fa4-a74d-6f36854a71ce\userFiles-ae1658e1-9644-46e0-bd81-8d9c33cf23dd
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-0409ad2a-12b6-4fa4-a74d-6f36854a71ce\userFiles-ae1658e1-9644-46e0-bd81-8d9c33cf23dd\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/13 14:41:10.074 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-0409ad2a-12b6-4fa4-a74d-6f36854a71ce
24/04/13 14:41:10.077 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-0409ad2a-12b6-4fa4-a74d-6f36854a71ce
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-0409ad2a-12b6-4fa4-a74d-6f36854a71ce\userFiles-ae1658e1-9644-46e0-bd81-8d9c33cf23dd\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 13:49:04.932 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 13:49:05.141 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/14 13:49:05.164 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/14 13:49:05.229 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/14 13:49:05.300 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 13:49:05.300 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/14 13:49:05.300 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 13:49:05.301 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/14 13:49:05.327 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/14 13:49:05.339 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/14 13:49:05.339 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/14 13:49:05.403 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/14 13:49:05.403 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/14 13:49:05.403 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/14 13:49:05.404 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/14 13:49:05.404 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/14 13:49:05.634 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 52909.
24/04/14 13:49:05.703 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/14 13:49:05.752 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/14 13:49:05.781 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/14 13:49:05.782 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/14 13:49:05.785 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/14 13:49:05.820 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-12c9ae43-1dc8-4d65-9430-17187eacf657
24/04/14 13:49:05.849 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/14 13:49:05.871 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/14 13:49:05.875 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/14 13:49:06.099 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/14 13:49:06.240 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/14 13:49:06.295 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:52909/jars/sparklyr-3.0-2.12.jar with timestamp 1713098945133
24/04/14 13:49:06.385 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/14 13:49:06.393 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/14 13:49:06.406 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:52909/jars/sparklyr-3.0-2.12.jar with timestamp 1713098945133
24/04/14 13:49:06.454 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:52909 after 23 ms (0 ms spent in bootstraps)
24/04/14 13:49:06.460 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:52909/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-db34bbd2-fe53-4c64-ae52-7bd619767ae7\userFiles-0be224cd-92a3-49da-812d-5a5c55bc0551\fetchFileTemp6631462731201399848.tmp
24/04/14 13:49:06.631 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-db34bbd2-fe53-4c64-ae52-7bd619767ae7/userFiles-0be224cd-92a3-49da-812d-5a5c55bc0551/sparklyr-3.0-2.12.jar to class loader
24/04/14 13:49:06.655 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52929.
24/04/14 13:49:06.657 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:52929
24/04/14 13:49:06.660 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/14 13:49:06.672 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 52929, None)
24/04/14 13:49:06.677 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:52929 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 52929, None)
24/04/14 13:49:06.682 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 52929, None)
24/04/14 13:49:06.685 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 52929, None)
24/04/14 13:49:07.037 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/14 13:49:07.048 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/14 13:49:11.162 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/14 13:49:11.299 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 13:49:11.623 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/14 13:49:11.823 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/14 13:49:11.824 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/14 13:49:11.825 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/14 13:49:11.877 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/14 13:49:12.033 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/14 13:49:12.034 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/14 13:49:13.073 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/14 13:49:14.539 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/14 13:49:14.542 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/14 13:49:14.681 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/14 13:49:14.682 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/14 13:49:14.712 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/14 13:49:14.844 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/14 13:49:14.847 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/14 13:49:14.887 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/14 13:49:15.015 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 13:49:15.018 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 13:49:15.043 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/14 13:49:15.043 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/14 13:49:15.044 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/14 13:49:15.045 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 13:49:15.046 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 13:49:15.047 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 13:49:15.048 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 13:49:15.050 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 13:49:15.051 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 13:49:15.913 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 207.7208 ms
24/04/14 13:49:16.043 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 13:49:16.052 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,006854 s
24/04/14 13:49:20.445 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/14 13:49:21.795 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.0017 ms
24/04/14 13:49:21.856 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 13:49:21.871 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/14 13:49:21.871 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/14 13:49:21.872 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 13:49:21.873 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 13:49:21.876 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/14 13:49:21.945 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 13:49:22.662 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 13:49:22.665 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:52929 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 13:49:22.668 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/14 13:49:22.682 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 13:49:22.683 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/14 13:49:22.735 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 13:49:22.746 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/14 13:49:23.260 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 150.1748 ms
24/04/14 13:49:23.284 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1559 bytes result sent to driver
24/04/14 13:49:23.293 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 568 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 13:49:23.296 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/14 13:49:23.303 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 1,410 s
24/04/14 13:49:23.307 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 13:49:23.308 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/14 13:49:23.308 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 1,452454 s
24/04/14 13:49:23.584 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 186.7969 ms
24/04/14 13:49:26.880 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 13:49:26.881 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/14 13:49:26.882 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/14 13:49:26.882 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 13:49:26.882 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 13:49:26.883 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/14 13:49:26.889 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 13:49:26.892 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 13:49:26.893 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:52929 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 13:49:26.894 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/14 13:49:26.895 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 13:49:26.895 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/14 13:49:26.896 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 13:49:26.897 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/14 13:49:26.948 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1387 bytes result sent to driver
24/04/14 13:49:26.979 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 83 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 13:49:26.980 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/14 13:49:26.981 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,096 s
24/04/14 13:49:26.981 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 13:49:26.981 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/14 13:49:26.982 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,100775 s
24/04/14 13:49:27.015 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:52929 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 13:49:29.429 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 13:49:29.429 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 13:49:29.430 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 13:49:29.431 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 13:49:29.432 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 13:49:29.432 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 13:49:29.490 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 32.4874 ms
24/04/14 13:49:29.517 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.4782 ms
24/04/14 13:49:29.533 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.4714 ms
24/04/14 14:26:47.624 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
24/04/14 14:26:57.644 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
24/04/14 14:27:07.658 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
24/04/14 14:27:17.664 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
24/04/14 14:27:21.272 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
24/04/14 14:27:21.272 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
24/04/14 14:27:21.273 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
24/04/14 14:27:21.273 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
24/04/14 14:33:06.916 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/14 14:33:06.918 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/14 14:33:06.986 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/14 14:33:07.032 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/14 14:33:07.060 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/14 14:33:07.061 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/14 14:33:07.067 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/14 14:33:07.077 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/14 14:33:07.083 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-db34bbd2-fe53-4c64-ae52-7bd619767ae7\userFiles-0be224cd-92a3-49da-812d-5a5c55bc0551
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-db34bbd2-fe53-4c64-ae52-7bd619767ae7\userFiles-0be224cd-92a3-49da-812d-5a5c55bc0551\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 14:33:07.090 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/14 14:33:07.090 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/14 14:33:07.092 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-db34bbd2-fe53-4c64-ae52-7bd619767ae7
24/04/14 14:33:07.095 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-db34bbd2-fe53-4c64-ae52-7bd619767ae7
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-db34bbd2-fe53-4c64-ae52-7bd619767ae7\userFiles-0be224cd-92a3-49da-812d-5a5c55bc0551\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 14:33:07.098 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-1d125f5e-9c87-4fe9-8e76-4beaf0584330
24/04/14 14:33:07.102 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-db34bbd2-fe53-4c64-ae52-7bd619767ae7\userFiles-0be224cd-92a3-49da-812d-5a5c55bc0551
24/04/14 14:33:07.104 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-db34bbd2-fe53-4c64-ae52-7bd619767ae7\userFiles-0be224cd-92a3-49da-812d-5a5c55bc0551
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-db34bbd2-fe53-4c64-ae52-7bd619767ae7\userFiles-0be224cd-92a3-49da-812d-5a5c55bc0551\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 14:33:19.574 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 14:33:19.769 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/14 14:33:19.792 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/14 14:33:19.848 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/14 14:33:19.944 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 14:33:19.945 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/14 14:33:19.945 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 14:33:19.946 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/14 14:33:19.975 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/14 14:33:19.986 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/14 14:33:19.986 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/14 14:33:20.042 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/14 14:33:20.042 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/14 14:33:20.043 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/14 14:33:20.043 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/14 14:33:20.043 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/14 14:33:20.136 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 59040.
24/04/14 14:33:20.164 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/14 14:33:20.202 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/14 14:33:20.229 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/14 14:33:20.230 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/14 14:33:20.233 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/14 14:33:20.261 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-ff822d63-acef-4b0c-bfb9-7a71dca23e43
24/04/14 14:33:20.289 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/14 14:33:20.312 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/14 14:33:20.316 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/14 14:33:20.542 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/14 14:33:20.648 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/14 14:33:20.695 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:59040/jars/sparklyr-3.0-2.12.jar with timestamp 1713101599761
24/04/14 14:33:20.773 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/14 14:33:20.780 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/14 14:33:20.791 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:59040/jars/sparklyr-3.0-2.12.jar with timestamp 1713101599761
24/04/14 14:33:20.831 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:59040 after 18 ms (0 ms spent in bootstraps)
24/04/14 14:33:20.841 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:59040/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1d588a5f-f06b-4af3-aec5-5cef90013474\userFiles-e54e21ee-340f-4764-a475-4d2badf19342\fetchFileTemp8645257544339804310.tmp
24/04/14 14:33:21.003 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-1d588a5f-f06b-4af3-aec5-5cef90013474/userFiles-e54e21ee-340f-4764-a475-4d2badf19342/sparklyr-3.0-2.12.jar to class loader
24/04/14 14:33:21.016 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59060.
24/04/14 14:33:21.016 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:59060
24/04/14 14:33:21.018 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/14 14:33:21.027 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 59060, None)
24/04/14 14:33:21.031 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:59060 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 59060, None)
24/04/14 14:33:21.034 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 59060, None)
24/04/14 14:33:21.035 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 59060, None)
24/04/14 14:33:21.339 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/14 14:33:21.347 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/14 14:33:25.105 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/14 14:33:25.259 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 14:33:25.489 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/14 14:33:25.735 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/14 14:33:25.736 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/14 14:33:25.736 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/14 14:33:25.780 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/14 14:33:25.917 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/14 14:33:25.918 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/14 14:33:26.934 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/14 14:33:28.263 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/14 14:33:28.265 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/14 14:33:28.331 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/14 14:33:28.331 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/14 14:33:28.357 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/14 14:33:28.480 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/14 14:33:28.481 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/14 14:33:28.518 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/14 14:33:28.647 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 14:33:28.650 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 14:33:28.666 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/14 14:33:28.667 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/14 14:33:28.667 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/14 14:33:28.668 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 14:33:28.668 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 14:33:28.670 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 14:33:28.670 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 14:33:28.672 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 14:33:28.672 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 14:33:29.388 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 188.9822 ms
24/04/14 14:33:29.500 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 14:33:29.507 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,004950 s
24/04/14 14:33:33.760 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/14 14:33:35.098 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.276 ms
24/04/14 14:33:35.145 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 14:33:35.159 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/14 14:33:35.159 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/14 14:33:35.160 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 14:33:35.163 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 14:33:35.166 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/14 14:33:35.236 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 14:33:35.310 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 14:33:35.315 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:59060 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 14:33:35.320 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/14 14:33:35.343 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 14:33:35.345 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/14 14:33:35.398 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 14:33:35.414 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/14 14:33:35.952 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 190.0173 ms
24/04/14 14:33:35.977 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1559 bytes result sent to driver
24/04/14 14:33:35.988 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 599 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 14:33:35.989 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/14 14:33:35.995 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,813 s
24/04/14 14:33:35.998 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 14:33:35.999 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/14 14:33:35.999 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,853488 s
24/04/14 14:33:36.270 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 193.7579 ms
24/04/14 14:33:39.429 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 14:33:39.431 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/14 14:33:39.431 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/14 14:33:39.431 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 14:33:39.431 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 14:33:39.432 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/14 14:33:39.437 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 14:33:39.439 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 14:33:39.439 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:59060 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 14:33:39.440 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/14 14:33:39.440 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 14:33:39.440 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/14 14:33:39.441 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 14:33:39.442 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/14 14:33:39.510 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1516 bytes result sent to driver
24/04/14 14:33:39.512 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 71 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 14:33:39.512 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/14 14:33:39.513 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,080 s
24/04/14 14:33:39.513 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 14:33:39.513 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/14 14:33:39.514 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,084020 s
24/04/14 14:33:42.001 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 14:33:42.001 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 14:33:42.003 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 14:33:42.003 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 14:33:42.004 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 14:33:42.004 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 14:33:42.073 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 38.76 ms
24/04/14 14:33:42.099 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.2454 ms
24/04/14 14:33:42.115 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.8623 ms
24/04/14 14:47:54.443 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/14 14:47:54.444 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/14 14:47:54.468 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/14 14:47:54.492 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/14 14:47:54.515 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/14 14:47:54.516 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/14 14:47:54.527 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/14 14:47:54.530 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/14 14:47:54.535 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1d588a5f-f06b-4af3-aec5-5cef90013474\userFiles-e54e21ee-340f-4764-a475-4d2badf19342
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1d588a5f-f06b-4af3-aec5-5cef90013474\userFiles-e54e21ee-340f-4764-a475-4d2badf19342\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 14:47:54.536 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/14 14:47:54.536 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/14 14:47:54.537 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1d588a5f-f06b-4af3-aec5-5cef90013474
24/04/14 14:47:54.540 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1d588a5f-f06b-4af3-aec5-5cef90013474
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1d588a5f-f06b-4af3-aec5-5cef90013474\userFiles-e54e21ee-340f-4764-a475-4d2badf19342\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 14:47:54.541 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-edc1b195-8086-4cd7-a225-9958ff1c357e
24/04/14 14:47:54.543 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1d588a5f-f06b-4af3-aec5-5cef90013474\userFiles-e54e21ee-340f-4764-a475-4d2badf19342
24/04/14 14:47:54.545 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1d588a5f-f06b-4af3-aec5-5cef90013474\userFiles-e54e21ee-340f-4764-a475-4d2badf19342
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1d588a5f-f06b-4af3-aec5-5cef90013474\userFiles-e54e21ee-340f-4764-a475-4d2badf19342\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 14:48:06.296 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 14:48:06.481 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/14 14:48:06.499 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/14 14:48:06.554 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/14 14:48:06.625 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 14:48:06.626 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/14 14:48:06.626 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 14:48:06.627 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/14 14:48:06.651 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/14 14:48:06.663 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/14 14:48:06.664 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/14 14:48:06.717 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/14 14:48:06.717 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/14 14:48:06.718 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/14 14:48:06.718 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/14 14:48:06.718 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/14 14:48:06.821 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 60062.
24/04/14 14:48:06.847 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/14 14:48:06.883 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/14 14:48:06.905 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/14 14:48:06.906 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/14 14:48:06.909 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/14 14:48:06.932 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-59d10d38-ce90-4895-b3ee-2893d922100a
24/04/14 14:48:06.949 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/14 14:48:06.963 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/14 14:48:06.969 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/14 14:48:07.101 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/14 14:48:07.175 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/14 14:48:07.214 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:60062/jars/sparklyr-3.0-2.12.jar with timestamp 1713102486475
24/04/14 14:48:07.285 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/14 14:48:07.292 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/14 14:48:07.304 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:60062/jars/sparklyr-3.0-2.12.jar with timestamp 1713102486475
24/04/14 14:48:07.345 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:60062 after 19 ms (0 ms spent in bootstraps)
24/04/14 14:48:07.349 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:60062/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1333ccc7-38db-4156-869f-570ac0f6b9cd\userFiles-111a8a0e-405c-4432-8eb1-fd2ef32a904f\fetchFileTemp524033940281270640.tmp
24/04/14 14:48:07.509 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-1333ccc7-38db-4156-869f-570ac0f6b9cd/userFiles-111a8a0e-405c-4432-8eb1-fd2ef32a904f/sparklyr-3.0-2.12.jar to class loader
24/04/14 14:48:07.521 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60082.
24/04/14 14:48:07.521 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:60082
24/04/14 14:48:07.523 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/14 14:48:07.530 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 60082, None)
24/04/14 14:48:07.533 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:60082 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 60082, None)
24/04/14 14:48:07.536 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 60082, None)
24/04/14 14:48:07.537 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 60082, None)
24/04/14 14:48:07.794 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/14 14:48:07.802 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/14 14:48:11.191 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/14 14:48:11.334 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 14:48:11.524 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/14 14:48:11.730 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/14 14:48:11.731 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/14 14:48:11.732 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/14 14:48:11.774 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/14 14:48:11.894 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/14 14:48:11.894 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/14 14:48:12.779 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/14 14:48:14.061 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/14 14:48:14.063 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/14 14:48:14.117 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/14 14:48:14.117 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/14 14:48:14.140 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/14 14:48:14.260 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/14 14:48:14.262 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/14 14:48:14.296 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/14 14:48:14.374 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 14:48:14.376 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 14:48:14.394 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/14 14:48:14.394 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/14 14:48:14.395 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/14 14:48:14.395 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 14:48:14.395 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 14:48:14.398 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 14:48:14.398 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 14:48:14.400 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 14:48:14.401 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 14:48:15.081 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 167.7736 ms
24/04/14 14:48:15.189 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 14:48:15.195 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,005144 s
24/04/14 14:48:19.309 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/14 14:48:20.673 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.9998 ms
24/04/14 14:48:20.741 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 14:48:20.758 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/14 14:48:20.759 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/14 14:48:20.759 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 14:48:20.760 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 14:48:20.765 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/14 14:48:20.830 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 14:48:20.882 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 14:48:20.885 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:60082 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 14:48:20.889 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/14 14:48:20.905 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 14:48:20.906 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/14 14:48:20.960 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 14:48:20.971 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/14 14:48:21.536 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 168.9441 ms
24/04/14 14:48:21.559 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1559 bytes result sent to driver
24/04/14 14:48:21.568 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 618 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 14:48:21.570 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/14 14:48:21.576 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,796 s
24/04/14 14:48:21.580 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 14:48:21.580 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/14 14:48:21.581 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,839880 s
24/04/14 14:48:21.897 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 212.7904 ms
24/04/14 14:48:25.075 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 14:48:25.076 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/14 14:48:25.077 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/14 14:48:25.077 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 14:48:25.077 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 14:48:25.078 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/14 14:48:25.082 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 14:48:25.084 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 14:48:25.085 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:60082 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 14:48:25.086 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/14 14:48:25.086 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 14:48:25.087 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/14 14:48:25.088 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 14:48:25.089 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/14 14:48:25.129 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/14 14:48:25.131 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 43 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 14:48:25.131 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/14 14:48:25.132 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,053 s
24/04/14 14:48:25.132 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 14:48:25.133 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/14 14:48:25.133 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,057359 s
24/04/14 14:48:25.209 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:60082 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 14:48:25.217 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:60082 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 14:48:27.571 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 14:48:27.571 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 14:48:27.573 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 14:48:27.573 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 14:48:27.574 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 14:48:27.574 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 14:48:27.632 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 31.4804 ms
24/04/14 14:48:27.658 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.9715 ms
24/04/14 14:48:27.676 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.7637 ms
24/04/14 15:01:49.843 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/14 15:01:49.844 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/14 15:01:49.891 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/14 15:01:49.920 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/14 15:01:49.935 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/14 15:01:49.935 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/14 15:01:49.940 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/14 15:01:49.946 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/14 15:01:49.956 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1333ccc7-38db-4156-869f-570ac0f6b9cd\userFiles-111a8a0e-405c-4432-8eb1-fd2ef32a904f
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1333ccc7-38db-4156-869f-570ac0f6b9cd\userFiles-111a8a0e-405c-4432-8eb1-fd2ef32a904f\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 15:01:49.959 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/14 15:01:49.959 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/14 15:01:49.960 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-90805326-c4be-4636-a05a-da950d17af5d
24/04/14 15:01:49.963 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1333ccc7-38db-4156-869f-570ac0f6b9cd\userFiles-111a8a0e-405c-4432-8eb1-fd2ef32a904f
24/04/14 15:01:49.968 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1333ccc7-38db-4156-869f-570ac0f6b9cd\userFiles-111a8a0e-405c-4432-8eb1-fd2ef32a904f
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1333ccc7-38db-4156-869f-570ac0f6b9cd\userFiles-111a8a0e-405c-4432-8eb1-fd2ef32a904f\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 15:01:49.968 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1333ccc7-38db-4156-869f-570ac0f6b9cd
24/04/14 15:01:49.972 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1333ccc7-38db-4156-869f-570ac0f6b9cd
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1333ccc7-38db-4156-869f-570ac0f6b9cd\userFiles-111a8a0e-405c-4432-8eb1-fd2ef32a904f\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 15:02:02.650 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 15:02:02.910 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/14 15:02:02.938 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/14 15:02:03.006 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/14 15:02:03.100 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 15:02:03.102 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/14 15:02:03.102 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 15:02:03.105 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/14 15:02:03.149 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/14 15:02:03.171 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/14 15:02:03.171 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/14 15:02:03.254 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/14 15:02:03.254 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/14 15:02:03.254 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/14 15:02:03.256 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/14 15:02:03.256 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/14 15:02:03.372 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 60605.
24/04/14 15:02:03.399 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/14 15:02:03.436 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/14 15:02:03.465 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/14 15:02:03.466 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/14 15:02:03.471 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/14 15:02:03.506 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-56710843-3e36-4ba0-b5ed-25cc4b31cb12
24/04/14 15:02:03.533 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/14 15:02:03.558 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/14 15:02:03.562 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/14 15:02:03.746 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/14 15:02:03.820 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/14 15:02:03.858 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:60605/jars/sparklyr-3.0-2.12.jar with timestamp 1713103322899
24/04/14 15:02:03.930 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/14 15:02:03.937 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/14 15:02:03.949 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:60605/jars/sparklyr-3.0-2.12.jar with timestamp 1713103322899
24/04/14 15:02:03.997 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:60605 after 21 ms (0 ms spent in bootstraps)
24/04/14 15:02:04.001 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:60605/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1211a3b0-cdcd-4542-ba1e-bbe186e8df2b\userFiles-bbcfedce-ab5a-4150-aa15-2424b2e7dbe2\fetchFileTemp3498373631561362447.tmp
24/04/14 15:02:04.213 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-1211a3b0-cdcd-4542-ba1e-bbe186e8df2b/userFiles-bbcfedce-ab5a-4150-aa15-2424b2e7dbe2/sparklyr-3.0-2.12.jar to class loader
24/04/14 15:02:04.225 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60625.
24/04/14 15:02:04.225 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:60625
24/04/14 15:02:04.227 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/14 15:02:04.235 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 60625, None)
24/04/14 15:02:04.238 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:60625 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 60625, None)
24/04/14 15:02:04.241 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 60625, None)
24/04/14 15:02:04.242 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 60625, None)
24/04/14 15:02:04.511 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/14 15:02:04.519 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/14 15:02:08.129 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/14 15:02:08.271 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 15:02:08.466 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/14 15:02:08.674 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/14 15:02:08.674 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/14 15:02:08.675 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/14 15:02:08.714 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/14 15:02:08.840 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/14 15:02:08.841 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/14 15:02:10.071 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/14 15:02:11.789 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/14 15:02:11.794 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/14 15:02:11.871 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/14 15:02:11.871 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/14 15:02:11.909 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/14 15:02:12.084 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/14 15:02:12.085 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/14 15:02:12.144 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/14 15:02:12.251 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 15:02:12.253 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 15:02:12.277 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/14 15:02:12.278 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/14 15:02:12.279 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/14 15:02:12.279 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 15:02:12.279 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 15:02:12.281 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 15:02:12.281 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 15:02:12.283 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 15:02:12.283 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 15:02:13.080 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 181.8462 ms
24/04/14 15:02:13.203 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 15:02:13.210 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,006290 s
24/04/14 15:02:18.046 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/14 15:02:19.593 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.1643 ms
24/04/14 15:02:19.653 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 15:02:19.672 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/14 15:02:19.673 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/14 15:02:19.674 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 15:02:19.675 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 15:02:19.679 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/14 15:02:19.774 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 15:02:19.828 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 15:02:19.831 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:60625 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 15:02:19.836 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/14 15:02:19.850 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 15:02:19.851 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/14 15:02:19.896 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 15:02:19.907 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/14 15:02:20.422 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 166.7323 ms
24/04/14 15:02:20.446 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1559 bytes result sent to driver
24/04/14 15:02:20.455 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 567 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 15:02:20.457 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/14 15:02:20.463 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,758 s
24/04/14 15:02:20.467 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 15:02:20.467 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/14 15:02:20.469 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,814311 s
24/04/14 15:02:20.761 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 208.7729 ms
24/04/14 15:02:24.023 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 15:02:24.024 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/14 15:02:24.024 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/14 15:02:24.024 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 15:02:24.025 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 15:02:24.026 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/14 15:02:24.032 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 15:02:24.035 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 15:02:24.036 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:60625 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 15:02:24.036 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/14 15:02:24.037 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 15:02:24.037 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/14 15:02:24.039 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 15:02:24.039 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/14 15:02:24.091 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/14 15:02:24.093 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 55 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 15:02:24.093 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/14 15:02:24.094 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,067 s
24/04/14 15:02:24.095 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 15:02:24.095 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/14 15:02:24.095 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,071664 s
24/04/14 15:02:24.198 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:60625 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 15:02:24.205 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:60625 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 15:02:26.673 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 15:02:26.673 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 15:02:26.674 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 15:02:26.675 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 15:02:26.676 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 15:02:26.676 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 15:02:26.749 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 35.0843 ms
24/04/14 15:02:26.784 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.7619 ms
24/04/14 15:02:26.808 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.221 ms
24/04/14 15:04:17.475 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/14 15:04:17.476 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/14 15:04:17.495 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/14 15:04:17.523 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/14 15:04:17.542 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/14 15:04:17.542 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/14 15:04:17.547 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/14 15:04:17.554 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/14 15:04:17.564 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1211a3b0-cdcd-4542-ba1e-bbe186e8df2b\userFiles-bbcfedce-ab5a-4150-aa15-2424b2e7dbe2
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1211a3b0-cdcd-4542-ba1e-bbe186e8df2b\userFiles-bbcfedce-ab5a-4150-aa15-2424b2e7dbe2\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 15:04:17.566 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/14 15:04:17.567 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/14 15:04:17.570 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-86b5686c-e3f2-4ac7-84f0-9d3f6b3a70d3
24/04/14 15:04:17.575 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1211a3b0-cdcd-4542-ba1e-bbe186e8df2b
24/04/14 15:04:17.578 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1211a3b0-cdcd-4542-ba1e-bbe186e8df2b
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1211a3b0-cdcd-4542-ba1e-bbe186e8df2b\userFiles-bbcfedce-ab5a-4150-aa15-2424b2e7dbe2\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 15:04:17.578 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1211a3b0-cdcd-4542-ba1e-bbe186e8df2b\userFiles-bbcfedce-ab5a-4150-aa15-2424b2e7dbe2
24/04/14 15:04:17.581 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1211a3b0-cdcd-4542-ba1e-bbe186e8df2b\userFiles-bbcfedce-ab5a-4150-aa15-2424b2e7dbe2
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1211a3b0-cdcd-4542-ba1e-bbe186e8df2b\userFiles-bbcfedce-ab5a-4150-aa15-2424b2e7dbe2\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 15:04:29.479 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 15:04:29.670 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/14 15:04:29.690 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/14 15:04:29.740 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/14 15:04:29.837 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 15:04:29.838 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/14 15:04:29.839 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 15:04:29.840 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/14 15:04:29.871 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/14 15:04:29.883 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/14 15:04:29.884 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/14 15:04:29.936 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/14 15:04:29.937 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/14 15:04:29.937 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/14 15:04:29.937 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/14 15:04:29.938 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/14 15:04:30.033 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 60799.
24/04/14 15:04:30.064 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/14 15:04:30.102 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/14 15:04:30.126 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/14 15:04:30.127 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/14 15:04:30.130 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/14 15:04:30.153 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-10792bea-da9f-462f-b178-b6a013a3edf0
24/04/14 15:04:30.171 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/14 15:04:30.187 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/14 15:04:30.190 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/14 15:04:30.338 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/14 15:04:30.413 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/14 15:04:30.452 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:60799/jars/sparklyr-3.0-2.12.jar with timestamp 1713103469663
24/04/14 15:04:30.523 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/14 15:04:30.530 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/14 15:04:30.541 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:60799/jars/sparklyr-3.0-2.12.jar with timestamp 1713103469663
24/04/14 15:04:30.584 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:60799 after 21 ms (0 ms spent in bootstraps)
24/04/14 15:04:30.589 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:60799/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1a1d4042-a1ce-4cfb-b498-1675321939e0\userFiles-2f5751bd-7552-4d15-836f-2856dbbb605c\fetchFileTemp1295951992504846968.tmp
24/04/14 15:04:30.745 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-1a1d4042-a1ce-4cfb-b498-1675321939e0/userFiles-2f5751bd-7552-4d15-836f-2856dbbb605c/sparklyr-3.0-2.12.jar to class loader
24/04/14 15:04:30.758 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60822.
24/04/14 15:04:30.758 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:60822
24/04/14 15:04:30.760 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/14 15:04:30.767 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 60822, None)
24/04/14 15:04:30.770 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:60822 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 60822, None)
24/04/14 15:04:30.773 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 60822, None)
24/04/14 15:04:30.774 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 60822, None)
24/04/14 15:04:31.033 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/14 15:04:31.040 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/14 15:04:34.438 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/14 15:04:34.568 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 15:04:34.753 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/14 15:04:34.963 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/14 15:04:34.964 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/14 15:04:34.964 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/14 15:04:35.003 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/14 15:04:35.124 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/14 15:04:35.125 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/14 15:04:36.035 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/14 15:04:37.328 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/14 15:04:37.330 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/14 15:04:37.383 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/14 15:04:37.383 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/14 15:04:37.405 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/14 15:04:37.524 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/14 15:04:37.526 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/14 15:04:37.565 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/14 15:04:37.645 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 15:04:37.647 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 15:04:37.661 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/14 15:04:37.662 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/14 15:04:37.662 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/14 15:04:37.663 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 15:04:37.663 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 15:04:37.665 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 15:04:37.665 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 15:04:37.666 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 15:04:37.667 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 15:04:38.353 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 175.1931 ms
24/04/14 15:04:38.460 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 15:04:38.467 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,005183 s
24/04/14 15:04:42.289 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/14 15:04:43.666 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.2865 ms
24/04/14 15:04:43.711 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 15:04:43.725 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/14 15:04:43.725 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/14 15:04:43.726 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 15:04:43.728 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 15:04:43.731 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/14 15:04:43.793 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 15:04:43.851 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 15:04:43.853 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:60822 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 15:04:43.857 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/14 15:04:43.871 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 15:04:43.873 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/14 15:04:43.925 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 15:04:43.938 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/14 15:04:44.433 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 165.0963 ms
24/04/14 15:04:44.456 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1516 bytes result sent to driver
24/04/14 15:04:44.464 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 551 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 15:04:44.467 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/14 15:04:44.472 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,727 s
24/04/14 15:04:44.476 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 15:04:44.476 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/14 15:04:44.477 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,765311 s
24/04/14 15:04:44.771 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 195.7978 ms
24/04/14 15:04:47.937 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 15:04:47.938 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/14 15:04:47.938 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/14 15:04:47.938 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 15:04:47.939 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 15:04:47.939 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/14 15:04:47.945 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 15:04:47.947 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 15:04:47.948 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:60822 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 15:04:47.949 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/14 15:04:47.950 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 15:04:47.950 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/14 15:04:47.951 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 15:04:47.953 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/14 15:04:47.996 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/14 15:04:47.998 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 47 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 15:04:47.998 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/14 15:04:47.999 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,058 s
24/04/14 15:04:47.999 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 15:04:47.999 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/14 15:04:47.999 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,062669 s
24/04/14 15:04:48.069 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:60822 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 15:04:50.442 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 15:04:50.443 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 15:04:50.445 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 15:04:50.446 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 15:04:50.448 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 15:04:50.448 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 15:04:50.509 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 30.8229 ms
24/04/14 15:04:50.540 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.1319 ms
24/04/14 15:04:50.555 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.1857 ms
24/04/14 15:05:12.753 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 15:05:12.754 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/14 15:05:12.754 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/14 15:05:12.754 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 15:05:12.755 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 15:05:12.756 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at collect at utils.scala:26), which has no missing parents
24/04/14 15:05:12.769 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 56.4 KiB, free 912.2 MiB)
24/04/14 15:05:12.771 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 912.2 MiB)
24/04/14 15:05:12.772 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:60822 (size: 13.5 KiB, free: 912.3 MiB)
24/04/14 15:05:12.774 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/14 15:05:12.774 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 15:05:12.774 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/14 15:05:12.791 dispatcher-event-loop-0 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 15:05:12.791 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 15:05:12.792 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/14 15:05:12.947 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 109.5222 ms
24/04/14 15:05:12.965 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 10.4982 ms
24/04/14 15:05:12.969 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1467 bytes result sent to driver
24/04/14 15:05:12.970 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 195 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 15:05:12.971 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/14 15:05:12.971 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0,214 s
24/04/14 15:05:12.972 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 15:05:12.972 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/14 15:05:12.972 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0,218873 s
24/04/14 15:05:12.991 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.7495 ms
24/04/14 15:05:54.644 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 15:05:54.644 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
24/04/14 15:05:54.644 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
24/04/14 15:05:54.644 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 15:05:54.645 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 15:05:54.646 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:26), which has no missing parents
24/04/14 15:05:54.653 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 56.4 KiB, free 912.1 MiB)
24/04/14 15:05:54.655 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 912.1 MiB)
24/04/14 15:05:54.655 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-LH06ASP:60822 (size: 13.5 KiB, free: 912.3 MiB)
24/04/14 15:05:54.656 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
24/04/14 15:05:54.656 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 15:05:54.656 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/14 15:05:54.664 dispatcher-event-loop-0 WARN TaskSetManager: Stage 3 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 15:05:54.665 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 15:05:54.665 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/14 15:05:54.701 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1510 bytes result sent to driver
24/04/14 15:05:54.702 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 45 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 15:05:54.703 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/14 15:05:54.703 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0,057 s
24/04/14 15:05:54.703 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 15:05:54.704 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/04/14 15:05:54.704 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0,060685 s
24/04/14 15:13:03.369 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/14 15:13:03.370 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/14 15:13:03.385 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/14 15:13:03.419 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/14 15:13:03.437 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/14 15:13:03.437 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/14 15:13:03.440 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/14 15:13:03.443 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/14 15:13:03.448 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1a1d4042-a1ce-4cfb-b498-1675321939e0\userFiles-2f5751bd-7552-4d15-836f-2856dbbb605c
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1a1d4042-a1ce-4cfb-b498-1675321939e0\userFiles-2f5751bd-7552-4d15-836f-2856dbbb605c\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 15:13:03.450 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/14 15:13:03.451 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/14 15:13:03.451 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1a1d4042-a1ce-4cfb-b498-1675321939e0
24/04/14 15:13:03.455 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1a1d4042-a1ce-4cfb-b498-1675321939e0
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1a1d4042-a1ce-4cfb-b498-1675321939e0\userFiles-2f5751bd-7552-4d15-836f-2856dbbb605c\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 15:13:03.456 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1a1d4042-a1ce-4cfb-b498-1675321939e0\userFiles-2f5751bd-7552-4d15-836f-2856dbbb605c
24/04/14 15:13:03.459 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1a1d4042-a1ce-4cfb-b498-1675321939e0\userFiles-2f5751bd-7552-4d15-836f-2856dbbb605c
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1a1d4042-a1ce-4cfb-b498-1675321939e0\userFiles-2f5751bd-7552-4d15-836f-2856dbbb605c\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 15:13:03.460 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-b8156eb7-ae67-4cef-96c1-9d485db446b7
24/04/14 17:30:09.013 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 17:30:09.225 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/14 17:30:09.248 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/14 17:30:09.313 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/14 17:30:09.381 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 17:30:09.382 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/14 17:30:09.382 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/14 17:30:09.383 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/14 17:30:09.412 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/14 17:30:09.427 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/14 17:30:09.427 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/14 17:30:09.485 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/14 17:30:09.485 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/14 17:30:09.485 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/14 17:30:09.486 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/14 17:30:09.486 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/14 17:30:09.573 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 63522.
24/04/14 17:30:09.604 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/14 17:30:09.643 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/14 17:30:09.670 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/14 17:30:09.670 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/14 17:30:09.674 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/14 17:30:09.705 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-6cd9e65b-59f9-44f7-85e8-a8fa3f4c69f4
24/04/14 17:30:09.733 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/14 17:30:09.759 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/14 17:30:09.764 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/14 17:30:10.037 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/14 17:30:10.167 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/14 17:30:10.217 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:63522/jars/sparklyr-3.0-2.12.jar with timestamp 1713112209217
24/04/14 17:30:10.295 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/14 17:30:10.304 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/14 17:30:10.316 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:63522/jars/sparklyr-3.0-2.12.jar with timestamp 1713112209217
24/04/14 17:30:10.360 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:63522 after 21 ms (0 ms spent in bootstraps)
24/04/14 17:30:10.366 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:63522/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-11ff8928-2268-4097-b738-954081439a84\userFiles-2358e5b1-f4b0-400f-9548-9acc46766441\fetchFileTemp3766881699594006508.tmp
24/04/14 17:30:10.529 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-11ff8928-2268-4097-b738-954081439a84/userFiles-2358e5b1-f4b0-400f-9548-9acc46766441/sparklyr-3.0-2.12.jar to class loader
24/04/14 17:30:10.540 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63542.
24/04/14 17:30:10.541 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:63542
24/04/14 17:30:10.542 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/14 17:30:10.567 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 63542, None)
24/04/14 17:30:10.572 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:63542 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 63542, None)
24/04/14 17:30:10.576 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 63542, None)
24/04/14 17:30:10.578 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 63542, None)
24/04/14 17:30:10.936 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/14 17:30:10.945 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/14 17:30:15.086 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/14 17:30:15.219 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/14 17:30:15.553 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/14 17:30:15.741 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/14 17:30:15.742 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/14 17:30:15.742 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/14 17:30:15.790 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/14 17:30:15.946 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/14 17:30:15.947 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/14 17:30:16.972 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/14 17:30:18.411 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/14 17:30:18.414 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/14 17:30:18.492 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/14 17:30:18.492 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/14 17:30:18.518 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/14 17:30:18.643 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/14 17:30:18.645 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/14 17:30:18.682 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/14 17:30:18.801 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 17:30:18.803 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 17:30:18.820 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/14 17:30:18.820 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/14 17:30:18.821 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/14 17:30:18.822 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 17:30:18.822 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 17:30:18.824 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 17:30:18.824 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 17:30:18.825 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 17:30:18.826 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 17:30:19.847 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 232.2976 ms
24/04/14 17:30:20.000 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 17:30:20.008 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,006436 s
24/04/14 17:30:24.661 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/14 17:30:26.332 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.8823 ms
24/04/14 17:30:26.404 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 17:30:26.425 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/14 17:30:26.426 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/14 17:30:26.426 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 17:30:26.428 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 17:30:26.433 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/14 17:30:26.529 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 17:30:26.619 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 17:30:26.626 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 17:30:26.633 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/14 17:30:26.656 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 17:30:26.658 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/14 17:30:26.733 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 17:30:26.753 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/14 17:30:27.341 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 204.2508 ms
24/04/14 17:30:27.366 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1559 bytes result sent to driver
24/04/14 17:30:27.377 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 658 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:30:27.379 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/14 17:30:27.385 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,928 s
24/04/14 17:30:27.388 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:30:27.388 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/14 17:30:27.389 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,985765 s
24/04/14 17:30:27.704 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 231.7126 ms
24/04/14 17:30:32.036 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 17:30:32.058 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 17:30:32.059 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/14 17:30:32.059 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/14 17:30:32.060 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 17:30:32.060 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 17:30:32.062 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/14 17:30:32.071 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 17:30:32.074 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 17:30:32.075 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 17:30:32.075 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/14 17:30:32.076 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 17:30:32.077 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/14 17:30:32.078 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 17:30:32.079 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/14 17:30:32.144 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/14 17:30:32.149 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 71 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:30:32.149 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/14 17:30:32.150 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,087 s
24/04/14 17:30:32.151 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:30:32.151 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/14 17:30:32.151 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,093484 s
24/04/14 17:30:35.072 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 17:30:35.073 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/14 17:30:35.073 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/14 17:30:35.073 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 17:30:35.074 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 17:30:35.075 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at collect at utils.scala:26), which has no missing parents
24/04/14 17:30:35.086 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 56.4 KiB, free 912.2 MiB)
24/04/14 17:30:35.088 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 912.2 MiB)
24/04/14 17:30:35.089 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 13.5 KiB, free: 912.3 MiB)
24/04/14 17:30:35.089 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/14 17:30:35.089 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 17:30:35.090 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/14 17:30:35.103 dispatcher-event-loop-1 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 17:30:35.103 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 17:30:35.104 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/14 17:30:35.333 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 165.4321 ms
24/04/14 17:30:35.375 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 22.1972 ms
24/04/14 17:30:35.394 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1467 bytes result sent to driver
24/04/14 17:30:35.402 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 312 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:30:35.404 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/14 17:30:35.405 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0,329 s
24/04/14 17:30:35.406 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:30:35.406 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/14 17:30:35.407 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0,333197 s
24/04/14 17:30:35.451 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 29.8792 ms
24/04/14 17:30:36.494 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 17:30:36.495 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 17:30:36.534 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/14 17:30:36.534 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/14 17:30:36.535 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/14 17:30:36.535 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/14 17:30:36.626 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 43.3707 ms
24/04/14 17:30:36.659 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.43 ms
24/04/14 17:30:36.673 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.8977 ms
24/04/14 17:33:10.165 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 13.5 KiB, free: 912.3 MiB)
24/04/14 17:33:10.170 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 17:49:17.139 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 17:49:17.141 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
24/04/14 17:49:17.141 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
24/04/14 17:49:17.141 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 17:49:17.142 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 17:49:17.143 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:26), which has no missing parents
24/04/14 17:49:17.148 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 17:49:17.151 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 17:49:17.152 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 17:49:17.152 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
24/04/14 17:49:17.153 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 17:49:17.153 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/14 17:49:17.154 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 17:49:17.156 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/14 17:49:17.195 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1430 bytes result sent to driver
24/04/14 17:49:17.197 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 43 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:49:17.197 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/14 17:49:17.198 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0,054 s
24/04/14 17:49:17.198 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:49:17.199 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/04/14 17:49:17.199 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0,059214 s
24/04/14 17:49:20.303 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 17:49:20.304 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/04/14 17:49:20.304 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
24/04/14 17:49:20.304 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 17:49:20.304 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 17:49:20.307 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at utils.scala:26), which has no missing parents
24/04/14 17:49:20.311 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/14 17:49:20.314 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/14 17:49:20.315 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 17:49:20.315 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
24/04/14 17:49:20.316 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 17:49:20.316 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/04/14 17:49:20.317 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 17:49:20.317 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/04/14 17:49:20.352 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1430 bytes result sent to driver
24/04/14 17:49:20.353 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 36 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:49:20.353 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/04/14 17:49:20.354 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0,046 s
24/04/14 17:49:20.354 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:49:20.354 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/04/14 17:49:20.355 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0,051259 s
24/04/14 17:49:20.428 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 17:49:20.432 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/14 17:49:27.619 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 17:49:27.619 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
24/04/14 17:49:27.620 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
24/04/14 17:49:27.620 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 17:49:27.621 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 17:49:27.623 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[28] at collect at utils.scala:26), which has no missing parents
24/04/14 17:49:27.627 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 123.2 KiB, free 912.2 MiB)
24/04/14 17:49:27.628 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 912.1 MiB)
24/04/14 17:49:27.629 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 31.0 KiB, free: 912.3 MiB)
24/04/14 17:49:27.629 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
24/04/14 17:49:27.630 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[28] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 17:49:27.630 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/04/14 17:49:27.638 dispatcher-event-loop-0 WARN TaskSetManager: Stage 5 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 17:49:27.638 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 17:49:27.638 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/04/14 17:49:28.048 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 686.4 KiB, free 911.5 MiB)
24/04/14 17:49:28.050 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_22_0 in memory on DESKTOP-LH06ASP:63542 (size: 686.4 KiB, free: 911.6 MiB)
24/04/14 17:49:28.062 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 3.6095 ms
24/04/14 17:49:28.204 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 128.8522 ms
24/04/14 17:49:28.994 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 171.9864 ms
24/04/14 17:49:29.019 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 4.8892 ms
24/04/14 17:49:29.162 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 247548 bytes result sent to driver
24/04/14 17:49:29.163 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1533 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:49:29.164 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/04/14 17:49:29.164 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 1,541 s
24/04/14 17:49:29.165 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:49:29.165 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/04/14 17:49:29.165 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 1,546718 s
24/04/14 17:49:29.387 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 108.393 ms
24/04/14 17:49:31.972 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 17:49:31.973 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
24/04/14 17:49:31.973 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
24/04/14 17:49:31.973 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 17:49:31.976 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 17:49:31.977 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[34] at collect at utils.scala:26), which has no missing parents
24/04/14 17:49:31.980 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 123.2 KiB, free 911.4 MiB)
24/04/14 17:49:31.982 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 911.3 MiB)
24/04/14 17:49:31.983 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 31.0 KiB, free: 911.6 MiB)
24/04/14 17:49:31.984 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535
24/04/14 17:49:31.984 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[34] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 17:49:31.984 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
24/04/14 17:49:31.995 dispatcher-event-loop-0 WARN TaskSetManager: Stage 6 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 17:49:31.995 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 17:49:31.996 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/04/14 17:49:32.005 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 17:49:32.098 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 135223 bytes result sent to driver
24/04/14 17:49:32.099 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 112 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:49:32.099 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/04/14 17:49:32.100 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0,123 s
24/04/14 17:49:32.100 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:49:32.101 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
24/04/14 17:49:32.101 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0,128464 s
24/04/14 17:59:25.347 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/14 17:59:26.021 nioEventLoopGroup-2-2 INFO Instrumentation: [ddb82b0a] training finished
24/04/14 17:59:26.730 nioEventLoopGroup-2-2 INFO Instrumentation: [abe5ca82] training finished
24/04/14 17:59:27.361 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 54.8009 ms
24/04/14 17:59:27.439 nioEventLoopGroup-2-2 INFO Instrumentation: [ca1d4a7f] Stage class: RandomForestRegressor
24/04/14 17:59:27.439 nioEventLoopGroup-2-2 INFO Instrumentation: [ca1d4a7f] Stage uid: random_forest__b37e1725_f5c0_415f_bd08_a879e17b9ea5
24/04/14 17:59:27.439 nioEventLoopGroup-2-2 INFO Instrumentation: [ca1d4a7f] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
24/04/14 17:59:27.454 nioEventLoopGroup-2-2 INFO Instrumentation: [ca1d4a7f] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/14 17:59:27.533 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/14 17:59:27.533 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/14 17:59:27.533 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (take at DecisionTreeMetadata.scala:119)
24/04/14 17:59:27.533 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 17:59:27.533 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 17:59:27.533 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[47] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/14 17:59:27.548 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 398.0 KiB, free 911.1 MiB)
24/04/14 17:59:27.548 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 82.7 KiB, free 911.0 MiB)
24/04/14 17:59:27.548 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 82.7 KiB, free: 911.5 MiB)
24/04/14 17:59:27.548 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:27.548 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[47] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:27.548 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
24/04/14 17:59:27.548 dispatcher-event-loop-0 WARN TaskSetManager: Stage 7 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 17:59:27.548 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 17:59:27.548 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
24/04/14 17:59:27.666 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 17:59:27.901 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 107.7892 ms
24/04/14 17:59:27.916 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 5.8131 ms
24/04/14 17:59:27.932 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 6.9661 ms
24/04/14 17:59:27.948 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 5.3364 ms
24/04/14 17:59:27.948 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1657 bytes result sent to driver
24/04/14 17:59:27.948 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 400 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:27.948 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/04/14 17:59:27.963 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (take at DecisionTreeMetadata.scala:119) finished in 0,430 s
24/04/14 17:59:27.963 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:59:27.963 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
24/04/14 17:59:27.963 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: take at DecisionTreeMetadata.scala:119, took 0,425690 s
24/04/14 17:59:27.963 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/14 17:59:27.963 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions
24/04/14 17:59:27.963 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (aggregate at DecisionTreeMetadata.scala:125)
24/04/14 17:59:27.963 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 17:59:27.963 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 17:59:27.963 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[46] at retag at RandomForest.scala:274), which has no missing parents
24/04/14 17:59:27.979 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 398.0 KiB, free 910.6 MiB)
24/04/14 17:59:27.979 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 82.9 KiB, free 910.5 MiB)
24/04/14 17:59:27.979 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 82.9 KiB, free: 911.4 MiB)
24/04/14 17:59:27.979 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:27.979 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[46] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:27.979 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
24/04/14 17:59:27.995 dispatcher-event-loop-1 WARN TaskSetManager: Stage 8 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 17:59:27.995 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 17:59:27.995 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
24/04/14 17:59:28.010 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 17:59:28.423 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 82.7 KiB, free: 911.5 MiB)
24/04/14 17:59:28.423 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/14 17:59:28.516 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1772 bytes result sent to driver
24/04/14 17:59:28.516 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 537 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:28.516 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/04/14 17:59:28.516 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,537 s
24/04/14 17:59:28.516 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:59:28.516 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/04/14 17:59:28.516 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,542233 s
24/04/14 17:59:28.579 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/14 17:59:28.608 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 49 (flatMap at RandomForest.scala:1039) as input to shuffle 0
24/04/14 17:59:28.608 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (collectAsMap at RandomForest.scala:1054) with 1 output partitions
24/04/14 17:59:28.608 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 10 (collectAsMap at RandomForest.scala:1054)
24/04/14 17:59:28.608 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
24/04/14 17:59:28.608 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
24/04/14 17:59:28.608 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[49] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/14 17:59:28.623 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 407.0 KiB, free 910.8 MiB)
24/04/14 17:59:28.623 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 86.5 KiB, free 910.7 MiB)
24/04/14 17:59:28.623 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 86.5 KiB, free: 911.5 MiB)
24/04/14 17:59:28.623 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:28.623 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[49] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:28.633 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
24/04/14 17:59:28.642 dispatcher-event-loop-0 WARN TaskSetManager: Stage 9 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 17:59:28.642 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/14 17:59:28.642 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
24/04/14 17:59:28.697 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 17:59:29.214 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2040 bytes result sent to driver
24/04/14 17:59:29.214 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 581 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:29.214 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
24/04/14 17:59:29.214 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 9 (flatMap at RandomForest.scala:1039) finished in 0,606 s
24/04/14 17:59:29.230 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/14 17:59:29.230 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/14 17:59:29.230 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 10)
24/04/14 17:59:29.230 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/14 17:59:29.234 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[51] at map at RandomForest.scala:1054), which has no missing parents
24/04/14 17:59:29.240 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 11.9 KiB, free 910.7 MiB)
24/04/14 17:59:29.241 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 910.7 MiB)
24/04/14 17:59:29.242 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 4.5 KiB, free: 911.5 MiB)
24/04/14 17:59:29.243 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:29.244 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[51] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:29.244 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
24/04/14 17:59:29.246 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/14 17:59:29.246 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
24/04/14 17:59:29.266 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/14 17:59:29.282 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
24/04/14 17:59:29.344 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 48798 bytes result sent to driver
24/04/14 17:59:29.344 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 99 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:29.344 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
24/04/14 17:59:29.344 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 10 (collectAsMap at RandomForest.scala:1054) finished in 0,106 s
24/04/14 17:59:29.344 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:59:29.344 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
24/04/14 17:59:29.344 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: collectAsMap at RandomForest.scala:1054, took 0,771069 s
24/04/14 17:59:29.360 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 59.3 KiB, free 910.6 MiB)
24/04/14 17:59:29.360 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 910.6 MiB)
24/04/14 17:59:29.360 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 10.1 KiB, free: 911.5 MiB)
24/04/14 17:59:29.360 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 11 from broadcast at RandomForest.scala:293
24/04/14 17:59:29.375 nioEventLoopGroup-2-2 INFO Instrumentation: [ca1d4a7f] {"numFeatures":545}
24/04/14 17:59:29.375 nioEventLoopGroup-2-2 INFO Instrumentation: [ca1d4a7f] {"numClasses":0}
24/04/14 17:59:29.375 nioEventLoopGroup-2-2 INFO Instrumentation: [ca1d4a7f] {"numExamples":1439}
24/04/14 17:59:29.375 nioEventLoopGroup-2-2 INFO Instrumentation: [ca1d4a7f] {"sumOfWeights":1439.0}
24/04/14 17:59:29.395 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.1 KiB, free 910.6 MiB)
24/04/14 17:59:29.398 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 910.6 MiB)
24/04/14 17:59:29.399 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 10.3 KiB, free: 911.4 MiB)
24/04/14 17:59:29.399 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 12 from broadcast at RandomForest.scala:622
24/04/14 17:59:29.428 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/14 17:59:29.428 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 54 (mapPartitions at RandomForest.scala:644) as input to shuffle 1
24/04/14 17:59:29.428 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/14 17:59:29.428 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collectAsMap at RandomForest.scala:663)
24/04/14 17:59:29.428 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
24/04/14 17:59:29.428 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
24/04/14 17:59:29.428 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[54] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/14 17:59:29.443 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 441.6 KiB, free 910.1 MiB)
24/04/14 17:59:29.443 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 99.2 KiB, free 910.0 MiB)
24/04/14 17:59:29.443 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 99.2 KiB, free: 911.3 MiB)
24/04/14 17:59:29.443 dag-scheduler-event-loop INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:29.443 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[54] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:29.443 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
24/04/14 17:59:29.443 dispatcher-event-loop-1 WARN TaskSetManager: Stage 11 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 17:59:29.459 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/14 17:59:29.459 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
24/04/14 17:59:29.475 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 86.5 KiB, free: 911.4 MiB)
24/04/14 17:59:29.484 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 4.5 KiB, free: 911.4 MiB)
24/04/14 17:59:29.484 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 17:59:29.791 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO MemoryStore: Block rdd_53_0 stored as values in memory (estimated size 3.2 MiB, free 907.4 MiB)
24/04/14 17:59:29.791 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_53_0 in memory on DESKTOP-LH06ASP:63542 (size: 3.2 MiB, free: 908.3 MiB)
24/04/14 17:59:29.838 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1954 bytes result sent to driver
24/04/14 17:59:29.838 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 395 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:29.838 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
24/04/14 17:59:29.838 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 11 (mapPartitions at RandomForest.scala:644) finished in 0,410 s
24/04/14 17:59:29.838 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/14 17:59:29.838 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/14 17:59:29.838 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 12)
24/04/14 17:59:29.838 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/14 17:59:29.838 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[56] at map at RandomForest.scala:663), which has no missing parents
24/04/14 17:59:29.838 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.4 KiB, free 907.4 MiB)
24/04/14 17:59:29.853 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 907.4 MiB)
24/04/14 17:59:29.853 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 3.8 KiB, free: 908.3 MiB)
24/04/14 17:59:29.853 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:29.853 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[56] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:29.853 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
24/04/14 17:59:29.853 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/14 17:59:29.853 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
24/04/14 17:59:29.853 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO ShuffleBlockFetcherIterator: Getting 1 (194.1 KiB) non-empty blocks including 1 (194.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/14 17:59:29.853 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/14 17:59:29.963 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 6380 bytes result sent to driver
24/04/14 17:59:29.963 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 110 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:29.963 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
24/04/14 17:59:29.963 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collectAsMap at RandomForest.scala:663) finished in 0,125 s
24/04/14 17:59:29.963 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:59:29.963 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
24/04/14 17:59:29.963 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collectAsMap at RandomForest.scala:663, took 0,544045 s
24/04/14 17:59:29.963 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(12) (from destroy at RandomForest.scala:674)
24/04/14 17:59:29.963 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 10.3 KiB, free: 908.3 MiB)
24/04/14 17:59:29.983 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 32.6 KiB, free 907.4 MiB)
24/04/14 17:59:29.983 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 907.3 MiB)
24/04/14 17:59:29.983 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 20.3 KiB, free: 908.3 MiB)
24/04/14 17:59:29.983 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 15 from broadcast at RandomForest.scala:622
24/04/14 17:59:29.998 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/14 17:59:29.998 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 57 (mapPartitions at RandomForest.scala:644) as input to shuffle 2
24/04/14 17:59:29.998 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/14 17:59:29.998 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (collectAsMap at RandomForest.scala:663)
24/04/14 17:59:29.998 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
24/04/14 17:59:29.998 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
24/04/14 17:59:29.998 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[57] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/14 17:59:30.014 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 462.6 KiB, free 906.9 MiB)
24/04/14 17:59:30.014 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 112.4 KiB, free 906.8 MiB)
24/04/14 17:59:30.014 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 112.4 KiB, free: 908.2 MiB)
24/04/14 17:59:30.014 dag-scheduler-event-loop INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:30.014 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[57] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:30.014 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
24/04/14 17:59:30.029 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 3.8 KiB, free: 908.2 MiB)
24/04/14 17:59:30.029 dispatcher-event-loop-1 WARN TaskSetManager: Stage 13 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 17:59:30.029 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/14 17:59:30.029 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
24/04/14 17:59:30.029 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 99.2 KiB, free: 908.3 MiB)
24/04/14 17:59:30.045 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO BlockManager: Found block rdd_53_0 locally
24/04/14 17:59:30.092 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1911 bytes result sent to driver
24/04/14 17:59:30.092 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 78 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:30.092 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
24/04/14 17:59:30.092 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 13 (mapPartitions at RandomForest.scala:644) finished in 0,094 s
24/04/14 17:59:30.092 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/14 17:59:30.092 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/14 17:59:30.092 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 14)
24/04/14 17:59:30.092 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/14 17:59:30.092 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[59] at map at RandomForest.scala:663), which has no missing parents
24/04/14 17:59:30.092 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 11.1 KiB, free 907.3 MiB)
24/04/14 17:59:30.092 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 907.3 MiB)
24/04/14 17:59:30.092 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 5.2 KiB, free: 908.2 MiB)
24/04/14 17:59:30.108 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:30.108 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[59] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:30.108 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
24/04/14 17:59:30.108 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/14 17:59:30.108 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
24/04/14 17:59:30.108 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO ShuffleBlockFetcherIterator: Getting 1 (312.6 KiB) non-empty blocks including 1 (312.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/14 17:59:30.108 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/14 17:59:30.133 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 10467 bytes result sent to driver
24/04/14 17:59:30.133 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 25 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:30.133 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
24/04/14 17:59:30.133 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (collectAsMap at RandomForest.scala:663) finished in 0,041 s
24/04/14 17:59:30.133 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:59:30.133 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
24/04/14 17:59:30.133 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collectAsMap at RandomForest.scala:663, took 0,135089 s
24/04/14 17:59:30.133 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(15) (from destroy at RandomForest.scala:674)
24/04/14 17:59:30.133 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 20.3 KiB, free: 908.3 MiB)
24/04/14 17:59:30.148 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 57.2 KiB, free 907.3 MiB)
24/04/14 17:59:30.148 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 907.3 MiB)
24/04/14 17:59:30.148 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 35.2 KiB, free: 908.2 MiB)
24/04/14 17:59:30.148 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 18 from broadcast at RandomForest.scala:622
24/04/14 17:59:30.165 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/14 17:59:30.166 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 60 (mapPartitions at RandomForest.scala:644) as input to shuffle 3
24/04/14 17:59:30.166 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/14 17:59:30.167 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 16 (collectAsMap at RandomForest.scala:663)
24/04/14 17:59:30.167 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
24/04/14 17:59:30.167 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
24/04/14 17:59:30.168 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[60] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/14 17:59:30.179 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 495.5 KiB, free 906.8 MiB)
24/04/14 17:59:30.181 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 131.2 KiB, free 906.7 MiB)
24/04/14 17:59:30.181 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 131.2 KiB, free: 908.1 MiB)
24/04/14 17:59:30.182 dag-scheduler-event-loop INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:30.182 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[60] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:30.182 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
24/04/14 17:59:30.187 dispatcher-event-loop-1 WARN TaskSetManager: Stage 15 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 17:59:30.187 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/14 17:59:30.187 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
24/04/14 17:59:30.187 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO BlockManager: Found block rdd_53_0 locally
24/04/14 17:59:30.250 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1868 bytes result sent to driver
24/04/14 17:59:30.251 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 68 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:30.251 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
24/04/14 17:59:30.252 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 15 (mapPartitions at RandomForest.scala:644) finished in 0,083 s
24/04/14 17:59:30.252 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/14 17:59:30.252 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/14 17:59:30.252 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 16)
24/04/14 17:59:30.252 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/14 17:59:30.252 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at map at RandomForest.scala:663), which has no missing parents
24/04/14 17:59:30.253 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 14.0 KiB, free 906.6 MiB)
24/04/14 17:59:30.255 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 906.6 MiB)
24/04/14 17:59:30.255 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 6.0 KiB, free: 908.1 MiB)
24/04/14 17:59:30.256 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:30.256 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:30.256 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
24/04/14 17:59:30.257 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/14 17:59:30.257 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
24/04/14 17:59:30.259 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO ShuffleBlockFetcherIterator: Getting 1 (457.6 KiB) non-empty blocks including 1 (457.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/14 17:59:30.259 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/14 17:59:30.281 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 16724 bytes result sent to driver
24/04/14 17:59:30.281 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 24 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:30.281 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
24/04/14 17:59:30.281 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 16 (collectAsMap at RandomForest.scala:663) finished in 0,029 s
24/04/14 17:59:30.281 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:59:30.281 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
24/04/14 17:59:30.281 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collectAsMap at RandomForest.scala:663, took 0,118004 s
24/04/14 17:59:30.281 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(18) (from destroy at RandomForest.scala:674)
24/04/14 17:59:30.281 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 35.2 KiB, free: 908.1 MiB)
24/04/14 17:59:30.281 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 77.4 KiB, free 906.7 MiB)
24/04/14 17:59:30.281 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 906.6 MiB)
24/04/14 17:59:30.281 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 48.2 KiB, free: 908.1 MiB)
24/04/14 17:59:30.281 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 21 from broadcast at RandomForest.scala:622
24/04/14 17:59:30.297 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/14 17:59:30.297 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 63 (mapPartitions at RandomForest.scala:644) as input to shuffle 4
24/04/14 17:59:30.297 dag-scheduler-event-loop INFO DAGScheduler: Got job 14 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/14 17:59:30.297 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 18 (collectAsMap at RandomForest.scala:663)
24/04/14 17:59:30.297 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
24/04/14 17:59:30.297 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
24/04/14 17:59:30.297 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[63] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/14 17:59:30.312 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 532.4 KiB, free 906.1 MiB)
24/04/14 17:59:30.312 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 149.4 KiB, free 905.9 MiB)
24/04/14 17:59:30.312 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 149.4 KiB, free: 907.9 MiB)
24/04/14 17:59:30.312 dag-scheduler-event-loop INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:30.312 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[63] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:30.312 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
24/04/14 17:59:30.328 dispatcher-event-loop-1 WARN TaskSetManager: Stage 17 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 17:59:30.328 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/14 17:59:30.328 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
24/04/14 17:59:30.328 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO BlockManager: Found block rdd_53_0 locally
24/04/14 17:59:30.359 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 5.2 KiB, free: 907.9 MiB)
24/04/14 17:59:30.359 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 112.4 KiB, free: 908.1 MiB)
24/04/14 17:59:30.375 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 131.2 KiB, free: 908.2 MiB)
24/04/14 17:59:30.375 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 6.0 KiB, free: 908.2 MiB)
24/04/14 17:59:30.406 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1954 bytes result sent to driver
24/04/14 17:59:30.406 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 94 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:30.406 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
24/04/14 17:59:30.422 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 17 (mapPartitions at RandomForest.scala:644) finished in 0,109 s
24/04/14 17:59:30.422 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/14 17:59:30.422 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/14 17:59:30.422 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 18)
24/04/14 17:59:30.422 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/14 17:59:30.422 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[65] at map at RandomForest.scala:663), which has no missing parents
24/04/14 17:59:30.422 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 16.5 KiB, free 907.1 MiB)
24/04/14 17:59:30.422 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 907.1 MiB)
24/04/14 17:59:30.422 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 6.6 KiB, free: 908.2 MiB)
24/04/14 17:59:30.422 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:30.422 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[65] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:30.422 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
24/04/14 17:59:30.422 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/14 17:59:30.422 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
24/04/14 17:59:30.422 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/14 17:59:30.422 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/14 17:59:30.453 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 21950 bytes result sent to driver
24/04/14 17:59:30.453 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 31 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:30.453 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
24/04/14 17:59:30.453 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 18 (collectAsMap at RandomForest.scala:663) finished in 0,031 s
24/04/14 17:59:30.453 dag-scheduler-event-loop INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:59:30.453 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
24/04/14 17:59:30.453 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 14 finished: collectAsMap at RandomForest.scala:663, took 0,152434 s
24/04/14 17:59:30.453 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(21) (from destroy at RandomForest.scala:674)
24/04/14 17:59:30.453 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 48.2 KiB, free: 908.2 MiB)
24/04/14 17:59:30.453 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 71.7 KiB, free 907.2 MiB)
24/04/14 17:59:30.468 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 44.5 KiB, free 907.1 MiB)
24/04/14 17:59:30.468 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 44.5 KiB, free: 908.2 MiB)
24/04/14 17:59:30.468 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 24 from broadcast at RandomForest.scala:622
24/04/14 17:59:30.468 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/14 17:59:30.468 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 66 (mapPartitions at RandomForest.scala:644) as input to shuffle 5
24/04/14 17:59:30.468 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/14 17:59:30.468 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 20 (collectAsMap at RandomForest.scala:663)
24/04/14 17:59:30.468 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
24/04/14 17:59:30.468 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
24/04/14 17:59:30.484 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[66] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/14 17:59:30.484 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 552.2 KiB, free 906.6 MiB)
24/04/14 17:59:30.484 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 152.3 KiB, free 906.4 MiB)
24/04/14 17:59:30.484 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 152.3 KiB, free: 908.0 MiB)
24/04/14 17:59:30.484 dag-scheduler-event-loop INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:30.484 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[66] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:30.484 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
24/04/14 17:59:30.500 dispatcher-event-loop-1 WARN TaskSetManager: Stage 19 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 17:59:30.500 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/14 17:59:30.500 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
24/04/14 17:59:30.516 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO BlockManager: Found block rdd_53_0 locally
24/04/14 17:59:30.563 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1911 bytes result sent to driver
24/04/14 17:59:30.563 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 79 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:30.563 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
24/04/14 17:59:30.563 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 19 (mapPartitions at RandomForest.scala:644) finished in 0,079 s
24/04/14 17:59:30.563 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/14 17:59:30.563 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/14 17:59:30.563 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 20)
24/04/14 17:59:30.563 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/14 17:59:30.563 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[68] at map at RandomForest.scala:663), which has no missing parents
24/04/14 17:59:30.563 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 15.8 KiB, free 906.4 MiB)
24/04/14 17:59:30.563 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 906.4 MiB)
24/04/14 17:59:30.563 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 6.3 KiB, free: 908.0 MiB)
24/04/14 17:59:30.563 dag-scheduler-event-loop INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:30.563 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[68] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:30.563 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
24/04/14 17:59:30.563 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/14 17:59:30.563 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
24/04/14 17:59:30.563 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO ShuffleBlockFetcherIterator: Getting 1 (457.6 KiB) non-empty blocks including 1 (457.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/14 17:59:30.563 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/14 17:59:30.594 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 20483 bytes result sent to driver
24/04/14 17:59:30.594 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 31 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:30.594 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
24/04/14 17:59:30.594 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 20 (collectAsMap at RandomForest.scala:663) finished in 0,031 s
24/04/14 17:59:30.594 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:59:30.594 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
24/04/14 17:59:30.594 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collectAsMap at RandomForest.scala:663, took 0,116703 s
24/04/14 17:59:30.594 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(24) (from destroy at RandomForest.scala:674)
24/04/14 17:59:30.594 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/14 17:59:30.594 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_24_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 44.5 KiB, free: 908.1 MiB)
24/04/14 17:59:30.594 nioEventLoopGroup-2-2 INFO RandomForest:   init: 0.0039227
  total: 1.2203433
  findBestSplits: 1.1840316
  chooseSplits: 1.1761299
24/04/14 17:59:30.594 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 53 from persistence list
24/04/14 17:59:30.610 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(11) (from destroy at RandomForest.scala:305)
24/04/14 17:59:30.610 block-manager-storage-async-thread-pool-84 INFO BlockManager: Removing RDD 53
24/04/14 17:59:30.610 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 10.1 KiB, free: 911.2 MiB)
24/04/14 17:59:30.610 nioEventLoopGroup-2-2 INFO Instrumentation: [ca1d4a7f] {"numFeatures":545}
24/04/14 17:59:30.625 nioEventLoopGroup-2-2 INFO Instrumentation: [ca1d4a7f] training finished
24/04/14 17:59:30.625 nioEventLoopGroup-2-2 INFO Instrumentation: [4f30f4b8] training finished
24/04/14 17:59:31.078 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_26_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 6.3 KiB, free: 911.2 MiB)
24/04/14 17:59:31.078 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_25_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 152.3 KiB, free: 911.4 MiB)
24/04/14 17:59:31.078 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 6.6 KiB, free: 911.4 MiB)
24/04/14 17:59:31.140 nioEventLoopGroup-2-2 INFO Instrumentation: [ad9dccfd] training finished
24/04/14 17:59:32.256 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 17:59:32.257 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collect at utils.scala:26) with 1 output partitions
24/04/14 17:59:32.257 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:26)
24/04/14 17:59:32.257 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 17:59:32.257 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 17:59:32.258 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[71] at collect at utils.scala:26), which has no missing parents
24/04/14 17:59:32.261 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 62.5 KiB, free 910.4 MiB)
24/04/14 17:59:32.262 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.4 MiB)
24/04/14 17:59:32.262 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 12.7 KiB, free: 911.4 MiB)
24/04/14 17:59:32.263 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1535
24/04/14 17:59:32.263 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[71] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 17:59:32.263 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
24/04/14 17:59:32.264 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 17:59:32.264 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
24/04/14 17:59:32.295 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO CodeGenerator: Code generated in 20.2196 ms
24/04/14 17:59:32.311 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1430 bytes result sent to driver
24/04/14 17:59:32.311 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 47 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 17:59:32.311 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
24/04/14 17:59:32.311 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 21 (collect at utils.scala:26) finished in 0,052 s
24/04/14 17:59:32.311 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 17:59:32.311 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
24/04/14 17:59:32.311 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collect at utils.scala:26, took 0,058209 s
24/04/14 17:59:32.436 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/14 17:59:32.436 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 105.3228 ms
24/04/14 18:00:11.149 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 149.4 KiB, free: 911.5 MiB)
24/04/14 18:00:11.164 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 82.9 KiB, free: 911.6 MiB)
24/04/14 18:00:11.164 block-manager-storage-async-thread-pool-20 INFO BlockManager: Removing RDD 53
24/04/14 18:15:50.777 nioEventLoopGroup-2-2 INFO Instrumentation: [37f18b88] training finished
24/04/14 18:15:50.839 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 477.8 KiB, free 911.2 MiB)
24/04/14 18:15:50.855 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 911.1 MiB)
24/04/14 18:15:50.855 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 37.4 KiB, free: 911.6 MiB)
24/04/14 18:15:50.855 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 28 from broadcast at RandomForestRegressor.scala:238
24/04/14 18:15:50.902 nioEventLoopGroup-2-2 INFO Instrumentation: [784f0b1e] training finished
24/04/14 18:15:51.901 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:15:51.901 dag-scheduler-event-loop INFO DAGScheduler: Got job 17 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:15:51.901 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:26)
24/04/14 18:15:51.901 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:15:51.901 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:15:51.901 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[74] at collect at utils.scala:26), which has no missing parents
24/04/14 18:15:51.901 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 62.6 KiB, free 911.1 MiB)
24/04/14 18:15:51.901 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.1 MiB)
24/04/14 18:15:51.901 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 12.7 KiB, free: 911.6 MiB)
24/04/14 18:15:51.901 dag-scheduler-event-loop INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1535
24/04/14 18:15:51.901 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[74] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:15:51.901 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
24/04/14 18:15:51.917 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 18:15:51.917 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
24/04/14 18:15:51.948 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO CodeGenerator: Code generated in 19.0768 ms
24/04/14 18:15:51.948 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1430 bytes result sent to driver
24/04/14 18:15:51.964 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 63 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:15:51.964 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
24/04/14 18:15:51.964 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 22 (collect at utils.scala:26) finished in 0,063 s
24/04/14 18:15:51.964 dag-scheduler-event-loop INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:15:51.964 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
24/04/14 18:15:51.964 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 17 finished: collect at utils.scala:26, took 0,055151 s
24/04/14 18:15:52.058 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 55.8078 ms
24/04/14 18:15:56.562 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:15:56.562 dag-scheduler-event-loop INFO DAGScheduler: Got job 18 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:15:56.562 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:26)
24/04/14 18:15:56.562 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:15:56.562 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:15:56.562 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[82] at collect at utils.scala:26), which has no missing parents
24/04/14 18:15:56.577 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 452.7 KiB, free 910.6 MiB)
24/04/14 18:15:56.577 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 910.5 MiB)
24/04/14 18:15:56.577 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 90.5 KiB, free: 911.5 MiB)
24/04/14 18:15:56.577 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1535
24/04/14 18:15:56.577 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[82] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:15:56.577 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
24/04/14 18:15:56.609 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_29_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/14 18:15:56.609 dispatcher-event-loop-1 WARN TaskSetManager: Stage 23 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 18:15:56.609 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 18:15:56.609 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
24/04/14 18:15:56.624 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 18:15:56.884 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO CodeGenerator: Code generated in 99.5138 ms
24/04/14 18:15:56.993 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO CodeGenerator: Code generated in 72.6996 ms
24/04/14 18:15:57.118 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 138396 bytes result sent to driver
24/04/14 18:15:57.118 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 541 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:15:57.118 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
24/04/14 18:15:57.118 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 23 (collect at utils.scala:26) finished in 0,556 s
24/04/14 18:15:57.118 dag-scheduler-event-loop INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:15:57.118 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
24/04/14 18:15:57.118 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 18 finished: collect at utils.scala:26, took 0,560069 s
24/04/14 18:15:57.259 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 71.1064 ms
24/04/14 18:16:58.324 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:16:58.324 dag-scheduler-event-loop INFO DAGScheduler: Got job 19 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:16:58.324 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:26)
24/04/14 18:16:58.324 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:16:58.324 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:16:58.339 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[90] at collect at utils.scala:26), which has no missing parents
24/04/14 18:16:58.339 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 452.7 KiB, free 910.2 MiB)
24/04/14 18:16:58.339 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 910.1 MiB)
24/04/14 18:16:58.339 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 90.5 KiB, free: 911.4 MiB)
24/04/14 18:16:58.339 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1535
24/04/14 18:16:58.339 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[90] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:16:58.339 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
24/04/14 18:16:58.371 dispatcher-event-loop-0 WARN TaskSetManager: Stage 24 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 18:16:58.371 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 18:16:58.371 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
24/04/14 18:16:58.371 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 18:16:58.692 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 138353 bytes result sent to driver
24/04/14 18:16:58.692 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 353 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:16:58.692 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
24/04/14 18:16:58.692 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 24 (collect at utils.scala:26) finished in 0,353 s
24/04/14 18:16:58.692 dag-scheduler-event-loop INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:16:58.692 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
24/04/14 18:16:58.692 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 19 finished: collect at utils.scala:26, took 0,356532 s
24/04/14 18:17:26.428 nioEventLoopGroup-2-2 INFO Instrumentation: [661f9b75] training finished
24/04/14 18:17:26.484 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 477.8 KiB, free 909.6 MiB)
24/04/14 18:17:26.486 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 909.6 MiB)
24/04/14 18:17:26.501 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 37.4 KiB, free: 911.4 MiB)
24/04/14 18:17:26.501 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 32 from broadcast at RandomForestRegressor.scala:238
24/04/14 18:17:26.548 nioEventLoopGroup-2-2 INFO Instrumentation: [fad32b85] training finished
24/04/14 18:17:27.500 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:17:27.500 dag-scheduler-event-loop INFO DAGScheduler: Got job 20 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:17:27.500 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:26)
24/04/14 18:17:27.500 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:17:27.500 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:17:27.500 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[93] at collect at utils.scala:26), which has no missing parents
24/04/14 18:17:27.516 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 62.6 KiB, free 909.5 MiB)
24/04/14 18:17:27.521 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.5 MiB)
24/04/14 18:17:27.521 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 12.7 KiB, free: 911.4 MiB)
24/04/14 18:17:27.521 dag-scheduler-event-loop INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1535
24/04/14 18:17:27.521 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[93] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:17:27.521 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
24/04/14 18:17:27.521 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 18:17:27.521 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
24/04/14 18:17:27.532 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1430 bytes result sent to driver
24/04/14 18:17:27.547 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 26 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:17:27.547 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
24/04/14 18:17:27.547 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 25 (collect at utils.scala:26) finished in 0,047 s
24/04/14 18:17:27.547 dag-scheduler-event-loop INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:17:27.547 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
24/04/14 18:17:27.547 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 20 finished: collect at utils.scala:26, took 0,035309 s
24/04/14 18:17:27.594 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_33_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/14 18:17:33.665 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:17:33.666 dag-scheduler-event-loop INFO DAGScheduler: Got job 21 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:17:33.666 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 26 (collect at utils.scala:26)
24/04/14 18:17:33.666 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:17:33.666 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:17:33.668 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[101] at collect at utils.scala:26), which has no missing parents
24/04/14 18:17:33.694 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 452.9 KiB, free 909.1 MiB)
24/04/14 18:17:33.696 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 90.6 KiB, free 909.0 MiB)
24/04/14 18:17:33.696 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 90.6 KiB, free: 911.3 MiB)
24/04/14 18:17:33.696 dag-scheduler-event-loop INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1535
24/04/14 18:17:33.697 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[101] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:17:33.697 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
24/04/14 18:17:33.704 dispatcher-event-loop-0 WARN TaskSetManager: Stage 26 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 18:17:33.704 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 18:17:33.705 Executor task launch worker for task 0.0 in stage 26.0 (TID 26) INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
24/04/14 18:17:33.726 Executor task launch worker for task 0.0 in stage 26.0 (TID 26) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 18:17:33.992 Executor task launch worker for task 0.0 in stage 26.0 (TID 26) INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2307 bytes result sent to driver
24/04/14 18:17:33.992 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 295 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:17:33.992 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
24/04/14 18:17:33.992 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 26 (collect at utils.scala:26) finished in 0,324 s
24/04/14 18:17:33.992 dag-scheduler-event-loop INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:17:33.992 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
24/04/14 18:17:33.992 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 21 finished: collect at utils.scala:26, took 0,331467 s
24/04/14 18:21:34.600 nioEventLoopGroup-2-2 INFO Instrumentation: [b9fbdfa7] training finished
24/04/14 18:21:34.647 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 477.8 KiB, free 908.6 MiB)
24/04/14 18:21:34.663 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 908.5 MiB)
24/04/14 18:21:34.663 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 37.4 KiB, free: 911.3 MiB)
24/04/14 18:21:34.663 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 35 from broadcast at RandomForestRegressor.scala:238
24/04/14 18:21:34.738 nioEventLoopGroup-2-2 INFO Instrumentation: [725d9c8a] training finished
24/04/14 18:21:35.925 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:21:35.925 dag-scheduler-event-loop INFO DAGScheduler: Got job 22 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:21:35.925 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:26)
24/04/14 18:21:35.925 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:21:35.925 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:21:35.925 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[104] at collect at utils.scala:26), which has no missing parents
24/04/14 18:21:35.940 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 62.6 KiB, free 908.5 MiB)
24/04/14 18:21:35.940 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 908.5 MiB)
24/04/14 18:21:35.940 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 12.7 KiB, free: 911.2 MiB)
24/04/14 18:21:35.940 dag-scheduler-event-loop INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1535
24/04/14 18:21:35.940 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[104] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:21:35.940 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
24/04/14 18:21:35.940 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 18:21:35.940 Executor task launch worker for task 0.0 in stage 27.0 (TID 27) INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
24/04/14 18:21:35.956 Executor task launch worker for task 0.0 in stage 27.0 (TID 27) INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 1430 bytes result sent to driver
24/04/14 18:21:35.956 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:21:35.956 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
24/04/14 18:21:35.956 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 27 (collect at utils.scala:26) finished in 0,031 s
24/04/14 18:21:35.956 dag-scheduler-event-loop INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:21:35.956 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
24/04/14 18:21:35.956 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 22 finished: collect at utils.scala:26, took 0,031304 s
24/04/14 18:21:42.350 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 12.7 KiB, free: 911.3 MiB)
24/04/14 18:21:42.350 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:21:42.350 dag-scheduler-event-loop INFO DAGScheduler: Got job 23 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:21:42.350 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:26)
24/04/14 18:21:42.350 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:21:42.350 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:21:42.350 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[112] at collect at utils.scala:26), which has no missing parents
24/04/14 18:21:42.381 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 452.9 KiB, free 908.1 MiB)
24/04/14 18:21:42.381 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 90.6 KiB, free 908.0 MiB)
24/04/14 18:21:42.381 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 90.6 KiB, free: 911.2 MiB)
24/04/14 18:21:42.381 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1535
24/04/14 18:21:42.381 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[112] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:21:42.381 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
24/04/14 18:21:42.397 dispatcher-event-loop-1 WARN TaskSetManager: Stage 28 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 18:21:42.397 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 18:21:42.397 Executor task launch worker for task 0.0 in stage 28.0 (TID 28) INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
24/04/14 18:21:42.413 Executor task launch worker for task 0.0 in stage 28.0 (TID 28) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 18:21:42.600 Executor task launch worker for task 0.0 in stage 28.0 (TID 28) INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 2221 bytes result sent to driver
24/04/14 18:21:42.600 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 203 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:21:42.600 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
24/04/14 18:21:42.600 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 28 (collect at utils.scala:26) finished in 0,250 s
24/04/14 18:21:42.600 dag-scheduler-event-loop INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:21:42.600 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
24/04/14 18:21:42.600 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 23 finished: collect at utils.scala:26, took 0,245092 s
24/04/14 18:21:46.537 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 90.6 KiB, free: 911.3 MiB)
24/04/14 18:21:46.677 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:21:46.677 dag-scheduler-event-loop INFO DAGScheduler: Got job 24 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:21:46.678 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:26)
24/04/14 18:21:46.678 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:21:46.678 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:21:46.678 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[120] at collect at utils.scala:26), which has no missing parents
24/04/14 18:21:46.686 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 452.7 KiB, free 908.1 MiB)
24/04/14 18:21:46.688 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 908.0 MiB)
24/04/14 18:21:46.689 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 90.5 KiB, free: 911.2 MiB)
24/04/14 18:21:46.689 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1535
24/04/14 18:21:46.689 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[120] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:21:46.689 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
24/04/14 18:21:46.696 dispatcher-event-loop-0 WARN TaskSetManager: Stage 29 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 18:21:46.696 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 18:21:46.697 Executor task launch worker for task 0.0 in stage 29.0 (TID 29) INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
24/04/14 18:21:46.701 Executor task launch worker for task 0.0 in stage 29.0 (TID 29) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 18:21:47.080 Executor task launch worker for task 0.0 in stage 29.0 (TID 29) INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 138396 bytes result sent to driver
24/04/14 18:21:47.110 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 420 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:21:47.110 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
24/04/14 18:21:47.110 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 29 (collect at utils.scala:26) finished in 0,431 s
24/04/14 18:21:47.110 dag-scheduler-event-loop INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:21:47.110 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
24/04/14 18:21:47.110 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 24 finished: collect at utils.scala:26, took 0,434419 s
24/04/14 18:21:47.151 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_38_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 90.5 KiB, free: 911.3 MiB)
24/04/14 18:29:56.037 nioEventLoopGroup-2-2 INFO Instrumentation: [0a52126d] training finished
24/04/14 18:29:56.101 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 477.8 KiB, free 908.1 MiB)
24/04/14 18:29:56.104 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 908.0 MiB)
24/04/14 18:29:56.104 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 37.4 KiB, free: 911.2 MiB)
24/04/14 18:29:56.105 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 39 from broadcast at RandomForestRegressor.scala:238
24/04/14 18:29:56.161 nioEventLoopGroup-2-2 INFO Instrumentation: [e9dce56d] training finished
24/04/14 18:29:57.372 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:29:57.372 dag-scheduler-event-loop INFO DAGScheduler: Got job 25 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:29:57.373 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:26)
24/04/14 18:29:57.373 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:29:57.373 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:29:57.376 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[123] at collect at utils.scala:26), which has no missing parents
24/04/14 18:29:57.379 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 62.6 KiB, free 908.0 MiB)
24/04/14 18:29:57.382 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 908.0 MiB)
24/04/14 18:29:57.384 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 12.7 KiB, free: 911.2 MiB)
24/04/14 18:29:57.384 dag-scheduler-event-loop INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1535
24/04/14 18:29:57.385 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[123] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:29:57.385 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
24/04/14 18:29:57.386 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 18:29:57.387 Executor task launch worker for task 0.0 in stage 30.0 (TID 30) INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
24/04/14 18:29:57.425 Executor task launch worker for task 0.0 in stage 30.0 (TID 30) INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 1430 bytes result sent to driver
24/04/14 18:29:57.426 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 41 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:29:57.426 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
24/04/14 18:29:57.426 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 30 (collect at utils.scala:26) finished in 0,049 s
24/04/14 18:29:57.427 dag-scheduler-event-loop INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:29:57.427 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
24/04/14 18:29:57.427 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 25 finished: collect at utils.scala:26, took 0,054696 s
24/04/14 18:29:57.519 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_40_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 12.7 KiB, free: 911.2 MiB)
24/04/14 18:30:08.358 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:30:08.358 dag-scheduler-event-loop INFO DAGScheduler: Got job 26 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:30:08.360 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:26)
24/04/14 18:30:08.360 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:30:08.360 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:30:08.362 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[131] at collect at utils.scala:26), which has no missing parents
24/04/14 18:30:08.418 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 452.9 KiB, free 907.6 MiB)
24/04/14 18:30:08.420 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 90.6 KiB, free 907.5 MiB)
24/04/14 18:30:08.420 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 90.6 KiB, free: 911.1 MiB)
24/04/14 18:30:08.420 dag-scheduler-event-loop INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1535
24/04/14 18:30:08.421 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[131] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:30:08.421 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
24/04/14 18:30:08.434 dispatcher-event-loop-0 WARN TaskSetManager: Stage 31 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 18:30:08.434 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 18:30:08.435 Executor task launch worker for task 0.0 in stage 31.0 (TID 31) INFO Executor: Running task 0.0 in stage 31.0 (TID 31)
24/04/14 18:30:08.447 Executor task launch worker for task 0.0 in stage 31.0 (TID 31) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 18:30:08.725 Executor task launch worker for task 0.0 in stage 31.0 (TID 31) INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 2264 bytes result sent to driver
24/04/14 18:30:08.726 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 305 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:30:08.726 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
24/04/14 18:30:08.726 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 31 (collect at utils.scala:26) finished in 0,363 s
24/04/14 18:30:08.727 dag-scheduler-event-loop INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:30:08.727 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
24/04/14 18:30:08.727 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 26 finished: collect at utils.scala:26, took 0,367943 s
24/04/14 18:30:11.267 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 90.5 KiB, free: 911.2 MiB)
24/04/14 18:30:11.270 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_41_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 90.6 KiB, free: 911.3 MiB)
24/04/14 18:30:11.273 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_34_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 90.6 KiB, free: 911.4 MiB)
24/04/14 18:30:11.277 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 90.5 KiB, free: 911.5 MiB)
24/04/14 18:30:14.629 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:30:14.629 dag-scheduler-event-loop INFO DAGScheduler: Got job 27 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:30:14.629 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:26)
24/04/14 18:30:14.629 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:30:14.630 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:30:14.631 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[139] at collect at utils.scala:26), which has no missing parents
24/04/14 18:30:14.638 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 452.7 KiB, free 909.2 MiB)
24/04/14 18:30:14.639 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 909.1 MiB)
24/04/14 18:30:14.640 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 90.5 KiB, free: 911.4 MiB)
24/04/14 18:30:14.640 dag-scheduler-event-loop INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1535
24/04/14 18:30:14.641 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[139] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:30:14.641 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
24/04/14 18:30:14.649 dispatcher-event-loop-0 WARN TaskSetManager: Stage 32 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 18:30:14.649 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 18:30:14.650 Executor task launch worker for task 0.0 in stage 32.0 (TID 32) INFO Executor: Running task 0.0 in stage 32.0 (TID 32)
24/04/14 18:30:14.660 Executor task launch worker for task 0.0 in stage 32.0 (TID 32) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 18:30:15.723 Executor task launch worker for task 0.0 in stage 32.0 (TID 32) INFO Executor: Finished task 0.0 in stage 32.0 (TID 32). 138396 bytes result sent to driver
24/04/14 18:30:15.726 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 1085 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:30:15.726 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
24/04/14 18:30:15.727 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 32 (collect at utils.scala:26) finished in 1,096 s
24/04/14 18:30:15.727 dag-scheduler-event-loop INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:30:15.728 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
24/04/14 18:30:15.728 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 27 finished: collect at utils.scala:26, took 1,099030 s
24/04/14 18:32:19.627 nioEventLoopGroup-2-2 INFO Instrumentation: [e9e7ddf1] training finished
24/04/14 18:32:19.674 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 477.8 KiB, free 908.6 MiB)
24/04/14 18:32:19.674 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 908.6 MiB)
24/04/14 18:32:19.674 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 37.4 KiB, free: 911.4 MiB)
24/04/14 18:32:19.674 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 43 from broadcast at RandomForestRegressor.scala:238
24/04/14 18:32:19.721 nioEventLoopGroup-2-2 INFO Instrumentation: [f688d7eb] training finished
24/04/14 18:32:19.846 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_42_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 90.5 KiB, free: 911.4 MiB)
24/04/14 18:32:20.998 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:32:20.999 dag-scheduler-event-loop INFO DAGScheduler: Got job 28 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:32:20.999 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:26)
24/04/14 18:32:20.999 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:32:20.999 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:32:21.000 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[142] at collect at utils.scala:26), which has no missing parents
24/04/14 18:32:21.004 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 62.6 KiB, free 909.1 MiB)
24/04/14 18:32:21.008 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.0 MiB)
24/04/14 18:32:21.008 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 12.7 KiB, free: 911.4 MiB)
24/04/14 18:32:21.009 dag-scheduler-event-loop INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1535
24/04/14 18:32:21.009 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[142] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:32:21.010 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
24/04/14 18:32:21.011 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/14 18:32:21.012 Executor task launch worker for task 0.0 in stage 33.0 (TID 33) INFO Executor: Running task 0.0 in stage 33.0 (TID 33)
24/04/14 18:32:21.053 Executor task launch worker for task 0.0 in stage 33.0 (TID 33) INFO Executor: Finished task 0.0 in stage 33.0 (TID 33). 1430 bytes result sent to driver
24/04/14 18:32:21.053 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 42 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:32:21.053 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
24/04/14 18:32:21.053 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 33 (collect at utils.scala:26) finished in 0,052 s
24/04/14 18:32:21.055 dag-scheduler-event-loop INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:32:21.055 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
24/04/14 18:32:21.055 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 28 finished: collect at utils.scala:26, took 0,057076 s
24/04/14 18:32:30.626 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:32:30.627 dag-scheduler-event-loop INFO DAGScheduler: Got job 29 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:32:30.627 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:26)
24/04/14 18:32:30.627 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:32:30.627 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:32:30.628 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[150] at collect at utils.scala:26), which has no missing parents
24/04/14 18:32:30.887 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 452.9 KiB, free 908.6 MiB)
24/04/14 18:32:30.889 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_44_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/14 18:32:30.890 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 90.6 KiB, free 908.6 MiB)
24/04/14 18:32:30.891 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 90.6 KiB, free: 911.4 MiB)
24/04/14 18:32:30.891 dag-scheduler-event-loop INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1535
24/04/14 18:32:30.892 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[150] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:32:30.892 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
24/04/14 18:32:30.916 dispatcher-event-loop-0 WARN TaskSetManager: Stage 34 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 18:32:30.916 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 34) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 18:32:30.917 Executor task launch worker for task 0.0 in stage 34.0 (TID 34) INFO Executor: Running task 0.0 in stage 34.0 (TID 34)
24/04/14 18:32:30.942 Executor task launch worker for task 0.0 in stage 34.0 (TID 34) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 18:32:31.242 Executor task launch worker for task 0.0 in stage 34.0 (TID 34) INFO Executor: Finished task 0.0 in stage 34.0 (TID 34). 2264 bytes result sent to driver
24/04/14 18:32:31.243 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 34) in 349 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:32:31.243 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
24/04/14 18:32:31.243 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 34 (collect at utils.scala:26) finished in 0,613 s
24/04/14 18:32:31.243 dag-scheduler-event-loop INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:32:31.243 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
24/04/14 18:32:31.244 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 29 finished: collect at utils.scala:26, took 0,617088 s
24/04/14 18:32:31.366 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_45_piece0 on DESKTOP-LH06ASP:63542 in memory (size: 90.6 KiB, free: 911.4 MiB)
24/04/14 18:32:41.139 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:32:41.140 dag-scheduler-event-loop INFO DAGScheduler: Got job 30 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:32:41.140 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:26)
24/04/14 18:32:41.140 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:32:41.140 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:32:41.143 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[158] at collect at utils.scala:26), which has no missing parents
24/04/14 18:32:41.158 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 452.7 KiB, free 908.7 MiB)
24/04/14 18:32:41.162 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 908.6 MiB)
24/04/14 18:32:41.163 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 90.5 KiB, free: 911.4 MiB)
24/04/14 18:32:41.165 dag-scheduler-event-loop INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1535
24/04/14 18:32:41.166 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[158] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:32:41.167 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
24/04/14 18:32:41.190 dispatcher-event-loop-0 WARN TaskSetManager: Stage 35 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 18:32:41.190 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 35) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 18:32:41.191 Executor task launch worker for task 0.0 in stage 35.0 (TID 35) INFO Executor: Running task 0.0 in stage 35.0 (TID 35)
24/04/14 18:32:41.218 Executor task launch worker for task 0.0 in stage 35.0 (TID 35) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 18:32:42.941 Executor task launch worker for task 0.0 in stage 35.0 (TID 35) INFO Executor: Finished task 0.0 in stage 35.0 (TID 35). 138439 bytes result sent to driver
24/04/14 18:32:42.942 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 35) in 1773 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:32:42.942 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
24/04/14 18:32:42.943 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 35 (collect at utils.scala:26) finished in 1,799 s
24/04/14 18:32:42.944 dag-scheduler-event-loop INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:32:42.944 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
24/04/14 18:32:42.944 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 30 finished: collect at utils.scala:26, took 1,805962 s
24/04/14 18:32:47.449 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/14 18:32:47.451 dag-scheduler-event-loop INFO DAGScheduler: Got job 31 (collect at utils.scala:26) with 1 output partitions
24/04/14 18:32:47.451 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:26)
24/04/14 18:32:47.451 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/14 18:32:47.452 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/14 18:32:47.453 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[164] at collect at utils.scala:26), which has no missing parents
24/04/14 18:32:47.456 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 123.2 KiB, free 908.5 MiB)
24/04/14 18:32:47.456 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 908.4 MiB)
24/04/14 18:32:47.456 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on DESKTOP-LH06ASP:63542 (size: 31.1 KiB, free: 911.3 MiB)
24/04/14 18:32:47.456 dag-scheduler-event-loop INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1535
24/04/14 18:32:47.462 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[164] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/14 18:32:47.462 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
24/04/14 18:32:47.481 dispatcher-event-loop-1 WARN TaskSetManager: Stage 36 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/14 18:32:47.481 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 36) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/14 18:32:47.486 Executor task launch worker for task 0.0 in stage 36.0 (TID 36) INFO Executor: Running task 0.0 in stage 36.0 (TID 36)
24/04/14 18:32:47.500 Executor task launch worker for task 0.0 in stage 36.0 (TID 36) INFO BlockManager: Found block rdd_22_0 locally
24/04/14 18:32:47.705 Executor task launch worker for task 0.0 in stage 36.0 (TID 36) INFO Executor: Finished task 0.0 in stage 36.0 (TID 36). 135266 bytes result sent to driver
24/04/14 18:32:47.709 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 36) in 243 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/14 18:32:47.709 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
24/04/14 18:32:47.712 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 36 (collect at utils.scala:26) finished in 0,259 s
24/04/14 18:32:47.714 dag-scheduler-event-loop INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/14 18:32:47.714 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
24/04/14 18:32:47.716 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 31 finished: collect at utils.scala:26, took 0,264939 s
24/04/14 18:49:06.203 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/14 18:49:06.207 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/14 18:49:06.243 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/14 18:49:06.270 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/14 18:49:06.393 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/14 18:49:06.393 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/14 18:49:06.397 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/14 18:49:06.403 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/14 18:49:06.409 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-11ff8928-2268-4097-b738-954081439a84\userFiles-2358e5b1-f4b0-400f-9548-9acc46766441
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-11ff8928-2268-4097-b738-954081439a84\userFiles-2358e5b1-f4b0-400f-9548-9acc46766441\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 18:49:06.413 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/14 18:49:06.414 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/14 18:49:06.414 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-11ff8928-2268-4097-b738-954081439a84
24/04/14 18:49:06.418 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-11ff8928-2268-4097-b738-954081439a84
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-11ff8928-2268-4097-b738-954081439a84\userFiles-2358e5b1-f4b0-400f-9548-9acc46766441\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/14 18:49:06.419 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-37cc3b01-9e45-456e-b0d4-bc532b2340e8
24/04/14 18:49:06.421 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-11ff8928-2268-4097-b738-954081439a84\userFiles-2358e5b1-f4b0-400f-9548-9acc46766441
24/04/14 18:49:06.424 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-11ff8928-2268-4097-b738-954081439a84\userFiles-2358e5b1-f4b0-400f-9548-9acc46766441
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-11ff8928-2268-4097-b738-954081439a84\userFiles-2358e5b1-f4b0-400f-9548-9acc46766441\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/15 10:53:00.178 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/15 10:53:00.481 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/15 10:53:00.509 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/15 10:53:00.588 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/15 10:53:00.676 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/15 10:53:00.676 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/15 10:53:00.677 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/15 10:53:00.677 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/15 10:53:00.708 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/15 10:53:00.719 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/15 10:53:00.720 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/15 10:53:00.802 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/15 10:53:00.802 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/15 10:53:00.803 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/15 10:53:00.803 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/15 10:53:00.803 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/15 10:53:00.918 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 65522.
24/04/15 10:53:00.958 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/15 10:53:01.005 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/15 10:53:01.047 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/15 10:53:01.048 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/15 10:53:01.051 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/15 10:53:01.088 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-204d5d87-7637-4354-aea6-36fa112fb2b5
24/04/15 10:53:01.138 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/15 10:53:01.171 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/15 10:53:01.178 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/15 10:53:01.466 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/15 10:53:01.628 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/15 10:53:01.718 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:65522/jars/sparklyr-3.0-2.12.jar with timestamp 1713174780467
24/04/15 10:53:01.837 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/15 10:53:01.846 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/15 10:53:01.859 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:65522/jars/sparklyr-3.0-2.12.jar with timestamp 1713174780467
24/04/15 10:53:01.911 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:65522 after 23 ms (0 ms spent in bootstraps)
24/04/15 10:53:01.919 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:65522/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-fae4c3ac-9c30-4dc3-af1e-396592169716\userFiles-e5e49fe6-3a85-45ed-a8c8-6980080c091f\fetchFileTemp6006342314091991546.tmp
24/04/15 10:53:02.133 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-fae4c3ac-9c30-4dc3-af1e-396592169716/userFiles-e5e49fe6-3a85-45ed-a8c8-6980080c091f/sparklyr-3.0-2.12.jar to class loader
24/04/15 10:53:02.154 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49159.
24/04/15 10:53:02.154 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:49159
24/04/15 10:53:02.156 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/15 10:53:02.168 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 49159, None)
24/04/15 10:53:02.172 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:49159 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 49159, None)
24/04/15 10:53:02.180 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 49159, None)
24/04/15 10:53:02.184 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 49159, None)
24/04/15 10:53:02.695 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/15 10:53:02.704 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/15 10:53:11.232 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/15 10:53:11.552 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/15 10:53:12.264 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/15 10:53:12.686 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/15 10:53:12.690 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/15 10:53:12.690 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/15 10:53:12.814 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/15 10:53:13.247 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/15 10:53:13.249 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/15 10:53:16.501 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/15 10:53:19.684 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/15 10:53:19.690 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/15 10:53:19.930 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/15 10:53:19.930 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/15 10:53:20.036 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/15 10:53:20.450 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/15 10:53:20.456 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/15 10:53:20.556 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/15 10:53:20.824 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 10:53:20.827 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 10:53:20.880 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/15 10:53:20.882 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/15 10:53:20.886 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/15 10:53:20.892 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 10:53:20.893 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 10:53:20.897 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 10:53:20.898 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 10:53:20.899 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/15 10:53:20.899 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/15 10:53:22.947 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 654.6566 ms
24/04/15 10:53:23.260 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:53:23.278 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,014723 s
24/04/15 10:53:33.666 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/15 10:53:37.130 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.6089 ms
24/04/15 10:53:37.334 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:53:37.371 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:53:37.373 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/15 10:53:37.375 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:53:37.383 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:53:37.397 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/15 10:53:37.634 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/15 10:53:37.939 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/15 10:53:37.949 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 10:53:37.966 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/15 10:53:38.014 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:53:38.020 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/15 10:53:38.183 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:53:38.217 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/15 10:53:40.476 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 793.6172 ms
24/04/15 10:53:40.553 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1516 bytes result sent to driver
24/04/15 10:53:40.590 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2439 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:53:40.601 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/15 10:53:40.618 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 3,171 s
24/04/15 10:53:40.624 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:53:40.627 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/15 10:53:40.632 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 3,296687 s
24/04/15 10:53:41.795 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 820.378 ms
24/04/15 10:53:41.797 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 10:53:47.480 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:53:47.480 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:53:47.480 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/15 10:53:47.480 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:53:47.480 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:53:47.480 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/15 10:53:47.497 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/15 10:53:47.501 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/15 10:53:47.504 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 10:53:47.506 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/15 10:53:47.509 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:53:47.510 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/15 10:53:47.513 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:53:47.514 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/15 10:53:47.615 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/15 10:53:47.620 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 107 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:53:47.621 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/15 10:53:47.622 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,135 s
24/04/15 10:53:47.623 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:53:47.623 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/15 10:53:47.626 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,142756 s
24/04/15 10:53:52.081 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:53:52.091 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:53:52.092 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/15 10:53:52.092 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:53:52.093 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:53:52.094 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at collect at utils.scala:26), which has no missing parents
24/04/15 10:53:52.119 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 56.4 KiB, free 912.2 MiB)
24/04/15 10:53:52.120 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 912.2 MiB)
24/04/15 10:53:52.126 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 13.5 KiB, free: 912.3 MiB)
24/04/15 10:53:52.126 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/15 10:53:52.131 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:53:52.131 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/15 10:53:52.183 dispatcher-event-loop-0 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:53:52.184 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 10:53:52.185 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/15 10:53:53.078 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 642.1256 ms
24/04/15 10:53:53.186 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 54.6177 ms
24/04/15 10:53:53.208 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1510 bytes result sent to driver
24/04/15 10:53:53.210 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1074 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:53:53.211 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/15 10:53:53.211 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 1,114 s
24/04/15 10:53:53.211 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:53:53.212 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/15 10:53:53.213 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 1,129773 s
24/04/15 10:53:53.291 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 58.625 ms
24/04/15 10:53:54.372 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 13.5 KiB, free: 912.3 MiB)
24/04/15 10:53:54.396 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 10:53:56.285 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:53:56.288 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:53:56.288 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
24/04/15 10:53:56.288 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:53:56.289 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:53:56.292 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:26), which has no missing parents
24/04/15 10:53:56.302 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/15 10:53:56.308 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/15 10:53:56.308 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 10:53:56.309 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
24/04/15 10:53:56.309 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:53:56.309 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/15 10:53:56.311 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:53:56.311 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/15 10:53:56.378 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1430 bytes result sent to driver
24/04/15 10:53:56.385 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 74 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:53:56.386 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/15 10:53:56.387 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0,091 s
24/04/15 10:53:56.387 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:53:56.388 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/04/15 10:53:56.389 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0,102795 s
24/04/15 10:54:01.577 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:54:01.579 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:54:01.580 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
24/04/15 10:54:01.580 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:54:01.581 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:54:01.583 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at utils.scala:26), which has no missing parents
24/04/15 10:54:01.592 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/15 10:54:01.594 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/15 10:54:01.595 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 10:54:01.598 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:01.599 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:01.599 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/04/15 10:54:01.602 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:54:01.604 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/04/15 10:54:01.704 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1430 bytes result sent to driver
24/04/15 10:54:01.711 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 109 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:01.712 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/04/15 10:54:01.713 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0,129 s
24/04/15 10:54:01.713 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:01.714 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/04/15 10:54:01.714 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0,136762 s
24/04/15 10:54:05.068 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:54:05.070 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:54:05.070 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
24/04/15 10:54:05.070 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:54:05.072 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:54:05.073 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[28] at collect at utils.scala:26), which has no missing parents
24/04/15 10:54:05.078 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 123.2 KiB, free 912.0 MiB)
24/04/15 10:54:05.081 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 912.0 MiB)
24/04/15 10:54:05.086 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 31.0 KiB, free: 912.2 MiB)
24/04/15 10:54:05.086 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:05.086 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[28] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:05.086 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/04/15 10:54:05.174 dispatcher-event-loop-0 WARN TaskSetManager: Stage 5 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:54:05.174 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 10:54:05.175 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/04/15 10:54:05.175 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 10:54:05.195 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 10:54:06.259 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 686.4 KiB, free 911.5 MiB)
24/04/15 10:54:06.272 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_22_0 in memory on DESKTOP-LH06ASP:49159 (size: 686.4 KiB, free: 911.6 MiB)
24/04/15 10:54:06.302 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 8.6784 ms
24/04/15 10:54:06.586 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 263.9279 ms
24/04/15 10:54:07.338 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 543.1224 ms
24/04/15 10:54:07.438 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 22.4347 ms
24/04/15 10:54:07.973 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 247505 bytes result sent to driver
24/04/15 10:54:07.974 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 2888 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:07.974 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/04/15 10:54:07.976 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 2,902 s
24/04/15 10:54:07.976 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:07.977 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/04/15 10:54:07.979 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 2,909804 s
24/04/15 10:54:08.721 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 444.8727 ms
24/04/15 10:54:09.571 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/15 10:54:13.633 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:54:13.635 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:54:13.635 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
24/04/15 10:54:13.635 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:54:13.637 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:54:13.638 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[34] at collect at utils.scala:26), which has no missing parents
24/04/15 10:54:13.644 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 123.2 KiB, free 911.5 MiB)
24/04/15 10:54:13.647 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 911.5 MiB)
24/04/15 10:54:13.648 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 31.0 KiB, free: 911.6 MiB)
24/04/15 10:54:13.649 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:13.650 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[34] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:13.650 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
24/04/15 10:54:13.698 dispatcher-event-loop-0 WARN TaskSetManager: Stage 6 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:54:13.698 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 10:54:13.699 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/04/15 10:54:13.719 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:54:13.946 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 135266 bytes result sent to driver
24/04/15 10:54:13.949 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 265 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:13.950 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/04/15 10:54:13.951 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0,312 s
24/04/15 10:54:13.951 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:13.951 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
24/04/15 10:54:13.952 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0,318458 s
24/04/15 10:54:18.524 nioEventLoopGroup-2-2 INFO Instrumentation: [f2552fdd] training finished
24/04/15 10:54:19.701 nioEventLoopGroup-2-2 INFO Instrumentation: [5bbbd221] training finished
24/04/15 10:54:20.309 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/15 10:54:21.762 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 213.8369 ms
24/04/15 10:54:21.995 nioEventLoopGroup-2-2 INFO Instrumentation: [68da2ff1] Stage class: RandomForestRegressor
24/04/15 10:54:21.996 nioEventLoopGroup-2-2 INFO Instrumentation: [68da2ff1] Stage uid: random_forest__69388d5a_72bd_4e7b_91ce_4259acfe05b6
24/04/15 10:54:21.996 nioEventLoopGroup-2-2 INFO Instrumentation: [68da2ff1] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
24/04/15 10:54:22.037 nioEventLoopGroup-2-2 INFO Instrumentation: [68da2ff1] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/15 10:54:22.365 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/15 10:54:22.365 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/15 10:54:22.365 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (take at DecisionTreeMetadata.scala:119)
24/04/15 10:54:22.365 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:54:22.365 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:54:22.376 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[47] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/15 10:54:22.401 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 398.0 KiB, free 911.2 MiB)
24/04/15 10:54:22.405 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 82.7 KiB, free 911.2 MiB)
24/04/15 10:54:22.412 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 82.7 KiB, free: 911.5 MiB)
24/04/15 10:54:22.412 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:22.416 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[47] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:22.416 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
24/04/15 10:54:22.448 dispatcher-event-loop-0 WARN TaskSetManager: Stage 7 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:54:22.448 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 10:54:22.449 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
24/04/15 10:54:22.799 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:54:24.053 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 652.7709 ms
24/04/15 10:54:24.155 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 43.2585 ms
24/04/15 10:54:24.230 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 25.5727 ms
24/04/15 10:54:24.263 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 13.6424 ms
24/04/15 10:54:24.280 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1700 bytes result sent to driver
24/04/15 10:54:24.291 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 1870 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:24.291 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/04/15 10:54:24.291 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (take at DecisionTreeMetadata.scala:119) finished in 1,912 s
24/04/15 10:54:24.291 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:24.291 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
24/04/15 10:54:24.291 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: take at DecisionTreeMetadata.scala:119, took 1,928406 s
24/04/15 10:54:24.334 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/15 10:54:24.338 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions
24/04/15 10:54:24.339 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (aggregate at DecisionTreeMetadata.scala:125)
24/04/15 10:54:24.339 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:54:24.341 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:54:24.346 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[46] at retag at RandomForest.scala:274), which has no missing parents
24/04/15 10:54:24.373 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 398.0 KiB, free 910.8 MiB)
24/04/15 10:54:24.380 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 82.9 KiB, free 910.7 MiB)
24/04/15 10:54:24.384 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 82.9 KiB, free: 911.5 MiB)
24/04/15 10:54:24.388 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:24.390 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[46] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:24.390 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
24/04/15 10:54:24.446 dispatcher-event-loop-1 WARN TaskSetManager: Stage 8 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:54:24.446 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 10:54:24.451 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
24/04/15 10:54:24.547 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:54:25.838 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 82.7 KiB, free: 911.5 MiB)
24/04/15 10:54:26.476 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1815 bytes result sent to driver
24/04/15 10:54:26.493 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 2100 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:26.494 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/04/15 10:54:26.494 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (aggregate at DecisionTreeMetadata.scala:125) finished in 2,146 s
24/04/15 10:54:26.494 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:26.494 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/04/15 10:54:26.494 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: aggregate at DecisionTreeMetadata.scala:125, took 2,160056 s
24/04/15 10:54:26.724 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/15 10:54:26.796 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 49 (flatMap at RandomForest.scala:1039) as input to shuffle 0
24/04/15 10:54:26.802 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (collectAsMap at RandomForest.scala:1054) with 1 output partitions
24/04/15 10:54:26.802 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 10 (collectAsMap at RandomForest.scala:1054)
24/04/15 10:54:26.803 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
24/04/15 10:54:26.809 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
24/04/15 10:54:26.814 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[49] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/15 10:54:26.836 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 407.0 KiB, free 910.8 MiB)
24/04/15 10:54:26.841 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 86.5 KiB, free 910.7 MiB)
24/04/15 10:54:26.846 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 86.5 KiB, free: 911.5 MiB)
24/04/15 10:54:26.846 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:26.851 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[49] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:26.852 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
24/04/15 10:54:26.870 dispatcher-event-loop-0 WARN TaskSetManager: Stage 9 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:54:26.870 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/15 10:54:26.872 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
24/04/15 10:54:27.050 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:54:29.211 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1997 bytes result sent to driver
24/04/15 10:54:29.213 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 2357 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:29.213 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
24/04/15 10:54:29.214 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 9 (flatMap at RandomForest.scala:1039) finished in 2,396 s
24/04/15 10:54:29.216 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:54:29.216 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:54:29.217 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 10)
24/04/15 10:54:29.217 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:54:29.228 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[51] at map at RandomForest.scala:1054), which has no missing parents
24/04/15 10:54:29.246 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 11.9 KiB, free 910.7 MiB)
24/04/15 10:54:29.248 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 910.7 MiB)
24/04/15 10:54:29.252 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 4.5 KiB, free: 911.5 MiB)
24/04/15 10:54:29.254 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:29.257 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[51] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:29.258 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
24/04/15 10:54:29.266 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 10:54:29.272 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
24/04/15 10:54:29.406 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:54:29.430 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 64 ms
24/04/15 10:54:29.797 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 48841 bytes result sent to driver
24/04/15 10:54:29.803 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 539 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:29.807 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 10 (collectAsMap at RandomForest.scala:1054) finished in 0,562 s
24/04/15 10:54:29.810 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:29.810 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
24/04/15 10:54:29.810 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
24/04/15 10:54:29.812 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: collectAsMap at RandomForest.scala:1054, took 3,086269 s
24/04/15 10:54:29.853 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 59.3 KiB, free 910.6 MiB)
24/04/15 10:54:29.862 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 910.6 MiB)
24/04/15 10:54:29.863 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 10.1 KiB, free: 911.5 MiB)
24/04/15 10:54:29.864 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 11 from broadcast at RandomForest.scala:293
24/04/15 10:54:29.895 nioEventLoopGroup-2-2 INFO Instrumentation: [68da2ff1] {"numFeatures":545}
24/04/15 10:54:29.895 nioEventLoopGroup-2-2 INFO Instrumentation: [68da2ff1] {"numClasses":0}
24/04/15 10:54:29.896 nioEventLoopGroup-2-2 INFO Instrumentation: [68da2ff1] {"numExamples":1439}
24/04/15 10:54:29.897 nioEventLoopGroup-2-2 INFO Instrumentation: [68da2ff1] {"sumOfWeights":1439.0}
24/04/15 10:54:29.932 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.1 KiB, free 910.6 MiB)
24/04/15 10:54:29.937 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 910.6 MiB)
24/04/15 10:54:29.940 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 10.3 KiB, free: 911.4 MiB)
24/04/15 10:54:29.942 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 12 from broadcast at RandomForest.scala:622
24/04/15 10:54:30.028 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/15 10:54:30.032 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 54 (mapPartitions at RandomForest.scala:644) as input to shuffle 1
24/04/15 10:54:30.032 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/15 10:54:30.033 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collectAsMap at RandomForest.scala:663)
24/04/15 10:54:30.033 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
24/04/15 10:54:30.034 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
24/04/15 10:54:30.041 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[54] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/15 10:54:30.097 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 86.5 KiB, free: 911.5 MiB)
24/04/15 10:54:30.108 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 441.6 KiB, free 910.6 MiB)
24/04/15 10:54:30.116 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 99.2 KiB, free 910.5 MiB)
24/04/15 10:54:30.125 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 99.2 KiB, free: 911.4 MiB)
24/04/15 10:54:30.125 dag-scheduler-event-loop INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:30.125 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[54] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:30.125 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
24/04/15 10:54:30.135 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 4.5 KiB, free: 911.4 MiB)
24/04/15 10:54:30.169 dispatcher-event-loop-1 WARN TaskSetManager: Stage 11 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:54:30.170 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/15 10:54:30.171 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
24/04/15 10:54:30.241 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:54:31.424 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO MemoryStore: Block rdd_53_0 stored as values in memory (estimated size 3.2 MiB, free 907.4 MiB)
24/04/15 10:54:31.427 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_53_0 in memory on DESKTOP-LH06ASP:49159 (size: 3.2 MiB, free: 908.3 MiB)
24/04/15 10:54:31.530 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1954 bytes result sent to driver
24/04/15 10:54:31.531 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 1396 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:31.532 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
24/04/15 10:54:31.533 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 11 (mapPartitions at RandomForest.scala:644) finished in 1,488 s
24/04/15 10:54:31.533 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:54:31.533 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:54:31.533 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 12)
24/04/15 10:54:31.533 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:54:31.534 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[56] at map at RandomForest.scala:663), which has no missing parents
24/04/15 10:54:31.536 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.4 KiB, free 907.4 MiB)
24/04/15 10:54:31.538 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 907.4 MiB)
24/04/15 10:54:31.539 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 3.8 KiB, free: 908.3 MiB)
24/04/15 10:54:31.539 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:31.540 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[56] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:31.540 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
24/04/15 10:54:31.541 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 10:54:31.541 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
24/04/15 10:54:31.545 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO ShuffleBlockFetcherIterator: Getting 1 (194.1 KiB) non-empty blocks including 1 (194.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:54:31.546 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/04/15 10:54:31.735 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 6380 bytes result sent to driver
24/04/15 10:54:31.736 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 196 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:31.736 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
24/04/15 10:54:31.736 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collectAsMap at RandomForest.scala:663) finished in 0,201 s
24/04/15 10:54:31.736 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:31.736 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
24/04/15 10:54:31.738 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collectAsMap at RandomForest.scala:663, took 1,708224 s
24/04/15 10:54:31.739 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(12) (from destroy at RandomForest.scala:674)
24/04/15 10:54:31.745 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 10.3 KiB, free: 908.3 MiB)
24/04/15 10:54:31.752 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 32.6 KiB, free 907.4 MiB)
24/04/15 10:54:31.754 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 907.3 MiB)
24/04/15 10:54:31.755 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 20.3 KiB, free: 908.3 MiB)
24/04/15 10:54:31.755 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 15 from broadcast at RandomForest.scala:622
24/04/15 10:54:31.776 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/15 10:54:31.777 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 57 (mapPartitions at RandomForest.scala:644) as input to shuffle 2
24/04/15 10:54:31.777 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/15 10:54:31.777 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (collectAsMap at RandomForest.scala:663)
24/04/15 10:54:31.777 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
24/04/15 10:54:31.777 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
24/04/15 10:54:31.778 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[57] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/15 10:54:31.789 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 462.6 KiB, free 906.9 MiB)
24/04/15 10:54:31.792 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 112.4 KiB, free 906.8 MiB)
24/04/15 10:54:31.792 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 112.4 KiB, free: 908.2 MiB)
24/04/15 10:54:31.793 dag-scheduler-event-loop INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:31.793 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[57] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:31.793 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
24/04/15 10:54:31.803 dispatcher-event-loop-1 WARN TaskSetManager: Stage 13 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:54:31.803 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/15 10:54:31.804 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
24/04/15 10:54:31.825 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO BlockManager: Found block rdd_53_0 locally
24/04/15 10:54:31.971 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1954 bytes result sent to driver
24/04/15 10:54:31.972 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 178 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:31.972 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
24/04/15 10:54:31.973 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 13 (mapPartitions at RandomForest.scala:644) finished in 0,194 s
24/04/15 10:54:31.973 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:54:31.973 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:54:31.973 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 14)
24/04/15 10:54:31.973 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:54:31.974 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[59] at map at RandomForest.scala:663), which has no missing parents
24/04/15 10:54:31.977 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 11.1 KiB, free 906.8 MiB)
24/04/15 10:54:31.978 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 906.8 MiB)
24/04/15 10:54:31.979 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.2 KiB, free: 908.1 MiB)
24/04/15 10:54:31.979 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:31.980 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[59] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:31.980 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
24/04/15 10:54:31.981 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 10:54:31.981 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
24/04/15 10:54:31.986 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO ShuffleBlockFetcherIterator: Getting 1 (312.6 KiB) non-empty blocks including 1 (312.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:54:31.986 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 10:54:32.034 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 10510 bytes result sent to driver
24/04/15 10:54:32.035 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 54 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:32.035 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
24/04/15 10:54:32.036 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (collectAsMap at RandomForest.scala:663) finished in 0,062 s
24/04/15 10:54:32.036 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:32.036 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
24/04/15 10:54:32.037 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collectAsMap at RandomForest.scala:663, took 0,261547 s
24/04/15 10:54:32.038 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(15) (from destroy at RandomForest.scala:674)
24/04/15 10:54:32.051 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 57.2 KiB, free 906.7 MiB)
24/04/15 10:54:32.052 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 20.3 KiB, free: 908.2 MiB)
24/04/15 10:54:32.054 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 906.7 MiB)
24/04/15 10:54:32.055 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 35.2 KiB, free: 908.1 MiB)
24/04/15 10:54:32.056 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 18 from broadcast at RandomForest.scala:622
24/04/15 10:54:32.083 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/15 10:54:32.086 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 60 (mapPartitions at RandomForest.scala:644) as input to shuffle 3
24/04/15 10:54:32.086 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/15 10:54:32.086 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 16 (collectAsMap at RandomForest.scala:663)
24/04/15 10:54:32.086 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
24/04/15 10:54:32.087 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
24/04/15 10:54:32.088 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[60] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/15 10:54:32.103 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 495.5 KiB, free 906.2 MiB)
24/04/15 10:54:32.106 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 131.2 KiB, free 906.1 MiB)
24/04/15 10:54:32.107 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 131.2 KiB, free: 908.0 MiB)
24/04/15 10:54:32.108 dag-scheduler-event-loop INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:32.109 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[60] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:32.109 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
24/04/15 10:54:32.136 dispatcher-event-loop-1 WARN TaskSetManager: Stage 15 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:54:32.137 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/15 10:54:32.137 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
24/04/15 10:54:32.163 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO BlockManager: Found block rdd_53_0 locally
24/04/15 10:54:32.292 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1954 bytes result sent to driver
24/04/15 10:54:32.294 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 171 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:32.294 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
24/04/15 10:54:32.295 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 15 (mapPartitions at RandomForest.scala:644) finished in 0,206 s
24/04/15 10:54:32.295 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:54:32.295 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:54:32.296 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 16)
24/04/15 10:54:32.296 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:54:32.296 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at map at RandomForest.scala:663), which has no missing parents
24/04/15 10:54:32.298 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 14.0 KiB, free 906.1 MiB)
24/04/15 10:54:32.300 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 906.1 MiB)
24/04/15 10:54:32.302 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 6.0 KiB, free: 908.0 MiB)
24/04/15 10:54:32.302 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:32.303 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:32.303 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
24/04/15 10:54:32.304 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 10:54:32.305 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
24/04/15 10:54:32.309 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO ShuffleBlockFetcherIterator: Getting 1 (457.6 KiB) non-empty blocks including 1 (457.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:54:32.309 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 10:54:32.353 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 16681 bytes result sent to driver
24/04/15 10:54:32.354 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 50 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:32.354 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
24/04/15 10:54:32.355 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 16 (collectAsMap at RandomForest.scala:663) finished in 0,057 s
24/04/15 10:54:32.355 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:32.355 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
24/04/15 10:54:32.355 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collectAsMap at RandomForest.scala:663, took 0,271633 s
24/04/15 10:54:32.356 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(18) (from destroy at RandomForest.scala:674)
24/04/15 10:54:32.358 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 35.2 KiB, free: 908.0 MiB)
24/04/15 10:54:32.371 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 77.4 KiB, free 906.1 MiB)
24/04/15 10:54:32.378 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 48.2 KiB, free 906.1 MiB)
24/04/15 10:54:32.378 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 48.2 KiB, free: 908.0 MiB)
24/04/15 10:54:32.378 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 112.4 KiB, free: 908.1 MiB)
24/04/15 10:54:32.378 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 21 from broadcast at RandomForest.scala:622
24/04/15 10:54:32.392 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 131.2 KiB, free: 908.2 MiB)
24/04/15 10:54:32.399 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.2 KiB, free: 908.2 MiB)
24/04/15 10:54:32.405 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 99.2 KiB, free: 908.3 MiB)
24/04/15 10:54:32.409 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 3.8 KiB, free: 908.3 MiB)
24/04/15 10:54:32.412 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 6.0 KiB, free: 908.3 MiB)
24/04/15 10:54:32.413 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/15 10:54:32.414 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 63 (mapPartitions at RandomForest.scala:644) as input to shuffle 4
24/04/15 10:54:32.415 dag-scheduler-event-loop INFO DAGScheduler: Got job 14 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/15 10:54:32.415 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 18 (collectAsMap at RandomForest.scala:663)
24/04/15 10:54:32.415 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
24/04/15 10:54:32.415 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
24/04/15 10:54:32.416 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[63] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/15 10:54:32.424 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 532.4 KiB, free 907.3 MiB)
24/04/15 10:54:32.426 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 149.4 KiB, free 907.1 MiB)
24/04/15 10:54:32.427 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 149.4 KiB, free: 908.2 MiB)
24/04/15 10:54:32.427 dag-scheduler-event-loop INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:32.430 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[63] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:32.430 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
24/04/15 10:54:32.439 dispatcher-event-loop-1 WARN TaskSetManager: Stage 17 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:54:32.439 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/15 10:54:32.440 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
24/04/15 10:54:32.457 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO BlockManager: Found block rdd_53_0 locally
24/04/15 10:54:32.531 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1954 bytes result sent to driver
24/04/15 10:54:32.532 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 102 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:32.532 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
24/04/15 10:54:32.533 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 17 (mapPartitions at RandomForest.scala:644) finished in 0,116 s
24/04/15 10:54:32.533 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:54:32.533 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:54:32.533 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 18)
24/04/15 10:54:32.533 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:54:32.534 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[65] at map at RandomForest.scala:663), which has no missing parents
24/04/15 10:54:32.536 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 16.5 KiB, free 907.1 MiB)
24/04/15 10:54:32.537 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 907.1 MiB)
24/04/15 10:54:32.538 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 6.6 KiB, free: 908.2 MiB)
24/04/15 10:54:32.538 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:32.539 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[65] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:32.539 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
24/04/15 10:54:32.539 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 10:54:32.540 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
24/04/15 10:54:32.542 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:54:32.543 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 10:54:32.582 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 21950 bytes result sent to driver
24/04/15 10:54:32.583 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 44 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:32.584 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
24/04/15 10:54:32.584 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 18 (collectAsMap at RandomForest.scala:663) finished in 0,050 s
24/04/15 10:54:32.584 dag-scheduler-event-loop INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:32.584 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
24/04/15 10:54:32.585 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 14 finished: collectAsMap at RandomForest.scala:663, took 0,170921 s
24/04/15 10:54:32.585 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(21) (from destroy at RandomForest.scala:674)
24/04/15 10:54:32.588 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 48.2 KiB, free: 908.2 MiB)
24/04/15 10:54:32.595 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 71.7 KiB, free 907.2 MiB)
24/04/15 10:54:32.597 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 44.5 KiB, free 907.1 MiB)
24/04/15 10:54:32.598 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 44.5 KiB, free: 908.2 MiB)
24/04/15 10:54:32.598 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 24 from broadcast at RandomForest.scala:622
24/04/15 10:54:32.617 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/15 10:54:32.618 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 66 (mapPartitions at RandomForest.scala:644) as input to shuffle 5
24/04/15 10:54:32.618 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/15 10:54:32.618 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 20 (collectAsMap at RandomForest.scala:663)
24/04/15 10:54:32.619 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
24/04/15 10:54:32.619 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
24/04/15 10:54:32.620 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[66] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/15 10:54:32.630 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 552.2 KiB, free 906.6 MiB)
24/04/15 10:54:32.633 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 152.3 KiB, free 906.4 MiB)
24/04/15 10:54:32.634 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 152.3 KiB, free: 908.0 MiB)
24/04/15 10:54:32.634 dag-scheduler-event-loop INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:32.634 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[66] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:32.634 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
24/04/15 10:54:32.644 dispatcher-event-loop-1 WARN TaskSetManager: Stage 19 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:54:32.644 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/15 10:54:32.644 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
24/04/15 10:54:32.664 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO BlockManager: Found block rdd_53_0 locally
24/04/15 10:54:32.722 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1911 bytes result sent to driver
24/04/15 10:54:32.724 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 89 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:32.725 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
24/04/15 10:54:32.725 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 19 (mapPartitions at RandomForest.scala:644) finished in 0,105 s
24/04/15 10:54:32.725 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:54:32.725 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:54:32.725 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 20)
24/04/15 10:54:32.725 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:54:32.726 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[68] at map at RandomForest.scala:663), which has no missing parents
24/04/15 10:54:32.728 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 15.8 KiB, free 906.4 MiB)
24/04/15 10:54:32.729 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 906.4 MiB)
24/04/15 10:54:32.729 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 6.3 KiB, free: 908.0 MiB)
24/04/15 10:54:32.730 dag-scheduler-event-loop INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:32.730 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[68] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:32.730 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
24/04/15 10:54:32.731 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 10:54:32.732 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
24/04/15 10:54:32.735 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO ShuffleBlockFetcherIterator: Getting 1 (457.6 KiB) non-empty blocks including 1 (457.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:54:32.735 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 10:54:32.778 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 20483 bytes result sent to driver
24/04/15 10:54:32.779 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 48 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:32.779 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
24/04/15 10:54:32.780 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 20 (collectAsMap at RandomForest.scala:663) finished in 0,054 s
24/04/15 10:54:32.780 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:32.780 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
24/04/15 10:54:32.780 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collectAsMap at RandomForest.scala:663, took 0,162879 s
24/04/15 10:54:32.781 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(24) (from destroy at RandomForest.scala:674)
24/04/15 10:54:32.782 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_24_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 44.5 KiB, free: 908.1 MiB)
24/04/15 10:54:32.782 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/15 10:54:32.783 nioEventLoopGroup-2-2 INFO RandomForest:   init: 0.0133659
  total: 2.890158
  findBestSplits: 2.8182865
  chooseSplits: 2.8071474
24/04/15 10:54:32.794 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 53 from persistence list
24/04/15 10:54:32.801 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(11) (from destroy at RandomForest.scala:305)
24/04/15 10:54:32.801 block-manager-storage-async-thread-pool-84 INFO BlockManager: Removing RDD 53
24/04/15 10:54:32.803 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 10.1 KiB, free: 911.2 MiB)
24/04/15 10:54:32.818 nioEventLoopGroup-2-2 INFO Instrumentation: [68da2ff1] {"numFeatures":545}
24/04/15 10:54:32.822 nioEventLoopGroup-2-2 INFO Instrumentation: [68da2ff1] training finished
24/04/15 10:54:32.825 nioEventLoopGroup-2-2 INFO Instrumentation: [8b20ea49] training finished
24/04/15 10:54:33.508 nioEventLoopGroup-2-2 INFO Instrumentation: [643d34b4] training finished
24/04/15 10:54:36.245 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 6.6 KiB, free: 911.2 MiB)
24/04/15 10:54:36.251 block-manager-storage-async-thread-pool-93 INFO BlockManager: Removing RDD 53
24/04/15 10:54:36.261 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_26_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 6.3 KiB, free: 911.3 MiB)
24/04/15 10:54:36.277 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_25_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 152.3 KiB, free: 911.4 MiB)
24/04/15 10:54:36.290 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 149.4 KiB, free: 911.5 MiB)
24/04/15 10:54:36.440 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:54:36.445 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:54:36.445 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:26)
24/04/15 10:54:36.445 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:54:36.445 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:54:36.448 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[71] at collect at utils.scala:26), which has no missing parents
24/04/15 10:54:36.448 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 62.5 KiB, free 911.1 MiB)
24/04/15 10:54:36.456 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.1 MiB)
24/04/15 10:54:36.457 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:54:36.458 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:36.458 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[71] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:36.458 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
24/04/15 10:54:36.459 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:54:36.460 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
24/04/15 10:54:36.610 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO CodeGenerator: Code generated in 84.6287 ms
24/04/15 10:54:36.622 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1430 bytes result sent to driver
24/04/15 10:54:36.624 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 165 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:36.624 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
24/04/15 10:54:36.626 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 21 (collect at utils.scala:26) finished in 0,176 s
24/04/15 10:54:36.626 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:36.626 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
24/04/15 10:54:36.627 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collect at utils.scala:26, took 0,181927 s
24/04/15 10:54:36.921 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 210.7487 ms
24/04/15 10:54:42.225 nioEventLoopGroup-2-2 INFO Instrumentation: [24814bcc] training finished
24/04/15 10:54:42.442 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 477.8 KiB, free 910.6 MiB)
24/04/15 10:54:42.589 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 910.6 MiB)
24/04/15 10:54:42.594 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 37.3 KiB, free: 911.5 MiB)
24/04/15 10:54:42.597 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 28 from broadcast at RandomForestRegressor.scala:238
24/04/15 10:54:42.788 nioEventLoopGroup-2-2 INFO Instrumentation: [e2c5ab90] training finished
24/04/15 10:54:44.668 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:54:44.769 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:54:44.770 dag-scheduler-event-loop INFO DAGScheduler: Got job 17 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:54:44.770 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:26)
24/04/15 10:54:44.770 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:54:44.770 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:54:44.771 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[74] at collect at utils.scala:26), which has no missing parents
24/04/15 10:54:44.775 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 62.6 KiB, free 910.6 MiB)
24/04/15 10:54:44.776 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.6 MiB)
24/04/15 10:54:44.777 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:54:44.777 dag-scheduler-event-loop INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:44.778 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[74] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:44.778 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
24/04/15 10:54:44.781 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:54:44.782 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
24/04/15 10:54:45.020 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO CodeGenerator: Code generated in 179.9402 ms
24/04/15 10:54:45.035 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1473 bytes result sent to driver
24/04/15 10:54:45.037 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 257 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:45.037 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
24/04/15 10:54:45.038 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 22 (collect at utils.scala:26) finished in 0,266 s
24/04/15 10:54:45.038 dag-scheduler-event-loop INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:45.038 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
24/04/15 10:54:45.039 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 17 finished: collect at utils.scala:26, took 0,269765 s
24/04/15 10:54:45.310 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 155.6752 ms
24/04/15 10:54:54.841 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:54:54.841 dag-scheduler-event-loop INFO DAGScheduler: Got job 18 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:54:54.842 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:26)
24/04/15 10:54:54.842 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:54:54.842 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:54:54.843 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[82] at collect at utils.scala:26), which has no missing parents
24/04/15 10:54:54.875 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 452.9 KiB, free 910.1 MiB)
24/04/15 10:54:54.876 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 90.6 KiB, free 910.1 MiB)
24/04/15 10:54:54.877 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 90.6 KiB, free: 911.4 MiB)
24/04/15 10:54:54.877 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1535
24/04/15 10:54:54.878 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[82] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:54:54.878 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
24/04/15 10:54:54.885 dispatcher-event-loop-1 WARN TaskSetManager: Stage 23 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:54:54.885 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 10:54:54.886 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
24/04/15 10:54:54.901 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:54:55.099 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_29_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/15 10:54:55.759 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO CodeGenerator: Code generated in 623.1319 ms
24/04/15 10:54:56.324 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO CodeGenerator: Code generated in 260.2915 ms
24/04/15 10:54:56.386 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2264 bytes result sent to driver
24/04/15 10:54:56.387 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 1508 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:54:56.387 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
24/04/15 10:54:56.388 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 23 (collect at utils.scala:26) finished in 1,545 s
24/04/15 10:54:56.389 dag-scheduler-event-loop INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:54:56.389 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
24/04/15 10:54:56.389 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 18 finished: collect at utils.scala:26, took 1,548115 s
24/04/15 10:54:56.908 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 322.6007 ms
24/04/15 10:55:04.838 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:55:04.839 dag-scheduler-event-loop INFO DAGScheduler: Got job 19 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:55:04.839 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:26)
24/04/15 10:55:04.839 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:55:04.840 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:55:04.842 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[90] at collect at utils.scala:26), which has no missing parents
24/04/15 10:55:04.850 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 452.7 KiB, free 909.7 MiB)
24/04/15 10:55:04.854 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 909.6 MiB)
24/04/15 10:55:04.854 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 90.5 KiB, free: 911.3 MiB)
24/04/15 10:55:04.855 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1535
24/04/15 10:55:04.857 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[90] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:55:04.858 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
24/04/15 10:55:04.944 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 90.6 KiB, free: 911.4 MiB)
24/04/15 10:55:04.949 dispatcher-event-loop-0 WARN TaskSetManager: Stage 24 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:55:04.949 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 10:55:04.949 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
24/04/15 10:55:04.966 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:55:06.086 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 138396 bytes result sent to driver
24/04/15 10:55:06.088 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 1229 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:55:06.089 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
24/04/15 10:55:06.090 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 24 (collect at utils.scala:26) finished in 1,247 s
24/04/15 10:55:06.091 dag-scheduler-event-loop INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:55:06.091 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
24/04/15 10:55:06.092 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 19 finished: collect at utils.scala:26, took 1,253121 s
24/04/15 10:55:10.420 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:55:10.420 dag-scheduler-event-loop INFO DAGScheduler: Got job 20 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:55:10.420 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:26)
24/04/15 10:55:10.420 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:55:10.425 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:55:10.427 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[96] at collect at utils.scala:26), which has no missing parents
24/04/15 10:55:10.437 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 123.2 KiB, free 910.0 MiB)
24/04/15 10:55:10.439 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 910.0 MiB)
24/04/15 10:55:10.439 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 31.1 KiB, free: 911.4 MiB)
24/04/15 10:55:10.440 dag-scheduler-event-loop INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1535
24/04/15 10:55:10.440 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[96] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:55:10.440 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
24/04/15 10:55:10.529 dispatcher-event-loop-0 WARN TaskSetManager: Stage 25 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:55:10.529 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 90.5 KiB, free: 911.5 MiB)
24/04/15 10:55:10.529 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 10:55:10.531 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
24/04/15 10:55:10.540 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:55:10.693 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 135223 bytes result sent to driver
24/04/15 10:55:10.697 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 256 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:55:10.698 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
24/04/15 10:55:10.700 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 25 (collect at utils.scala:26) finished in 0,271 s
24/04/15 10:55:10.701 dag-scheduler-event-loop INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:55:10.701 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
24/04/15 10:55:10.701 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 20 finished: collect at utils.scala:26, took 0,280251 s
24/04/15 10:55:15.542 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 17.744 ms
24/04/15 10:55:15.585 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 103 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
24/04/15 10:55:15.585 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:55:15.585 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 26 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:55:15.585 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:55:15.590 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:55:15.592 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[103] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:55:15.612 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 129.6 KiB, free 910.4 MiB)
24/04/15 10:55:15.615 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 910.3 MiB)
24/04/15 10:55:15.621 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 33.9 KiB, free: 911.4 MiB)
24/04/15 10:55:15.622 dag-scheduler-event-loop INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1535
24/04/15 10:55:15.623 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[103] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:55:15.623 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
24/04/15 10:55:15.636 dispatcher-event-loop-1 WARN TaskSetManager: Stage 26 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:55:15.637 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/15 10:55:15.638 Executor task launch worker for task 0.0 in stage 26.0 (TID 26) INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
24/04/15 10:55:15.661 Executor task launch worker for task 0.0 in stage 26.0 (TID 26) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:55:15.924 Executor task launch worker for task 0.0 in stage 26.0 (TID 26) INFO CodeGenerator: Code generated in 29.1623 ms
24/04/15 10:55:16.093 Executor task launch worker for task 0.0 in stage 26.0 (TID 26) INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2395 bytes result sent to driver
24/04/15 10:55:16.094 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 471 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:55:16.094 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
24/04/15 10:55:16.095 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 26 (count at NativeMethodAccessorImpl.java:0) finished in 0,502 s
24/04/15 10:55:16.095 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:55:16.095 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:55:16.095 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/15 10:55:16.095 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:55:16.263 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_32_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 31.1 KiB, free: 911.5 MiB)
24/04/15 10:55:16.270 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_33_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 33.9 KiB, free: 911.5 MiB)
24/04/15 10:55:16.279 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.2262 ms
24/04/15 10:55:16.318 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/15 10:55:16.320 dag-scheduler-event-loop INFO DAGScheduler: Got job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:55:16.320 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 28 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:55:16.320 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
24/04/15 10:55:16.320 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:55:16.324 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:55:16.330 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 12.1 KiB, free 910.6 MiB)
24/04/15 10:55:16.335 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.6 MiB)
24/04/15 10:55:16.335 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:55:16.335 dag-scheduler-event-loop INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1535
24/04/15 10:55:16.340 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:55:16.340 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
24/04/15 10:55:16.340 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 27) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/15 10:55:16.340 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO Executor: Running task 0.0 in stage 28.0 (TID 27)
24/04/15 10:55:16.355 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:55:16.355 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/04/15 10:55:16.370 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO Executor: Finished task 0.0 in stage 28.0 (TID 27). 3909 bytes result sent to driver
24/04/15 10:55:16.370 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 27) in 30 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:55:16.370 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
24/04/15 10:55:16.370 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 0,045 s
24/04/15 10:55:16.370 dag-scheduler-event-loop INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:55:16.370 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
24/04/15 10:55:16.370 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 22 finished: count at NativeMethodAccessorImpl.java:0, took 0,056974 s
24/04/15 10:55:17.411 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 10:55:17.413 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 10:55:17.420 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 10:55:17.420 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 10:55:17.420 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/15 10:55:17.420 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/15 10:55:17.481 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 26.654 ms
24/04/15 10:55:17.540 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.6683 ms
24/04/15 10:55:17.570 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.9439 ms
24/04/15 10:58:14.256 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 113 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
24/04/15 10:58:14.256 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:58:14.256 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 29 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:58:14.256 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:58:14.256 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:58:14.257 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:58:14.260 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 129.6 KiB, free 910.5 MiB)
24/04/15 10:58:14.262 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 910.5 MiB)
24/04/15 10:58:14.262 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 33.9 KiB, free: 911.5 MiB)
24/04/15 10:58:14.262 dag-scheduler-event-loop INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1535
24/04/15 10:58:14.263 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:58:14.263 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
24/04/15 10:58:14.274 dispatcher-event-loop-1 WARN TaskSetManager: Stage 29 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:58:14.274 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 28) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/15 10:58:14.275 Executor task launch worker for task 0.0 in stage 29.0 (TID 28) INFO Executor: Running task 0.0 in stage 29.0 (TID 28)
24/04/15 10:58:14.286 Executor task launch worker for task 0.0 in stage 29.0 (TID 28) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:58:14.378 Executor task launch worker for task 0.0 in stage 29.0 (TID 28) INFO Executor: Finished task 0.0 in stage 29.0 (TID 28). 2395 bytes result sent to driver
24/04/15 10:58:14.378 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 28) in 114 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:58:14.378 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
24/04/15 10:58:14.378 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 29 (count at NativeMethodAccessorImpl.java:0) finished in 0,121 s
24/04/15 10:58:14.378 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:58:14.378 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:58:14.378 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/15 10:58:14.378 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:58:14.394 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO DAGScheduler: Got job 24 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 31 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[116] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 12.1 KiB, free 910.5 MiB)
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.5 MiB)
24/04/15 10:58:14.394 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1535
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[116] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
24/04/15 10:58:14.394 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 29) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/15 10:58:14.394 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO Executor: Running task 0.0 in stage 31.0 (TID 29)
24/04/15 10:58:14.394 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:58:14.394 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 10:58:14.394 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO Executor: Finished task 0.0 in stage 31.0 (TID 29). 3909 bytes result sent to driver
24/04/15 10:58:14.394 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 29) in 0 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:58:14.394 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 31 (count at NativeMethodAccessorImpl.java:0) finished in 0,000 s
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:58:14.394 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
24/04/15 10:58:14.394 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 24 finished: count at NativeMethodAccessorImpl.java:0, took 0,010479 s
24/04/15 10:58:14.648 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.4633 ms
24/04/15 10:58:14.648 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 123 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8
24/04/15 10:58:14.648 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 25 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:58:14.648 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:58:14.648 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:58:14.648 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:58:14.648 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[123] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:58:14.667 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 129.6 KiB, free 910.3 MiB)
24/04/15 10:58:14.667 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 910.3 MiB)
24/04/15 10:58:14.667 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 33.9 KiB, free: 911.4 MiB)
24/04/15 10:58:14.667 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1535
24/04/15 10:58:14.667 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[123] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:58:14.667 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
24/04/15 10:58:14.711 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_35_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 33.9 KiB, free: 911.5 MiB)
24/04/15 10:58:14.711 dispatcher-event-loop-1 WARN TaskSetManager: Stage 32 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:58:14.711 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 30) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/15 10:58:14.711 Executor task launch worker for task 0.0 in stage 32.0 (TID 30) INFO Executor: Running task 0.0 in stage 32.0 (TID 30)
24/04/15 10:58:14.717 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_34_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:58:14.717 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:58:14.717 Executor task launch worker for task 0.0 in stage 32.0 (TID 30) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:58:14.795 Executor task launch worker for task 0.0 in stage 32.0 (TID 30) INFO Executor: Finished task 0.0 in stage 32.0 (TID 30). 2395 bytes result sent to driver
24/04/15 10:58:14.795 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 30) in 128 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:58:14.795 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
24/04/15 10:58:14.795 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0) finished in 0,147 s
24/04/15 10:58:14.795 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:58:14.795 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:58:14.795 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/15 10:58:14.795 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:58:14.811 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/15 10:58:14.811 dag-scheduler-event-loop INFO DAGScheduler: Got job 26 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:58:14.811 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 34 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:58:14.811 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
24/04/15 10:58:14.811 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:58:14.811 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[126] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:58:14.811 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 12.1 KiB, free 910.5 MiB)
24/04/15 10:58:14.811 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.5 MiB)
24/04/15 10:58:14.811 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:58:14.811 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1535
24/04/15 10:58:14.811 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[126] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:58:14.811 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
24/04/15 10:58:14.811 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 31) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/15 10:58:14.811 Executor task launch worker for task 0.0 in stage 34.0 (TID 31) INFO Executor: Running task 0.0 in stage 34.0 (TID 31)
24/04/15 10:58:14.827 Executor task launch worker for task 0.0 in stage 34.0 (TID 31) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:58:14.827 Executor task launch worker for task 0.0 in stage 34.0 (TID 31) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 10:58:14.827 Executor task launch worker for task 0.0 in stage 34.0 (TID 31) INFO Executor: Finished task 0.0 in stage 34.0 (TID 31). 3909 bytes result sent to driver
24/04/15 10:58:14.827 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 31) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:58:14.827 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
24/04/15 10:58:14.827 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 34 (count at NativeMethodAccessorImpl.java:0) finished in 0,016 s
24/04/15 10:58:14.827 dag-scheduler-event-loop INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:58:14.827 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
24/04/15 10:58:14.827 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 26 finished: count at NativeMethodAccessorImpl.java:0, took 0,011299 s
24/04/15 10:58:15.930 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:58:15.930 dag-scheduler-event-loop INFO DAGScheduler: Got job 27 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:58:15.930 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:26)
24/04/15 10:58:15.930 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:58:15.930 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:58:15.931 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[129] at collect at utils.scala:26), which has no missing parents
24/04/15 10:58:15.934 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 62.4 KiB, free 910.4 MiB)
24/04/15 10:58:15.934 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.4 MiB)
24/04/15 10:58:15.935 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:58:15.935 dag-scheduler-event-loop INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1535
24/04/15 10:58:15.936 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[129] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:58:15.936 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
24/04/15 10:58:15.936 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 32) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:58:15.937 Executor task launch worker for task 0.0 in stage 35.0 (TID 32) INFO Executor: Running task 0.0 in stage 35.0 (TID 32)
24/04/15 10:58:15.949 Executor task launch worker for task 0.0 in stage 35.0 (TID 32) INFO Executor: Finished task 0.0 in stage 35.0 (TID 32). 1430 bytes result sent to driver
24/04/15 10:58:15.949 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 32) in 13 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:58:15.949 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
24/04/15 10:58:15.949 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 35 (collect at utils.scala:26) finished in 0,017 s
24/04/15 10:58:15.949 dag-scheduler-event-loop INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:58:15.949 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
24/04/15 10:58:15.949 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 27 finished: collect at utils.scala:26, took 0,030348 s
24/04/15 10:58:19.044 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_38_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:58:19.047 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_39_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:58:19.047 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 33.9 KiB, free: 911.5 MiB)
24/04/15 10:58:19.078 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:58:19.078 dag-scheduler-event-loop INFO DAGScheduler: Got job 28 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:58:19.078 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:26)
24/04/15 10:58:19.078 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:58:19.078 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:58:19.078 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[132] at collect at utils.scala:26), which has no missing parents
24/04/15 10:58:19.078 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 62.4 KiB, free 910.6 MiB)
24/04/15 10:58:19.078 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.6 MiB)
24/04/15 10:58:19.093 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:58:19.093 dag-scheduler-event-loop INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1535
24/04/15 10:58:19.093 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[132] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:58:19.093 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
24/04/15 10:58:19.093 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 33) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:58:19.093 Executor task launch worker for task 0.0 in stage 36.0 (TID 33) INFO Executor: Running task 0.0 in stage 36.0 (TID 33)
24/04/15 10:58:19.109 Executor task launch worker for task 0.0 in stage 36.0 (TID 33) INFO Executor: Finished task 0.0 in stage 36.0 (TID 33). 1430 bytes result sent to driver
24/04/15 10:58:19.109 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 33) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:58:19.109 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
24/04/15 10:58:19.109 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 36 (collect at utils.scala:26) finished in 0,031 s
24/04/15 10:58:19.109 dag-scheduler-event-loop INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:58:19.109 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
24/04/15 10:58:19.109 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 28 finished: collect at utils.scala:26, took 0,028549 s
24/04/15 10:58:36.431 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:58:36.431 dag-scheduler-event-loop INFO DAGScheduler: Got job 29 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:58:36.431 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:26)
24/04/15 10:58:36.431 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:58:36.431 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:58:36.431 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[135] at collect at utils.scala:26), which has no missing parents
24/04/15 10:58:36.431 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 62.4 KiB, free 910.5 MiB)
24/04/15 10:58:36.431 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.5 MiB)
24/04/15 10:58:36.431 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:58:36.431 dag-scheduler-event-loop INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1535
24/04/15 10:58:36.431 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[135] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:58:36.431 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
24/04/15 10:58:36.447 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 34) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:58:36.447 Executor task launch worker for task 0.0 in stage 37.0 (TID 34) INFO Executor: Running task 0.0 in stage 37.0 (TID 34)
24/04/15 10:58:36.462 Executor task launch worker for task 0.0 in stage 37.0 (TID 34) INFO Executor: Finished task 0.0 in stage 37.0 (TID 34). 1430 bytes result sent to driver
24/04/15 10:58:36.462 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 34) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:58:36.462 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
24/04/15 10:58:36.462 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 37 (collect at utils.scala:26) finished in 0,031 s
24/04/15 10:58:36.462 dag-scheduler-event-loop INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:58:36.462 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
24/04/15 10:58:36.462 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 29 finished: collect at utils.scala:26, took 0,035738 s
24/04/15 10:58:39.780 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_41_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:58:39.780 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_40_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:58:39.839 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:58:39.839 dag-scheduler-event-loop INFO DAGScheduler: Got job 30 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:58:39.839 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:26)
24/04/15 10:58:39.839 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:58:39.839 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:58:39.839 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[138] at collect at utils.scala:26), which has no missing parents
24/04/15 10:58:39.839 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 62.4 KiB, free 910.6 MiB)
24/04/15 10:58:39.854 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.6 MiB)
24/04/15 10:58:39.854 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:58:39.854 dag-scheduler-event-loop INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1535
24/04/15 10:58:39.854 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[138] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:58:39.854 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
24/04/15 10:58:39.854 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 35) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:58:39.854 Executor task launch worker for task 0.0 in stage 38.0 (TID 35) INFO Executor: Running task 0.0 in stage 38.0 (TID 35)
24/04/15 10:58:39.886 Executor task launch worker for task 0.0 in stage 38.0 (TID 35) INFO Executor: Finished task 0.0 in stage 38.0 (TID 35). 1430 bytes result sent to driver
24/04/15 10:58:39.887 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 35) in 33 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:58:39.887 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
24/04/15 10:58:39.887 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 38 (collect at utils.scala:26) finished in 0,048 s
24/04/15 10:58:39.888 dag-scheduler-event-loop INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:58:39.888 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
24/04/15 10:58:39.888 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 30 finished: collect at utils.scala:26, took 0,038453 s
24/04/15 10:58:46.060 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_42_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:58:46.091 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:58:46.091 dag-scheduler-event-loop INFO DAGScheduler: Got job 31 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:58:46.091 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:26)
24/04/15 10:58:46.091 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:58:46.091 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:58:46.091 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[141] at collect at utils.scala:26), which has no missing parents
24/04/15 10:58:46.091 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 62.4 KiB, free 910.6 MiB)
24/04/15 10:58:46.107 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.6 MiB)
24/04/15 10:58:46.107 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:58:46.107 dag-scheduler-event-loop INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1535
24/04/15 10:58:46.107 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[141] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:58:46.107 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
24/04/15 10:58:46.107 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 36) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:58:46.107 Executor task launch worker for task 0.0 in stage 39.0 (TID 36) INFO Executor: Running task 0.0 in stage 39.0 (TID 36)
24/04/15 10:58:46.122 Executor task launch worker for task 0.0 in stage 39.0 (TID 36) INFO Executor: Finished task 0.0 in stage 39.0 (TID 36). 1430 bytes result sent to driver
24/04/15 10:58:46.122 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 36) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:58:46.122 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
24/04/15 10:58:46.122 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 39 (collect at utils.scala:26) finished in 0,031 s
24/04/15 10:58:46.122 dag-scheduler-event-loop INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:58:46.122 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
24/04/15 10:58:46.122 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 31 finished: collect at utils.scala:26, took 0,030014 s
24/04/15 10:58:48.885 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.8787 ms
24/04/15 10:58:48.895 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.2174 ms
24/04/15 10:58:48.900 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.3374 ms
24/04/15 10:58:48.932 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 156 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9
24/04/15 10:58:48.932 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 32 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/15 10:58:48.932 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 40 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:58:48.932 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:58:48.932 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:58:48.932 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[156] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:58:48.947 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 226.3 KiB, free 910.4 MiB)
24/04/15 10:58:49.002 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 57.1 KiB, free 910.3 MiB)
24/04/15 10:58:49.002 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 57.1 KiB, free: 911.4 MiB)
24/04/15 10:58:49.002 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_43_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:58:49.002 dag-scheduler-event-loop INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1535
24/04/15 10:58:49.002 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[156] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 10:58:49.002 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 40.0 with 2 tasks resource profile 0
24/04/15 10:58:49.018 dispatcher-event-loop-0 WARN TaskSetManager: Stage 40 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:58:49.018 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 37) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/15 10:58:49.018 Executor task launch worker for task 0.0 in stage 40.0 (TID 37) INFO Executor: Running task 0.0 in stage 40.0 (TID 37)
24/04/15 10:58:49.018 Executor task launch worker for task 0.0 in stage 40.0 (TID 37) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:58:49.103 Executor task launch worker for task 0.0 in stage 40.0 (TID 37) INFO Executor: Finished task 0.0 in stage 40.0 (TID 37). 3011 bytes result sent to driver
24/04/15 10:58:49.118 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 38) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/15 10:58:49.119 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 37) in 117 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 10:58:49.119 Executor task launch worker for task 1.0 in stage 40.0 (TID 38) INFO Executor: Running task 1.0 in stage 40.0 (TID 38)
24/04/15 10:58:49.121 Executor task launch worker for task 1.0 in stage 40.0 (TID 38) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:58:49.203 Executor task launch worker for task 1.0 in stage 40.0 (TID 38) INFO Executor: Finished task 1.0 in stage 40.0 (TID 38). 3011 bytes result sent to driver
24/04/15 10:58:49.203 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 38) in 100 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 10:58:49.203 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
24/04/15 10:58:49.203 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 40 (count at NativeMethodAccessorImpl.java:0) finished in 0,271 s
24/04/15 10:58:49.203 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:58:49.203 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:58:49.203 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/15 10:58:49.203 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:58:49.221 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.7058 ms
24/04/15 10:58:49.234 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/15 10:58:49.235 dag-scheduler-event-loop INFO DAGScheduler: Got job 33 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:58:49.235 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 42 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:58:49.235 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
24/04/15 10:58:49.235 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:58:49.236 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[159] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:58:49.237 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 12.1 KiB, free 910.4 MiB)
24/04/15 10:58:49.237 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.4 MiB)
24/04/15 10:58:49.237 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:58:49.237 dag-scheduler-event-loop INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1535
24/04/15 10:58:49.237 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[159] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:58:49.237 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
24/04/15 10:58:49.237 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 39) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/15 10:58:49.237 Executor task launch worker for task 0.0 in stage 42.0 (TID 39) INFO Executor: Running task 0.0 in stage 42.0 (TID 39)
24/04/15 10:58:49.237 Executor task launch worker for task 0.0 in stage 42.0 (TID 39) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:58:49.237 Executor task launch worker for task 0.0 in stage 42.0 (TID 39) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 10:58:49.237 Executor task launch worker for task 0.0 in stage 42.0 (TID 39) INFO Executor: Finished task 0.0 in stage 42.0 (TID 39). 3866 bytes result sent to driver
24/04/15 10:58:49.237 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 39) in 0 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:58:49.237 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
24/04/15 10:58:49.237 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 42 (count at NativeMethodAccessorImpl.java:0) finished in 0,000 s
24/04/15 10:58:49.237 dag-scheduler-event-loop INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:58:49.237 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
24/04/15 10:58:49.237 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 33 finished: count at NativeMethodAccessorImpl.java:0, took 0,012433 s
24/04/15 10:59:09.737 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 166 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 10
24/04/15 10:59:09.737 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 34 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:59:09.737 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:59:09.737 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:59:09.738 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:09.738 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[166] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:59:09.742 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 129.6 KiB, free 910.2 MiB)
24/04/15 10:59:09.743 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 910.2 MiB)
24/04/15 10:59:09.743 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 33.9 KiB, free: 911.4 MiB)
24/04/15 10:59:09.743 dag-scheduler-event-loop INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:09.744 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[166] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:59:09.744 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
24/04/15 10:59:09.789 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_45_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.8 KiB, free: 911.4 MiB)
24/04/15 10:59:09.789 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_44_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 57.1 KiB, free: 911.5 MiB)
24/04/15 10:59:09.789 dispatcher-event-loop-0 WARN TaskSetManager: Stage 43 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:59:09.789 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 40) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/15 10:59:09.789 Executor task launch worker for task 0.0 in stage 43.0 (TID 40) INFO Executor: Running task 0.0 in stage 43.0 (TID 40)
24/04/15 10:59:09.804 Executor task launch worker for task 0.0 in stage 43.0 (TID 40) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:59:09.898 Executor task launch worker for task 0.0 in stage 43.0 (TID 40) INFO Executor: Finished task 0.0 in stage 43.0 (TID 40). 2395 bytes result sent to driver
24/04/15 10:59:09.898 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 40) in 154 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:59:09.898 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
24/04/15 10:59:09.898 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0) finished in 0,159 s
24/04/15 10:59:09.898 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:59:09.898 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:59:09.898 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/15 10:59:09.898 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:59:09.929 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/15 10:59:09.929 dag-scheduler-event-loop INFO DAGScheduler: Got job 35 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:59:09.929 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 45 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:59:09.929 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
24/04/15 10:59:09.929 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:09.929 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[169] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:59:09.929 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 12.1 KiB, free 910.5 MiB)
24/04/15 10:59:09.929 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.5 MiB)
24/04/15 10:59:09.929 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:59:09.929 dag-scheduler-event-loop INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:09.929 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[169] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:59:09.929 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
24/04/15 10:59:09.929 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 41) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/15 10:59:09.929 Executor task launch worker for task 0.0 in stage 45.0 (TID 41) INFO Executor: Running task 0.0 in stage 45.0 (TID 41)
24/04/15 10:59:09.929 Executor task launch worker for task 0.0 in stage 45.0 (TID 41) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:59:09.929 Executor task launch worker for task 0.0 in stage 45.0 (TID 41) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 10:59:09.945 Executor task launch worker for task 0.0 in stage 45.0 (TID 41) INFO Executor: Finished task 0.0 in stage 45.0 (TID 41). 3866 bytes result sent to driver
24/04/15 10:59:09.945 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 41) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:59:09.945 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
24/04/15 10:59:09.945 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 45 (count at NativeMethodAccessorImpl.java:0) finished in 0,016 s
24/04/15 10:59:09.945 dag-scheduler-event-loop INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:59:09.945 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
24/04/15 10:59:09.945 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 35 finished: count at NativeMethodAccessorImpl.java:0, took 0,009816 s
24/04/15 10:59:10.175 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 176 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 11
24/04/15 10:59:10.175 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 36 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:59:10.175 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 46 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:59:10.175 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:59:10.175 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:10.175 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[176] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:59:10.175 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 129.6 KiB, free 910.4 MiB)
24/04/15 10:59:10.175 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 910.3 MiB)
24/04/15 10:59:10.175 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 33.9 KiB, free: 911.4 MiB)
24/04/15 10:59:10.175 dag-scheduler-event-loop INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:10.175 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[176] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:59:10.175 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
24/04/15 10:59:10.190 dispatcher-event-loop-0 WARN TaskSetManager: Stage 46 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:59:10.190 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 42) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/15 10:59:10.190 Executor task launch worker for task 0.0 in stage 46.0 (TID 42) INFO Executor: Running task 0.0 in stage 46.0 (TID 42)
24/04/15 10:59:10.190 Executor task launch worker for task 0.0 in stage 46.0 (TID 42) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:59:10.284 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_47_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.8 KiB, free: 911.4 MiB)
24/04/15 10:59:10.284 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_46_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 33.9 KiB, free: 911.5 MiB)
24/04/15 10:59:10.335 Executor task launch worker for task 0.0 in stage 46.0 (TID 42) INFO Executor: Finished task 0.0 in stage 46.0 (TID 42). 2438 bytes result sent to driver
24/04/15 10:59:10.335 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 42) in 160 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:59:10.335 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
24/04/15 10:59:10.335 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 46 (count at NativeMethodAccessorImpl.java:0) finished in 0,160 s
24/04/15 10:59:10.335 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:59:10.335 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:59:10.335 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/15 10:59:10.335 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:59:10.347 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO DAGScheduler: Got job 37 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 48 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[179] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 12.1 KiB, free 910.5 MiB)
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.5 MiB)
24/04/15 10:59:10.347 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[179] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
24/04/15 10:59:10.347 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 43) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/15 10:59:10.347 Executor task launch worker for task 0.0 in stage 48.0 (TID 43) INFO Executor: Running task 0.0 in stage 48.0 (TID 43)
24/04/15 10:59:10.347 Executor task launch worker for task 0.0 in stage 48.0 (TID 43) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:59:10.347 Executor task launch worker for task 0.0 in stage 48.0 (TID 43) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 10:59:10.347 Executor task launch worker for task 0.0 in stage 48.0 (TID 43) INFO Executor: Finished task 0.0 in stage 48.0 (TID 43). 3866 bytes result sent to driver
24/04/15 10:59:10.347 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 43) in 0 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:59:10.347 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 48 (count at NativeMethodAccessorImpl.java:0) finished in 0,000 s
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:59:10.347 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
24/04/15 10:59:10.362 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 37 finished: count at NativeMethodAccessorImpl.java:0, took 0,010705 s
24/04/15 10:59:11.448 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:59:11.449 dag-scheduler-event-loop INFO DAGScheduler: Got job 38 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:59:11.449 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 49 (collect at utils.scala:26)
24/04/15 10:59:11.449 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:59:11.449 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:11.450 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[182] at collect at utils.scala:26), which has no missing parents
24/04/15 10:59:11.452 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 62.4 KiB, free 910.4 MiB)
24/04/15 10:59:11.453 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.4 MiB)
24/04/15 10:59:11.453 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:59:11.454 dag-scheduler-event-loop INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:11.456 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[182] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:59:11.456 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
24/04/15 10:59:11.457 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 44) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:59:11.457 Executor task launch worker for task 0.0 in stage 49.0 (TID 44) INFO Executor: Running task 0.0 in stage 49.0 (TID 44)
24/04/15 10:59:11.474 Executor task launch worker for task 0.0 in stage 49.0 (TID 44) INFO Executor: Finished task 0.0 in stage 49.0 (TID 44). 1430 bytes result sent to driver
24/04/15 10:59:11.474 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 44) in 18 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:59:11.474 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
24/04/15 10:59:11.474 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 49 (collect at utils.scala:26) finished in 0,024 s
24/04/15 10:59:11.474 dag-scheduler-event-loop INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:59:11.474 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
24/04/15 10:59:11.474 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 38 finished: collect at utils.scala:26, took 0,036159 s
24/04/15 10:59:14.849 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_49_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:59:14.849 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_50_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:59:14.865 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_48_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 33.9 KiB, free: 911.5 MiB)
24/04/15 10:59:14.943 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:59:14.943 dag-scheduler-event-loop INFO DAGScheduler: Got job 39 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:59:14.943 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 50 (collect at utils.scala:26)
24/04/15 10:59:14.943 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:59:14.943 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:14.943 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[185] at collect at utils.scala:26), which has no missing parents
24/04/15 10:59:14.943 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 62.4 KiB, free 910.6 MiB)
24/04/15 10:59:14.943 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.6 MiB)
24/04/15 10:59:14.943 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:59:14.943 dag-scheduler-event-loop INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:14.943 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[185] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:59:14.943 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
24/04/15 10:59:14.943 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 45) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:59:14.943 Executor task launch worker for task 0.0 in stage 50.0 (TID 45) INFO Executor: Running task 0.0 in stage 50.0 (TID 45)
24/04/15 10:59:14.959 Executor task launch worker for task 0.0 in stage 50.0 (TID 45) INFO Executor: Finished task 0.0 in stage 50.0 (TID 45). 1430 bytes result sent to driver
24/04/15 10:59:14.974 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 45) in 31 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:59:14.974 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
24/04/15 10:59:14.974 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 50 (collect at utils.scala:26) finished in 0,031 s
24/04/15 10:59:14.974 dag-scheduler-event-loop INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:59:14.974 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
24/04/15 10:59:14.974 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 39 finished: collect at utils.scala:26, took 0,028239 s
24/04/15 10:59:31.981 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_51_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:59:32.041 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:59:32.041 dag-scheduler-event-loop INFO DAGScheduler: Got job 40 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:59:32.042 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 51 (collect at utils.scala:26)
24/04/15 10:59:32.042 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:59:32.042 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:32.043 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[188] at collect at utils.scala:26), which has no missing parents
24/04/15 10:59:32.046 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 62.4 KiB, free 910.6 MiB)
24/04/15 10:59:32.047 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.6 MiB)
24/04/15 10:59:32.047 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:59:32.047 dag-scheduler-event-loop INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:32.048 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[188] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:59:32.048 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
24/04/15 10:59:32.048 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 46) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:59:32.049 Executor task launch worker for task 0.0 in stage 51.0 (TID 46) INFO Executor: Running task 0.0 in stage 51.0 (TID 46)
24/04/15 10:59:32.080 Executor task launch worker for task 0.0 in stage 51.0 (TID 46) INFO Executor: Finished task 0.0 in stage 51.0 (TID 46). 1430 bytes result sent to driver
24/04/15 10:59:32.080 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 46) in 32 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:59:32.080 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
24/04/15 10:59:32.080 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 51 (collect at utils.scala:26) finished in 0,037 s
24/04/15 10:59:32.080 dag-scheduler-event-loop INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:59:32.080 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
24/04/15 10:59:32.080 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 40 finished: collect at utils.scala:26, took 0,043923 s
24/04/15 10:59:35.028 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:59:35.028 dag-scheduler-event-loop INFO DAGScheduler: Got job 41 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:59:35.028 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:26)
24/04/15 10:59:35.028 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:59:35.028 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:35.044 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[191] at collect at utils.scala:26), which has no missing parents
24/04/15 10:59:35.044 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 62.4 KiB, free 910.5 MiB)
24/04/15 10:59:35.044 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.5 MiB)
24/04/15 10:59:35.044 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:59:35.044 dag-scheduler-event-loop INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:35.044 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[191] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:59:35.044 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
24/04/15 10:59:35.044 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 47) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:59:35.044 Executor task launch worker for task 0.0 in stage 52.0 (TID 47) INFO Executor: Running task 0.0 in stage 52.0 (TID 47)
24/04/15 10:59:35.059 Executor task launch worker for task 0.0 in stage 52.0 (TID 47) INFO Executor: Finished task 0.0 in stage 52.0 (TID 47). 1430 bytes result sent to driver
24/04/15 10:59:35.059 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 47) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:59:35.059 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
24/04/15 10:59:35.059 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 52 (collect at utils.scala:26) finished in 0,015 s
24/04/15 10:59:35.059 dag-scheduler-event-loop INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:59:35.059 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
24/04/15 10:59:35.059 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 41 finished: collect at utils.scala:26, took 0,028189 s
24/04/15 10:59:35.147 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_53_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:59:35.147 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_52_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:59:41.456 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 10:59:41.456 dag-scheduler-event-loop INFO DAGScheduler: Got job 42 (collect at utils.scala:26) with 1 output partitions
24/04/15 10:59:41.456 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 53 (collect at utils.scala:26)
24/04/15 10:59:41.456 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:59:41.456 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:41.472 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[194] at collect at utils.scala:26), which has no missing parents
24/04/15 10:59:41.472 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 62.4 KiB, free 910.6 MiB)
24/04/15 10:59:41.472 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.6 MiB)
24/04/15 10:59:41.472 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:59:41.472 dag-scheduler-event-loop INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:41.472 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[194] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 10:59:41.472 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
24/04/15 10:59:41.472 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 48) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 10:59:41.472 Executor task launch worker for task 0.0 in stage 53.0 (TID 48) INFO Executor: Running task 0.0 in stage 53.0 (TID 48)
24/04/15 10:59:41.487 Executor task launch worker for task 0.0 in stage 53.0 (TID 48) INFO Executor: Finished task 0.0 in stage 53.0 (TID 48). 1430 bytes result sent to driver
24/04/15 10:59:41.487 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 48) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:59:41.487 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
24/04/15 10:59:41.487 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 53 (collect at utils.scala:26) finished in 0,015 s
24/04/15 10:59:41.487 dag-scheduler-event-loop INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:59:41.487 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
24/04/15 10:59:41.487 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 42 finished: collect at utils.scala:26, took 0,028450 s
24/04/15 10:59:44.158 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_54_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/15 10:59:44.283 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.6047 ms
24/04/15 10:59:44.296 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.1966 ms
24/04/15 10:59:44.309 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 209 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 12
24/04/15 10:59:44.310 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 43 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/15 10:59:44.310 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 54 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:59:44.310 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:59:44.311 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:44.311 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[209] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:59:44.322 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 226.3 KiB, free 910.4 MiB)
24/04/15 10:59:44.323 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 57.1 KiB, free 910.4 MiB)
24/04/15 10:59:44.323 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 57.1 KiB, free: 911.5 MiB)
24/04/15 10:59:44.323 dag-scheduler-event-loop INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:44.324 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[209] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 10:59:44.324 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks resource profile 0
24/04/15 10:59:44.333 dispatcher-event-loop-0 WARN TaskSetManager: Stage 54 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:59:44.333 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 49) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/15 10:59:44.334 Executor task launch worker for task 0.0 in stage 54.0 (TID 49) INFO Executor: Running task 0.0 in stage 54.0 (TID 49)
24/04/15 10:59:44.345 Executor task launch worker for task 0.0 in stage 54.0 (TID 49) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:59:44.461 Executor task launch worker for task 0.0 in stage 54.0 (TID 49) INFO Executor: Finished task 0.0 in stage 54.0 (TID 49). 3011 bytes result sent to driver
24/04/15 10:59:44.471 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 50) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/15 10:59:44.471 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 49) in 147 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 10:59:44.471 Executor task launch worker for task 1.0 in stage 54.0 (TID 50) INFO Executor: Running task 1.0 in stage 54.0 (TID 50)
24/04/15 10:59:44.482 Executor task launch worker for task 1.0 in stage 54.0 (TID 50) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:59:44.660 Executor task launch worker for task 1.0 in stage 54.0 (TID 50) INFO Executor: Finished task 1.0 in stage 54.0 (TID 50). 3054 bytes result sent to driver
24/04/15 10:59:44.660 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 50) in 199 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 10:59:44.660 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
24/04/15 10:59:44.660 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 54 (count at NativeMethodAccessorImpl.java:0) finished in 0,348 s
24/04/15 10:59:44.660 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:59:44.660 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:59:44.660 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/15 10:59:44.660 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:59:44.675 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO DAGScheduler: Got job 44 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 56 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[212] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 12.1 KiB, free 910.4 MiB)
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.4 MiB)
24/04/15 10:59:44.691 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[212] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
24/04/15 10:59:44.691 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 51) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/15 10:59:44.691 Executor task launch worker for task 0.0 in stage 56.0 (TID 51) INFO Executor: Running task 0.0 in stage 56.0 (TID 51)
24/04/15 10:59:44.691 Executor task launch worker for task 0.0 in stage 56.0 (TID 51) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:59:44.691 Executor task launch worker for task 0.0 in stage 56.0 (TID 51) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 10:59:44.691 Executor task launch worker for task 0.0 in stage 56.0 (TID 51) INFO Executor: Finished task 0.0 in stage 56.0 (TID 51). 3909 bytes result sent to driver
24/04/15 10:59:44.691 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 51) in 0 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:59:44.691 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 56 (count at NativeMethodAccessorImpl.java:0) finished in 0,000 s
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:59:44.691 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
24/04/15 10:59:44.691 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 44 finished: count at NativeMethodAccessorImpl.java:0, took 0,014505 s
24/04/15 10:59:45.205 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_56_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:59:45.205 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_55_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 57.1 KiB, free: 911.5 MiB)
24/04/15 10:59:45.220 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.3326 ms
24/04/15 10:59:45.236 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.5894 ms
24/04/15 10:59:45.251 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 227 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 13
24/04/15 10:59:45.251 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 45 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/15 10:59:45.251 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 57 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:59:45.251 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 10:59:45.251 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:45.251 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[227] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:59:45.251 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 226.3 KiB, free 910.4 MiB)
24/04/15 10:59:45.251 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 57.1 KiB, free 910.4 MiB)
24/04/15 10:59:45.251 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 57.1 KiB, free: 911.5 MiB)
24/04/15 10:59:45.251 dag-scheduler-event-loop INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:45.251 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[227] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 10:59:45.251 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 57.0 with 2 tasks resource profile 0
24/04/15 10:59:45.267 dispatcher-event-loop-0 WARN TaskSetManager: Stage 57 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 10:59:45.267 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 52) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/15 10:59:45.267 Executor task launch worker for task 0.0 in stage 57.0 (TID 52) INFO Executor: Running task 0.0 in stage 57.0 (TID 52)
24/04/15 10:59:45.267 Executor task launch worker for task 0.0 in stage 57.0 (TID 52) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:59:45.365 Executor task launch worker for task 0.0 in stage 57.0 (TID 52) INFO Executor: Finished task 0.0 in stage 57.0 (TID 52). 3011 bytes result sent to driver
24/04/15 10:59:45.377 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 53) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/15 10:59:45.377 Executor task launch worker for task 1.0 in stage 57.0 (TID 53) INFO Executor: Running task 1.0 in stage 57.0 (TID 53)
24/04/15 10:59:45.377 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 52) in 126 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 10:59:45.392 Executor task launch worker for task 1.0 in stage 57.0 (TID 53) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 10:59:45.545 Executor task launch worker for task 1.0 in stage 57.0 (TID 53) INFO Executor: Finished task 1.0 in stage 57.0 (TID 53). 3054 bytes result sent to driver
24/04/15 10:59:45.545 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 53) in 180 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 10:59:45.545 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
24/04/15 10:59:45.545 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 57 (count at NativeMethodAccessorImpl.java:0) finished in 0,294 s
24/04/15 10:59:45.545 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 10:59:45.545 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 10:59:45.545 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/15 10:59:45.545 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 10:59:45.561 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/15 10:59:45.561 dag-scheduler-event-loop INFO DAGScheduler: Got job 46 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/15 10:59:45.561 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 59 (count at NativeMethodAccessorImpl.java:0)
24/04/15 10:59:45.561 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
24/04/15 10:59:45.561 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 10:59:45.561 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[230] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/15 10:59:45.561 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 12.1 KiB, free 910.4 MiB)
24/04/15 10:59:45.561 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.4 MiB)
24/04/15 10:59:45.561 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 10:59:45.561 dag-scheduler-event-loop INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1535
24/04/15 10:59:45.561 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[230] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/15 10:59:45.561 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0
24/04/15 10:59:45.575 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 54) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/15 10:59:45.575 Executor task launch worker for task 0.0 in stage 59.0 (TID 54) INFO Executor: Running task 0.0 in stage 59.0 (TID 54)
24/04/15 10:59:45.577 Executor task launch worker for task 0.0 in stage 59.0 (TID 54) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 10:59:45.577 Executor task launch worker for task 0.0 in stage 59.0 (TID 54) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 10:59:45.579 Executor task launch worker for task 0.0 in stage 59.0 (TID 54) INFO Executor: Finished task 0.0 in stage 59.0 (TID 54). 3909 bytes result sent to driver
24/04/15 10:59:45.579 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 54) in 4 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 10:59:45.579 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
24/04/15 10:59:45.579 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 59 (count at NativeMethodAccessorImpl.java:0) finished in 0,018 s
24/04/15 10:59:45.579 dag-scheduler-event-loop INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 10:59:45.579 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
24/04/15 10:59:45.579 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 46 finished: count at NativeMethodAccessorImpl.java:0, took 0,014938 s
24/04/15 11:06:11.426 nioEventLoopGroup-2-2 INFO Instrumentation: [161e4daf] training finished
24/04/15 11:06:11.806 nioEventLoopGroup-2-2 INFO Instrumentation: [dc668f58] training finished
24/04/15 11:06:11.964 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_57_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 57.1 KiB, free: 911.5 MiB)
24/04/15 11:06:11.967 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_58_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/15 11:06:12.455 nioEventLoopGroup-2-2 INFO Instrumentation: [49c2a7ad] Stage class: RandomForestRegressor
24/04/15 11:06:12.455 nioEventLoopGroup-2-2 INFO Instrumentation: [49c2a7ad] Stage uid: random_forest__acd80942_b96b_4faf_920f_32a0156c4be6
24/04/15 11:06:12.455 nioEventLoopGroup-2-2 INFO Instrumentation: [49c2a7ad] training: numPartitions=2 storageLevel=StorageLevel(1 replicas)
24/04/15 11:06:12.455 nioEventLoopGroup-2-2 INFO Instrumentation: [49c2a7ad] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/15 11:06:12.502 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/15 11:06:12.502 dag-scheduler-event-loop INFO DAGScheduler: Got job 47 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/15 11:06:12.502 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 60 (take at DecisionTreeMetadata.scala:119)
24/04/15 11:06:12.502 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 11:06:12.502 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 11:06:12.502 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[253] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/15 11:06:12.518 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 521.9 KiB, free 910.1 MiB)
24/04/15 11:06:12.518 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 117.4 KiB, free 910.0 MiB)
24/04/15 11:06:12.518 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 117.4 KiB, free: 911.4 MiB)
24/04/15 11:06:12.518 dag-scheduler-event-loop INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:12.518 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[253] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/15 11:06:12.518 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
24/04/15 11:06:12.518 dispatcher-event-loop-1 WARN TaskSetManager: Stage 60 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 11:06:12.518 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 55) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/15 11:06:12.534 Executor task launch worker for task 0.0 in stage 60.0 (TID 55) INFO Executor: Running task 0.0 in stage 60.0 (TID 55)
24/04/15 11:06:12.549 Executor task launch worker for task 0.0 in stage 60.0 (TID 55) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 11:06:12.652 Executor task launch worker for task 0.0 in stage 60.0 (TID 55) INFO CodeGenerator: Code generated in 3.3035 ms
24/04/15 11:06:12.730 Executor task launch worker for task 0.0 in stage 60.0 (TID 55) INFO CodeGenerator: Code generated in 56.7947 ms
24/04/15 11:06:12.746 Executor task launch worker for task 0.0 in stage 60.0 (TID 55) INFO Executor: Finished task 0.0 in stage 60.0 (TID 55). 1993 bytes result sent to driver
24/04/15 11:06:12.746 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 55) in 228 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 11:06:12.746 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
24/04/15 11:06:12.746 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 60 (take at DecisionTreeMetadata.scala:119) finished in 0,244 s
24/04/15 11:06:12.746 dag-scheduler-event-loop INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:12.746 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
24/04/15 11:06:12.746 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 47 finished: take at DecisionTreeMetadata.scala:119, took 0,239654 s
24/04/15 11:06:12.746 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/15 11:06:12.746 dag-scheduler-event-loop INFO DAGScheduler: Got job 48 (aggregate at DecisionTreeMetadata.scala:125) with 2 output partitions
24/04/15 11:06:12.746 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 61 (aggregate at DecisionTreeMetadata.scala:125)
24/04/15 11:06:12.746 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 11:06:12.746 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 11:06:12.746 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[252] at retag at RandomForest.scala:274), which has no missing parents
24/04/15 11:06:12.762 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 521.9 KiB, free 909.5 MiB)
24/04/15 11:06:12.762 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 117.6 KiB, free 909.4 MiB)
24/04/15 11:06:12.762 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 117.6 KiB, free: 911.3 MiB)
24/04/15 11:06:12.762 dag-scheduler-event-loop INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:12.762 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 61 (MapPartitionsRDD[252] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:12.762 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 61.0 with 2 tasks resource profile 0
24/04/15 11:06:12.777 dispatcher-event-loop-0 WARN TaskSetManager: Stage 61 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 11:06:12.777 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 56) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/15 11:06:12.777 Executor task launch worker for task 0.0 in stage 61.0 (TID 56) INFO Executor: Running task 0.0 in stage 61.0 (TID 56)
24/04/15 11:06:12.793 Executor task launch worker for task 0.0 in stage 61.0 (TID 56) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 11:06:12.887 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_59_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 117.4 KiB, free: 911.4 MiB)
24/04/15 11:06:12.934 Executor task launch worker for task 0.0 in stage 61.0 (TID 56) INFO Executor: Finished task 0.0 in stage 61.0 (TID 56). 2108 bytes result sent to driver
24/04/15 11:06:12.953 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 57) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818920 bytes) 
24/04/15 11:06:12.954 Executor task launch worker for task 1.0 in stage 61.0 (TID 57) INFO Executor: Running task 1.0 in stage 61.0 (TID 57)
24/04/15 11:06:12.954 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 56) in 192 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:12.964 Executor task launch worker for task 1.0 in stage 61.0 (TID 57) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 11:06:13.016 Executor task launch worker for task 1.0 in stage 61.0 (TID 57) INFO CodeGenerator: Code generated in 2.5259 ms
24/04/15 11:06:13.047 Executor task launch worker for task 1.0 in stage 61.0 (TID 57) INFO Executor: Finished task 1.0 in stage 61.0 (TID 57). 2065 bytes result sent to driver
24/04/15 11:06:13.047 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 57) in 113 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:13.047 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
24/04/15 11:06:13.047 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 61 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,301 s
24/04/15 11:06:13.047 dag-scheduler-event-loop INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:13.047 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
24/04/15 11:06:13.047 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 48 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,297990 s
24/04/15 11:06:13.063 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/15 11:06:13.063 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 255 (flatMap at RandomForest.scala:1039) as input to shuffle 14
24/04/15 11:06:13.063 dag-scheduler-event-loop INFO DAGScheduler: Got job 49 (collectAsMap at RandomForest.scala:1054) with 2 output partitions
24/04/15 11:06:13.063 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 63 (collectAsMap at RandomForest.scala:1054)
24/04/15 11:06:13.063 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
24/04/15 11:06:13.063 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
24/04/15 11:06:13.063 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[255] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/15 11:06:13.078 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 531.0 KiB, free 909.5 MiB)
24/04/15 11:06:13.078 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 121.2 KiB, free 909.4 MiB)
24/04/15 11:06:13.078 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 121.2 KiB, free: 911.3 MiB)
24/04/15 11:06:13.078 dag-scheduler-event-loop INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:13.078 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[255] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:13.078 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 62.0 with 2 tasks resource profile 0
24/04/15 11:06:13.125 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_60_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 117.6 KiB, free: 911.4 MiB)
24/04/15 11:06:13.125 dispatcher-event-loop-1 WARN TaskSetManager: Stage 62 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 11:06:13.125 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 58) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:13.125 Executor task launch worker for task 0.0 in stage 62.0 (TID 58) INFO Executor: Running task 0.0 in stage 62.0 (TID 58)
24/04/15 11:06:13.125 Executor task launch worker for task 0.0 in stage 62.0 (TID 58) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 11:06:13.282 Executor task launch worker for task 0.0 in stage 62.0 (TID 58) INFO Executor: Finished task 0.0 in stage 62.0 (TID 58). 2248 bytes result sent to driver
24/04/15 11:06:13.282 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 59) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:13.282 Executor task launch worker for task 1.0 in stage 62.0 (TID 59) INFO Executor: Running task 1.0 in stage 62.0 (TID 59)
24/04/15 11:06:13.282 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 58) in 204 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:13.297 Executor task launch worker for task 1.0 in stage 62.0 (TID 59) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 11:06:13.713 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 82.9 KiB, free: 911.5 MiB)
24/04/15 11:06:13.862 Executor task launch worker for task 1.0 in stage 62.0 (TID 59) INFO Executor: Finished task 1.0 in stage 62.0 (TID 59). 2291 bytes result sent to driver
24/04/15 11:06:13.863 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 59) in 581 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:13.863 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
24/04/15 11:06:13.863 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 62 (flatMap at RandomForest.scala:1039) finished in 0,800 s
24/04/15 11:06:13.864 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 11:06:13.864 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 11:06:13.864 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 63)
24/04/15 11:06:13.864 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 11:06:13.864 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[257] at map at RandomForest.scala:1054), which has no missing parents
24/04/15 11:06:13.865 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 11.9 KiB, free 910.5 MiB)
24/04/15 11:06:13.866 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 910.5 MiB)
24/04/15 11:06:13.866 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 4.5 KiB, free: 911.5 MiB)
24/04/15 11:06:13.866 dag-scheduler-event-loop INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:13.866 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 63 (MapPartitionsRDD[257] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:13.867 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 63.0 with 2 tasks resource profile 0
24/04/15 11:06:13.867 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 60) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:13.868 Executor task launch worker for task 0.0 in stage 63.0 (TID 60) INFO Executor: Running task 0.0 in stage 63.0 (TID 60)
24/04/15 11:06:13.869 Executor task launch worker for task 0.0 in stage 63.0 (TID 60) INFO ShuffleBlockFetcherIterator: Getting 2 (30.8 KiB) non-empty blocks including 2 (30.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:13.869 Executor task launch worker for task 0.0 in stage 63.0 (TID 60) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:13.895 Executor task launch worker for task 0.0 in stage 63.0 (TID 60) INFO Executor: Finished task 0.0 in stage 63.0 (TID 60). 20610 bytes result sent to driver
24/04/15 11:06:13.896 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 61) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:13.896 Executor task launch worker for task 1.0 in stage 63.0 (TID 61) INFO Executor: Running task 1.0 in stage 63.0 (TID 61)
24/04/15 11:06:13.896 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 60) in 29 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:13.897 Executor task launch worker for task 1.0 in stage 63.0 (TID 61) INFO ShuffleBlockFetcherIterator: Getting 2 (30.1 KiB) non-empty blocks including 2 (30.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:13.897 Executor task launch worker for task 1.0 in stage 63.0 (TID 61) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:13.919 Executor task launch worker for task 1.0 in stage 63.0 (TID 61) INFO Executor: Finished task 1.0 in stage 63.0 (TID 61). 20222 bytes result sent to driver
24/04/15 11:06:13.920 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 61) in 25 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:13.920 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
24/04/15 11:06:13.921 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 63 (collectAsMap at RandomForest.scala:1054) finished in 0,056 s
24/04/15 11:06:13.921 dag-scheduler-event-loop INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:13.921 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
24/04/15 11:06:13.921 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 49 finished: collectAsMap at RandomForest.scala:1054, took 0,850610 s
24/04/15 11:06:13.925 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 46.6 KiB, free 910.4 MiB)
24/04/15 11:06:13.926 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 910.4 MiB)
24/04/15 11:06:13.926 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 7.6 KiB, free: 911.5 MiB)
24/04/15 11:06:13.926 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 63 from broadcast at RandomForest.scala:293
24/04/15 11:06:13.928 nioEventLoopGroup-2-2 INFO Instrumentation: [49c2a7ad] {"numFeatures":545}
24/04/15 11:06:13.928 nioEventLoopGroup-2-2 INFO Instrumentation: [49c2a7ad] {"numClasses":0}
24/04/15 11:06:13.928 nioEventLoopGroup-2-2 INFO Instrumentation: [49c2a7ad] {"numExamples":157}
24/04/15 11:06:13.928 nioEventLoopGroup-2-2 INFO Instrumentation: [49c2a7ad] {"sumOfWeights":157.0}
24/04/15 11:06:13.929 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 16.1 KiB, free 910.4 MiB)
24/04/15 11:06:13.930 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 910.4 MiB)
24/04/15 11:06:13.931 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 10.3 KiB, free: 911.5 MiB)
24/04/15 11:06:13.931 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 64 from broadcast at RandomForest.scala:622
24/04/15 11:06:13.950 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/15 11:06:13.950 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 260 (mapPartitions at RandomForest.scala:644) as input to shuffle 15
24/04/15 11:06:13.951 dag-scheduler-event-loop INFO DAGScheduler: Got job 50 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/15 11:06:13.951 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 65 (collectAsMap at RandomForest.scala:663)
24/04/15 11:06:13.951 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
24/04/15 11:06:13.951 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 64)
24/04/15 11:06:13.952 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[260] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/15 11:06:13.962 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 561.4 KiB, free 909.8 MiB)
24/04/15 11:06:13.963 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 133.5 KiB, free 909.7 MiB)
24/04/15 11:06:13.964 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 133.5 KiB, free: 911.3 MiB)
24/04/15 11:06:13.964 dag-scheduler-event-loop INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:13.965 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[260] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:13.965 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks resource profile 0
24/04/15 11:06:13.973 dispatcher-event-loop-1 WARN TaskSetManager: Stage 64 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 11:06:13.973 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 62) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:13.973 Executor task launch worker for task 0.0 in stage 64.0 (TID 62) INFO Executor: Running task 0.0 in stage 64.0 (TID 62)
24/04/15 11:06:13.990 Executor task launch worker for task 0.0 in stage 64.0 (TID 62) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 11:06:14.118 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_62_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 4.5 KiB, free: 911.3 MiB)
24/04/15 11:06:14.166 Executor task launch worker for task 0.0 in stage 64.0 (TID 62) INFO MemoryStore: Block rdd_259_0 stored as values in memory (estimated size 200.9 KiB, free 909.5 MiB)
24/04/15 11:06:14.166 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_259_0 in memory on DESKTOP-LH06ASP:49159 (size: 200.9 KiB, free: 911.1 MiB)
24/04/15 11:06:14.185 Executor task launch worker for task 0.0 in stage 64.0 (TID 62) INFO Executor: Finished task 0.0 in stage 64.0 (TID 62). 2291 bytes result sent to driver
24/04/15 11:06:14.193 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 63) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:14.193 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 62) in 228 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:14.193 Executor task launch worker for task 1.0 in stage 64.0 (TID 63) INFO Executor: Running task 1.0 in stage 64.0 (TID 63)
24/04/15 11:06:14.209 Executor task launch worker for task 1.0 in stage 64.0 (TID 63) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 11:06:14.315 Executor task launch worker for task 1.0 in stage 64.0 (TID 63) INFO MemoryStore: Block rdd_259_1 stored as values in memory (estimated size 161.6 KiB, free 909.4 MiB)
24/04/15 11:06:14.315 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_259_1 in memory on DESKTOP-LH06ASP:49159 (size: 161.6 KiB, free: 911.0 MiB)
24/04/15 11:06:14.331 Executor task launch worker for task 1.0 in stage 64.0 (TID 63) INFO Executor: Finished task 1.0 in stage 64.0 (TID 63). 2248 bytes result sent to driver
24/04/15 11:06:14.331 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 63) in 145 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:14.331 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
24/04/15 11:06:14.331 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 64 (mapPartitions at RandomForest.scala:644) finished in 0,378 s
24/04/15 11:06:14.331 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 11:06:14.331 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 11:06:14.331 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 65)
24/04/15 11:06:14.331 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 11:06:14.331 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[262] at map at RandomForest.scala:663), which has no missing parents
24/04/15 11:06:14.331 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 7.4 KiB, free 909.4 MiB)
24/04/15 11:06:14.331 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 909.4 MiB)
24/04/15 11:06:14.331 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 3.8 KiB, free: 911.0 MiB)
24/04/15 11:06:14.331 dag-scheduler-event-loop INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:14.331 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 65 (MapPartitionsRDD[262] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:14.331 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 65.0 with 2 tasks resource profile 0
24/04/15 11:06:14.331 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 64) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:14.331 Executor task launch worker for task 0.0 in stage 65.0 (TID 64) INFO Executor: Running task 0.0 in stage 65.0 (TID 64)
24/04/15 11:06:14.331 Executor task launch worker for task 0.0 in stage 65.0 (TID 64) INFO ShuffleBlockFetcherIterator: Getting 2 (92.9 KiB) non-empty blocks including 2 (92.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:14.331 Executor task launch worker for task 0.0 in stage 65.0 (TID 64) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:14.346 Executor task launch worker for task 0.0 in stage 65.0 (TID 64) INFO Executor: Finished task 0.0 in stage 65.0 (TID 64). 4296 bytes result sent to driver
24/04/15 11:06:14.346 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 65) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:14.346 Executor task launch worker for task 1.0 in stage 65.0 (TID 65) INFO Executor: Running task 1.0 in stage 65.0 (TID 65)
24/04/15 11:06:14.346 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 64) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:14.346 Executor task launch worker for task 1.0 in stage 65.0 (TID 65) INFO ShuffleBlockFetcherIterator: Getting 2 (92.9 KiB) non-empty blocks including 2 (92.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:14.346 Executor task launch worker for task 1.0 in stage 65.0 (TID 65) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:14.362 Executor task launch worker for task 1.0 in stage 65.0 (TID 65) INFO Executor: Finished task 1.0 in stage 65.0 (TID 65). 4266 bytes result sent to driver
24/04/15 11:06:14.362 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 65) in 16 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:14.362 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
24/04/15 11:06:14.362 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 65 (collectAsMap at RandomForest.scala:663) finished in 0,031 s
24/04/15 11:06:14.362 dag-scheduler-event-loop INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:14.362 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
24/04/15 11:06:14.362 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 50 finished: collectAsMap at RandomForest.scala:663, took 0,414385 s
24/04/15 11:06:14.362 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(64) (from destroy at RandomForest.scala:674)
24/04/15 11:06:14.362 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_64_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 10.3 KiB, free: 911.0 MiB)
24/04/15 11:06:14.362 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 32.6 KiB, free 909.4 MiB)
24/04/15 11:06:14.362 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 909.3 MiB)
24/04/15 11:06:14.362 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 20.3 KiB, free: 911.0 MiB)
24/04/15 11:06:14.362 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 67 from broadcast at RandomForest.scala:622
24/04/15 11:06:14.378 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/15 11:06:14.378 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 263 (mapPartitions at RandomForest.scala:644) as input to shuffle 16
24/04/15 11:06:14.378 dag-scheduler-event-loop INFO DAGScheduler: Got job 51 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/15 11:06:14.378 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 67 (collectAsMap at RandomForest.scala:663)
24/04/15 11:06:14.378 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
24/04/15 11:06:14.378 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)
24/04/15 11:06:14.378 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[263] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/15 11:06:14.393 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 582.4 KiB, free 908.8 MiB)
24/04/15 11:06:14.393 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 146.2 KiB, free 908.6 MiB)
24/04/15 11:06:14.393 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 146.2 KiB, free: 910.8 MiB)
24/04/15 11:06:14.393 dag-scheduler-event-loop INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:14.393 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[263] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:14.393 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 66.0 with 2 tasks resource profile 0
24/04/15 11:06:14.393 dispatcher-event-loop-1 WARN TaskSetManager: Stage 66 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 11:06:14.393 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 66) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:14.393 Executor task launch worker for task 0.0 in stage 66.0 (TID 66) INFO Executor: Running task 0.0 in stage 66.0 (TID 66)
24/04/15 11:06:14.425 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_66_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 3.8 KiB, free: 910.8 MiB)
24/04/15 11:06:14.425 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_65_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 133.5 KiB, free: 911.0 MiB)
24/04/15 11:06:14.440 Executor task launch worker for task 0.0 in stage 66.0 (TID 66) INFO BlockManager: Found block rdd_259_0 locally
24/04/15 11:06:14.456 Executor task launch worker for task 0.0 in stage 66.0 (TID 66) INFO Executor: Finished task 0.0 in stage 66.0 (TID 66). 2248 bytes result sent to driver
24/04/15 11:06:14.456 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 67) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:14.456 Executor task launch worker for task 1.0 in stage 66.0 (TID 67) INFO Executor: Running task 1.0 in stage 66.0 (TID 67)
24/04/15 11:06:14.456 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 66) in 63 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:14.471 Executor task launch worker for task 1.0 in stage 66.0 (TID 67) INFO BlockManager: Found block rdd_259_1 locally
24/04/15 11:06:14.487 Executor task launch worker for task 1.0 in stage 66.0 (TID 67) INFO Executor: Finished task 1.0 in stage 66.0 (TID 67). 2248 bytes result sent to driver
24/04/15 11:06:14.487 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 67) in 31 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:14.487 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
24/04/15 11:06:14.487 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 66 (mapPartitions at RandomForest.scala:644) finished in 0,109 s
24/04/15 11:06:14.487 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 11:06:14.487 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 11:06:14.487 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 67)
24/04/15 11:06:14.487 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 11:06:14.487 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[265] at map at RandomForest.scala:663), which has no missing parents
24/04/15 11:06:14.487 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 11.1 KiB, free 909.3 MiB)
24/04/15 11:06:14.487 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 909.3 MiB)
24/04/15 11:06:14.487 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.1 KiB, free: 910.9 MiB)
24/04/15 11:06:14.487 dag-scheduler-event-loop INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:14.487 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 67 (MapPartitionsRDD[265] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:14.487 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 67.0 with 2 tasks resource profile 0
24/04/15 11:06:14.487 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 68) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:14.487 Executor task launch worker for task 0.0 in stage 67.0 (TID 68) INFO Executor: Running task 0.0 in stage 67.0 (TID 68)
24/04/15 11:06:14.487 Executor task launch worker for task 0.0 in stage 67.0 (TID 68) INFO ShuffleBlockFetcherIterator: Getting 2 (165.4 KiB) non-empty blocks including 2 (165.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:14.487 Executor task launch worker for task 0.0 in stage 67.0 (TID 68) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:14.503 Executor task launch worker for task 0.0 in stage 67.0 (TID 68) INFO Executor: Finished task 0.0 in stage 67.0 (TID 68). 6359 bytes result sent to driver
24/04/15 11:06:14.503 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 69) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:14.503 Executor task launch worker for task 1.0 in stage 67.0 (TID 69) INFO Executor: Running task 1.0 in stage 67.0 (TID 69)
24/04/15 11:06:14.503 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 68) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:14.503 Executor task launch worker for task 1.0 in stage 67.0 (TID 69) INFO ShuffleBlockFetcherIterator: Getting 2 (138.5 KiB) non-empty blocks including 2 (138.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:14.503 Executor task launch worker for task 1.0 in stage 67.0 (TID 69) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:14.518 Executor task launch worker for task 1.0 in stage 67.0 (TID 69) INFO Executor: Finished task 1.0 in stage 67.0 (TID 69). 6277 bytes result sent to driver
24/04/15 11:06:14.518 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 69) in 15 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:14.518 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
24/04/15 11:06:14.518 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 67 (collectAsMap at RandomForest.scala:663) finished in 0,031 s
24/04/15 11:06:14.518 dag-scheduler-event-loop INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:14.518 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
24/04/15 11:06:14.518 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 51 finished: collectAsMap at RandomForest.scala:663, took 0,142713 s
24/04/15 11:06:14.518 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(67) (from destroy at RandomForest.scala:674)
24/04/15 11:06:14.518 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_67_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 20.3 KiB, free: 911.0 MiB)
24/04/15 11:06:14.518 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 42.5 KiB, free 909.3 MiB)
24/04/15 11:06:14.518 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 26.4 KiB, free 909.3 MiB)
24/04/15 11:06:14.518 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 26.4 KiB, free: 910.9 MiB)
24/04/15 11:06:14.518 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 70 from broadcast at RandomForest.scala:622
24/04/15 11:06:14.534 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/15 11:06:14.534 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 266 (mapPartitions at RandomForest.scala:644) as input to shuffle 17
24/04/15 11:06:14.534 dag-scheduler-event-loop INFO DAGScheduler: Got job 52 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/15 11:06:14.534 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 69 (collectAsMap at RandomForest.scala:663)
24/04/15 11:06:14.534 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
24/04/15 11:06:14.534 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 68)
24/04/15 11:06:14.534 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[266] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/15 11:06:14.555 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 601.9 KiB, free 908.7 MiB)
24/04/15 11:06:14.556 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 155.5 KiB, free 908.5 MiB)
24/04/15 11:06:14.556 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 155.5 KiB, free: 910.8 MiB)
24/04/15 11:06:14.556 dag-scheduler-event-loop INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:14.557 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[266] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:14.557 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 68.0 with 2 tasks resource profile 0
24/04/15 11:06:14.564 dispatcher-event-loop-1 WARN TaskSetManager: Stage 68 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 11:06:14.564 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 70) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:14.564 Executor task launch worker for task 0.0 in stage 68.0 (TID 70) INFO Executor: Running task 0.0 in stage 68.0 (TID 70)
24/04/15 11:06:14.575 Executor task launch worker for task 0.0 in stage 68.0 (TID 70) INFO BlockManager: Found block rdd_259_0 locally
24/04/15 11:06:14.584 Executor task launch worker for task 0.0 in stage 68.0 (TID 70) INFO Executor: Finished task 0.0 in stage 68.0 (TID 70). 2205 bytes result sent to driver
24/04/15 11:06:14.584 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 71) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:14.584 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 70) in 26 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:14.584 Executor task launch worker for task 1.0 in stage 68.0 (TID 71) INFO Executor: Running task 1.0 in stage 68.0 (TID 71)
24/04/15 11:06:14.600 Executor task launch worker for task 1.0 in stage 68.0 (TID 71) INFO BlockManager: Found block rdd_259_1 locally
24/04/15 11:06:14.620 Executor task launch worker for task 1.0 in stage 68.0 (TID 71) INFO Executor: Finished task 1.0 in stage 68.0 (TID 71). 2205 bytes result sent to driver
24/04/15 11:06:14.620 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 71) in 36 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:14.620 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
24/04/15 11:06:14.620 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 68 (mapPartitions at RandomForest.scala:644) finished in 0,086 s
24/04/15 11:06:14.620 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 11:06:14.620 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 11:06:14.620 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 69)
24/04/15 11:06:14.620 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 11:06:14.620 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[268] at map at RandomForest.scala:663), which has no missing parents
24/04/15 11:06:14.620 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 12.3 KiB, free 908.5 MiB)
24/04/15 11:06:14.620 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 908.5 MiB)
24/04/15 11:06:14.620 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.4 KiB, free: 910.8 MiB)
24/04/15 11:06:14.620 dag-scheduler-event-loop INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:14.620 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 69 (MapPartitionsRDD[268] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:14.620 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 69.0 with 2 tasks resource profile 0
24/04/15 11:06:14.620 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 72) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:14.620 Executor task launch worker for task 0.0 in stage 69.0 (TID 72) INFO Executor: Running task 0.0 in stage 69.0 (TID 72)
24/04/15 11:06:14.620 Executor task launch worker for task 0.0 in stage 69.0 (TID 72) INFO ShuffleBlockFetcherIterator: Getting 2 (172.8 KiB) non-empty blocks including 2 (172.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:14.620 Executor task launch worker for task 0.0 in stage 69.0 (TID 72) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:14.636 Executor task launch worker for task 0.0 in stage 69.0 (TID 72) INFO Executor: Finished task 0.0 in stage 69.0 (TID 72). 7580 bytes result sent to driver
24/04/15 11:06:14.636 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 73) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:14.636 Executor task launch worker for task 1.0 in stage 69.0 (TID 73) INFO Executor: Running task 1.0 in stage 69.0 (TID 73)
24/04/15 11:06:14.636 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 72) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:14.636 Executor task launch worker for task 1.0 in stage 69.0 (TID 73) INFO ShuffleBlockFetcherIterator: Getting 2 (172.8 KiB) non-empty blocks including 2 (172.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:14.636 Executor task launch worker for task 1.0 in stage 69.0 (TID 73) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:14.651 Executor task launch worker for task 1.0 in stage 69.0 (TID 73) INFO Executor: Finished task 1.0 in stage 69.0 (TID 73). 7619 bytes result sent to driver
24/04/15 11:06:14.667 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 73) in 31 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:14.667 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
24/04/15 11:06:14.667 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 69 (collectAsMap at RandomForest.scala:663) finished in 0,047 s
24/04/15 11:06:14.667 dag-scheduler-event-loop INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:14.667 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
24/04/15 11:06:14.667 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_71_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 155.5 KiB, free: 910.9 MiB)
24/04/15 11:06:14.667 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 52 finished: collectAsMap at RandomForest.scala:663, took 0,128222 s
24/04/15 11:06:14.667 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(70) (from destroy at RandomForest.scala:674)
24/04/15 11:06:14.667 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_70_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 26.4 KiB, free: 911.0 MiB)
24/04/15 11:06:14.667 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_68_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 146.2 KiB, free: 911.1 MiB)
24/04/15 11:06:14.667 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 40.0 KiB, free 910.0 MiB)
24/04/15 11:06:14.667 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 25.1 KiB, free 910.0 MiB)
24/04/15 11:06:14.667 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 25.1 KiB, free: 911.1 MiB)
24/04/15 11:06:14.667 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 73 from broadcast at RandomForest.scala:622
24/04/15 11:06:14.667 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_69_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.1 KiB, free: 911.1 MiB)
24/04/15 11:06:14.683 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/15 11:06:14.683 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 269 (mapPartitions at RandomForest.scala:644) as input to shuffle 18
24/04/15 11:06:14.683 dag-scheduler-event-loop INFO DAGScheduler: Got job 53 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/15 11:06:14.683 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 71 (collectAsMap at RandomForest.scala:663)
24/04/15 11:06:14.683 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
24/04/15 11:06:14.683 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 70)
24/04/15 11:06:14.683 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[269] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/15 11:06:14.698 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 613.3 KiB, free 909.4 MiB)
24/04/15 11:06:14.698 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 157.8 KiB, free 909.2 MiB)
24/04/15 11:06:14.698 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 157.8 KiB, free: 910.9 MiB)
24/04/15 11:06:14.698 dag-scheduler-event-loop INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:14.698 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[269] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:14.698 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 70.0 with 2 tasks resource profile 0
24/04/15 11:06:14.714 dispatcher-event-loop-1 WARN TaskSetManager: Stage 70 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 11:06:14.714 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 74) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:14.714 Executor task launch worker for task 0.0 in stage 70.0 (TID 74) INFO Executor: Running task 0.0 in stage 70.0 (TID 74)
24/04/15 11:06:14.714 Executor task launch worker for task 0.0 in stage 70.0 (TID 74) INFO BlockManager: Found block rdd_259_0 locally
24/04/15 11:06:14.730 Executor task launch worker for task 0.0 in stage 70.0 (TID 74) INFO Executor: Finished task 0.0 in stage 70.0 (TID 74). 2248 bytes result sent to driver
24/04/15 11:06:14.745 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 75) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:14.745 Executor task launch worker for task 1.0 in stage 70.0 (TID 75) INFO Executor: Running task 1.0 in stage 70.0 (TID 75)
24/04/15 11:06:14.745 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 74) in 47 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:14.745 Executor task launch worker for task 1.0 in stage 70.0 (TID 75) INFO BlockManager: Found block rdd_259_1 locally
24/04/15 11:06:14.761 Executor task launch worker for task 1.0 in stage 70.0 (TID 75) INFO Executor: Finished task 1.0 in stage 70.0 (TID 75). 2205 bytes result sent to driver
24/04/15 11:06:14.761 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 75) in 31 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:14.761 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
24/04/15 11:06:14.761 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 70 (mapPartitions at RandomForest.scala:644) finished in 0,078 s
24/04/15 11:06:14.761 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 11:06:14.761 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 11:06:14.761 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 71)
24/04/15 11:06:14.761 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 11:06:14.761 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[271] at map at RandomForest.scala:663), which has no missing parents
24/04/15 11:06:14.761 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 12.0 KiB, free 909.2 MiB)
24/04/15 11:06:14.761 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 909.2 MiB)
24/04/15 11:06:14.761 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 5.3 KiB, free: 910.9 MiB)
24/04/15 11:06:14.761 dag-scheduler-event-loop INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:14.761 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 71 (MapPartitionsRDD[271] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:14.761 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 71.0 with 2 tasks resource profile 0
24/04/15 11:06:14.761 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 76) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:14.761 Executor task launch worker for task 0.0 in stage 71.0 (TID 76) INFO Executor: Running task 0.0 in stage 71.0 (TID 76)
24/04/15 11:06:14.776 Executor task launch worker for task 0.0 in stage 71.0 (TID 76) INFO ShuffleBlockFetcherIterator: Getting 2 (158.6 KiB) non-empty blocks including 2 (158.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:14.776 Executor task launch worker for task 0.0 in stage 71.0 (TID 76) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:14.776 Executor task launch worker for task 0.0 in stage 71.0 (TID 76) INFO Executor: Finished task 0.0 in stage 71.0 (TID 76). 7369 bytes result sent to driver
24/04/15 11:06:14.776 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 77) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:14.792 Executor task launch worker for task 1.0 in stage 71.0 (TID 77) INFO Executor: Running task 1.0 in stage 71.0 (TID 77)
24/04/15 11:06:14.792 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 76) in 31 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:14.792 Executor task launch worker for task 1.0 in stage 71.0 (TID 77) INFO ShuffleBlockFetcherIterator: Getting 2 (150.3 KiB) non-empty blocks including 2 (150.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:14.792 Executor task launch worker for task 1.0 in stage 71.0 (TID 77) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:14.792 Executor task launch worker for task 1.0 in stage 71.0 (TID 77) INFO Executor: Finished task 1.0 in stage 71.0 (TID 77). 7136 bytes result sent to driver
24/04/15 11:06:14.792 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 77) in 16 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:14.792 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
24/04/15 11:06:14.792 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 71 (collectAsMap at RandomForest.scala:663) finished in 0,031 s
24/04/15 11:06:14.792 dag-scheduler-event-loop INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:14.792 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished
24/04/15 11:06:14.792 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 53 finished: collectAsMap at RandomForest.scala:663, took 0,108652 s
24/04/15 11:06:14.792 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(73) (from destroy at RandomForest.scala:674)
24/04/15 11:06:14.792 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_73_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 25.1 KiB, free: 910.9 MiB)
24/04/15 11:06:14.792 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 26.0 KiB, free 909.3 MiB)
24/04/15 11:06:14.792 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 909.3 MiB)
24/04/15 11:06:14.792 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 16.3 KiB, free: 910.9 MiB)
24/04/15 11:06:14.792 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 76 from broadcast at RandomForest.scala:622
24/04/15 11:06:14.808 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/15 11:06:14.808 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 272 (mapPartitions at RandomForest.scala:644) as input to shuffle 19
24/04/15 11:06:14.808 dag-scheduler-event-loop INFO DAGScheduler: Got job 54 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/15 11:06:14.808 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 73 (collectAsMap at RandomForest.scala:663)
24/04/15 11:06:14.808 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)
24/04/15 11:06:14.808 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 72)
24/04/15 11:06:14.808 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[272] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/15 11:06:14.823 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 613.5 KiB, free 908.7 MiB)
24/04/15 11:06:14.823 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 151.8 KiB, free 908.5 MiB)
24/04/15 11:06:14.823 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 151.8 KiB, free: 910.8 MiB)
24/04/15 11:06:14.823 dag-scheduler-event-loop INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:14.823 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[272] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:14.823 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 72.0 with 2 tasks resource profile 0
24/04/15 11:06:14.839 dispatcher-event-loop-1 WARN TaskSetManager: Stage 72 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 11:06:14.839 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 78) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:14.839 Executor task launch worker for task 0.0 in stage 72.0 (TID 78) INFO Executor: Running task 0.0 in stage 72.0 (TID 78)
24/04/15 11:06:14.839 Executor task launch worker for task 0.0 in stage 72.0 (TID 78) INFO BlockManager: Found block rdd_259_0 locally
24/04/15 11:06:14.855 Executor task launch worker for task 0.0 in stage 72.0 (TID 78) INFO Executor: Finished task 0.0 in stage 72.0 (TID 78). 2205 bytes result sent to driver
24/04/15 11:06:14.886 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_74_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 157.8 KiB, free: 910.9 MiB)
24/04/15 11:06:14.886 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_72_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.4 KiB, free: 910.9 MiB)
24/04/15 11:06:14.886 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 79) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/15 11:06:14.886 Executor task launch worker for task 1.0 in stage 72.0 (TID 79) INFO Executor: Running task 1.0 in stage 72.0 (TID 79)
24/04/15 11:06:14.886 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 78) in 63 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:14.886 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_75_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 5.3 KiB, free: 910.9 MiB)
24/04/15 11:06:14.901 Executor task launch worker for task 1.0 in stage 72.0 (TID 79) INFO BlockManager: Found block rdd_259_1 locally
24/04/15 11:06:14.917 Executor task launch worker for task 1.0 in stage 72.0 (TID 79) INFO Executor: Finished task 1.0 in stage 72.0 (TID 79). 2205 bytes result sent to driver
24/04/15 11:06:14.917 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 79) in 62 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:14.917 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
24/04/15 11:06:14.917 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 72 (mapPartitions at RandomForest.scala:644) finished in 0,109 s
24/04/15 11:06:14.917 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/15 11:06:14.917 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/15 11:06:14.917 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 73)
24/04/15 11:06:14.917 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/15 11:06:14.917 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[274] at map at RandomForest.scala:663), which has no missing parents
24/04/15 11:06:14.917 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 10.4 KiB, free 909.3 MiB)
24/04/15 11:06:14.917 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 909.3 MiB)
24/04/15 11:06:14.917 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 4.8 KiB, free: 910.9 MiB)
24/04/15 11:06:14.917 dag-scheduler-event-loop INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:14.917 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 73 (MapPartitionsRDD[274] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/15 11:06:14.917 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 73.0 with 2 tasks resource profile 0
24/04/15 11:06:14.917 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 80) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:14.917 Executor task launch worker for task 0.0 in stage 73.0 (TID 80) INFO Executor: Running task 0.0 in stage 73.0 (TID 80)
24/04/15 11:06:14.917 Executor task launch worker for task 0.0 in stage 73.0 (TID 80) INFO ShuffleBlockFetcherIterator: Getting 2 (94.6 KiB) non-empty blocks including 2 (94.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:14.917 Executor task launch worker for task 0.0 in stage 73.0 (TID 80) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:14.933 Executor task launch worker for task 0.0 in stage 73.0 (TID 80) INFO Executor: Finished task 0.0 in stage 73.0 (TID 80). 5483 bytes result sent to driver
24/04/15 11:06:14.933 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 81) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/15 11:06:14.933 Executor task launch worker for task 1.0 in stage 73.0 (TID 81) INFO Executor: Running task 1.0 in stage 73.0 (TID 81)
24/04/15 11:06:14.933 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 80) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/15 11:06:14.933 Executor task launch worker for task 1.0 in stage 73.0 (TID 81) INFO ShuffleBlockFetcherIterator: Getting 2 (98.5 KiB) non-empty blocks including 2 (98.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/15 11:06:14.933 Executor task launch worker for task 1.0 in stage 73.0 (TID 81) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/15 11:06:14.933 Executor task launch worker for task 1.0 in stage 73.0 (TID 81) INFO Executor: Finished task 1.0 in stage 73.0 (TID 81). 5415 bytes result sent to driver
24/04/15 11:06:14.933 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 81) in 0 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/15 11:06:14.933 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
24/04/15 11:06:14.933 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 73 (collectAsMap at RandomForest.scala:663) finished in 0,016 s
24/04/15 11:06:14.933 dag-scheduler-event-loop INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:14.948 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
24/04/15 11:06:14.948 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 54 finished: collectAsMap at RandomForest.scala:663, took 0,128933 s
24/04/15 11:06:14.948 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(76) (from destroy at RandomForest.scala:674)
24/04/15 11:06:14.948 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/15 11:06:14.948 nioEventLoopGroup-2-2 INFO RandomForest:   init: 4.65E-5
  total: 1.0215612
  findBestSplits: 1.0123319
  chooseSplits: 1.0110879
24/04/15 11:06:14.948 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_76_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 16.3 KiB, free: 911.0 MiB)
24/04/15 11:06:14.948 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 259 from persistence list
24/04/15 11:06:14.951 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(63) (from destroy at RandomForest.scala:305)
24/04/15 11:06:14.951 block-manager-storage-async-thread-pool-286 INFO BlockManager: Removing RDD 259
24/04/15 11:06:14.952 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_63_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 7.6 KiB, free: 911.3 MiB)
24/04/15 11:06:14.954 nioEventLoopGroup-2-2 INFO Instrumentation: [49c2a7ad] {"numFeatures":545}
24/04/15 11:06:14.955 nioEventLoopGroup-2-2 INFO Instrumentation: [49c2a7ad] training finished
24/04/15 11:06:14.955 nioEventLoopGroup-2-2 INFO Instrumentation: [4b76cd59] training finished
24/04/15 11:06:15.484 nioEventLoopGroup-2-2 INFO Instrumentation: [2f2e04cf] training finished
24/04/15 11:06:15.809 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_77_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 151.8 KiB, free: 911.5 MiB)
24/04/15 11:06:15.809 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_78_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 4.8 KiB, free: 911.5 MiB)
24/04/15 11:06:15.809 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_61_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 121.2 KiB, free: 911.6 MiB)
24/04/15 11:06:15.809 block-manager-storage-async-thread-pool-202 INFO BlockManager: Removing RDD 259
24/04/15 11:06:17.061 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 11:06:17.061 dag-scheduler-event-loop INFO DAGScheduler: Got job 55 (collect at utils.scala:26) with 1 output partitions
24/04/15 11:06:17.061 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:26)
24/04/15 11:06:17.061 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 11:06:17.061 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 11:06:17.061 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[277] at collect at utils.scala:26), which has no missing parents
24/04/15 11:06:17.061 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 62.5 KiB, free 911.1 MiB)
24/04/15 11:06:17.061 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.1 MiB)
24/04/15 11:06:17.061 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 11:06:17.061 dag-scheduler-event-loop INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:17.061 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[277] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 11:06:17.061 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
24/04/15 11:06:17.061 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 82) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 11:06:17.061 Executor task launch worker for task 0.0 in stage 74.0 (TID 82) INFO Executor: Running task 0.0 in stage 74.0 (TID 82)
24/04/15 11:06:17.093 Executor task launch worker for task 0.0 in stage 74.0 (TID 82) INFO Executor: Finished task 0.0 in stage 74.0 (TID 82). 1430 bytes result sent to driver
24/04/15 11:06:17.093 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 82) in 32 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 11:06:17.093 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
24/04/15 11:06:17.093 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 74 (collect at utils.scala:26) finished in 0,032 s
24/04/15 11:06:17.093 dag-scheduler-event-loop INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:17.093 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
24/04/15 11:06:17.093 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 55 finished: collect at utils.scala:26, took 0,029565 s
24/04/15 11:06:19.520 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_79_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 11:06:19.757 nioEventLoopGroup-2-2 INFO Instrumentation: [0cbae958] training finished
24/04/15 11:06:19.820 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 450.0 KiB, free 910.7 MiB)
24/04/15 11:06:19.820 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 27.8 KiB, free 910.7 MiB)
24/04/15 11:06:19.820 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 27.8 KiB, free: 911.6 MiB)
24/04/15 11:06:19.820 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 80 from broadcast at RandomForestRegressor.scala:238
24/04/15 11:06:19.882 nioEventLoopGroup-2-2 INFO Instrumentation: [a060cc1f] training finished
24/04/15 11:06:20.852 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 11:06:20.852 dag-scheduler-event-loop INFO DAGScheduler: Got job 56 (collect at utils.scala:26) with 1 output partitions
24/04/15 11:06:20.852 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:26)
24/04/15 11:06:20.852 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 11:06:20.852 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 11:06:20.852 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[280] at collect at utils.scala:26), which has no missing parents
24/04/15 11:06:20.867 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 62.6 KiB, free 910.6 MiB)
24/04/15 11:06:20.867 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 910.6 MiB)
24/04/15 11:06:20.867 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 12.8 KiB, free: 911.6 MiB)
24/04/15 11:06:20.867 dag-scheduler-event-loop INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:20.867 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[280] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 11:06:20.867 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0
24/04/15 11:06:20.867 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 83) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 11:06:20.867 Executor task launch worker for task 0.0 in stage 75.0 (TID 83) INFO Executor: Running task 0.0 in stage 75.0 (TID 83)
24/04/15 11:06:20.883 Executor task launch worker for task 0.0 in stage 75.0 (TID 83) INFO Executor: Finished task 0.0 in stage 75.0 (TID 83). 1430 bytes result sent to driver
24/04/15 11:06:20.883 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 83) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 11:06:20.883 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
24/04/15 11:06:20.883 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 75 (collect at utils.scala:26) finished in 0,016 s
24/04/15 11:06:20.883 dag-scheduler-event-loop INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:20.883 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished
24/04/15 11:06:20.883 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 56 finished: collect at utils.scala:26, took 0,027004 s
24/04/15 11:06:25.961 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_81_piece0 on DESKTOP-LH06ASP:49159 in memory (size: 12.8 KiB, free: 911.6 MiB)
24/04/15 11:06:26.114 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 11:06:26.115 dag-scheduler-event-loop INFO DAGScheduler: Got job 57 (collect at utils.scala:26) with 1 output partitions
24/04/15 11:06:26.115 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 76 (collect at utils.scala:26)
24/04/15 11:06:26.115 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 11:06:26.115 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 11:06:26.116 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[288] at collect at utils.scala:26), which has no missing parents
24/04/15 11:06:26.125 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 452.7 KiB, free 910.2 MiB)
24/04/15 11:06:26.127 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 910.1 MiB)
24/04/15 11:06:26.127 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 90.5 KiB, free: 911.5 MiB)
24/04/15 11:06:26.127 dag-scheduler-event-loop INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:26.127 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[288] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 11:06:26.127 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
24/04/15 11:06:26.136 dispatcher-event-loop-0 WARN TaskSetManager: Stage 76 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 11:06:26.136 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 84) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 11:06:26.136 Executor task launch worker for task 0.0 in stage 76.0 (TID 84) INFO Executor: Running task 0.0 in stage 76.0 (TID 84)
24/04/15 11:06:26.146 Executor task launch worker for task 0.0 in stage 76.0 (TID 84) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 11:06:26.443 Executor task launch worker for task 0.0 in stage 76.0 (TID 84) INFO CodeGenerator: Code generated in 113.3473 ms
24/04/15 11:06:26.753 Executor task launch worker for task 0.0 in stage 76.0 (TID 84) INFO Executor: Finished task 0.0 in stage 76.0 (TID 84). 140015 bytes result sent to driver
24/04/15 11:06:26.754 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 84) in 626 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 11:06:26.754 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
24/04/15 11:06:26.755 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 76 (collect at utils.scala:26) finished in 0,637 s
24/04/15 11:06:26.755 dag-scheduler-event-loop INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:26.755 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
24/04/15 11:06:26.755 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 57 finished: collect at utils.scala:26, took 0,640500 s
24/04/15 11:06:32.199 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 11:06:32.201 dag-scheduler-event-loop INFO DAGScheduler: Got job 58 (collect at utils.scala:26) with 1 output partitions
24/04/15 11:06:32.201 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 77 (collect at utils.scala:26)
24/04/15 11:06:32.201 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 11:06:32.201 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 11:06:32.202 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[294] at collect at utils.scala:26), which has no missing parents
24/04/15 11:06:32.209 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 123.2 KiB, free 910.0 MiB)
24/04/15 11:06:32.210 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 910.0 MiB)
24/04/15 11:06:32.211 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on DESKTOP-LH06ASP:49159 (size: 31.0 KiB, free: 911.4 MiB)
24/04/15 11:06:32.212 dag-scheduler-event-loop INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1535
24/04/15 11:06:32.213 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[294] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 11:06:32.213 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0
24/04/15 11:06:32.229 dispatcher-event-loop-0 WARN TaskSetManager: Stage 77 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 11:06:32.231 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 85) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 11:06:32.232 Executor task launch worker for task 0.0 in stage 77.0 (TID 85) INFO Executor: Running task 0.0 in stage 77.0 (TID 85)
24/04/15 11:06:32.253 Executor task launch worker for task 0.0 in stage 77.0 (TID 85) INFO BlockManager: Found block rdd_22_0 locally
24/04/15 11:06:32.450 Executor task launch worker for task 0.0 in stage 77.0 (TID 85) INFO Executor: Finished task 0.0 in stage 77.0 (TID 85). 135266 bytes result sent to driver
24/04/15 11:06:32.451 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 85) in 237 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 11:06:32.452 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
24/04/15 11:06:32.452 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 77 (collect at utils.scala:26) finished in 0,248 s
24/04/15 11:06:32.453 dag-scheduler-event-loop INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 11:06:32.453 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished
24/04/15 11:06:32.454 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 58 finished: collect at utils.scala:26, took 0,252752 s
24/04/15 11:21:11.675 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/15 11:21:11.675 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/15 11:21:11.722 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/15 11:21:11.753 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/15 20:42:23.014 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/15 20:42:23.354 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/15 20:42:23.383 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/15 20:42:23.471 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/15 20:42:23.543 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/15 20:42:23.543 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/15 20:42:23.543 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/15 20:42:23.543 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/15 20:42:23.589 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/15 20:42:23.608 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/15 20:42:23.609 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/15 20:42:23.693 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/15 20:42:23.694 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/15 20:42:23.694 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/15 20:42:23.694 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/15 20:42:23.694 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/15 20:42:23.788 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 64167.
24/04/15 20:42:23.822 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/15 20:42:23.859 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/15 20:42:23.888 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/15 20:42:23.889 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/15 20:42:23.893 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/15 20:42:23.924 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-df984719-0c0d-4b61-95b9-be218382fbcd
24/04/15 20:42:23.953 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/15 20:42:23.975 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/15 20:42:23.979 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/15 20:42:24.209 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/15 20:42:24.329 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/15 20:42:24.423 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:64167/jars/sparklyr-3.0-2.12.jar with timestamp 1713210143339
24/04/15 20:42:24.546 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/15 20:42:24.554 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/15 20:42:24.566 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:64167/jars/sparklyr-3.0-2.12.jar with timestamp 1713210143339
24/04/15 20:42:24.607 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:64167 after 19 ms (0 ms spent in bootstraps)
24/04/15 20:42:24.612 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:64167/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e26af886-8973-425e-854b-08392f02924a\userFiles-f6f64e82-2e2a-4875-bba9-e61655f7e9f2\fetchFileTemp8406824704511110910.tmp
24/04/15 20:42:24.775 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-e26af886-8973-425e-854b-08392f02924a/userFiles-f6f64e82-2e2a-4875-bba9-e61655f7e9f2/sparklyr-3.0-2.12.jar to class loader
24/04/15 20:42:24.788 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64187.
24/04/15 20:42:24.788 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:64187
24/04/15 20:42:24.790 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/15 20:42:24.799 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 20:42:24.803 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:64187 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 20:42:24.806 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 20:42:24.807 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 20:42:25.341 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/15 20:42:25.349 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/15 20:42:29.871 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/15 20:42:30.017 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/15 20:42:30.373 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/15 20:42:30.563 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/15 20:42:30.563 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/15 20:42:30.563 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/15 20:42:30.607 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/15 20:42:30.753 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/15 20:42:30.754 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/15 20:42:32.298 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/15 20:42:35.987 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/15 20:42:35.991 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/15 20:42:36.090 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/15 20:42:36.091 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/15 20:42:36.127 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/15 20:42:36.356 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/15 20:42:36.360 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/15 20:42:36.448 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/15 20:42:36.637 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 20:42:36.641 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 20:42:36.673 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/15 20:42:36.673 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/15 20:42:36.674 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/15 20:42:36.675 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 20:42:36.676 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 20:42:36.678 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 20:42:36.678 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 20:42:36.683 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/15 20:42:36.684 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/15 20:42:37.842 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 234.8967 ms
24/04/15 20:42:37.947 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 20:42:37.963 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,005987 s
24/04/15 20:42:43.855 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/15 20:42:45.356 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.4014 ms
24/04/15 20:42:45.395 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 20:42:45.420 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/15 20:42:45.420 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/15 20:42:45.420 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 20:42:45.421 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 20:42:45.424 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/15 20:42:45.522 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/15 20:42:45.667 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/15 20:42:45.670 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:64187 (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 20:42:45.674 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/15 20:42:45.689 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 20:42:45.691 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/15 20:42:45.751 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 20:42:45.767 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/15 20:42:46.301 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 208.1759 ms
24/04/15 20:42:46.326 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1516 bytes result sent to driver
24/04/15 20:42:46.336 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 596 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 20:42:46.338 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/15 20:42:46.344 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,885 s
24/04/15 20:42:46.349 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 20:42:46.350 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/15 20:42:46.351 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,947513 s
24/04/15 20:42:46.550 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:64187 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 20:42:46.678 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 244.5044 ms
24/04/15 20:42:50.392 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 20:42:50.408 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/15 20:42:50.408 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/15 20:42:50.408 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 20:42:50.408 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 20:42:50.408 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/15 20:42:50.408 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/15 20:42:50.408 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/15 20:42:50.408 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:64187 (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 20:42:50.408 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/15 20:42:50.408 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 20:42:50.408 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/15 20:42:50.408 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 20:42:50.408 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/15 20:42:50.467 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/15 20:42:50.469 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 61 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 20:42:50.469 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/15 20:42:50.470 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,062 s
24/04/15 20:42:50.470 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 20:42:50.471 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/15 20:42:50.471 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,063012 s
24/04/15 20:42:50.640 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:64187 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 20:42:53.090 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 20:42:53.090 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 20:42:53.090 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 20:42:53.090 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 20:42:53.090 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/15 20:42:53.090 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/15 20:42:53.222 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 76.5195 ms
24/04/15 20:42:53.274 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.7989 ms
24/04/15 20:42:53.299 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.3405 ms
24/04/15 21:23:19.448 dispatcher-HeartbeatReceiver WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 962760 ms exceeds timeout 120000 ms
24/04/15 21:23:19.526 kill-executor-thread WARN SparkContext: Killing executors is not supported by current scheduler.
24/04/15 21:23:21.646 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.646 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.646 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.661 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.661 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.677 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.677 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.677 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.677 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.677 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.693 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.693 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.693 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.693 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.693 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.693 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.693 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.693 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.693 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.693 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.708 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.708 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.708 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.717 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.717 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.717 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.717 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.717 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.724 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.724 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.724 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.724 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.724 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.724 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.724 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.724 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.724 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.724 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.724 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.724 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.740 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.740 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.740 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.740 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.740 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.740 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.740 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.740 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.755 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
24/04/15 21:23:21.755 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
24/04/15 21:23:21.755 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.755 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.755 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.755 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.755 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.755 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.771 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.771 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.771 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.771 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.771 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.771 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.771 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.771 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.771 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.771 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.787 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.787 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.787 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.787 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.787 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.787 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.787 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.787 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.802 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.802 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.802 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.802 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.818 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.818 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.834 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.834 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.834 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.834 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.834 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.849 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.849 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.880 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.880 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.880 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.880 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.880 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.880 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.880 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.880 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.896 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.896 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.896 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.896 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.896 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.896 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.896 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.896 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.896 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.896 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.896 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.896 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.896 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.896 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.896 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.912 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.912 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.918 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.918 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.918 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.918 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.918 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.918 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.918 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.918 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.918 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.918 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.918 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.928 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.928 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.928 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.928 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.928 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.928 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.928 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.928 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.928 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.928 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.928 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.943 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.943 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.943 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.943 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.943 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.943 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.943 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.943 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.959 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.975 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.975 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.975 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.975 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.975 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.975 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.975 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.975 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.975 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.975 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.975 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.975 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.975 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.975 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.975 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.975 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.975 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.990 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.990 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.990 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.990 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.990 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.990 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.990 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.990 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.990 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.990 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.990 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.990 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.990 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:21.990 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.990 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:21.990 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:21.990 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:21.990 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.006 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.006 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.006 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.006 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.006 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.006 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.006 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.006 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.006 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.006 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.006 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.006 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.006 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.006 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.006 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.018 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.018 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.018 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.018 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.018 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.022 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.022 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.022 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.022 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.022 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.022 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.022 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.022 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.022 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.022 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.022 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.022 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.053 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.053 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.053 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.053 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.053 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.053 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.053 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.053 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.053 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.053 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.053 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.053 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.053 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.053 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.053 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.053 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.053 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.053 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.069 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.069 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.069 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.069 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.069 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.069 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.069 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.069 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.069 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.069 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.069 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.069 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.069 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.069 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.069 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.069 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.069 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.069 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.069 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.069 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.069 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.069 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.084 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.084 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.084 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.084 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.084 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.084 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.084 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.084 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.084 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.084 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.084 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.084 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.084 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.084 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.084 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.084 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.084 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.084 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.084 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.084 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.084 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.084 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.084 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.084 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.084 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.100 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.100 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.100 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.100 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
24/04/15 21:23:22.100 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
	at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
	at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
	at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
	at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
	at scala.concurrent.Future.flatMap(Future.scala:306)
	at scala.concurrent.Future.flatMap$(Future.scala:306)
	at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
	... 17 more
24/04/15 21:23:22.100 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.100 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.100 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.100 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.100 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.100 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.116 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.116 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.116 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.116 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.118 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.118 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.118 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.118 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.118 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.118 executor-heartbeater INFO Executor: Told to re-register on heartbeat
24/04/15 21:23:22.118 executor-heartbeater INFO BlockManager: BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None) re-registering with master
24/04/15 21:23:22.118 executor-heartbeater INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64187, None)
24/04/15 21:23:22.118 dispatcher-BlockManagerMaster ERROR Inbox: Ignoring error
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.118 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
	... 3 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@DESKTOP-LH06ASP:64167
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.Promise.success(Promise.scala:86)
	at scala.concurrent.Promise.success$(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
	... 8 more
24/04/15 21:23:22.118 executor-heartbeater ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times
24/04/15 21:23:32.160 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/15 21:23:32.160 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/15 21:23:32.176 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/15 21:23:32.191 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/15 21:23:32.207 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/15 21:23:32.207 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/15 21:23:32.207 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/15 21:23:32.223 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/15 21:23:32.223 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e26af886-8973-425e-854b-08392f02924a\userFiles-f6f64e82-2e2a-4875-bba9-e61655f7e9f2
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e26af886-8973-425e-854b-08392f02924a\userFiles-f6f64e82-2e2a-4875-bba9-e61655f7e9f2\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/15 21:23:32.223 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/15 21:23:32.223 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/15 21:23:32.223 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e26af886-8973-425e-854b-08392f02924a\userFiles-f6f64e82-2e2a-4875-bba9-e61655f7e9f2
24/04/15 21:23:32.234 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e26af886-8973-425e-854b-08392f02924a\userFiles-f6f64e82-2e2a-4875-bba9-e61655f7e9f2
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e26af886-8973-425e-854b-08392f02924a\userFiles-f6f64e82-2e2a-4875-bba9-e61655f7e9f2\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/15 21:23:32.234 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e26af886-8973-425e-854b-08392f02924a
24/04/15 21:23:32.239 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e26af886-8973-425e-854b-08392f02924a
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e26af886-8973-425e-854b-08392f02924a\userFiles-f6f64e82-2e2a-4875-bba9-e61655f7e9f2\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/15 21:23:32.239 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-61842010-f550-4076-8c5c-b7f6eddd23a2
24/04/15 21:53:35.508 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/15 21:53:35.882 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/15 21:53:35.973 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/15 21:53:36.177 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/15 21:53:36.292 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/15 21:53:36.294 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/15 21:53:36.296 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/15 21:53:36.297 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/15 21:53:36.340 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/15 21:53:36.356 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/15 21:53:36.357 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/15 21:53:36.440 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/15 21:53:36.440 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/15 21:53:36.440 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/15 21:53:36.440 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/15 21:53:36.440 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/15 21:53:36.636 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 50157.
24/04/15 21:53:36.760 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/15 21:53:36.878 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/15 21:53:36.960 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/15 21:53:36.962 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/15 21:53:36.984 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/15 21:53:37.135 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-4934231a-1eed-4390-bef8-18c67f6d8ca5
24/04/15 21:53:37.237 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/15 21:53:37.317 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/15 21:53:37.329 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/15 21:53:37.740 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/15 21:53:37.926 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/15 21:53:37.998 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:50157/jars/sparklyr-3.0-2.12.jar with timestamp 1713214415839
24/04/15 21:53:38.152 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/15 21:53:38.167 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/15 21:53:38.182 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:50157/jars/sparklyr-3.0-2.12.jar with timestamp 1713214415839
24/04/15 21:53:38.268 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:50157 after 53 ms (0 ms spent in bootstraps)
24/04/15 21:53:38.296 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:50157/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e62817b4-1799-4ac8-83cd-fe3168a0da3b\userFiles-ec5e75b9-f70a-4af2-b5e4-91a443827bb4\fetchFileTemp8802913385837690741.tmp
24/04/15 21:53:38.594 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-e62817b4-1799-4ac8-83cd-fe3168a0da3b/userFiles-ec5e75b9-f70a-4af2-b5e4-91a443827bb4/sparklyr-3.0-2.12.jar to class loader
24/04/15 21:53:38.623 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50204.
24/04/15 21:53:38.624 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:50204
24/04/15 21:53:38.626 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/15 21:53:38.646 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 50204, None)
24/04/15 21:53:38.655 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:50204 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 50204, None)
24/04/15 21:53:38.659 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 50204, None)
24/04/15 21:53:38.661 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 50204, None)
24/04/15 21:53:39.140 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/15 21:53:39.151 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/15 21:53:46.073 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/15 21:53:46.305 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/15 21:53:46.642 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/15 21:53:46.936 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/15 21:53:46.938 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/15 21:53:46.938 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/15 21:53:46.995 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/15 21:53:47.177 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/15 21:53:47.178 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/15 21:53:48.734 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/15 21:53:50.704 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/15 21:53:50.708 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/15 21:53:50.811 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/15 21:53:50.812 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/15 21:53:50.854 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/15 21:53:51.104 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/15 21:53:51.106 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/15 21:53:51.160 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/15 21:53:51.330 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 21:53:51.332 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 21:53:51.372 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/15 21:53:51.373 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/15 21:53:51.375 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/15 21:53:51.377 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 21:53:51.378 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 21:53:51.381 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 21:53:51.381 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 21:53:51.385 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/15 21:53:51.385 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/15 21:53:52.796 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 285.6748 ms
24/04/15 21:53:52.943 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 21:53:52.953 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,006659 s
24/04/15 21:53:57.938 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/15 21:54:00.067 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 31.3411 ms
24/04/15 21:54:00.217 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 21:54:00.246 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/15 21:54:00.247 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/15 21:54:00.248 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 21:54:00.251 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 21:54:00.261 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/15 21:54:00.441 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/15 21:54:00.650 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/15 21:54:00.658 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:50204 (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 21:54:00.667 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/15 21:54:00.701 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 21:54:00.704 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/15 21:54:00.851 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 21:54:00.892 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/15 21:54:02.555 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 1041.4535 ms
24/04/15 21:54:02.613 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1516 bytes result sent to driver
24/04/15 21:54:02.624 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1805 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 21:54:02.628 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/15 21:54:02.642 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 2,345 s
24/04/15 21:54:02.647 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 21:54:02.648 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/15 21:54:02.649 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 2,432134 s
24/04/15 21:54:03.041 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 249.3438 ms
24/04/15 21:54:05.769 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:50204 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 21:54:07.555 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 21:54:07.557 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/15 21:54:07.557 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/15 21:54:07.557 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 21:54:07.558 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 21:54:07.560 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/15 21:54:07.567 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/15 21:54:07.570 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/15 21:54:07.571 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:50204 (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 21:54:07.572 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/15 21:54:07.573 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 21:54:07.573 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/15 21:54:07.575 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 21:54:07.577 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/15 21:54:07.651 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/15 21:54:07.655 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 80 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 21:54:07.655 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/15 21:54:07.656 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,094 s
24/04/15 21:54:07.656 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 21:54:07.657 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/15 21:54:07.657 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,101143 s
24/04/15 21:54:10.538 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 21:54:10.538 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 21:54:10.540 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 21:54:10.540 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 21:54:10.542 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/15 21:54:10.542 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/15 21:54:10.638 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 48.7552 ms
24/04/15 21:54:10.673 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.5852 ms
24/04/15 21:54:10.687 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.2241 ms
24/04/15 21:56:44.793 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/15 21:56:44.794 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/15 21:56:44.825 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/15 21:56:44.855 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/15 21:56:44.874 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/15 21:56:44.875 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/15 21:56:44.878 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/15 21:56:44.882 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/15 21:56:44.887 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e62817b4-1799-4ac8-83cd-fe3168a0da3b\userFiles-ec5e75b9-f70a-4af2-b5e4-91a443827bb4
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e62817b4-1799-4ac8-83cd-fe3168a0da3b\userFiles-ec5e75b9-f70a-4af2-b5e4-91a443827bb4\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/15 21:56:44.889 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/15 21:56:44.889 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/15 21:56:44.890 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-f52005cb-b23d-40c6-81ae-c94b0c7e01f7
24/04/15 21:56:44.892 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e62817b4-1799-4ac8-83cd-fe3168a0da3b\userFiles-ec5e75b9-f70a-4af2-b5e4-91a443827bb4
24/04/15 21:56:44.895 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e62817b4-1799-4ac8-83cd-fe3168a0da3b\userFiles-ec5e75b9-f70a-4af2-b5e4-91a443827bb4
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e62817b4-1799-4ac8-83cd-fe3168a0da3b\userFiles-ec5e75b9-f70a-4af2-b5e4-91a443827bb4\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/15 21:56:44.895 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e62817b4-1799-4ac8-83cd-fe3168a0da3b
24/04/15 21:56:44.898 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e62817b4-1799-4ac8-83cd-fe3168a0da3b
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-e62817b4-1799-4ac8-83cd-fe3168a0da3b\userFiles-ec5e75b9-f70a-4af2-b5e4-91a443827bb4\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/15 21:56:57.264 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/15 21:56:57.452 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/15 21:56:57.468 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/15 21:56:57.530 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/15 21:56:57.624 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/15 21:56:57.624 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/15 21:56:57.624 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/15 21:56:57.624 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/15 21:56:57.655 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/15 21:56:57.671 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/15 21:56:57.671 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/15 21:56:57.733 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/15 21:56:57.733 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/15 21:56:57.733 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/15 21:56:57.733 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/15 21:56:57.733 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/15 21:56:57.827 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 50568.
24/04/15 21:56:57.858 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/15 21:56:57.889 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/15 21:56:57.921 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/15 21:56:57.921 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/15 21:56:57.936 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/15 21:56:57.952 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-f0e8e9c6-2f72-453f-9a75-d682834557fb
24/04/15 21:56:57.968 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/15 21:56:57.983 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/15 21:56:57.983 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/15 21:56:58.155 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/15 21:56:58.249 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/15 21:56:58.280 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:50568/jars/sparklyr-3.0-2.12.jar with timestamp 1713214617436
24/04/15 21:56:58.358 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/15 21:56:58.358 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/15 21:56:58.374 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:50568/jars/sparklyr-3.0-2.12.jar with timestamp 1713214617436
24/04/15 21:56:58.421 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:50568 after 19 ms (0 ms spent in bootstraps)
24/04/15 21:56:58.421 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:50568/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1616d155-4bd5-4e46-88f9-e5eb92346c8b\userFiles-79b05243-968a-4b20-b2ce-46f8773f2fa0\fetchFileTemp6135602164478572444.tmp
24/04/15 21:56:58.577 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-1616d155-4bd5-4e46-88f9-e5eb92346c8b/userFiles-79b05243-968a-4b20-b2ce-46f8773f2fa0/sparklyr-3.0-2.12.jar to class loader
24/04/15 21:56:58.593 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50588.
24/04/15 21:56:58.593 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:50588
24/04/15 21:56:58.593 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/15 21:56:58.608 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 50588, None)
24/04/15 21:56:58.624 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:50588 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 50588, None)
24/04/15 21:56:58.624 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 50588, None)
24/04/15 21:56:58.624 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 50588, None)
24/04/15 21:56:58.889 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/15 21:56:58.889 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/15 21:57:02.582 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/15 21:57:02.710 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/15 21:57:02.945 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/15 21:57:03.224 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/15 21:57:03.224 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/15 21:57:03.224 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/15 21:57:03.268 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/15 21:57:03.393 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/15 21:57:03.394 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/15 21:57:04.414 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/15 21:57:05.711 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/15 21:57:05.713 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/15 21:57:05.780 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/15 21:57:05.780 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/15 21:57:05.796 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/15 21:57:05.930 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/15 21:57:05.930 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/15 21:57:05.962 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/15 21:57:06.070 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 21:57:06.072 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 21:57:06.079 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/15 21:57:06.079 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/15 21:57:06.079 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/15 21:57:06.079 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 21:57:06.079 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 21:57:06.079 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 21:57:06.079 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 21:57:06.079 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/15 21:57:06.079 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/15 21:57:06.802 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 175.7162 ms
24/04/15 21:57:06.915 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 21:57:06.921 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,005067 s
24/04/15 21:57:10.803 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/15 21:57:12.119 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.9349 ms
24/04/15 21:57:12.176 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 21:57:12.176 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/15 21:57:12.191 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/15 21:57:12.191 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 21:57:12.191 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 21:57:12.191 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/15 21:57:12.276 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/15 21:57:12.326 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/15 21:57:12.326 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 21:57:12.326 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/15 21:57:12.349 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 21:57:12.351 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/15 21:57:12.393 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 21:57:12.410 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/15 21:57:12.909 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 158.7212 ms
24/04/15 21:57:12.926 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1559 bytes result sent to driver
24/04/15 21:57:12.945 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 551 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 21:57:12.948 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/15 21:57:12.954 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,734 s
24/04/15 21:57:12.958 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 21:57:12.959 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/15 21:57:12.960 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,782327 s
24/04/15 21:57:13.267 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 205.4806 ms
24/04/15 21:57:16.418 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 21:57:16.419 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/15 21:57:16.420 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/15 21:57:16.420 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 21:57:16.420 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 21:57:16.421 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/15 21:57:16.424 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/15 21:57:16.424 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/15 21:57:16.424 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 12.7 KiB, free: 912.3 MiB)
24/04/15 21:57:16.424 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/15 21:57:16.424 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 21:57:16.424 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/15 21:57:16.424 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 21:57:16.424 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/15 21:57:16.507 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1473 bytes result sent to driver
24/04/15 21:57:16.507 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 83 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 21:57:16.507 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/15 21:57:16.507 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,084 s
24/04/15 21:57:16.507 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 21:57:16.507 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/15 21:57:16.507 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,098981 s
24/04/15 21:57:18.750 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 21:57:18.751 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 21:57:18.754 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/15 21:57:18.754 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/15 21:57:18.756 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/15 21:57:18.757 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/15 21:57:18.825 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 36.9896 ms
24/04/15 21:57:18.840 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.569 ms
24/04/15 21:57:18.858 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.1422 ms
24/04/15 21:59:03.661 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 21:59:03.661 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/15 21:59:03.661 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/15 21:59:03.661 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 21:59:03.661 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 21:59:03.677 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26), which has no missing parents
24/04/15 21:59:03.699 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 107.3 KiB, free 912.0 MiB)
24/04/15 21:59:03.701 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 912.0 MiB)
24/04/15 21:59:03.703 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 27.1 KiB, free: 912.2 MiB)
24/04/15 21:59:03.704 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/15 21:59:03.705 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 21:59:03.706 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/15 21:59:03.709 dispatcher-event-loop-0 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 21:59:03.709 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 21:59:03.709 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/15 21:59:03.912 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 127.4204 ms
24/04/15 21:59:04.330 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 686.4 KiB, free 911.4 MiB)
24/04/15 21:59:04.330 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on DESKTOP-LH06ASP:50588 (size: 686.4 KiB, free: 911.6 MiB)
24/04/15 21:59:04.343 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 4.8718 ms
24/04/15 21:59:04.426 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 21:59:04.492 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 101.3411 ms
24/04/15 21:59:04.523 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_13_0]
24/04/15 21:59:04.523 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2485 bytes result sent to driver
24/04/15 21:59:04.523 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 816 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 21:59:04.523 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/15 21:59:04.523 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0,845 s
24/04/15 21:59:04.523 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 21:59:04.523 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/15 21:59:04.523 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0,861837 s
24/04/15 21:59:04.740 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 148.8495 ms
24/04/15 22:11:30.839 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 22:11:30.855 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
24/04/15 22:11:30.855 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
24/04/15 22:11:30.855 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 22:11:30.855 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 22:11:30.855 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at collect at utils.scala:26), which has no missing parents
24/04/15 22:11:30.855 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 56.4 KiB, free 911.4 MiB)
24/04/15 22:11:30.855 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 911.4 MiB)
24/04/15 22:11:30.871 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 13.5 KiB, free: 911.6 MiB)
24/04/15 22:11:30.871 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
24/04/15 22:11:30.871 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 22:11:30.871 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/15 22:11:30.871 dispatcher-event-loop-0 WARN TaskSetManager: Stage 3 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 22:11:30.871 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 22:11:30.871 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/15 22:11:30.949 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 10.7536 ms
24/04/15 22:11:30.949 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1467 bytes result sent to driver
24/04/15 22:11:30.949 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 78 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 22:11:30.949 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/15 22:11:30.949 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0,094 s
24/04/15 22:11:30.949 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 22:11:30.949 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/04/15 22:11:30.949 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0,105463 s
24/04/15 22:11:30.964 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.1218 ms
24/04/15 22:22:42.693 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 13.5 KiB, free: 911.6 MiB)
24/04/15 22:22:42.693 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 22:22:42.709 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 27.1 KiB, free: 911.6 MiB)
24/04/15 22:22:44.001 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 22:22:44.001 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/04/15 22:22:44.001 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
24/04/15 22:22:44.001 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 22:22:44.001 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 22:22:44.001 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:26), which has no missing parents
24/04/15 22:22:44.001 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 62.4 KiB, free 911.6 MiB)
24/04/15 22:22:44.001 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.6 MiB)
24/04/15 22:22:44.001 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 22:22:44.001 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
24/04/15 22:22:44.001 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 22:22:44.001 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/04/15 22:22:44.016 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 22:22:44.016 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/04/15 22:22:44.048 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1387 bytes result sent to driver
24/04/15 22:22:44.078 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 62 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 22:22:44.080 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/04/15 22:22:44.082 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0,080 s
24/04/15 22:22:44.083 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 22:22:44.084 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/04/15 22:22:44.084 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0,080220 s
24/04/15 22:22:47.455 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 22:22:47.455 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
24/04/15 22:22:47.455 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
24/04/15 22:22:47.455 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 22:22:47.455 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 22:22:47.455 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at collect at utils.scala:26), which has no missing parents
24/04/15 22:22:47.455 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 62.4 KiB, free 911.5 MiB)
24/04/15 22:22:47.455 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.5 MiB)
24/04/15 22:22:47.455 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 22:22:47.455 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
24/04/15 22:22:47.455 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 22:22:47.455 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/04/15 22:22:47.455 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 22:22:47.455 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/04/15 22:22:47.487 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1430 bytes result sent to driver
24/04/15 22:22:47.487 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 32 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 22:22:47.487 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/04/15 22:22:47.487 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0,032 s
24/04/15 22:22:47.487 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 22:22:47.487 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/04/15 22:22:47.487 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0,038422 s
24/04/15 22:22:49.604 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 22:22:49.604 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 22:22:49.698 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 22:22:49.698 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
24/04/15 22:22:49.698 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
24/04/15 22:22:49.698 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 22:22:49.698 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 22:22:49.698 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[32] at collect at utils.scala:26), which has no missing parents
24/04/15 22:22:49.714 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 123.2 KiB, free 911.5 MiB)
24/04/15 22:22:49.714 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 911.5 MiB)
24/04/15 22:22:49.714 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 31.0 KiB, free: 911.6 MiB)
24/04/15 22:22:49.714 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535
24/04/15 22:22:49.714 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[32] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 22:22:49.714 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
24/04/15 22:22:49.729 dispatcher-event-loop-1 WARN TaskSetManager: Stage 6 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 22:22:49.729 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 22:22:49.729 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/04/15 22:22:49.729 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO BlockManager: Found block rdd_13_0 locally
24/04/15 22:22:49.948 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 143.3389 ms
24/04/15 22:22:49.964 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 4.2031 ms
24/04/15 22:22:50.089 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 247591 bytes result sent to driver
24/04/15 22:22:50.089 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 375 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 22:22:50.089 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/04/15 22:22:50.089 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0,391 s
24/04/15 22:22:50.089 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 22:22:50.089 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
24/04/15 22:22:50.089 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0,396066 s
24/04/15 22:22:52.479 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/15 22:22:52.603 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 22:22:52.603 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
24/04/15 22:22:52.603 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
24/04/15 22:22:52.603 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 22:22:52.603 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 22:22:52.619 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[38] at collect at utils.scala:26), which has no missing parents
24/04/15 22:22:52.619 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 123.2 KiB, free 911.5 MiB)
24/04/15 22:22:52.619 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 911.5 MiB)
24/04/15 22:22:52.619 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 31.0 KiB, free: 911.6 MiB)
24/04/15 22:22:52.619 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535
24/04/15 22:22:52.619 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 22:22:52.619 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
24/04/15 22:22:52.634 dispatcher-event-loop-0 WARN TaskSetManager: Stage 7 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 22:22:52.634 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 22:22:52.634 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
24/04/15 22:22:52.634 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO BlockManager: Found block rdd_13_0 locally
24/04/15 22:22:52.784 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 135223 bytes result sent to driver
24/04/15 22:22:52.797 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 178 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 22:22:52.797 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/04/15 22:22:52.797 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0,178 s
24/04/15 22:22:52.797 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 22:22:52.797 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
24/04/15 22:22:52.797 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0,182066 s
24/04/15 22:25:22.370 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/15 22:25:22.424 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 22:25:22.424 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (collect at utils.scala:26) with 1 output partitions
24/04/15 22:25:22.424 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:26)
24/04/15 22:25:22.424 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 22:25:22.424 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 22:25:22.424 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[41] at collect at utils.scala:26), which has no missing parents
24/04/15 22:25:22.424 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 62.4 KiB, free 911.6 MiB)
24/04/15 22:25:22.439 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.6 MiB)
24/04/15 22:25:22.440 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 22:25:22.440 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535
24/04/15 22:25:22.441 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[41] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 22:25:22.441 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
24/04/15 22:25:22.442 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 22:25:22.442 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
24/04/15 22:25:22.468 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1430 bytes result sent to driver
24/04/15 22:25:22.470 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 29 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 22:25:22.470 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/04/15 22:25:22.470 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (collect at utils.scala:26) finished in 0,046 s
24/04/15 22:25:22.471 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 22:25:22.471 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/04/15 22:25:22.471 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: collect at utils.scala:26, took 0,039513 s
24/04/15 22:25:25.369 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 22:25:25.369 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (collect at utils.scala:26) with 1 output partitions
24/04/15 22:25:25.369 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:26)
24/04/15 22:25:25.369 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 22:25:25.369 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 22:25:25.369 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[44] at collect at utils.scala:26), which has no missing parents
24/04/15 22:25:25.385 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 62.4 KiB, free 911.5 MiB)
24/04/15 22:25:25.385 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.5 MiB)
24/04/15 22:25:25.385 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 22:25:25.385 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1535
24/04/15 22:25:25.385 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[44] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 22:25:25.385 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
24/04/15 22:25:25.385 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/15 22:25:25.385 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
24/04/15 22:25:25.416 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1430 bytes result sent to driver
24/04/15 22:25:25.416 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 31 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 22:25:25.416 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
24/04/15 22:25:25.416 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (collect at utils.scala:26) finished in 0,047 s
24/04/15 22:25:25.416 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 22:25:25.416 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
24/04/15 22:25:25.416 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: collect at utils.scala:26, took 0,037375 s
24/04/15 22:25:27.550 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 22:25:27.550 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collect at utils.scala:26) with 1 output partitions
24/04/15 22:25:27.550 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:26)
24/04/15 22:25:27.550 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 22:25:27.565 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 22:25:27.565 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[50] at collect at utils.scala:26), which has no missing parents
24/04/15 22:25:27.565 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 123.2 KiB, free 911.4 MiB)
24/04/15 22:25:27.565 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 911.3 MiB)
24/04/15 22:25:27.565 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 31.1 KiB, free: 911.6 MiB)
24/04/15 22:25:27.565 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1535
24/04/15 22:25:27.565 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[50] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 22:25:27.565 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
24/04/15 22:25:27.565 dispatcher-event-loop-0 WARN TaskSetManager: Stage 10 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 22:25:27.565 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 22:25:27.565 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
24/04/15 22:25:27.612 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 22:25:27.612 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/15 22:25:27.612 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO BlockManager: Found block rdd_13_0 locally
24/04/15 22:25:27.715 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 246270 bytes result sent to driver
24/04/15 22:25:27.717 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 152 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 22:25:27.717 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
24/04/15 22:25:27.717 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 10 (collect at utils.scala:26) finished in 0,152 s
24/04/15 22:25:27.718 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 22:25:27.718 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
24/04/15 22:25:27.718 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collect at utils.scala:26, took 0,154648 s
24/04/15 22:25:30.031 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/15 22:25:30.046 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collect at utils.scala:26) with 1 output partitions
24/04/15 22:25:30.050 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:26)
24/04/15 22:25:30.050 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/15 22:25:30.050 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/15 22:25:30.050 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[56] at collect at utils.scala:26), which has no missing parents
24/04/15 22:25:30.050 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 123.2 KiB, free 911.4 MiB)
24/04/15 22:25:30.050 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 911.3 MiB)
24/04/15 22:25:30.050 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on DESKTOP-LH06ASP:50588 (size: 31.1 KiB, free: 911.6 MiB)
24/04/15 22:25:30.050 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1535
24/04/15 22:25:30.050 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[56] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/15 22:25:30.050 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
24/04/15 22:25:30.068 dispatcher-event-loop-0 WARN TaskSetManager: Stage 11 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/15 22:25:30.068 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/15 22:25:30.068 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
24/04/15 22:25:30.068 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO BlockManager: Found block rdd_13_0 locally
24/04/15 22:25:30.148 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 31.1 KiB, free: 911.6 MiB)
24/04/15 22:25:30.180 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 136802 bytes result sent to driver
24/04/15 22:25:30.195 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 145 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/15 22:25:30.195 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
24/04/15 22:25:30.195 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 11 (collect at utils.scala:26) finished in 0,145 s
24/04/15 22:25:30.195 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/15 22:25:30.195 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
24/04/15 22:25:30.195 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collect at utils.scala:26, took 0,152179 s
24/04/15 22:26:59.287 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on DESKTOP-LH06ASP:50588 in memory (size: 31.1 KiB, free: 911.6 MiB)
24/04/15 22:27:30.959 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/15 22:27:30.960 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/15 22:27:30.982 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/15 22:27:31.001 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/15 22:27:31.055 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/15 22:27:31.056 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/15 22:27:31.059 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/15 22:27:31.062 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/15 22:27:31.068 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1616d155-4bd5-4e46-88f9-e5eb92346c8b\userFiles-79b05243-968a-4b20-b2ce-46f8773f2fa0
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1616d155-4bd5-4e46-88f9-e5eb92346c8b\userFiles-79b05243-968a-4b20-b2ce-46f8773f2fa0\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/15 22:27:31.069 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/15 22:27:31.070 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/15 22:27:31.070 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-2f1211ea-c5b7-4651-8aec-fc50a3cf242e
24/04/15 22:27:31.072 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1616d155-4bd5-4e46-88f9-e5eb92346c8b\userFiles-79b05243-968a-4b20-b2ce-46f8773f2fa0
24/04/15 22:27:31.075 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1616d155-4bd5-4e46-88f9-e5eb92346c8b\userFiles-79b05243-968a-4b20-b2ce-46f8773f2fa0
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1616d155-4bd5-4e46-88f9-e5eb92346c8b\userFiles-79b05243-968a-4b20-b2ce-46f8773f2fa0\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/15 22:27:31.075 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1616d155-4bd5-4e46-88f9-e5eb92346c8b
24/04/15 22:27:31.078 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1616d155-4bd5-4e46-88f9-e5eb92346c8b
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1616d155-4bd5-4e46-88f9-e5eb92346c8b\userFiles-79b05243-968a-4b20-b2ce-46f8773f2fa0\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/16 11:35:05.330 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/16 11:35:05.812 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/16 11:35:05.862 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/16 11:35:05.992 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/16 11:35:06.093 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/16 11:35:06.093 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/16 11:35:06.094 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/16 11:35:06.095 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/16 11:35:06.140 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/16 11:35:06.159 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/16 11:35:06.160 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/16 11:35:06.260 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/16 11:35:06.262 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/16 11:35:06.262 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/16 11:35:06.262 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/16 11:35:06.262 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/16 11:35:06.403 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 56310.
24/04/16 11:35:06.455 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/16 11:35:06.513 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/16 11:35:06.564 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/16 11:35:06.568 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/16 11:35:06.581 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/16 11:35:06.637 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-ebc91d5f-55af-40ce-950a-afcaeacbb637
24/04/16 11:35:06.680 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/16 11:35:06.717 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/16 11:35:06.723 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/16 11:35:07.058 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/16 11:35:07.226 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/16 11:35:07.305 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:56310/jars/sparklyr-3.0-2.12.jar with timestamp 1713263705797
24/04/16 11:35:07.444 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/16 11:35:07.476 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/16 11:35:07.515 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:56310/jars/sparklyr-3.0-2.12.jar with timestamp 1713263705797
24/04/16 11:35:07.656 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:56310 after 68 ms (0 ms spent in bootstraps)
24/04/16 11:35:07.679 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:56310/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-99de32a5-0760-4bde-9742-34745eaef5ef\userFiles-f1433f33-ccea-40d4-b466-34b5fd74bf7b\fetchFileTemp2264881599188458321.tmp
24/04/16 11:35:08.155 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-99de32a5-0760-4bde-9742-34745eaef5ef/userFiles-f1433f33-ccea-40d4-b466-34b5fd74bf7b/sparklyr-3.0-2.12.jar to class loader
24/04/16 11:35:08.192 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56331.
24/04/16 11:35:08.193 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:56331
24/04/16 11:35:08.195 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/16 11:35:08.202 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 56331, None)
24/04/16 11:35:08.218 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:56331 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 56331, None)
24/04/16 11:35:08.234 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 56331, None)
24/04/16 11:35:08.234 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 56331, None)
24/04/16 11:35:09.432 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/16 11:35:09.515 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/16 11:35:19.621 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/16 11:35:19.839 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/16 11:35:20.491 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/16 11:35:21.093 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/16 11:35:21.093 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/16 11:35:21.093 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/16 11:35:21.220 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/16 11:35:21.557 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/16 11:35:21.559 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/16 11:35:23.351 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/16 11:35:25.847 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/16 11:35:25.851 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/16 11:35:25.957 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/16 11:35:25.957 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/16 11:35:26.000 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/16 11:35:26.207 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/16 11:35:26.207 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/16 11:35:26.276 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/16 11:35:26.438 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 11:35:26.443 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 11:35:26.469 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/16 11:35:26.471 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/16 11:35:26.472 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/16 11:35:26.472 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 11:35:26.473 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 11:35:26.476 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 11:35:26.476 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 11:35:26.478 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 11:35:26.478 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 11:35:27.802 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 459.8888 ms
24/04/16 11:35:28.072 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:35:28.083 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,006688 s
24/04/16 11:35:34.753 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/16 11:35:36.991 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.2155 ms
24/04/16 11:35:37.105 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:35:37.145 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/16 11:35:37.145 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/16 11:35:37.145 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:35:37.145 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:35:37.156 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/16 11:35:37.361 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/16 11:35:37.526 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/16 11:35:37.526 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 11:35:37.537 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/16 11:35:37.567 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 11:35:37.569 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/16 11:35:37.720 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 11:35:37.760 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/16 11:35:38.535 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 313.9456 ms
24/04/16 11:35:38.577 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1516 bytes result sent to driver
24/04/16 11:35:38.594 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 914 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:35:38.594 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/16 11:35:38.609 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 1,418 s
24/04/16 11:35:38.610 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:35:38.610 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/16 11:35:38.617 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 1,505254 s
24/04/16 11:35:38.778 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 11:35:39.172 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 350.2152 ms
24/04/16 11:35:44.801 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:35:44.806 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/16 11:35:44.806 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/16 11:35:44.806 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:35:44.806 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:35:44.806 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/16 11:35:44.812 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/16 11:35:44.812 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/16 11:35:44.812 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 11:35:44.818 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/16 11:35:44.818 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 11:35:44.818 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/16 11:35:44.818 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 11:35:44.818 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/16 11:35:44.915 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1473 bytes result sent to driver
24/04/16 11:35:44.921 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 103 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:35:44.921 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/16 11:35:44.921 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,111 s
24/04/16 11:35:44.921 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:35:44.921 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/16 11:35:44.921 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,117485 s
24/04/16 11:35:49.212 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 11:35:49.214 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 11:35:49.214 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 11:35:49.214 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 11:35:49.214 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 11:35:49.214 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 11:35:49.447 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 108.7278 ms
24/04/16 11:35:49.491 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.0827 ms
24/04/16 11:35:49.513 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.9181 ms
24/04/16 11:36:35.459 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:36:35.459 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/16 11:36:35.459 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/16 11:36:35.459 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:36:35.459 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:36:35.459 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at collect at utils.scala:26), which has no missing parents
24/04/16 11:36:35.483 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 56.4 KiB, free 912.2 MiB)
24/04/16 11:36:35.491 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 912.2 MiB)
24/04/16 11:36:35.491 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 13.5 KiB, free: 912.3 MiB)
24/04/16 11:36:35.491 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/16 11:36:35.491 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 11:36:35.491 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/16 11:36:35.510 dispatcher-event-loop-1 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:36:35.510 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 11:36:35.510 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/16 11:36:35.737 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 132.3883 ms
24/04/16 11:36:35.759 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 10.4445 ms
24/04/16 11:36:35.765 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1510 bytes result sent to driver
24/04/16 11:36:35.765 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 274 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:36:35.765 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/16 11:36:35.765 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0,306 s
24/04/16 11:36:35.765 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:36:35.765 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/16 11:36:35.770 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0,301239 s
24/04/16 11:36:35.792 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 19.0573 ms
24/04/16 11:36:36.407 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 13.5 KiB, free: 912.3 MiB)
24/04/16 11:36:38.317 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:36:38.324 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
24/04/16 11:36:38.324 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
24/04/16 11:36:38.324 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:36:38.324 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:36:38.324 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:26), which has no missing parents
24/04/16 11:36:38.324 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/16 11:36:38.334 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/16 11:36:38.335 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 11:36:38.335 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
24/04/16 11:36:38.337 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 11:36:38.337 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/16 11:36:38.337 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 11:36:38.337 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/16 11:36:38.403 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1430 bytes result sent to driver
24/04/16 11:36:38.403 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 66 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:36:38.403 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/16 11:36:38.403 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0,079 s
24/04/16 11:36:38.403 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:36:38.403 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/04/16 11:36:38.403 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0,084193 s
24/04/16 11:36:42.820 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 11:36:42.895 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:36:42.895 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/04/16 11:36:42.895 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
24/04/16 11:36:42.895 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:36:42.897 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:36:42.897 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at utils.scala:26), which has no missing parents
24/04/16 11:36:42.897 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/16 11:36:42.897 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/16 11:36:42.897 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 11:36:42.897 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
24/04/16 11:36:42.897 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 11:36:42.897 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/04/16 11:36:42.897 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 11:36:42.897 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/04/16 11:36:42.958 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1430 bytes result sent to driver
24/04/16 11:36:43.100 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 195 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:36:43.100 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/04/16 11:36:43.100 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0,203 s
24/04/16 11:36:43.100 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:36:43.100 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/04/16 11:36:43.100 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0,205652 s
24/04/16 11:36:47.103 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:36:47.104 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
24/04/16 11:36:47.104 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
24/04/16 11:36:47.104 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:36:47.104 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:36:47.104 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[28] at collect at utils.scala:26), which has no missing parents
24/04/16 11:36:47.120 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 123.2 KiB, free 912.0 MiB)
24/04/16 11:36:47.124 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 912.0 MiB)
24/04/16 11:36:47.126 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.0 KiB, free: 912.2 MiB)
24/04/16 11:36:47.126 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
24/04/16 11:36:47.126 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[28] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 11:36:47.126 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/04/16 11:36:47.133 dispatcher-event-loop-1 WARN TaskSetManager: Stage 5 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:36:47.133 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 11:36:47.133 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/04/16 11:36:47.548 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 11:36:47.555 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 11:36:48.131 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 686.4 KiB, free 911.5 MiB)
24/04/16 11:36:48.131 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_22_0 in memory on DESKTOP-LH06ASP:56331 (size: 686.4 KiB, free: 911.6 MiB)
24/04/16 11:36:48.153 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 6.6369 ms
24/04/16 11:36:48.320 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 153.7954 ms
24/04/16 11:36:48.716 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 278.8039 ms
24/04/16 11:36:48.747 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO CodeGenerator: Code generated in 7.47 ms
24/04/16 11:36:49.029 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 245072 bytes result sent to driver
24/04/16 11:36:49.031 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1905 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:36:49.031 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/04/16 11:36:49.031 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 1,918 s
24/04/16 11:36:49.031 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:36:49.031 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/04/16 11:36:49.033 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 1,929844 s
24/04/16 11:36:49.493 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 233.1397 ms
24/04/16 11:36:53.258 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 11:36:53.272 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:36:53.272 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
24/04/16 11:36:53.272 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
24/04/16 11:36:53.272 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:36:53.272 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:36:53.272 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[34] at collect at utils.scala:26), which has no missing parents
24/04/16 11:36:53.283 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 123.2 KiB, free 911.5 MiB)
24/04/16 11:36:53.289 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 911.5 MiB)
24/04/16 11:36:53.289 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 11:36:53.289 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535
24/04/16 11:36:53.289 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[34] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 11:36:53.289 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
24/04/16 11:36:53.304 dispatcher-event-loop-1 WARN TaskSetManager: Stage 6 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:36:53.304 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 11:36:53.304 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/04/16 11:36:53.318 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 11:36:53.464 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 137627 bytes result sent to driver
24/04/16 11:36:53.465 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 173 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:36:53.466 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/04/16 11:36:53.466 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0,183 s
24/04/16 11:36:53.466 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:36:53.467 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
24/04/16 11:36:53.467 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0,189477 s
24/04/16 11:36:58.200 nioEventLoopGroup-2-2 INFO Instrumentation: [2f307bb0] training finished
24/04/16 11:36:58.499 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 11:36:58.985 nioEventLoopGroup-2-2 INFO Instrumentation: [4fd2a71c] training finished
24/04/16 11:36:59.856 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 69.5164 ms
24/04/16 11:36:59.934 nioEventLoopGroup-2-2 INFO Instrumentation: [f6e013f1] Stage class: RandomForestRegressor
24/04/16 11:36:59.934 nioEventLoopGroup-2-2 INFO Instrumentation: [f6e013f1] Stage uid: random_forest__72bdf567_289c_4a59_b38f_554012e4a9e0
24/04/16 11:36:59.934 nioEventLoopGroup-2-2 INFO Instrumentation: [f6e013f1] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
24/04/16 11:36:59.950 nioEventLoopGroup-2-2 INFO Instrumentation: [f6e013f1] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/16 11:37:00.077 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 11:37:00.080 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 11:37:00.080 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (take at DecisionTreeMetadata.scala:119)
24/04/16 11:37:00.080 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:37:00.080 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:37:00.080 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[47] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 11:37:00.094 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 398.0 KiB, free 911.2 MiB)
24/04/16 11:37:00.100 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 82.7 KiB, free 911.2 MiB)
24/04/16 11:37:00.100 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 82.7 KiB, free: 911.5 MiB)
24/04/16 11:37:00.100 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:00.100 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[47] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:00.100 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
24/04/16 11:37:00.115 dispatcher-event-loop-0 WARN TaskSetManager: Stage 7 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:37:00.115 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 11:37:00.115 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
24/04/16 11:37:00.253 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 11:37:00.552 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 123.099 ms
24/04/16 11:37:00.583 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 8.0698 ms
24/04/16 11:37:00.601 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 7.6877 ms
24/04/16 11:37:00.617 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO CodeGenerator: Code generated in 6.099 ms
24/04/16 11:37:00.617 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1700 bytes result sent to driver
24/04/16 11:37:00.617 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 517 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:00.617 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/04/16 11:37:00.617 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (take at DecisionTreeMetadata.scala:119) finished in 0,535 s
24/04/16 11:37:00.617 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:00.617 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
24/04/16 11:37:00.617 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: take at DecisionTreeMetadata.scala:119, took 0,548672 s
24/04/16 11:37:00.631 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 11:37:00.631 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions
24/04/16 11:37:00.631 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 11:37:00.631 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:37:00.631 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:37:00.647 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[46] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 11:37:00.649 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 398.0 KiB, free 910.8 MiB)
24/04/16 11:37:00.664 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 82.8 KiB, free 910.7 MiB)
24/04/16 11:37:00.671 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 82.8 KiB, free: 911.5 MiB)
24/04/16 11:37:00.672 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:00.672 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[46] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:00.672 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
24/04/16 11:37:00.680 dispatcher-event-loop-1 WARN TaskSetManager: Stage 8 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:37:00.680 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 11:37:00.680 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
24/04/16 11:37:00.698 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 11:37:00.922 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 82.7 KiB, free: 911.5 MiB)
24/04/16 11:37:01.452 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1815 bytes result sent to driver
24/04/16 11:37:01.455 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 783 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:01.455 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/04/16 11:37:01.455 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,806 s
24/04/16 11:37:01.455 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:01.455 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/04/16 11:37:01.455 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,813556 s
24/04/16 11:37:01.574 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 11:37:01.616 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 49 (flatMap at RandomForest.scala:1039) as input to shuffle 0
24/04/16 11:37:01.624 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (collectAsMap at RandomForest.scala:1054) with 1 output partitions
24/04/16 11:37:01.625 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 10 (collectAsMap at RandomForest.scala:1054)
24/04/16 11:37:01.625 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
24/04/16 11:37:01.625 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
24/04/16 11:37:01.629 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[49] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 11:37:01.651 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 407.0 KiB, free 910.8 MiB)
24/04/16 11:37:01.655 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 86.5 KiB, free 910.7 MiB)
24/04/16 11:37:01.655 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 86.5 KiB, free: 911.5 MiB)
24/04/16 11:37:01.658 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:01.658 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[49] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:01.658 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
24/04/16 11:37:01.673 dispatcher-event-loop-1 WARN TaskSetManager: Stage 9 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:37:01.673 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 11:37:01.677 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
24/04/16 11:37:01.788 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 11:37:01.967 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 82.8 KiB, free: 911.5 MiB)
24/04/16 11:37:02.605 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2040 bytes result sent to driver
24/04/16 11:37:02.605 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 944 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:02.605 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
24/04/16 11:37:02.614 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 9 (flatMap at RandomForest.scala:1039) finished in 0,982 s
24/04/16 11:37:02.614 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 11:37:02.614 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 11:37:02.614 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 10)
24/04/16 11:37:02.614 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 11:37:02.614 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[51] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 11:37:02.627 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 11.9 KiB, free 911.1 MiB)
24/04/16 11:37:02.629 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 911.1 MiB)
24/04/16 11:37:02.629 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 4.5 KiB, free: 911.5 MiB)
24/04/16 11:37:02.629 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:02.629 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[51] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:02.629 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
24/04/16 11:37:02.637 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 11:37:02.637 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
24/04/16 11:37:02.715 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 11:37:02.715 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 31 ms
24/04/16 11:37:02.974 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 48769 bytes result sent to driver
24/04/16 11:37:03.002 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 373 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:03.002 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
24/04/16 11:37:03.002 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 10 (collectAsMap at RandomForest.scala:1054) finished in 0,379 s
24/04/16 11:37:03.002 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:03.002 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
24/04/16 11:37:03.002 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: collectAsMap at RandomForest.scala:1054, took 1,433511 s
24/04/16 11:37:03.033 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 59.1 KiB, free 911.1 MiB)
24/04/16 11:37:03.049 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 911.1 MiB)
24/04/16 11:37:03.049 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 10.0 KiB, free: 911.5 MiB)
24/04/16 11:37:03.049 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 11 from broadcast at RandomForest.scala:293
24/04/16 11:37:03.070 nioEventLoopGroup-2-2 INFO Instrumentation: [f6e013f1] {"numFeatures":545}
24/04/16 11:37:03.070 nioEventLoopGroup-2-2 INFO Instrumentation: [f6e013f1] {"numClasses":0}
24/04/16 11:37:03.070 nioEventLoopGroup-2-2 INFO Instrumentation: [f6e013f1] {"numExamples":1429}
24/04/16 11:37:03.070 nioEventLoopGroup-2-2 INFO Instrumentation: [f6e013f1] {"sumOfWeights":1429.0}
24/04/16 11:37:03.086 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.1 KiB, free 911.0 MiB)
24/04/16 11:37:03.095 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 911.0 MiB)
24/04/16 11:37:03.096 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 10.3 KiB, free: 911.5 MiB)
24/04/16 11:37:03.096 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 12 from broadcast at RandomForest.scala:622
24/04/16 11:37:03.126 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 11:37:03.129 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 54 (mapPartitions at RandomForest.scala:644) as input to shuffle 1
24/04/16 11:37:03.129 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 11:37:03.129 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collectAsMap at RandomForest.scala:663)
24/04/16 11:37:03.129 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
24/04/16 11:37:03.131 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
24/04/16 11:37:03.133 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[54] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 11:37:03.145 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 441.5 KiB, free 910.6 MiB)
24/04/16 11:37:03.147 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 99.2 KiB, free 910.5 MiB)
24/04/16 11:37:03.149 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 99.2 KiB, free: 911.4 MiB)
24/04/16 11:37:03.150 dag-scheduler-event-loop INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:03.150 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[54] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:03.150 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
24/04/16 11:37:03.157 dispatcher-event-loop-1 WARN TaskSetManager: Stage 11 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:37:03.157 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 11:37:03.157 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
24/04/16 11:37:03.185 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 11:37:03.417 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 4.5 KiB, free: 911.4 MiB)
24/04/16 11:37:03.431 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 86.5 KiB, free: 911.5 MiB)
24/04/16 11:37:03.841 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO MemoryStore: Block rdd_53_0 stored as values in memory (estimated size 3.2 MiB, free 907.9 MiB)
24/04/16 11:37:03.843 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_53_0 in memory on DESKTOP-LH06ASP:56331 (size: 3.2 MiB, free: 908.4 MiB)
24/04/16 11:37:03.959 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1954 bytes result sent to driver
24/04/16 11:37:03.961 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 809 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:03.961 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
24/04/16 11:37:03.962 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 11 (mapPartitions at RandomForest.scala:644) finished in 0,828 s
24/04/16 11:37:03.963 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 11:37:03.963 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 11:37:03.963 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 12)
24/04/16 11:37:03.963 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 11:37:03.963 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[56] at map at RandomForest.scala:663), which has no missing parents
24/04/16 11:37:03.965 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.4 KiB, free 907.8 MiB)
24/04/16 11:37:03.968 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 907.8 MiB)
24/04/16 11:37:03.968 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 3.8 KiB, free: 908.4 MiB)
24/04/16 11:37:03.969 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:03.969 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[56] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:03.969 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
24/04/16 11:37:03.970 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 11:37:03.970 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
24/04/16 11:37:03.973 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO ShuffleBlockFetcherIterator: Getting 1 (194.1 KiB) non-empty blocks including 1 (194.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 11:37:03.973 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 11:37:04.198 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 6380 bytes result sent to driver
24/04/16 11:37:04.200 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 230 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:04.200 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
24/04/16 11:37:04.201 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collectAsMap at RandomForest.scala:663) finished in 0,237 s
24/04/16 11:37:04.201 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:04.201 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
24/04/16 11:37:04.202 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collectAsMap at RandomForest.scala:663, took 1,073501 s
24/04/16 11:37:04.205 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(12) (from destroy at RandomForest.scala:674)
24/04/16 11:37:04.208 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 10.3 KiB, free: 908.4 MiB)
24/04/16 11:37:04.219 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 32.6 KiB, free 907.8 MiB)
24/04/16 11:37:04.221 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 907.8 MiB)
24/04/16 11:37:04.222 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 20.3 KiB, free: 908.3 MiB)
24/04/16 11:37:04.223 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 15 from broadcast at RandomForest.scala:622
24/04/16 11:37:04.237 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 11:37:04.237 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 57 (mapPartitions at RandomForest.scala:644) as input to shuffle 2
24/04/16 11:37:04.237 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 11:37:04.237 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (collectAsMap at RandomForest.scala:663)
24/04/16 11:37:04.237 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
24/04/16 11:37:04.237 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
24/04/16 11:37:04.237 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[57] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 11:37:04.260 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 462.6 KiB, free 907.4 MiB)
24/04/16 11:37:04.263 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 112.3 KiB, free 907.3 MiB)
24/04/16 11:37:04.264 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 112.3 KiB, free: 908.2 MiB)
24/04/16 11:37:04.264 dag-scheduler-event-loop INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:04.265 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[57] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:04.265 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
24/04/16 11:37:04.275 dispatcher-event-loop-1 WARN TaskSetManager: Stage 13 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:37:04.275 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 11:37:04.275 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
24/04/16 11:37:04.295 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO BlockManager: Found block rdd_53_0 locally
24/04/16 11:37:04.421 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1954 bytes result sent to driver
24/04/16 11:37:04.421 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 155 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:04.421 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
24/04/16 11:37:04.421 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 13 (mapPartitions at RandomForest.scala:644) finished in 0,184 s
24/04/16 11:37:04.421 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 11:37:04.421 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 11:37:04.421 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 14)
24/04/16 11:37:04.421 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 11:37:04.421 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[59] at map at RandomForest.scala:663), which has no missing parents
24/04/16 11:37:04.426 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 11.1 KiB, free 907.2 MiB)
24/04/16 11:37:04.426 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 907.2 MiB)
24/04/16 11:37:04.426 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.2 KiB, free: 908.2 MiB)
24/04/16 11:37:04.426 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:04.426 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[59] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:04.426 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
24/04/16 11:37:04.426 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 11:37:04.426 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
24/04/16 11:37:04.437 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO ShuffleBlockFetcherIterator: Getting 1 (312.6 KiB) non-empty blocks including 1 (312.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 11:37:04.437 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/04/16 11:37:04.489 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 10497 bytes result sent to driver
24/04/16 11:37:04.489 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 63 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:04.489 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
24/04/16 11:37:04.491 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (collectAsMap at RandomForest.scala:663) finished in 0,065 s
24/04/16 11:37:04.491 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:04.491 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
24/04/16 11:37:04.491 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collectAsMap at RandomForest.scala:663, took 0,248648 s
24/04/16 11:37:04.494 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(15) (from destroy at RandomForest.scala:674)
24/04/16 11:37:04.497 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 20.3 KiB, free: 908.2 MiB)
24/04/16 11:37:04.511 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 54.7 KiB, free 907.2 MiB)
24/04/16 11:37:04.511 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 907.2 MiB)
24/04/16 11:37:04.511 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 33.9 KiB, free: 908.2 MiB)
24/04/16 11:37:04.511 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 18 from broadcast at RandomForest.scala:622
24/04/16 11:37:04.543 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 11:37:04.543 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 60 (mapPartitions at RandomForest.scala:644) as input to shuffle 3
24/04/16 11:37:04.543 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 11:37:04.543 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 16 (collectAsMap at RandomForest.scala:663)
24/04/16 11:37:04.543 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
24/04/16 11:37:04.543 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
24/04/16 11:37:04.543 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[60] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 11:37:04.561 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 493.2 KiB, free 906.7 MiB)
24/04/16 11:37:04.565 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 129.7 KiB, free 906.6 MiB)
24/04/16 11:37:04.566 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 129.7 KiB, free: 908.1 MiB)
24/04/16 11:37:04.567 dag-scheduler-event-loop INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:04.568 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[60] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:04.568 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
24/04/16 11:37:04.578 dispatcher-event-loop-1 WARN TaskSetManager: Stage 15 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:37:04.579 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 11:37:04.579 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
24/04/16 11:37:04.609 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO BlockManager: Found block rdd_53_0 locally
24/04/16 11:37:04.744 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1911 bytes result sent to driver
24/04/16 11:37:04.745 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 176 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:04.746 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
24/04/16 11:37:04.746 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 15 (mapPartitions at RandomForest.scala:644) finished in 0,203 s
24/04/16 11:37:04.746 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 11:37:04.746 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 11:37:04.747 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 16)
24/04/16 11:37:04.747 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 11:37:04.747 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[62] at map at RandomForest.scala:663), which has no missing parents
24/04/16 11:37:04.749 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 13.8 KiB, free 906.6 MiB)
24/04/16 11:37:04.751 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 906.6 MiB)
24/04/16 11:37:04.752 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.9 KiB, free: 908.1 MiB)
24/04/16 11:37:04.753 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:04.753 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[62] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:04.753 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
24/04/16 11:37:04.754 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 11:37:04.754 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
24/04/16 11:37:04.757 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO ShuffleBlockFetcherIterator: Getting 1 (416.0 KiB) non-empty blocks including 1 (416.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 11:37:04.757 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 11:37:04.808 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 16113 bytes result sent to driver
24/04/16 11:37:04.810 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 56 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:04.810 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
24/04/16 11:37:04.810 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 16 (collectAsMap at RandomForest.scala:663) finished in 0,062 s
24/04/16 11:37:04.810 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:04.810 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
24/04/16 11:37:04.810 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collectAsMap at RandomForest.scala:663, took 0,265385 s
24/04/16 11:37:04.810 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(18) (from destroy at RandomForest.scala:674)
24/04/16 11:37:04.819 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 33.9 KiB, free: 908.1 MiB)
24/04/16 11:37:04.826 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 68.5 KiB, free 906.6 MiB)
24/04/16 11:37:04.828 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 42.3 KiB, free 906.6 MiB)
24/04/16 11:37:04.829 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 42.3 KiB, free: 908.1 MiB)
24/04/16 11:37:04.829 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 21 from broadcast at RandomForest.scala:622
24/04/16 11:37:04.852 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 11:37:04.852 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 63 (mapPartitions at RandomForest.scala:644) as input to shuffle 4
24/04/16 11:37:04.852 dag-scheduler-event-loop INFO DAGScheduler: Got job 14 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 11:37:04.852 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 18 (collectAsMap at RandomForest.scala:663)
24/04/16 11:37:04.852 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
24/04/16 11:37:04.852 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
24/04/16 11:37:04.852 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[63] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 11:37:04.871 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 523.4 KiB, free 906.0 MiB)
24/04/16 11:37:04.875 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 143.5 KiB, free 905.9 MiB)
24/04/16 11:37:04.876 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 143.5 KiB, free: 907.9 MiB)
24/04/16 11:37:04.876 dag-scheduler-event-loop INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:04.877 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[63] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:04.877 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
24/04/16 11:37:04.902 dispatcher-event-loop-1 WARN TaskSetManager: Stage 17 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:37:04.902 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 11:37:04.903 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
24/04/16 11:37:04.903 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.2 KiB, free: 907.9 MiB)
24/04/16 11:37:04.913 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 3.8 KiB, free: 907.9 MiB)
24/04/16 11:37:04.923 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 129.7 KiB, free: 908.1 MiB)
24/04/16 11:37:04.932 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO BlockManager: Found block rdd_53_0 locally
24/04/16 11:37:04.943 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.9 KiB, free: 908.1 MiB)
24/04/16 11:37:04.954 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 112.3 KiB, free: 908.2 MiB)
24/04/16 11:37:05.043 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1911 bytes result sent to driver
24/04/16 11:37:05.045 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 167 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:05.045 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
24/04/16 11:37:05.046 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 17 (mapPartitions at RandomForest.scala:644) finished in 0,188 s
24/04/16 11:37:05.046 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 11:37:05.046 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 11:37:05.046 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 18)
24/04/16 11:37:05.047 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 11:37:05.047 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[65] at map at RandomForest.scala:663), which has no missing parents
24/04/16 11:37:05.049 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 15.4 KiB, free 907.1 MiB)
24/04/16 11:37:05.050 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 907.1 MiB)
24/04/16 11:37:05.051 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 6.3 KiB, free: 908.2 MiB)
24/04/16 11:37:05.052 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:05.055 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[65] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:05.055 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
24/04/16 11:37:05.056 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 11:37:05.057 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
24/04/16 11:37:05.060 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 11:37:05.060 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 11:37:05.110 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 19559 bytes result sent to driver
24/04/16 11:37:05.112 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 56 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:05.112 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
24/04/16 11:37:05.113 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 18 (collectAsMap at RandomForest.scala:663) finished in 0,065 s
24/04/16 11:37:05.113 dag-scheduler-event-loop INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:05.114 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
24/04/16 11:37:05.114 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 14 finished: collectAsMap at RandomForest.scala:663, took 0,258647 s
24/04/16 11:37:05.115 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(21) (from destroy at RandomForest.scala:674)
24/04/16 11:37:05.118 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 42.3 KiB, free: 908.2 MiB)
24/04/16 11:37:05.131 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 79.1 KiB, free 907.1 MiB)
24/04/16 11:37:05.135 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 49.0 KiB, free 907.1 MiB)
24/04/16 11:37:05.136 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 49.0 KiB, free: 908.2 MiB)
24/04/16 11:37:05.136 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 24 from broadcast at RandomForest.scala:622
24/04/16 11:37:05.153 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 11:37:05.153 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 66 (mapPartitions at RandomForest.scala:644) as input to shuffle 5
24/04/16 11:37:05.153 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 11:37:05.153 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 20 (collectAsMap at RandomForest.scala:663)
24/04/16 11:37:05.153 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
24/04/16 11:37:05.153 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
24/04/16 11:37:05.153 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[66] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 11:37:05.163 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 555.0 KiB, free 906.5 MiB)
24/04/16 11:37:05.173 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 156.1 KiB, free 906.4 MiB)
24/04/16 11:37:05.173 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 156.1 KiB, free: 908.0 MiB)
24/04/16 11:37:05.173 dag-scheduler-event-loop INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:05.175 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[66] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:05.175 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
24/04/16 11:37:05.179 dispatcher-event-loop-1 WARN TaskSetManager: Stage 19 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:37:05.179 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 11:37:05.179 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
24/04/16 11:37:05.194 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO BlockManager: Found block rdd_53_0 locally
24/04/16 11:37:05.279 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1954 bytes result sent to driver
24/04/16 11:37:05.292 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 117 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:05.292 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
24/04/16 11:37:05.292 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 19 (mapPartitions at RandomForest.scala:644) finished in 0,139 s
24/04/16 11:37:05.292 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 11:37:05.292 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 11:37:05.292 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 20)
24/04/16 11:37:05.292 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 11:37:05.292 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[68] at map at RandomForest.scala:663), which has no missing parents
24/04/16 11:37:05.296 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 16.7 KiB, free 906.4 MiB)
24/04/16 11:37:05.296 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 906.4 MiB)
24/04/16 11:37:05.296 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 6.5 KiB, free: 908.0 MiB)
24/04/16 11:37:05.296 dag-scheduler-event-loop INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:05.296 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[68] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:05.296 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
24/04/16 11:37:05.296 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 11:37:05.296 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
24/04/16 11:37:05.307 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 11:37:05.307 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/04/16 11:37:05.353 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 22314 bytes result sent to driver
24/04/16 11:37:05.369 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 73 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:05.369 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
24/04/16 11:37:05.370 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 20 (collectAsMap at RandomForest.scala:663) finished in 0,074 s
24/04/16 11:37:05.370 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:05.370 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
24/04/16 11:37:05.370 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collectAsMap at RandomForest.scala:663, took 0,212028 s
24/04/16 11:37:05.371 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(24) (from destroy at RandomForest.scala:674)
24/04/16 11:37:05.371 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 11:37:05.371 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_24_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 49.0 KiB, free: 908.1 MiB)
24/04/16 11:37:05.371 nioEventLoopGroup-2-2 INFO RandomForest:   init: 0.0045689
  total: 2.3044547
  findBestSplits: 2.2397853
  chooseSplits: 2.2276465
24/04/16 11:37:05.385 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 53 from persistence list
24/04/16 11:37:05.385 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(11) (from destroy at RandomForest.scala:305)
24/04/16 11:37:05.385 block-manager-storage-async-thread-pool-78 INFO BlockManager: Removing RDD 53
24/04/16 11:37:05.385 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 10.0 KiB, free: 911.2 MiB)
24/04/16 11:37:05.401 nioEventLoopGroup-2-2 INFO Instrumentation: [f6e013f1] {"numFeatures":545}
24/04/16 11:37:05.401 nioEventLoopGroup-2-2 INFO Instrumentation: [f6e013f1] training finished
24/04/16 11:37:05.401 nioEventLoopGroup-2-2 INFO Instrumentation: [58d7af6e] training finished
24/04/16 11:37:06.165 nioEventLoopGroup-2-2 INFO Instrumentation: [1cca30cc] training finished
24/04/16 11:37:06.341 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_25_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 156.1 KiB, free: 911.4 MiB)
24/04/16 11:37:06.345 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 6.3 KiB, free: 911.4 MiB)
24/04/16 11:37:06.349 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_26_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 6.5 KiB, free: 911.4 MiB)
24/04/16 11:37:07.931 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:37:07.947 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collect at utils.scala:26) with 1 output partitions
24/04/16 11:37:07.947 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:26)
24/04/16 11:37:07.947 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:37:07.947 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:37:07.947 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[71] at collect at utils.scala:26), which has no missing parents
24/04/16 11:37:07.950 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 62.5 KiB, free 910.4 MiB)
24/04/16 11:37:07.953 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.4 MiB)
24/04/16 11:37:07.953 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 11:37:07.953 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:07.953 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[71] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:07.953 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
24/04/16 11:37:07.956 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 11:37:07.956 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
24/04/16 11:37:08.014 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO CodeGenerator: Code generated in 33.6646 ms
24/04/16 11:37:08.026 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1430 bytes result sent to driver
24/04/16 11:37:08.026 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 70 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:08.026 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
24/04/16 11:37:08.026 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 21 (collect at utils.scala:26) finished in 0,079 s
24/04/16 11:37:08.026 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:08.026 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
24/04/16 11:37:08.026 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collect at utils.scala:26, took 0,083675 s
24/04/16 11:37:08.152 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 86.381 ms
24/04/16 11:37:12.194 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 11:37:12.203 nioEventLoopGroup-2-2 INFO Instrumentation: [be98307b] training finished
24/04/16 11:37:12.310 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 476.3 KiB, free 910.0 MiB)
24/04/16 11:37:12.325 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 37.1 KiB, free 909.9 MiB)
24/04/16 11:37:12.325 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 37.1 KiB, free: 911.4 MiB)
24/04/16 11:37:12.325 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 28 from broadcast at RandomForestRegressor.scala:238
24/04/16 11:37:12.443 nioEventLoopGroup-2-2 INFO Instrumentation: [b5ebf438] training finished
24/04/16 11:37:13.941 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:37:13.942 dag-scheduler-event-loop INFO DAGScheduler: Got job 17 (collect at utils.scala:26) with 1 output partitions
24/04/16 11:37:13.942 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:26)
24/04/16 11:37:13.942 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:37:13.942 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:37:13.942 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[74] at collect at utils.scala:26), which has no missing parents
24/04/16 11:37:13.945 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 62.6 KiB, free 909.9 MiB)
24/04/16 11:37:13.945 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.9 MiB)
24/04/16 11:37:13.947 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 11:37:13.947 dag-scheduler-event-loop INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:13.947 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[74] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:13.947 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
24/04/16 11:37:13.948 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 11:37:13.948 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
24/04/16 11:37:14.012 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO CodeGenerator: Code generated in 33.2714 ms
24/04/16 11:37:14.012 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1430 bytes result sent to driver
24/04/16 11:37:14.012 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 64 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:14.012 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
24/04/16 11:37:14.012 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 22 (collect at utils.scala:26) finished in 0,070 s
24/04/16 11:37:14.012 dag-scheduler-event-loop INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:14.012 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
24/04/16 11:37:14.012 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 17 finished: collect at utils.scala:26, took 0,081832 s
24/04/16 11:37:14.146 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 75.4726 ms
24/04/16 11:37:20.498 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_29_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 11:37:20.786 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:37:20.786 dag-scheduler-event-loop INFO DAGScheduler: Got job 18 (collect at utils.scala:26) with 1 output partitions
24/04/16 11:37:20.786 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:26)
24/04/16 11:37:20.786 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:37:20.793 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:37:20.793 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[82] at collect at utils.scala:26), which has no missing parents
24/04/16 11:37:20.802 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 452.7 KiB, free 909.5 MiB)
24/04/16 11:37:20.802 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 909.4 MiB)
24/04/16 11:37:20.805 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 90.5 KiB, free: 911.3 MiB)
24/04/16 11:37:20.805 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:20.805 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[82] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:20.806 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
24/04/16 11:37:20.806 dispatcher-event-loop-0 WARN TaskSetManager: Stage 23 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:37:20.806 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 11:37:20.806 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
24/04/16 11:37:20.818 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 11:37:21.179 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO CodeGenerator: Code generated in 143.2836 ms
24/04/16 11:37:21.356 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO CodeGenerator: Code generated in 65.059 ms
24/04/16 11:37:21.547 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 141114 bytes result sent to driver
24/04/16 11:37:21.547 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 741 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:21.547 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
24/04/16 11:37:21.547 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 23 (collect at utils.scala:26) finished in 0,754 s
24/04/16 11:37:21.547 dag-scheduler-event-loop INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:21.547 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
24/04/16 11:37:21.547 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 18 finished: collect at utils.scala:26, took 0,758804 s
24/04/16 11:37:21.736 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 117.3118 ms
24/04/16 11:37:25.749 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.9846 ms
24/04/16 11:37:25.805 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 11:37:25.805 dag-scheduler-event-loop INFO DAGScheduler: Got job 19 (collect at utils.scala:26) with 1 output partitions
24/04/16 11:37:25.805 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:26)
24/04/16 11:37:25.805 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 11:37:25.805 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 11:37:25.805 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[90] at collect at utils.scala:26), which has no missing parents
24/04/16 11:37:25.820 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 373.1 KiB, free 909.1 MiB)
24/04/16 11:37:25.820 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 75.3 KiB, free 909.0 MiB)
24/04/16 11:37:25.820 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 75.3 KiB, free: 911.2 MiB)
24/04/16 11:37:25.820 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1535
24/04/16 11:37:25.820 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[90] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 11:37:25.820 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
24/04/16 11:37:25.837 dispatcher-event-loop-0 WARN TaskSetManager: Stage 24 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 11:37:25.837 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 11:37:25.837 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
24/04/16 11:37:25.853 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 11:37:26.241 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 4848 bytes result sent to driver
24/04/16 11:37:26.242 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 408 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 11:37:26.242 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
24/04/16 11:37:26.243 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 24 (collect at utils.scala:26) finished in 0,431 s
24/04/16 11:37:26.243 dag-scheduler-event-loop INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 11:37:26.243 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
24/04/16 11:37:26.243 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 19 finished: collect at utils.scala:26, took 0,435218 s
24/04/16 11:37:26.249 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.0605 ms
24/04/16 12:05:10.056 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 99.2 KiB, free: 911.3 MiB)
24/04/16 12:05:10.063 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 90.5 KiB, free: 911.4 MiB)
24/04/16 12:05:10.067 block-manager-storage-async-thread-pool-118 INFO BlockManager: Removing RDD 53
24/04/16 12:05:10.074 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 143.5 KiB, free: 911.5 MiB)
24/04/16 12:05:10.078 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 75.3 KiB, free: 911.6 MiB)
24/04/16 12:08:04.340 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 43.8225 ms
24/04/16 12:08:04.421 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 97 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
24/04/16 12:08:04.431 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 20 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 12:08:04.431 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:08:04.431 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 12:08:04.431 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:08:04.435 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[97] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:08:04.451 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 129.6 KiB, free 911.0 MiB)
24/04/16 12:08:04.469 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 911.0 MiB)
24/04/16 12:08:04.469 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 33.9 KiB, free: 911.6 MiB)
24/04/16 12:08:04.481 dag-scheduler-event-loop INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1535
24/04/16 12:08:04.481 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[97] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 12:08:04.481 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
24/04/16 12:08:04.618 dispatcher-event-loop-1 WARN TaskSetManager: Stage 25 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 12:08:04.618 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 12:08:04.627 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
24/04/16 12:08:04.706 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 12:08:05.037 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO CodeGenerator: Code generated in 6.1964 ms
24/04/16 12:08:05.110 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2481 bytes result sent to driver
24/04/16 12:08:05.110 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 627 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:08:05.110 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
24/04/16 12:08:05.110 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0,673 s
24/04/16 12:08:05.116 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 12:08:05.116 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 12:08:05.117 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 12:08:05.117 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 12:08:05.181 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.274 ms
24/04/16 12:08:05.229 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 12:08:05.229 dag-scheduler-event-loop INFO DAGScheduler: Got job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 12:08:05.229 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 27 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:08:05.229 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
24/04/16 12:08:05.229 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:08:05.229 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[100] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:08:05.236 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 12.1 KiB, free 911.0 MiB)
24/04/16 12:08:05.249 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 911.0 MiB)
24/04/16 12:08:05.250 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.8 KiB, free: 911.6 MiB)
24/04/16 12:08:05.250 dag-scheduler-event-loop INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1535
24/04/16 12:08:05.250 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[100] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 12:08:05.252 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
24/04/16 12:08:05.252 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 26) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 12:08:05.252 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO Executor: Running task 0.0 in stage 27.0 (TID 26)
24/04/16 12:08:05.263 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 12:08:05.268 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/04/16 12:08:05.277 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO Executor: Finished task 0.0 in stage 27.0 (TID 26). 3952 bytes result sent to driver
24/04/16 12:08:05.277 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 26) in 25 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:08:05.277 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
24/04/16 12:08:05.277 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0,048 s
24/04/16 12:08:05.277 dag-scheduler-event-loop INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 12:08:05.277 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
24/04/16 12:08:05.277 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 21 finished: count at NativeMethodAccessorImpl.java:0, took 0,059900 s
24/04/16 12:08:05.995 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_32_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 33.9 KiB, free: 911.6 MiB)
24/04/16 12:08:06.000 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_33_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.8 KiB, free: 911.6 MiB)
24/04/16 12:08:06.040 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.1108 ms
24/04/16 12:08:06.058 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 107 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
24/04/16 12:08:06.058 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 12:08:06.058 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:08:06.059 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 12:08:06.059 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:08:06.059 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[107] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:08:06.063 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 129.6 KiB, free 911.0 MiB)
24/04/16 12:08:06.063 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 911.0 MiB)
24/04/16 12:08:06.063 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 33.9 KiB, free: 911.6 MiB)
24/04/16 12:08:06.063 dag-scheduler-event-loop INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1535
24/04/16 12:08:06.063 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[107] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 12:08:06.063 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
24/04/16 12:08:06.072 dispatcher-event-loop-1 WARN TaskSetManager: Stage 28 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 12:08:06.072 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 27) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 12:08:06.072 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO Executor: Running task 0.0 in stage 28.0 (TID 27)
24/04/16 12:08:06.072 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 12:08:06.235 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO Executor: Finished task 0.0 in stage 28.0 (TID 27). 2395 bytes result sent to driver
24/04/16 12:08:06.236 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 27) in 173 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:08:06.236 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
24/04/16 12:08:06.236 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 0,177 s
24/04/16 12:08:06.236 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 12:08:06.236 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 12:08:06.236 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 12:08:06.236 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 12:08:06.269 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 12:08:06.270 dag-scheduler-event-loop INFO DAGScheduler: Got job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 12:08:06.270 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:08:06.270 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
24/04/16 12:08:06.270 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:08:06.270 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[110] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:08:06.274 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 12.1 KiB, free 911.0 MiB)
24/04/16 12:08:06.274 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 911.0 MiB)
24/04/16 12:08:06.274 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.8 KiB, free: 911.6 MiB)
24/04/16 12:08:06.277 dag-scheduler-event-loop INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1535
24/04/16 12:08:06.277 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[110] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 12:08:06.277 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
24/04/16 12:08:06.279 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 28) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 12:08:06.280 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO Executor: Running task 0.0 in stage 30.0 (TID 28)
24/04/16 12:08:06.280 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 12:08:06.280 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 12:08:06.286 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO Executor: Finished task 0.0 in stage 30.0 (TID 28). 3909 bytes result sent to driver
24/04/16 12:08:06.286 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 28) in 7 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:08:06.286 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
24/04/16 12:08:06.286 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:0) finished in 0,013 s
24/04/16 12:08:06.286 dag-scheduler-event-loop INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 12:08:06.286 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
24/04/16 12:08:06.286 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 23 finished: count at NativeMethodAccessorImpl.java:0, took 0,020903 s
24/04/16 12:24:12.265 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 117 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8
24/04/16 12:24:12.265 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 24 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 12:24:12.265 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:24:12.265 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 12:24:12.265 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:24:12.265 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[117] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:24:12.281 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 129.6 KiB, free 910.8 MiB)
24/04/16 12:24:12.281 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 910.8 MiB)
24/04/16 12:24:12.281 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 33.9 KiB, free: 911.5 MiB)
24/04/16 12:24:12.281 dag-scheduler-event-loop INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1535
24/04/16 12:24:12.281 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[117] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 12:24:12.281 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
24/04/16 12:24:12.296 dispatcher-event-loop-0 WARN TaskSetManager: Stage 31 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 12:24:12.296 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 29) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 12:24:12.296 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO Executor: Running task 0.0 in stage 31.0 (TID 29)
24/04/16 12:24:12.312 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 12:24:12.491 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO Executor: Finished task 0.0 in stage 31.0 (TID 29). 2395 bytes result sent to driver
24/04/16 12:24:12.491 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 29) in 210 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:24:12.491 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
24/04/16 12:24:12.492 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0) finished in 0,227 s
24/04/16 12:24:12.492 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 12:24:12.492 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 12:24:12.492 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 12:24:12.492 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 12:24:12.504 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 12:24:12.504 dag-scheduler-event-loop INFO DAGScheduler: Got job 25 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 12:24:12.504 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 33 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:24:12.504 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
24/04/16 12:24:12.504 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:24:12.504 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[120] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:24:12.520 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 12.1 KiB, free 910.8 MiB)
24/04/16 12:24:12.522 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.8 MiB)
24/04/16 12:24:12.522 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 12:24:12.522 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1535
24/04/16 12:24:12.522 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[120] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 12:24:12.522 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
24/04/16 12:24:12.523 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 30) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 12:24:12.523 Executor task launch worker for task 0.0 in stage 33.0 (TID 30) INFO Executor: Running task 0.0 in stage 33.0 (TID 30)
24/04/16 12:24:12.526 Executor task launch worker for task 0.0 in stage 33.0 (TID 30) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 12:24:12.526 Executor task launch worker for task 0.0 in stage 33.0 (TID 30) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 12:24:12.530 Executor task launch worker for task 0.0 in stage 33.0 (TID 30) INFO Executor: Finished task 0.0 in stage 33.0 (TID 30). 3909 bytes result sent to driver
24/04/16 12:24:12.531 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 30) in 8 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:24:12.531 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
24/04/16 12:24:12.531 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 33 (count at NativeMethodAccessorImpl.java:0) finished in 0,012 s
24/04/16 12:24:12.531 dag-scheduler-event-loop INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 12:24:12.531 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
24/04/16 12:24:12.531 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 25 finished: count at NativeMethodAccessorImpl.java:0, took 0,015362 s
24/04/16 12:24:12.709 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_35_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 12:24:12.714 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 12:24:12.721 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_34_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 33.9 KiB, free: 911.6 MiB)
24/04/16 12:24:12.725 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 33.9 KiB, free: 911.6 MiB)
24/04/16 12:24:12.993 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 127 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9
24/04/16 12:24:12.993 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 26 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 12:24:12.993 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 34 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:24:12.993 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 12:24:12.993 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:24:12.993 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[127] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:24:12.999 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 129.6 KiB, free 911.0 MiB)
24/04/16 12:24:12.999 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 911.0 MiB)
24/04/16 12:24:12.999 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 33.9 KiB, free: 911.6 MiB)
24/04/16 12:24:12.999 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1535
24/04/16 12:24:12.999 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[127] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 12:24:12.999 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
24/04/16 12:24:13.008 dispatcher-event-loop-0 WARN TaskSetManager: Stage 34 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 12:24:13.008 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 31) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 12:24:13.008 Executor task launch worker for task 0.0 in stage 34.0 (TID 31) INFO Executor: Running task 0.0 in stage 34.0 (TID 31)
24/04/16 12:24:13.025 Executor task launch worker for task 0.0 in stage 34.0 (TID 31) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 12:24:13.171 Executor task launch worker for task 0.0 in stage 34.0 (TID 31) INFO Executor: Finished task 0.0 in stage 34.0 (TID 31). 2438 bytes result sent to driver
24/04/16 12:24:13.172 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 31) in 173 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:24:13.172 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
24/04/16 12:24:13.173 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 34 (count at NativeMethodAccessorImpl.java:0) finished in 0,180 s
24/04/16 12:24:13.173 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 12:24:13.173 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 12:24:13.173 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 12:24:13.173 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 12:24:13.195 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 12:24:13.196 dag-scheduler-event-loop INFO DAGScheduler: Got job 27 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 12:24:13.196 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 36 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:24:13.196 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
24/04/16 12:24:13.196 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:24:13.196 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[130] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:24:13.198 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 12.1 KiB, free 911.0 MiB)
24/04/16 12:24:13.200 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 911.0 MiB)
24/04/16 12:24:13.200 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.8 KiB, free: 911.6 MiB)
24/04/16 12:24:13.200 dag-scheduler-event-loop INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1535
24/04/16 12:24:13.201 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[130] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 12:24:13.201 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
24/04/16 12:24:13.202 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 32) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 12:24:13.202 Executor task launch worker for task 0.0 in stage 36.0 (TID 32) INFO Executor: Running task 0.0 in stage 36.0 (TID 32)
24/04/16 12:24:13.205 Executor task launch worker for task 0.0 in stage 36.0 (TID 32) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 12:24:13.205 Executor task launch worker for task 0.0 in stage 36.0 (TID 32) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 12:24:13.207 Executor task launch worker for task 0.0 in stage 36.0 (TID 32) INFO Executor: Finished task 0.0 in stage 36.0 (TID 32). 3909 bytes result sent to driver
24/04/16 12:24:13.208 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 32) in 7 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:24:13.208 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
24/04/16 12:24:13.208 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 36 (count at NativeMethodAccessorImpl.java:0) finished in 0,011 s
24/04/16 12:24:13.209 dag-scheduler-event-loop INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 12:24:13.209 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
24/04/16 12:24:13.209 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 27 finished: count at NativeMethodAccessorImpl.java:0, took 0,014142 s
24/04/16 12:24:15.124 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 12:24:15.125 dag-scheduler-event-loop INFO DAGScheduler: Got job 28 (collect at utils.scala:26) with 1 output partitions
24/04/16 12:24:15.125 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:26)
24/04/16 12:24:15.125 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 12:24:15.125 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:24:15.125 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[133] at collect at utils.scala:26), which has no missing parents
24/04/16 12:24:15.128 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 62.4 KiB, free 910.9 MiB)
24/04/16 12:24:15.129 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.9 MiB)
24/04/16 12:24:15.130 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 12:24:15.131 dag-scheduler-event-loop INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1535
24/04/16 12:24:15.131 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[133] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 12:24:15.131 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
24/04/16 12:24:15.132 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 33) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 12:24:15.133 Executor task launch worker for task 0.0 in stage 37.0 (TID 33) INFO Executor: Running task 0.0 in stage 37.0 (TID 33)
24/04/16 12:24:15.212 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_39_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 12:24:15.213 Executor task launch worker for task 0.0 in stage 37.0 (TID 33) INFO Executor: Finished task 0.0 in stage 37.0 (TID 33). 1473 bytes result sent to driver
24/04/16 12:24:15.215 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 33) in 83 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:24:15.215 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
24/04/16 12:24:15.216 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 37 (collect at utils.scala:26) finished in 0,090 s
24/04/16 12:24:15.216 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_38_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 33.9 KiB, free: 911.6 MiB)
24/04/16 12:24:15.216 dag-scheduler-event-loop INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 12:24:15.216 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
24/04/16 12:24:15.217 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 28 finished: collect at utils.scala:26, took 0,092794 s
24/04/16 12:24:20.088 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 12:24:20.088 dag-scheduler-event-loop INFO DAGScheduler: Got job 29 (collect at utils.scala:26) with 1 output partitions
24/04/16 12:24:20.088 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:26)
24/04/16 12:24:20.088 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 12:24:20.088 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:24:20.088 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[136] at collect at utils.scala:26), which has no missing parents
24/04/16 12:24:20.104 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 62.4 KiB, free 911.0 MiB)
24/04/16 12:24:20.104 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.0 MiB)
24/04/16 12:24:20.104 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 12:24:20.104 dag-scheduler-event-loop INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1535
24/04/16 12:24:20.104 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[136] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 12:24:20.104 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
24/04/16 12:24:20.104 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 34) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 12:24:20.104 Executor task launch worker for task 0.0 in stage 38.0 (TID 34) INFO Executor: Running task 0.0 in stage 38.0 (TID 34)
24/04/16 12:24:20.135 Executor task launch worker for task 0.0 in stage 38.0 (TID 34) INFO Executor: Finished task 0.0 in stage 38.0 (TID 34). 1430 bytes result sent to driver
24/04/16 12:24:20.135 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 34) in 31 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:24:20.135 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
24/04/16 12:24:20.143 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 38 (collect at utils.scala:26) finished in 0,055 s
24/04/16 12:24:20.143 dag-scheduler-event-loop INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 12:24:20.143 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
24/04/16 12:24:20.143 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 29 finished: collect at utils.scala:26, took 0,043715 s
24/04/16 12:24:46.449 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 12:24:46.449 dag-scheduler-event-loop INFO DAGScheduler: Got job 30 (collect at utils.scala:26) with 1 output partitions
24/04/16 12:24:46.449 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:26)
24/04/16 12:24:46.449 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 12:24:46.449 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:24:46.449 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[139] at collect at utils.scala:26), which has no missing parents
24/04/16 12:24:46.454 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 62.4 KiB, free 910.9 MiB)
24/04/16 12:24:46.454 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.9 MiB)
24/04/16 12:24:46.454 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 12:24:46.454 dag-scheduler-event-loop INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1535
24/04/16 12:24:46.454 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[139] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 12:24:46.459 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
24/04/16 12:24:46.459 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 35) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 12:24:46.459 Executor task launch worker for task 0.0 in stage 39.0 (TID 35) INFO Executor: Running task 0.0 in stage 39.0 (TID 35)
24/04/16 12:24:46.493 Executor task launch worker for task 0.0 in stage 39.0 (TID 35) INFO Executor: Finished task 0.0 in stage 39.0 (TID 35). 1430 bytes result sent to driver
24/04/16 12:24:46.493 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 35) in 34 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:24:46.493 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
24/04/16 12:24:46.493 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 39 (collect at utils.scala:26) finished in 0,039 s
24/04/16 12:24:46.493 dag-scheduler-event-loop INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 12:24:46.493 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
24/04/16 12:24:46.493 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 30 finished: collect at utils.scala:26, took 0,049637 s
24/04/16 12:24:46.655 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_41_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 12:24:46.661 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_40_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 12:24:46.669 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_42_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 12:24:51.359 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 12:24:51.359 dag-scheduler-event-loop INFO DAGScheduler: Got job 31 (collect at utils.scala:26) with 1 output partitions
24/04/16 12:24:51.359 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:26)
24/04/16 12:24:51.359 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 12:24:51.359 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:24:51.359 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[142] at collect at utils.scala:26), which has no missing parents
24/04/16 12:24:51.369 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 62.4 KiB, free 911.1 MiB)
24/04/16 12:24:51.369 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.1 MiB)
24/04/16 12:24:51.369 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 12:24:51.369 dag-scheduler-event-loop INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1535
24/04/16 12:24:51.369 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[142] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 12:24:51.369 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
24/04/16 12:24:51.372 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 36) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 12:24:51.372 Executor task launch worker for task 0.0 in stage 40.0 (TID 36) INFO Executor: Running task 0.0 in stage 40.0 (TID 36)
24/04/16 12:24:51.401 Executor task launch worker for task 0.0 in stage 40.0 (TID 36) INFO Executor: Finished task 0.0 in stage 40.0 (TID 36). 1387 bytes result sent to driver
24/04/16 12:24:51.401 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 36) in 32 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:24:51.401 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
24/04/16 12:24:51.401 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 40 (collect at utils.scala:26) finished in 0,033 s
24/04/16 12:24:51.401 dag-scheduler-event-loop INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 12:24:51.401 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
24/04/16 12:24:51.401 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 31 finished: collect at utils.scala:26, took 0,038116 s
24/04/16 12:25:00.935 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_43_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 12:25:01.014 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 12:25:01.014 dag-scheduler-event-loop INFO DAGScheduler: Got job 32 (collect at utils.scala:26) with 1 output partitions
24/04/16 12:25:01.014 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 41 (collect at utils.scala:26)
24/04/16 12:25:01.014 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 12:25:01.014 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:25:01.014 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[145] at collect at utils.scala:26), which has no missing parents
24/04/16 12:25:01.014 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 62.4 KiB, free 911.1 MiB)
24/04/16 12:25:01.014 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.1 MiB)
24/04/16 12:25:01.014 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 12:25:01.014 dag-scheduler-event-loop INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1535
24/04/16 12:25:01.014 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[145] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 12:25:01.014 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
24/04/16 12:25:01.028 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 37) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 12:25:01.029 Executor task launch worker for task 0.0 in stage 41.0 (TID 37) INFO Executor: Running task 0.0 in stage 41.0 (TID 37)
24/04/16 12:25:01.048 Executor task launch worker for task 0.0 in stage 41.0 (TID 37) INFO Executor: Finished task 0.0 in stage 41.0 (TID 37). 1387 bytes result sent to driver
24/04/16 12:25:01.048 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 37) in 20 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:25:01.048 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
24/04/16 12:25:01.048 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 41 (collect at utils.scala:26) finished in 0,034 s
24/04/16 12:25:01.048 dag-scheduler-event-loop INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 12:25:01.048 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
24/04/16 12:25:01.062 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 32 finished: collect at utils.scala:26, took 0,039497 s
24/04/16 12:25:05.144 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.6521 ms
24/04/16 12:25:05.165 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.2713 ms
24/04/16 12:25:05.197 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.7623 ms
24/04/16 12:25:05.236 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 160 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 10
24/04/16 12:25:05.236 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 33 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/16 12:25:05.237 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 42 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:25:05.237 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 12:25:05.237 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:25:05.237 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[160] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:25:05.259 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 226.3 KiB, free 910.8 MiB)
24/04/16 12:25:05.260 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 57.1 KiB, free 910.8 MiB)
24/04/16 12:25:05.261 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 57.1 KiB, free: 911.5 MiB)
24/04/16 12:25:05.262 dag-scheduler-event-loop INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1535
24/04/16 12:25:05.262 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[160] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 12:25:05.262 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 42.0 with 2 tasks resource profile 0
24/04/16 12:25:05.275 dispatcher-event-loop-0 WARN TaskSetManager: Stage 42 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 12:25:05.276 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 38) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 12:25:05.276 Executor task launch worker for task 0.0 in stage 42.0 (TID 38) INFO Executor: Running task 0.0 in stage 42.0 (TID 38)
24/04/16 12:25:05.293 Executor task launch worker for task 0.0 in stage 42.0 (TID 38) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 12:25:05.474 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_44_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 12:25:05.566 Executor task launch worker for task 0.0 in stage 42.0 (TID 38) INFO Executor: Finished task 0.0 in stage 42.0 (TID 38). 3097 bytes result sent to driver
24/04/16 12:25:05.575 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 39) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 12:25:05.575 Executor task launch worker for task 1.0 in stage 42.0 (TID 39) INFO Executor: Running task 1.0 in stage 42.0 (TID 39)
24/04/16 12:25:05.575 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 38) in 312 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 12:25:05.585 Executor task launch worker for task 1.0 in stage 42.0 (TID 39) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 12:25:05.720 Executor task launch worker for task 1.0 in stage 42.0 (TID 39) INFO Executor: Finished task 1.0 in stage 42.0 (TID 39). 3011 bytes result sent to driver
24/04/16 12:25:05.721 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 39) in 155 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 12:25:05.721 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
24/04/16 12:25:05.721 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 42 (count at NativeMethodAccessorImpl.java:0) finished in 0,482 s
24/04/16 12:25:05.722 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 12:25:05.722 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 12:25:05.722 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 12:25:05.722 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 12:25:05.744 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.0133 ms
24/04/16 12:25:05.758 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 12:25:05.759 dag-scheduler-event-loop INFO DAGScheduler: Got job 34 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 12:25:05.759 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 44 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:25:05.759 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
24/04/16 12:25:05.760 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:25:05.760 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[163] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:25:05.761 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 12.1 KiB, free 910.8 MiB)
24/04/16 12:25:05.767 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.8 MiB)
24/04/16 12:25:05.767 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 12:25:05.767 dag-scheduler-event-loop INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1535
24/04/16 12:25:05.768 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[163] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 12:25:05.768 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
24/04/16 12:25:05.769 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 40) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 12:25:05.770 Executor task launch worker for task 0.0 in stage 44.0 (TID 40) INFO Executor: Running task 0.0 in stage 44.0 (TID 40)
24/04/16 12:25:05.772 Executor task launch worker for task 0.0 in stage 44.0 (TID 40) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 12:25:05.773 Executor task launch worker for task 0.0 in stage 44.0 (TID 40) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 12:25:05.779 Executor task launch worker for task 0.0 in stage 44.0 (TID 40) INFO Executor: Finished task 0.0 in stage 44.0 (TID 40). 3909 bytes result sent to driver
24/04/16 12:25:05.780 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 40) in 11 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:25:05.780 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
24/04/16 12:25:05.782 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 44 (count at NativeMethodAccessorImpl.java:0) finished in 0,021 s
24/04/16 12:25:05.782 dag-scheduler-event-loop INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 12:25:05.782 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
24/04/16 12:25:05.782 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 34 finished: count at NativeMethodAccessorImpl.java:0, took 0,023903 s
24/04/16 12:25:06.578 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.057 ms
24/04/16 12:25:06.596 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.3252 ms
24/04/16 12:25:06.615 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 178 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 11
24/04/16 12:25:06.616 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 35 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/16 12:25:06.616 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 45 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:25:06.616 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 12:25:06.616 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:25:06.617 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[178] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:25:06.627 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 226.3 KiB, free 910.6 MiB)
24/04/16 12:25:06.628 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 57.2 KiB, free 910.6 MiB)
24/04/16 12:25:06.629 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 57.2 KiB, free: 911.5 MiB)
24/04/16 12:25:06.629 dag-scheduler-event-loop INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1535
24/04/16 12:25:06.629 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[178] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 12:25:06.630 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks resource profile 0
24/04/16 12:25:06.687 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_45_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 57.1 KiB, free: 911.5 MiB)
24/04/16 12:25:06.692 dispatcher-event-loop-0 WARN TaskSetManager: Stage 45 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 12:25:06.692 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 41) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 12:25:06.693 Executor task launch worker for task 0.0 in stage 45.0 (TID 41) INFO Executor: Running task 0.0 in stage 45.0 (TID 41)
24/04/16 12:25:06.700 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_46_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 12:25:06.711 Executor task launch worker for task 0.0 in stage 45.0 (TID 41) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 12:25:06.879 Executor task launch worker for task 0.0 in stage 45.0 (TID 41) INFO Executor: Finished task 0.0 in stage 45.0 (TID 41). 3011 bytes result sent to driver
24/04/16 12:25:06.888 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 42) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 12:25:06.889 Executor task launch worker for task 1.0 in stage 45.0 (TID 42) INFO Executor: Running task 1.0 in stage 45.0 (TID 42)
24/04/16 12:25:06.889 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 41) in 259 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 12:25:06.904 Executor task launch worker for task 1.0 in stage 45.0 (TID 42) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 12:25:07.030 Executor task launch worker for task 1.0 in stage 45.0 (TID 42) INFO Executor: Finished task 1.0 in stage 45.0 (TID 42). 3011 bytes result sent to driver
24/04/16 12:25:07.030 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 42) in 150 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 12:25:07.037 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
24/04/16 12:25:07.037 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 45 (count at NativeMethodAccessorImpl.java:0) finished in 0,420 s
24/04/16 12:25:07.037 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 12:25:07.037 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 12:25:07.037 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 12:25:07.037 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 12:25:07.053 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 12:25:07.053 dag-scheduler-event-loop INFO DAGScheduler: Got job 36 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 12:25:07.053 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 47 (count at NativeMethodAccessorImpl.java:0)
24/04/16 12:25:07.053 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
24/04/16 12:25:07.053 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 12:25:07.053 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[181] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 12:25:07.069 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 12.1 KiB, free 910.8 MiB)
24/04/16 12:25:07.070 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.8 MiB)
24/04/16 12:25:07.071 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 12:25:07.071 dag-scheduler-event-loop INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1535
24/04/16 12:25:07.071 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[181] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 12:25:07.071 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0
24/04/16 12:25:07.072 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 43) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 12:25:07.072 Executor task launch worker for task 0.0 in stage 47.0 (TID 43) INFO Executor: Running task 0.0 in stage 47.0 (TID 43)
24/04/16 12:25:07.074 Executor task launch worker for task 0.0 in stage 47.0 (TID 43) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 12:25:07.074 Executor task launch worker for task 0.0 in stage 47.0 (TID 43) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 12:25:07.077 Executor task launch worker for task 0.0 in stage 47.0 (TID 43) INFO Executor: Finished task 0.0 in stage 47.0 (TID 43). 3909 bytes result sent to driver
24/04/16 12:25:07.079 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 43) in 7 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 12:25:07.079 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
24/04/16 12:25:07.079 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 47 (count at NativeMethodAccessorImpl.java:0) finished in 0,026 s
24/04/16 12:25:07.079 dag-scheduler-event-loop INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 12:25:07.079 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
24/04/16 12:25:07.079 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 36 finished: count at NativeMethodAccessorImpl.java:0, took 0,013946 s
24/04/16 13:22:36.987 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
24/04/16 13:22:47.005 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
24/04/16 13:22:57.008 executor-heartbeater WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
24/04/16 13:23:03.256 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
24/04/16 13:23:03.256 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
24/04/16 13:23:03.256 heartbeat-receiver-event-loop-thread WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
24/04/16 13:23:56.627 nioEventLoopGroup-2-2 INFO Instrumentation: [9ed53982] training finished
24/04/16 13:23:56.965 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_48_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 13:23:56.967 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_47_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 57.2 KiB, free: 911.6 MiB)
24/04/16 13:23:57.117 nioEventLoopGroup-2-2 INFO Instrumentation: [21b3553c] training finished
24/04/16 13:23:57.721 nioEventLoopGroup-2-2 INFO Instrumentation: [4010161d] Stage class: RandomForestRegressor
24/04/16 13:23:57.721 nioEventLoopGroup-2-2 INFO Instrumentation: [4010161d] Stage uid: random_forest__0eead532_dd7b_41a3_b320_9b286c66dd2b
24/04/16 13:23:57.721 nioEventLoopGroup-2-2 INFO Instrumentation: [4010161d] training: numPartitions=2 storageLevel=StorageLevel(1 replicas)
24/04/16 13:23:57.721 nioEventLoopGroup-2-2 INFO Instrumentation: [4010161d] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/16 13:23:57.767 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 13:23:57.767 dag-scheduler-event-loop INFO DAGScheduler: Got job 37 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 13:23:57.767 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 48 (take at DecisionTreeMetadata.scala:119)
24/04/16 13:23:57.767 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:23:57.767 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:23:57.767 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[204] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 13:23:57.767 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 521.9 KiB, free 910.6 MiB)
24/04/16 13:23:57.767 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 117.4 KiB, free 910.5 MiB)
24/04/16 13:23:57.767 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 117.4 KiB, free: 911.5 MiB)
24/04/16 13:23:57.767 dag-scheduler-event-loop INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:57.767 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[204] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 13:23:57.767 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
24/04/16 13:23:57.783 dispatcher-event-loop-1 WARN TaskSetManager: Stage 48 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:23:57.783 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 44) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 13:23:57.783 Executor task launch worker for task 0.0 in stage 48.0 (TID 44) INFO Executor: Running task 0.0 in stage 48.0 (TID 44)
24/04/16 13:23:57.799 Executor task launch worker for task 0.0 in stage 48.0 (TID 44) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:23:57.877 Executor task launch worker for task 0.0 in stage 48.0 (TID 44) INFO CodeGenerator: Code generated in 3.7062 ms
24/04/16 13:23:57.955 Executor task launch worker for task 0.0 in stage 48.0 (TID 44) INFO CodeGenerator: Code generated in 45.5452 ms
24/04/16 13:23:57.971 Executor task launch worker for task 0.0 in stage 48.0 (TID 44) INFO Executor: Finished task 0.0 in stage 48.0 (TID 44). 1993 bytes result sent to driver
24/04/16 13:23:57.971 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 44) in 204 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 13:23:57.971 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
24/04/16 13:23:57.971 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 48 (take at DecisionTreeMetadata.scala:119) finished in 0,204 s
24/04/16 13:23:57.971 dag-scheduler-event-loop INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:23:57.971 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
24/04/16 13:23:57.971 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 37 finished: take at DecisionTreeMetadata.scala:119, took 0,207234 s
24/04/16 13:23:57.971 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 13:23:57.971 dag-scheduler-event-loop INFO DAGScheduler: Got job 38 (aggregate at DecisionTreeMetadata.scala:125) with 2 output partitions
24/04/16 13:23:57.971 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 49 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 13:23:57.971 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:23:57.971 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:23:57.971 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[203] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 13:23:57.986 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 521.9 KiB, free 910.0 MiB)
24/04/16 13:23:57.986 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 117.6 KiB, free 909.9 MiB)
24/04/16 13:23:57.986 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 117.6 KiB, free: 911.4 MiB)
24/04/16 13:23:57.986 dag-scheduler-event-loop INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:57.986 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 49 (MapPartitionsRDD[203] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:57.986 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 49.0 with 2 tasks resource profile 0
24/04/16 13:23:58.002 dispatcher-event-loop-0 WARN TaskSetManager: Stage 49 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:23:58.002 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 45) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 13:23:58.002 Executor task launch worker for task 0.0 in stage 49.0 (TID 45) INFO Executor: Running task 0.0 in stage 49.0 (TID 45)
24/04/16 13:23:58.017 Executor task launch worker for task 0.0 in stage 49.0 (TID 45) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:23:58.127 Executor task launch worker for task 0.0 in stage 49.0 (TID 45) INFO Executor: Finished task 0.0 in stage 49.0 (TID 45). 2065 bytes result sent to driver
24/04/16 13:23:58.127 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 46) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 13:23:58.127 Executor task launch worker for task 1.0 in stage 49.0 (TID 46) INFO Executor: Running task 1.0 in stage 49.0 (TID 46)
24/04/16 13:23:58.127 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 45) in 141 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:58.149 Executor task launch worker for task 1.0 in stage 49.0 (TID 46) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:23:58.211 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_49_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 117.4 KiB, free: 911.5 MiB)
24/04/16 13:23:58.226 Executor task launch worker for task 1.0 in stage 49.0 (TID 46) INFO CodeGenerator: Code generated in 2.749 ms
24/04/16 13:23:58.258 Executor task launch worker for task 1.0 in stage 49.0 (TID 46) INFO Executor: Finished task 1.0 in stage 49.0 (TID 46). 2108 bytes result sent to driver
24/04/16 13:23:58.258 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 46) in 131 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:58.258 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
24/04/16 13:23:58.258 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 49 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,287 s
24/04/16 13:23:58.258 dag-scheduler-event-loop INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:23:58.258 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
24/04/16 13:23:58.258 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 38 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,287960 s
24/04/16 13:23:58.273 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 13:23:58.273 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 206 (flatMap at RandomForest.scala:1039) as input to shuffle 12
24/04/16 13:23:58.273 dag-scheduler-event-loop INFO DAGScheduler: Got job 39 (collectAsMap at RandomForest.scala:1054) with 2 output partitions
24/04/16 13:23:58.273 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 51 (collectAsMap at RandomForest.scala:1054)
24/04/16 13:23:58.273 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
24/04/16 13:23:58.273 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
24/04/16 13:23:58.273 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[206] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 13:23:58.289 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 531.0 KiB, free 910.0 MiB)
24/04/16 13:23:58.289 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 121.2 KiB, free 909.9 MiB)
24/04/16 13:23:58.289 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 121.2 KiB, free: 911.4 MiB)
24/04/16 13:23:58.289 dag-scheduler-event-loop INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:58.289 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[206] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:58.289 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 50.0 with 2 tasks resource profile 0
24/04/16 13:23:58.289 dispatcher-event-loop-1 WARN TaskSetManager: Stage 50 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:23:58.289 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 47) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:58.289 Executor task launch worker for task 0.0 in stage 50.0 (TID 47) INFO Executor: Running task 0.0 in stage 50.0 (TID 47)
24/04/16 13:23:58.305 Executor task launch worker for task 0.0 in stage 50.0 (TID 47) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:23:58.476 Executor task launch worker for task 0.0 in stage 50.0 (TID 47) INFO Executor: Finished task 0.0 in stage 50.0 (TID 47). 2291 bytes result sent to driver
24/04/16 13:23:58.476 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 48) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:58.476 Executor task launch worker for task 1.0 in stage 50.0 (TID 48) INFO Executor: Running task 1.0 in stage 50.0 (TID 48)
24/04/16 13:23:58.476 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 47) in 187 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:58.492 Executor task launch worker for task 1.0 in stage 50.0 (TID 48) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:23:58.611 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_50_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 117.6 KiB, free: 911.5 MiB)
24/04/16 13:23:58.681 Executor task launch worker for task 1.0 in stage 50.0 (TID 48) INFO Executor: Finished task 1.0 in stage 50.0 (TID 48). 2334 bytes result sent to driver
24/04/16 13:23:58.681 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 48) in 205 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:58.681 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
24/04/16 13:23:58.681 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 50 (flatMap at RandomForest.scala:1039) finished in 0,408 s
24/04/16 13:23:58.681 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:23:58.681 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:23:58.697 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 51)
24/04/16 13:23:58.697 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:23:58.697 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[208] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 13:23:58.697 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 11.9 KiB, free 910.5 MiB)
24/04/16 13:23:58.697 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 910.5 MiB)
24/04/16 13:23:58.697 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 4.5 KiB, free: 911.5 MiB)
24/04/16 13:23:58.697 dag-scheduler-event-loop INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:58.697 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (MapPartitionsRDD[208] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:58.697 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks resource profile 0
24/04/16 13:23:58.697 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 49) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:58.697 Executor task launch worker for task 0.0 in stage 51.0 (TID 49) INFO Executor: Running task 0.0 in stage 51.0 (TID 49)
24/04/16 13:23:58.697 Executor task launch worker for task 0.0 in stage 51.0 (TID 49) INFO ShuffleBlockFetcherIterator: Getting 2 (31.9 KiB) non-empty blocks including 2 (31.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:58.697 Executor task launch worker for task 0.0 in stage 51.0 (TID 49) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:58.714 Executor task launch worker for task 0.0 in stage 51.0 (TID 49) INFO Executor: Finished task 0.0 in stage 51.0 (TID 49). 21465 bytes result sent to driver
24/04/16 13:23:58.714 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 50) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:58.714 Executor task launch worker for task 1.0 in stage 51.0 (TID 50) INFO Executor: Running task 1.0 in stage 51.0 (TID 50)
24/04/16 13:23:58.714 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 49) in 17 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:58.714 Executor task launch worker for task 1.0 in stage 51.0 (TID 50) INFO ShuffleBlockFetcherIterator: Getting 2 (31.4 KiB) non-empty blocks including 2 (31.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:58.714 Executor task launch worker for task 1.0 in stage 51.0 (TID 50) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:58.730 Executor task launch worker for task 1.0 in stage 51.0 (TID 50) INFO Executor: Finished task 1.0 in stage 51.0 (TID 50). 20598 bytes result sent to driver
24/04/16 13:23:58.746 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 50) in 32 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:58.746 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
24/04/16 13:23:58.746 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 51 (collectAsMap at RandomForest.scala:1054) finished in 0,049 s
24/04/16 13:23:58.746 dag-scheduler-event-loop INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:23:58.746 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
24/04/16 13:23:58.746 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 39 finished: collectAsMap at RandomForest.scala:1054, took 0,461718 s
24/04/16 13:23:58.746 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 47.5 KiB, free 910.4 MiB)
24/04/16 13:23:58.746 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 910.4 MiB)
24/04/16 13:23:58.746 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 8.0 KiB, free: 911.5 MiB)
24/04/16 13:23:58.746 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 53 from broadcast at RandomForest.scala:293
24/04/16 13:23:58.746 nioEventLoopGroup-2-2 INFO Instrumentation: [4010161d] {"numFeatures":545}
24/04/16 13:23:58.746 nioEventLoopGroup-2-2 INFO Instrumentation: [4010161d] {"numClasses":0}
24/04/16 13:23:58.746 nioEventLoopGroup-2-2 INFO Instrumentation: [4010161d] {"numExamples":159}
24/04/16 13:23:58.746 nioEventLoopGroup-2-2 INFO Instrumentation: [4010161d] {"sumOfWeights":159.0}
24/04/16 13:23:58.746 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 16.1 KiB, free 910.4 MiB)
24/04/16 13:23:58.746 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 910.4 MiB)
24/04/16 13:23:58.746 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 10.3 KiB, free: 911.5 MiB)
24/04/16 13:23:58.746 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 54 from broadcast at RandomForest.scala:622
24/04/16 13:23:58.761 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 13:23:58.761 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 211 (mapPartitions at RandomForest.scala:644) as input to shuffle 13
24/04/16 13:23:58.761 dag-scheduler-event-loop INFO DAGScheduler: Got job 40 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 13:23:58.761 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 53 (collectAsMap at RandomForest.scala:663)
24/04/16 13:23:58.761 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
24/04/16 13:23:58.761 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
24/04/16 13:23:58.761 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[211] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 13:23:58.777 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 561.9 KiB, free 909.8 MiB)
24/04/16 13:23:58.777 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 133.7 KiB, free 909.7 MiB)
24/04/16 13:23:58.777 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 133.7 KiB, free: 911.3 MiB)
24/04/16 13:23:58.777 dag-scheduler-event-loop INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:58.777 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[211] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:58.777 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 52.0 with 2 tasks resource profile 0
24/04/16 13:23:58.777 dispatcher-event-loop-1 WARN TaskSetManager: Stage 52 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:23:58.777 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 51) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:58.777 Executor task launch worker for task 0.0 in stage 52.0 (TID 51) INFO Executor: Running task 0.0 in stage 52.0 (TID 51)
24/04/16 13:23:58.792 Executor task launch worker for task 0.0 in stage 52.0 (TID 51) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:23:58.886 Executor task launch worker for task 0.0 in stage 52.0 (TID 51) INFO MemoryStore: Block rdd_210_0 stored as values in memory (estimated size 180.1 KiB, free 909.5 MiB)
24/04/16 13:23:58.886 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_210_0 in memory on DESKTOP-LH06ASP:56331 (size: 180.1 KiB, free: 911.1 MiB)
24/04/16 13:23:58.902 Executor task launch worker for task 0.0 in stage 52.0 (TID 51) INFO Executor: Finished task 0.0 in stage 52.0 (TID 51). 2291 bytes result sent to driver
24/04/16 13:23:58.918 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 52) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:58.918 Executor task launch worker for task 1.0 in stage 52.0 (TID 52) INFO Executor: Running task 1.0 in stage 52.0 (TID 52)
24/04/16 13:23:58.918 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 51) in 141 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:58.933 Executor task launch worker for task 1.0 in stage 52.0 (TID 52) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:23:59.027 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_51_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 121.2 KiB, free: 911.3 MiB)
24/04/16 13:23:59.027 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_52_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 4.5 KiB, free: 911.3 MiB)
24/04/16 13:23:59.042 Executor task launch worker for task 1.0 in stage 52.0 (TID 52) INFO MemoryStore: Block rdd_210_1 stored as values in memory (estimated size 187.0 KiB, free 910.0 MiB)
24/04/16 13:23:59.042 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_210_1 in memory on DESKTOP-LH06ASP:56331 (size: 187.0 KiB, free: 911.1 MiB)
24/04/16 13:23:59.058 Executor task launch worker for task 1.0 in stage 52.0 (TID 52) INFO Executor: Finished task 1.0 in stage 52.0 (TID 52). 2291 bytes result sent to driver
24/04/16 13:23:59.058 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 52) in 156 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:59.058 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
24/04/16 13:23:59.058 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 52 (mapPartitions at RandomForest.scala:644) finished in 0,297 s
24/04/16 13:23:59.058 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:23:59.058 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:23:59.058 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 53)
24/04/16 13:23:59.058 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:23:59.058 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[213] at map at RandomForest.scala:663), which has no missing parents
24/04/16 13:23:59.058 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 7.4 KiB, free 910.0 MiB)
24/04/16 13:23:59.058 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 910.0 MiB)
24/04/16 13:23:59.058 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 3.8 KiB, free: 911.1 MiB)
24/04/16 13:23:59.058 dag-scheduler-event-loop INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:59.058 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[213] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:59.058 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 53.0 with 2 tasks resource profile 0
24/04/16 13:23:59.058 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 53) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:59.058 Executor task launch worker for task 0.0 in stage 53.0 (TID 53) INFO Executor: Running task 0.0 in stage 53.0 (TID 53)
24/04/16 13:23:59.074 Executor task launch worker for task 0.0 in stage 53.0 (TID 53) INFO ShuffleBlockFetcherIterator: Getting 2 (92.9 KiB) non-empty blocks including 2 (92.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:59.074 Executor task launch worker for task 0.0 in stage 53.0 (TID 53) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:59.074 Executor task launch worker for task 0.0 in stage 53.0 (TID 53) INFO Executor: Finished task 0.0 in stage 53.0 (TID 53). 4266 bytes result sent to driver
24/04/16 13:23:59.074 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 54) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:59.074 Executor task launch worker for task 1.0 in stage 53.0 (TID 54) INFO Executor: Running task 1.0 in stage 53.0 (TID 54)
24/04/16 13:23:59.074 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 53) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:59.074 Executor task launch worker for task 1.0 in stage 53.0 (TID 54) INFO ShuffleBlockFetcherIterator: Getting 2 (92.9 KiB) non-empty blocks including 2 (92.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:59.074 Executor task launch worker for task 1.0 in stage 53.0 (TID 54) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:59.089 Executor task launch worker for task 1.0 in stage 53.0 (TID 54) INFO Executor: Finished task 1.0 in stage 53.0 (TID 54). 4236 bytes result sent to driver
24/04/16 13:23:59.089 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 54) in 15 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:59.089 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
24/04/16 13:23:59.089 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 53 (collectAsMap at RandomForest.scala:663) finished in 0,031 s
24/04/16 13:23:59.089 dag-scheduler-event-loop INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:23:59.089 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
24/04/16 13:23:59.089 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 40 finished: collectAsMap at RandomForest.scala:663, took 0,323420 s
24/04/16 13:23:59.089 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(54) (from destroy at RandomForest.scala:674)
24/04/16 13:23:59.089 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_54_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 10.3 KiB, free: 911.1 MiB)
24/04/16 13:23:59.089 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 30.1 KiB, free 910.0 MiB)
24/04/16 13:23:59.089 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 910.0 MiB)
24/04/16 13:23:59.089 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 18.8 KiB, free: 911.1 MiB)
24/04/16 13:23:59.089 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 57 from broadcast at RandomForest.scala:622
24/04/16 13:23:59.105 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 13:23:59.105 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 214 (mapPartitions at RandomForest.scala:644) as input to shuffle 14
24/04/16 13:23:59.105 dag-scheduler-event-loop INFO DAGScheduler: Got job 41 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 13:23:59.105 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 55 (collectAsMap at RandomForest.scala:663)
24/04/16 13:23:59.105 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
24/04/16 13:23:59.105 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)
24/04/16 13:23:59.105 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[214] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 13:23:59.105 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 580.7 KiB, free 909.4 MiB)
24/04/16 13:23:59.105 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 144.9 KiB, free 909.3 MiB)
24/04/16 13:23:59.105 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 144.9 KiB, free: 910.9 MiB)
24/04/16 13:23:59.105 dag-scheduler-event-loop INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:59.121 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[214] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:59.121 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks resource profile 0
24/04/16 13:23:59.121 dispatcher-event-loop-1 WARN TaskSetManager: Stage 54 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:23:59.121 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 55) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:59.121 Executor task launch worker for task 0.0 in stage 54.0 (TID 55) INFO Executor: Running task 0.0 in stage 54.0 (TID 55)
24/04/16 13:23:59.136 Executor task launch worker for task 0.0 in stage 54.0 (TID 55) INFO BlockManager: Found block rdd_210_0 locally
24/04/16 13:23:59.156 Executor task launch worker for task 0.0 in stage 54.0 (TID 55) INFO Executor: Finished task 0.0 in stage 54.0 (TID 55). 2291 bytes result sent to driver
24/04/16 13:23:59.163 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 56) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:59.163 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 55) in 42 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:59.163 Executor task launch worker for task 1.0 in stage 54.0 (TID 56) INFO Executor: Running task 1.0 in stage 54.0 (TID 56)
24/04/16 13:23:59.174 Executor task launch worker for task 1.0 in stage 54.0 (TID 56) INFO BlockManager: Found block rdd_210_1 locally
24/04/16 13:23:59.179 Executor task launch worker for task 1.0 in stage 54.0 (TID 56) INFO Executor: Finished task 1.0 in stage 54.0 (TID 56). 2248 bytes result sent to driver
24/04/16 13:23:59.179 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 56) in 22 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:59.179 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
24/04/16 13:23:59.179 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 54 (mapPartitions at RandomForest.scala:644) finished in 0,074 s
24/04/16 13:23:59.179 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:23:59.179 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:23:59.179 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 55)
24/04/16 13:23:59.179 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:23:59.179 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[216] at map at RandomForest.scala:663), which has no missing parents
24/04/16 13:23:59.179 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 10.9 KiB, free 909.3 MiB)
24/04/16 13:23:59.179 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 909.3 MiB)
24/04/16 13:23:59.179 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.0 KiB, free: 910.9 MiB)
24/04/16 13:23:59.179 dag-scheduler-event-loop INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:59.179 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[216] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:59.179 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks resource profile 0
24/04/16 13:23:59.179 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 57) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:59.179 Executor task launch worker for task 0.0 in stage 55.0 (TID 57) INFO Executor: Running task 0.0 in stage 55.0 (TID 57)
24/04/16 13:23:59.195 Executor task launch worker for task 0.0 in stage 55.0 (TID 57) INFO ShuffleBlockFetcherIterator: Getting 2 (149.6 KiB) non-empty blocks including 2 (149.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:59.195 Executor task launch worker for task 0.0 in stage 55.0 (TID 57) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:59.195 Executor task launch worker for task 0.0 in stage 55.0 (TID 57) INFO Executor: Finished task 0.0 in stage 55.0 (TID 57). 6122 bytes result sent to driver
24/04/16 13:23:59.195 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 58) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:59.195 Executor task launch worker for task 1.0 in stage 55.0 (TID 58) INFO Executor: Running task 1.0 in stage 55.0 (TID 58)
24/04/16 13:23:59.195 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 57) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:59.195 Executor task launch worker for task 1.0 in stage 55.0 (TID 58) INFO ShuffleBlockFetcherIterator: Getting 2 (136.7 KiB) non-empty blocks including 2 (136.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:59.195 Executor task launch worker for task 1.0 in stage 55.0 (TID 58) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:59.211 Executor task launch worker for task 1.0 in stage 55.0 (TID 58) INFO Executor: Finished task 1.0 in stage 55.0 (TID 58). 5860 bytes result sent to driver
24/04/16 13:23:59.211 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 58) in 16 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:59.211 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
24/04/16 13:23:59.211 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 55 (collectAsMap at RandomForest.scala:663) finished in 0,032 s
24/04/16 13:23:59.211 dag-scheduler-event-loop INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:23:59.211 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
24/04/16 13:23:59.211 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 41 finished: collectAsMap at RandomForest.scala:663, took 0,108167 s
24/04/16 13:23:59.211 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(57) (from destroy at RandomForest.scala:674)
24/04/16 13:23:59.211 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_57_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 18.8 KiB, free: 910.9 MiB)
24/04/16 13:23:59.211 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 42.5 KiB, free 909.3 MiB)
24/04/16 13:23:59.211 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 26.4 KiB, free 909.2 MiB)
24/04/16 13:23:59.211 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 26.4 KiB, free: 910.9 MiB)
24/04/16 13:23:59.211 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 60 from broadcast at RandomForest.scala:622
24/04/16 13:23:59.236 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 13:23:59.237 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 217 (mapPartitions at RandomForest.scala:644) as input to shuffle 15
24/04/16 13:23:59.237 dag-scheduler-event-loop INFO DAGScheduler: Got job 42 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 13:23:59.237 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 57 (collectAsMap at RandomForest.scala:663)
24/04/16 13:23:59.237 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
24/04/16 13:23:59.237 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 56)
24/04/16 13:23:59.238 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[217] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 13:23:59.246 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 601.7 KiB, free 908.6 MiB)
24/04/16 13:23:59.248 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 155.4 KiB, free 908.5 MiB)
24/04/16 13:23:59.249 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 155.4 KiB, free: 910.8 MiB)
24/04/16 13:23:59.249 dag-scheduler-event-loop INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:59.249 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[217] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:59.249 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 56.0 with 2 tasks resource profile 0
24/04/16 13:23:59.255 dispatcher-event-loop-1 WARN TaskSetManager: Stage 56 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:23:59.255 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 59) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:59.256 Executor task launch worker for task 0.0 in stage 56.0 (TID 59) INFO Executor: Running task 0.0 in stage 56.0 (TID 59)
24/04/16 13:23:59.263 Executor task launch worker for task 0.0 in stage 56.0 (TID 59) INFO BlockManager: Found block rdd_210_0 locally
24/04/16 13:23:59.278 Executor task launch worker for task 0.0 in stage 56.0 (TID 59) INFO Executor: Finished task 0.0 in stage 56.0 (TID 59). 2205 bytes result sent to driver
24/04/16 13:23:59.278 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 60) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:59.278 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 59) in 28 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:59.278 Executor task launch worker for task 1.0 in stage 56.0 (TID 60) INFO Executor: Running task 1.0 in stage 56.0 (TID 60)
24/04/16 13:23:59.294 Executor task launch worker for task 1.0 in stage 56.0 (TID 60) INFO BlockManager: Found block rdd_210_1 locally
24/04/16 13:23:59.325 Executor task launch worker for task 1.0 in stage 56.0 (TID 60) INFO Executor: Finished task 1.0 in stage 56.0 (TID 60). 2248 bytes result sent to driver
24/04/16 13:23:59.325 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 60) in 47 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:59.325 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
24/04/16 13:23:59.325 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 56 (mapPartitions at RandomForest.scala:644) finished in 0,087 s
24/04/16 13:23:59.325 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:23:59.325 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:23:59.325 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 57)
24/04/16 13:23:59.325 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:23:59.325 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[219] at map at RandomForest.scala:663), which has no missing parents
24/04/16 13:23:59.325 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 12.3 KiB, free 908.5 MiB)
24/04/16 13:23:59.325 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 908.5 MiB)
24/04/16 13:23:59.325 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.3 KiB, free: 910.8 MiB)
24/04/16 13:23:59.325 dag-scheduler-event-loop INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:59.325 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 57 (MapPartitionsRDD[219] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:59.325 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 57.0 with 2 tasks resource profile 0
24/04/16 13:23:59.325 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 61) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:59.325 Executor task launch worker for task 0.0 in stage 57.0 (TID 61) INFO Executor: Running task 0.0 in stage 57.0 (TID 61)
24/04/16 13:23:59.325 Executor task launch worker for task 0.0 in stage 57.0 (TID 61) INFO ShuffleBlockFetcherIterator: Getting 2 (181.9 KiB) non-empty blocks including 2 (181.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:59.325 Executor task launch worker for task 0.0 in stage 57.0 (TID 61) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:59.341 Executor task launch worker for task 0.0 in stage 57.0 (TID 61) INFO Executor: Finished task 0.0 in stage 57.0 (TID 61). 7649 bytes result sent to driver
24/04/16 13:23:59.341 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 62) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:59.341 Executor task launch worker for task 1.0 in stage 57.0 (TID 62) INFO Executor: Running task 1.0 in stage 57.0 (TID 62)
24/04/16 13:23:59.341 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 61) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:59.356 Executor task launch worker for task 1.0 in stage 57.0 (TID 62) INFO ShuffleBlockFetcherIterator: Getting 2 (174.4 KiB) non-empty blocks including 2 (174.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:59.356 Executor task launch worker for task 1.0 in stage 57.0 (TID 62) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:59.370 Executor task launch worker for task 1.0 in stage 57.0 (TID 62) INFO Executor: Finished task 1.0 in stage 57.0 (TID 62). 7606 bytes result sent to driver
24/04/16 13:23:59.370 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 62) in 29 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:59.370 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
24/04/16 13:23:59.371 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 57 (collectAsMap at RandomForest.scala:663) finished in 0,046 s
24/04/16 13:23:59.371 dag-scheduler-event-loop INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:23:59.371 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
24/04/16 13:23:59.371 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 42 finished: collectAsMap at RandomForest.scala:663, took 0,134292 s
24/04/16 13:23:59.372 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(60) (from destroy at RandomForest.scala:674)
24/04/16 13:23:59.373 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_60_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 26.4 KiB, free: 910.8 MiB)
24/04/16 13:23:59.375 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 36.7 KiB, free 908.5 MiB)
24/04/16 13:23:59.376 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 908.5 MiB)
24/04/16 13:23:59.377 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 22.9 KiB, free: 910.8 MiB)
24/04/16 13:23:59.377 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 63 from broadcast at RandomForest.scala:622
24/04/16 13:23:59.391 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 13:23:59.392 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 220 (mapPartitions at RandomForest.scala:644) as input to shuffle 16
24/04/16 13:23:59.392 dag-scheduler-event-loop INFO DAGScheduler: Got job 43 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 13:23:59.392 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 59 (collectAsMap at RandomForest.scala:663)
24/04/16 13:23:59.392 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
24/04/16 13:23:59.392 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)
24/04/16 13:23:59.392 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[220] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 13:23:59.401 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 610.2 KiB, free 907.9 MiB)
24/04/16 13:23:59.404 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 155.4 KiB, free 907.7 MiB)
24/04/16 13:23:59.404 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 155.4 KiB, free: 910.6 MiB)
24/04/16 13:23:59.404 dag-scheduler-event-loop INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:59.405 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[220] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:59.405 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 58.0 with 2 tasks resource profile 0
24/04/16 13:23:59.413 dispatcher-event-loop-1 WARN TaskSetManager: Stage 58 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:23:59.413 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 63) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:59.413 Executor task launch worker for task 0.0 in stage 58.0 (TID 63) INFO Executor: Running task 0.0 in stage 58.0 (TID 63)
24/04/16 13:23:59.433 Executor task launch worker for task 0.0 in stage 58.0 (TID 63) INFO BlockManager: Found block rdd_210_0 locally
24/04/16 13:23:59.452 Executor task launch worker for task 0.0 in stage 58.0 (TID 63) INFO Executor: Finished task 0.0 in stage 58.0 (TID 63). 2248 bytes result sent to driver
24/04/16 13:23:59.461 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_59_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.0 KiB, free: 910.6 MiB)
24/04/16 13:23:59.464 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_58_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 144.9 KiB, free: 910.8 MiB)
24/04/16 13:23:59.464 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 58.0 (TID 64) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:59.464 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 63) in 59 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:59.464 Executor task launch worker for task 1.0 in stage 58.0 (TID 64) INFO Executor: Running task 1.0 in stage 58.0 (TID 64)
24/04/16 13:23:59.467 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_61_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 155.4 KiB, free: 910.9 MiB)
24/04/16 13:23:59.480 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_56_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 3.8 KiB, free: 910.9 MiB)
24/04/16 13:23:59.483 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_62_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.3 KiB, free: 910.9 MiB)
24/04/16 13:23:59.489 Executor task launch worker for task 1.0 in stage 58.0 (TID 64) INFO BlockManager: Found block rdd_210_1 locally
24/04/16 13:23:59.509 Executor task launch worker for task 1.0 in stage 58.0 (TID 64) INFO Executor: Finished task 1.0 in stage 58.0 (TID 64). 2205 bytes result sent to driver
24/04/16 13:23:59.511 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 58.0 (TID 64) in 59 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:59.511 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
24/04/16 13:23:59.511 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 58 (mapPartitions at RandomForest.scala:644) finished in 0,118 s
24/04/16 13:23:59.511 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:23:59.512 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:23:59.512 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 59)
24/04/16 13:23:59.512 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:23:59.512 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[222] at map at RandomForest.scala:663), which has no missing parents
24/04/16 13:23:59.513 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 11.6 KiB, free 909.2 MiB)
24/04/16 13:23:59.515 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 909.2 MiB)
24/04/16 13:23:59.515 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.2 KiB, free: 910.9 MiB)
24/04/16 13:23:59.516 dag-scheduler-event-loop INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:59.516 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 59 (MapPartitionsRDD[222] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:59.516 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 59.0 with 2 tasks resource profile 0
24/04/16 13:23:59.517 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 65) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:59.517 Executor task launch worker for task 0.0 in stage 59.0 (TID 65) INFO Executor: Running task 0.0 in stage 59.0 (TID 65)
24/04/16 13:23:59.518 Executor task launch worker for task 0.0 in stage 59.0 (TID 65) INFO ShuffleBlockFetcherIterator: Getting 2 (150.3 KiB) non-empty blocks including 2 (150.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:59.518 Executor task launch worker for task 0.0 in stage 59.0 (TID 65) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:59.530 Executor task launch worker for task 0.0 in stage 59.0 (TID 65) INFO Executor: Finished task 0.0 in stage 59.0 (TID 65). 6943 bytes result sent to driver
24/04/16 13:23:59.531 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 66) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:59.531 Executor task launch worker for task 1.0 in stage 59.0 (TID 66) INFO Executor: Running task 1.0 in stage 59.0 (TID 66)
24/04/16 13:23:59.531 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 65) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:59.533 Executor task launch worker for task 1.0 in stage 59.0 (TID 66) INFO ShuffleBlockFetcherIterator: Getting 2 (152.4 KiB) non-empty blocks including 2 (152.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:59.533 Executor task launch worker for task 1.0 in stage 59.0 (TID 66) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:59.544 Executor task launch worker for task 1.0 in stage 59.0 (TID 66) INFO Executor: Finished task 1.0 in stage 59.0 (TID 66). 6775 bytes result sent to driver
24/04/16 13:23:59.545 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 66) in 14 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:59.545 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
24/04/16 13:23:59.545 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 59 (collectAsMap at RandomForest.scala:663) finished in 0,032 s
24/04/16 13:23:59.545 dag-scheduler-event-loop INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:23:59.545 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
24/04/16 13:23:59.546 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 43 finished: collectAsMap at RandomForest.scala:663, took 0,154468 s
24/04/16 13:23:59.546 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(63) (from destroy at RandomForest.scala:674)
24/04/16 13:23:59.548 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_63_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 22.9 KiB, free: 910.9 MiB)
24/04/16 13:23:59.549 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 26.0 KiB, free 909.2 MiB)
24/04/16 13:23:59.550 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 909.2 MiB)
24/04/16 13:23:59.551 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 16.3 KiB, free: 910.9 MiB)
24/04/16 13:23:59.552 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 66 from broadcast at RandomForest.scala:622
24/04/16 13:23:59.566 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 13:23:59.567 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 223 (mapPartitions at RandomForest.scala:644) as input to shuffle 17
24/04/16 13:23:59.567 dag-scheduler-event-loop INFO DAGScheduler: Got job 44 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 13:23:59.567 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 61 (collectAsMap at RandomForest.scala:663)
24/04/16 13:23:59.567 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
24/04/16 13:23:59.567 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 60)
24/04/16 13:23:59.567 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[223] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 13:23:59.580 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 609.7 KiB, free 908.6 MiB)
24/04/16 13:23:59.580 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 151.1 KiB, free 908.5 MiB)
24/04/16 13:23:59.580 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 151.1 KiB, free: 910.8 MiB)
24/04/16 13:23:59.580 dag-scheduler-event-loop INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:59.580 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[223] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:59.580 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 60.0 with 2 tasks resource profile 0
24/04/16 13:23:59.589 dispatcher-event-loop-1 WARN TaskSetManager: Stage 60 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:23:59.589 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 67) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:59.590 Executor task launch worker for task 0.0 in stage 60.0 (TID 67) INFO Executor: Running task 0.0 in stage 60.0 (TID 67)
24/04/16 13:23:59.603 Executor task launch worker for task 0.0 in stage 60.0 (TID 67) INFO BlockManager: Found block rdd_210_0 locally
24/04/16 13:23:59.621 Executor task launch worker for task 0.0 in stage 60.0 (TID 67) INFO Executor: Finished task 0.0 in stage 60.0 (TID 67). 2248 bytes result sent to driver
24/04/16 13:23:59.626 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 68) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:23:59.626 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 67) in 46 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:59.626 Executor task launch worker for task 1.0 in stage 60.0 (TID 68) INFO Executor: Running task 1.0 in stage 60.0 (TID 68)
24/04/16 13:23:59.648 Executor task launch worker for task 1.0 in stage 60.0 (TID 68) INFO BlockManager: Found block rdd_210_1 locally
24/04/16 13:23:59.664 Executor task launch worker for task 1.0 in stage 60.0 (TID 68) INFO Executor: Finished task 1.0 in stage 60.0 (TID 68). 2248 bytes result sent to driver
24/04/16 13:23:59.664 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 68) in 43 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:59.664 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
24/04/16 13:23:59.665 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 60 (mapPartitions at RandomForest.scala:644) finished in 0,097 s
24/04/16 13:23:59.665 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:23:59.665 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:23:59.665 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 61)
24/04/16 13:23:59.665 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:23:59.665 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[225] at map at RandomForest.scala:663), which has no missing parents
24/04/16 13:23:59.667 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 10.4 KiB, free 908.5 MiB)
24/04/16 13:23:59.668 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 908.5 MiB)
24/04/16 13:23:59.668 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 4.9 KiB, free: 910.8 MiB)
24/04/16 13:23:59.668 dag-scheduler-event-loop INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1535
24/04/16 13:23:59.668 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 61 (MapPartitionsRDD[225] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:23:59.668 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 61.0 with 2 tasks resource profile 0
24/04/16 13:23:59.669 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 69) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:59.669 Executor task launch worker for task 0.0 in stage 61.0 (TID 69) INFO Executor: Running task 0.0 in stage 61.0 (TID 69)
24/04/16 13:23:59.671 Executor task launch worker for task 0.0 in stage 61.0 (TID 69) INFO ShuffleBlockFetcherIterator: Getting 2 (108.3 KiB) non-empty blocks including 2 (108.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:59.671 Executor task launch worker for task 0.0 in stage 61.0 (TID 69) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:59.682 Executor task launch worker for task 0.0 in stage 61.0 (TID 69) INFO Executor: Finished task 0.0 in stage 61.0 (TID 69). 5552 bytes result sent to driver
24/04/16 13:23:59.683 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 70) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:23:59.683 Executor task launch worker for task 1.0 in stage 61.0 (TID 70) INFO Executor: Running task 1.0 in stage 61.0 (TID 70)
24/04/16 13:23:59.683 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 69) in 14 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:23:59.685 Executor task launch worker for task 1.0 in stage 61.0 (TID 70) INFO ShuffleBlockFetcherIterator: Getting 2 (112.9 KiB) non-empty blocks including 2 (112.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:23:59.685 Executor task launch worker for task 1.0 in stage 61.0 (TID 70) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:23:59.696 Executor task launch worker for task 1.0 in stage 61.0 (TID 70) INFO Executor: Finished task 1.0 in stage 61.0 (TID 70). 5496 bytes result sent to driver
24/04/16 13:23:59.697 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 70) in 14 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:23:59.697 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
24/04/16 13:23:59.697 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 61 (collectAsMap at RandomForest.scala:663) finished in 0,031 s
24/04/16 13:23:59.697 dag-scheduler-event-loop INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:23:59.697 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
24/04/16 13:23:59.698 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 44 finished: collectAsMap at RandomForest.scala:663, took 0,131397 s
24/04/16 13:23:59.698 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(66) (from destroy at RandomForest.scala:674)
24/04/16 13:23:59.699 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 13:23:59.699 nioEventLoopGroup-2-2 INFO RandomForest:   init: 4.15E-5
  total: 0.9452218
  findBestSplits: 0.936445
  chooseSplits: 0.934706
24/04/16 13:23:59.700 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_66_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 16.3 KiB, free: 910.8 MiB)
24/04/16 13:23:59.702 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 210 from persistence list
24/04/16 13:23:59.703 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(53) (from destroy at RandomForest.scala:305)
24/04/16 13:23:59.704 block-manager-storage-async-thread-pool-259 INFO BlockManager: Removing RDD 210
24/04/16 13:23:59.705 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_53_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 8.0 KiB, free: 911.2 MiB)
24/04/16 13:23:59.709 nioEventLoopGroup-2-2 INFO Instrumentation: [4010161d] {"numFeatures":545}
24/04/16 13:23:59.709 nioEventLoopGroup-2-2 INFO Instrumentation: [4010161d] training finished
24/04/16 13:23:59.710 nioEventLoopGroup-2-2 INFO Instrumentation: [e86ff623] training finished
24/04/16 13:24:00.488 nioEventLoopGroup-2-2 INFO Instrumentation: [f92b2257] training finished
24/04/16 13:24:00.625 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_68_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 4.9 KiB, free: 911.2 MiB)
24/04/16 13:24:00.641 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_65_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.2 KiB, free: 911.2 MiB)
24/04/16 13:24:00.641 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_67_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 151.1 KiB, free: 911.3 MiB)
24/04/16 13:24:01.625 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 13:24:01.625 dag-scheduler-event-loop INFO DAGScheduler: Got job 45 (collect at utils.scala:26) with 1 output partitions
24/04/16 13:24:01.625 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:26)
24/04/16 13:24:01.625 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:24:01.625 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:24:01.625 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[228] at collect at utils.scala:26), which has no missing parents
24/04/16 13:24:01.641 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 62.5 KiB, free 909.6 MiB)
24/04/16 13:24:01.641 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.6 MiB)
24/04/16 13:24:01.641 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 13:24:01.641 dag-scheduler-event-loop INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1535
24/04/16 13:24:01.641 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[228] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 13:24:01.641 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
24/04/16 13:24:01.641 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 71) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 13:24:01.641 Executor task launch worker for task 0.0 in stage 62.0 (TID 71) INFO Executor: Running task 0.0 in stage 62.0 (TID 71)
24/04/16 13:24:01.656 Executor task launch worker for task 0.0 in stage 62.0 (TID 71) INFO Executor: Finished task 0.0 in stage 62.0 (TID 71). 1430 bytes result sent to driver
24/04/16 13:24:01.656 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 71) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 13:24:01.656 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
24/04/16 13:24:01.656 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 62 (collect at utils.scala:26) finished in 0,031 s
24/04/16 13:24:01.656 dag-scheduler-event-loop INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:24:01.656 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished
24/04/16 13:24:01.656 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 45 finished: collect at utils.scala:26, took 0,028826 s
24/04/16 13:24:04.362 nioEventLoopGroup-2-2 INFO Instrumentation: [b61c863d] training finished
24/04/16 13:24:04.428 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 448.6 KiB, free 909.2 MiB)
24/04/16 13:24:04.428 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 909.2 MiB)
24/04/16 13:24:04.428 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 27.5 KiB, free: 911.3 MiB)
24/04/16 13:24:04.428 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 70 from broadcast at RandomForestRegressor.scala:238
24/04/16 13:24:04.509 nioEventLoopGroup-2-2 INFO Instrumentation: [ffd08f8d] training finished
24/04/16 13:24:04.575 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_69_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 13:24:06.283 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 13:24:06.284 dag-scheduler-event-loop INFO DAGScheduler: Got job 46 (collect at utils.scala:26) with 1 output partitions
24/04/16 13:24:06.284 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:26)
24/04/16 13:24:06.284 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:24:06.284 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:24:06.285 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[231] at collect at utils.scala:26), which has no missing parents
24/04/16 13:24:06.287 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 62.6 KiB, free 909.2 MiB)
24/04/16 13:24:06.288 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.2 MiB)
24/04/16 13:24:06.288 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 13:24:06.289 dag-scheduler-event-loop INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1535
24/04/16 13:24:06.289 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[231] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 13:24:06.289 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
24/04/16 13:24:06.290 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 72) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 13:24:06.290 Executor task launch worker for task 0.0 in stage 63.0 (TID 72) INFO Executor: Running task 0.0 in stage 63.0 (TID 72)
24/04/16 13:24:06.326 Executor task launch worker for task 0.0 in stage 63.0 (TID 72) INFO Executor: Finished task 0.0 in stage 63.0 (TID 72). 1430 bytes result sent to driver
24/04/16 13:24:06.328 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 72) in 39 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 13:24:06.328 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
24/04/16 13:24:06.329 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 63 (collect at utils.scala:26) finished in 0,044 s
24/04/16 13:24:06.329 dag-scheduler-event-loop INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:24:06.329 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
24/04/16 13:24:06.330 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 46 finished: collect at utils.scala:26, took 0,046004 s
24/04/16 13:24:14.531 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 13:24:14.533 dag-scheduler-event-loop INFO DAGScheduler: Got job 47 (collect at utils.scala:26) with 1 output partitions
24/04/16 13:24:14.533 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:26)
24/04/16 13:24:14.533 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:24:14.534 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:24:14.534 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[239] at collect at utils.scala:26), which has no missing parents
24/04/16 13:24:14.546 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 452.7 KiB, free 908.7 MiB)
24/04/16 13:24:14.548 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 908.6 MiB)
24/04/16 13:24:14.549 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 90.5 KiB, free: 911.2 MiB)
24/04/16 13:24:14.551 dag-scheduler-event-loop INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1535
24/04/16 13:24:14.552 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[239] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 13:24:14.552 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
24/04/16 13:24:14.591 dispatcher-event-loop-1 WARN TaskSetManager: Stage 64 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:24:14.591 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 73) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 13:24:14.592 Executor task launch worker for task 0.0 in stage 64.0 (TID 73) INFO Executor: Running task 0.0 in stage 64.0 (TID 73)
24/04/16 13:24:14.617 Executor task launch worker for task 0.0 in stage 64.0 (TID 73) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:24:14.731 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_71_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.2 MiB)
24/04/16 13:24:15.084 Executor task launch worker for task 0.0 in stage 64.0 (TID 73) INFO CodeGenerator: Code generated in 174.4019 ms
24/04/16 13:24:15.345 Executor task launch worker for task 0.0 in stage 64.0 (TID 73) INFO Executor: Finished task 0.0 in stage 64.0 (TID 73). 142684 bytes result sent to driver
24/04/16 13:24:15.345 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 73) in 787 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 13:24:15.346 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
24/04/16 13:24:15.346 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 64 (collect at utils.scala:26) finished in 0,811 s
24/04/16 13:24:15.346 dag-scheduler-event-loop INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:24:15.346 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
24/04/16 13:24:15.346 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 47 finished: collect at utils.scala:26, took 0,814847 s
24/04/16 13:24:18.786 block-manager-storage-async-thread-pool-286 INFO BlockManager: Removing RDD 210
24/04/16 13:24:18.791 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_72_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 90.5 KiB, free: 911.3 MiB)
24/04/16 13:24:18.800 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_64_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 155.4 KiB, free: 911.4 MiB)
24/04/16 13:24:18.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_55_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 133.7 KiB, free: 911.6 MiB)
24/04/16 13:24:18.807 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 13:24:18.808 dag-scheduler-event-loop INFO DAGScheduler: Got job 48 (collect at utils.scala:26) with 1 output partitions
24/04/16 13:24:18.808 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:26)
24/04/16 13:24:18.808 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:24:18.808 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:24:18.809 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[245] at collect at utils.scala:26), which has no missing parents
24/04/16 13:24:18.813 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 123.2 KiB, free 910.5 MiB)
24/04/16 13:24:18.814 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 910.5 MiB)
24/04/16 13:24:18.815 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 13:24:18.815 dag-scheduler-event-loop INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1535
24/04/16 13:24:18.815 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[245] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 13:24:18.815 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
24/04/16 13:24:18.826 dispatcher-event-loop-0 WARN TaskSetManager: Stage 65 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:24:18.827 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 74) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 13:24:18.827 Executor task launch worker for task 0.0 in stage 65.0 (TID 74) INFO Executor: Running task 0.0 in stage 65.0 (TID 74)
24/04/16 13:24:18.836 Executor task launch worker for task 0.0 in stage 65.0 (TID 74) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:24:18.945 Executor task launch worker for task 0.0 in stage 65.0 (TID 74) INFO Executor: Finished task 0.0 in stage 65.0 (TID 74). 137627 bytes result sent to driver
24/04/16 13:24:18.946 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 74) in 130 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 13:24:18.946 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
24/04/16 13:24:18.948 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 65 (collect at utils.scala:26) finished in 0,138 s
24/04/16 13:24:18.948 dag-scheduler-event-loop INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:24:18.948 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
24/04/16 13:24:18.948 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 48 finished: collect at utils.scala:26, took 0,140328 s
24/04/16 13:26:59.654 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 13:26:59.654 dag-scheduler-event-loop INFO DAGScheduler: Got job 49 (collect at utils.scala:26) with 1 output partitions
24/04/16 13:26:59.654 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 66 (collect at utils.scala:26)
24/04/16 13:26:59.654 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:26:59.654 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:26:59.654 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[253] at collect at utils.scala:26), which has no missing parents
24/04/16 13:26:59.669 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 373.1 KiB, free 910.1 MiB)
24/04/16 13:26:59.669 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 75.3 KiB, free 910.1 MiB)
24/04/16 13:26:59.669 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 75.3 KiB, free: 911.5 MiB)
24/04/16 13:26:59.669 dag-scheduler-event-loop INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1535
24/04/16 13:26:59.669 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[253] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 13:26:59.669 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
24/04/16 13:26:59.669 dispatcher-event-loop-1 WARN TaskSetManager: Stage 66 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:26:59.669 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 75) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 13:26:59.669 Executor task launch worker for task 0.0 in stage 66.0 (TID 75) INFO Executor: Running task 0.0 in stage 66.0 (TID 75)
24/04/16 13:26:59.701 Executor task launch worker for task 0.0 in stage 66.0 (TID 75) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:26:59.915 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_73_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 13:27:00.050 Executor task launch worker for task 0.0 in stage 66.0 (TID 75) INFO CodeGenerator: Code generated in 108.7728 ms
24/04/16 13:27:00.140 Executor task launch worker for task 0.0 in stage 66.0 (TID 75) INFO Executor: Finished task 0.0 in stage 66.0 (TID 75). 7154 bytes result sent to driver
24/04/16 13:27:00.148 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 75) in 479 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 13:27:00.148 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
24/04/16 13:27:00.148 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 66 (collect at utils.scala:26) finished in 0,494 s
24/04/16 13:27:00.148 dag-scheduler-event-loop INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:00.148 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
24/04/16 13:27:00.149 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 49 finished: collect at utils.scala:26, took 0,484211 s
24/04/16 13:27:05.244 nioEventLoopGroup-2-2 INFO Instrumentation: [3984df87] training finished
24/04/16 13:27:05.617 nioEventLoopGroup-2-2 INFO Instrumentation: [a6f40337] training finished
24/04/16 13:27:06.147 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_74_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 75.3 KiB, free: 911.6 MiB)
24/04/16 13:27:06.290 nioEventLoopGroup-2-2 INFO Instrumentation: [4e4dd52b] Stage class: RandomForestRegressor
24/04/16 13:27:06.290 nioEventLoopGroup-2-2 INFO Instrumentation: [4e4dd52b] Stage uid: random_forest__8bf7287d_f603_4ed0_9906_bc70d865e51c
24/04/16 13:27:06.290 nioEventLoopGroup-2-2 INFO Instrumentation: [4e4dd52b] training: numPartitions=2 storageLevel=StorageLevel(1 replicas)
24/04/16 13:27:06.290 nioEventLoopGroup-2-2 INFO Instrumentation: [4e4dd52b] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/16 13:27:06.328 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 13:27:06.329 dag-scheduler-event-loop INFO DAGScheduler: Got job 50 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 13:27:06.330 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 67 (take at DecisionTreeMetadata.scala:119)
24/04/16 13:27:06.330 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:27:06.330 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:27:06.330 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[276] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 13:27:06.341 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 521.9 KiB, free 910.2 MiB)
24/04/16 13:27:06.343 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 117.4 KiB, free 910.0 MiB)
24/04/16 13:27:06.343 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 117.4 KiB, free: 911.5 MiB)
24/04/16 13:27:06.344 dag-scheduler-event-loop INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:06.344 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[276] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 13:27:06.344 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0
24/04/16 13:27:06.351 dispatcher-event-loop-1 WARN TaskSetManager: Stage 67 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:27:06.351 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 76) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 13:27:06.352 Executor task launch worker for task 0.0 in stage 67.0 (TID 76) INFO Executor: Running task 0.0 in stage 67.0 (TID 76)
24/04/16 13:27:06.385 Executor task launch worker for task 0.0 in stage 67.0 (TID 76) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:27:06.592 Executor task launch worker for task 0.0 in stage 67.0 (TID 76) INFO CodeGenerator: Code generated in 74.3501 ms
24/04/16 13:27:06.597 Executor task launch worker for task 0.0 in stage 67.0 (TID 76) INFO Executor: Finished task 0.0 in stage 67.0 (TID 76). 1950 bytes result sent to driver
24/04/16 13:27:06.597 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 76) in 253 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 13:27:06.597 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
24/04/16 13:27:06.597 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 67 (take at DecisionTreeMetadata.scala:119) finished in 0,266 s
24/04/16 13:27:06.597 dag-scheduler-event-loop INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:06.597 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
24/04/16 13:27:06.597 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 50 finished: take at DecisionTreeMetadata.scala:119, took 0,275838 s
24/04/16 13:27:06.597 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 13:27:06.597 dag-scheduler-event-loop INFO DAGScheduler: Got job 51 (aggregate at DecisionTreeMetadata.scala:125) with 2 output partitions
24/04/16 13:27:06.597 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 68 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 13:27:06.597 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:27:06.597 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:27:06.597 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[275] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 13:27:06.613 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 521.9 KiB, free 909.5 MiB)
24/04/16 13:27:06.613 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 117.6 KiB, free 909.4 MiB)
24/04/16 13:27:06.613 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 117.6 KiB, free: 911.3 MiB)
24/04/16 13:27:06.613 dag-scheduler-event-loop INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:06.613 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 68 (MapPartitionsRDD[275] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:06.613 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 68.0 with 2 tasks resource profile 0
24/04/16 13:27:06.613 dispatcher-event-loop-0 WARN TaskSetManager: Stage 68 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:27:06.613 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 77) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 13:27:06.613 Executor task launch worker for task 0.0 in stage 68.0 (TID 77) INFO Executor: Running task 0.0 in stage 68.0 (TID 77)
24/04/16 13:27:06.628 Executor task launch worker for task 0.0 in stage 68.0 (TID 77) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:27:06.723 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_75_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 117.4 KiB, free: 911.5 MiB)
24/04/16 13:27:06.754 Executor task launch worker for task 0.0 in stage 68.0 (TID 77) INFO Executor: Finished task 0.0 in stage 68.0 (TID 77). 2108 bytes result sent to driver
24/04/16 13:27:06.754 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 78) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 13:27:06.754 Executor task launch worker for task 1.0 in stage 68.0 (TID 78) INFO Executor: Running task 1.0 in stage 68.0 (TID 78)
24/04/16 13:27:06.754 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 77) in 141 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:06.769 Executor task launch worker for task 1.0 in stage 68.0 (TID 78) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:27:06.859 Executor task launch worker for task 1.0 in stage 68.0 (TID 78) INFO Executor: Finished task 1.0 in stage 68.0 (TID 78). 2065 bytes result sent to driver
24/04/16 13:27:06.859 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 78) in 105 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:06.859 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
24/04/16 13:27:06.859 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 68 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,262 s
24/04/16 13:27:06.859 dag-scheduler-event-loop INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:06.859 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
24/04/16 13:27:06.859 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 51 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,258076 s
24/04/16 13:27:06.874 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 13:27:06.874 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 278 (flatMap at RandomForest.scala:1039) as input to shuffle 18
24/04/16 13:27:06.874 dag-scheduler-event-loop INFO DAGScheduler: Got job 52 (collectAsMap at RandomForest.scala:1054) with 2 output partitions
24/04/16 13:27:06.874 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 70 (collectAsMap at RandomForest.scala:1054)
24/04/16 13:27:06.874 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 69)
24/04/16 13:27:06.874 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 69)
24/04/16 13:27:06.874 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[278] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 13:27:06.874 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 531.0 KiB, free 909.5 MiB)
24/04/16 13:27:06.890 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 121.2 KiB, free 909.4 MiB)
24/04/16 13:27:06.890 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 121.2 KiB, free: 911.3 MiB)
24/04/16 13:27:06.890 dag-scheduler-event-loop INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:06.890 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[278] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:06.890 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 69.0 with 2 tasks resource profile 0
24/04/16 13:27:06.890 dispatcher-event-loop-1 WARN TaskSetManager: Stage 69 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:27:06.890 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 79) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:06.890 Executor task launch worker for task 0.0 in stage 69.0 (TID 79) INFO Executor: Running task 0.0 in stage 69.0 (TID 79)
24/04/16 13:27:06.906 Executor task launch worker for task 0.0 in stage 69.0 (TID 79) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:27:07.062 Executor task launch worker for task 0.0 in stage 69.0 (TID 79) INFO Executor: Finished task 0.0 in stage 69.0 (TID 79). 2248 bytes result sent to driver
24/04/16 13:27:07.140 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_76_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 117.6 KiB, free: 911.4 MiB)
24/04/16 13:27:07.140 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 80) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:07.140 Executor task launch worker for task 1.0 in stage 69.0 (TID 80) INFO Executor: Running task 1.0 in stage 69.0 (TID 80)
24/04/16 13:27:07.140 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 79) in 250 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:07.156 Executor task launch worker for task 1.0 in stage 69.0 (TID 80) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:27:07.290 Executor task launch worker for task 1.0 in stage 69.0 (TID 80) INFO Executor: Finished task 1.0 in stage 69.0 (TID 80). 2248 bytes result sent to driver
24/04/16 13:27:07.290 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 80) in 228 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:07.290 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
24/04/16 13:27:07.290 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 69 (flatMap at RandomForest.scala:1039) finished in 0,416 s
24/04/16 13:27:07.290 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:27:07.290 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:27:07.290 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 70)
24/04/16 13:27:07.290 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:27:07.290 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[280] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 13:27:07.290 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 11.9 KiB, free 910.0 MiB)
24/04/16 13:27:07.290 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 910.0 MiB)
24/04/16 13:27:07.290 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 4.5 KiB, free: 911.4 MiB)
24/04/16 13:27:07.290 dag-scheduler-event-loop INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:07.290 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 70 (MapPartitionsRDD[280] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:07.306 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 70.0 with 2 tasks resource profile 0
24/04/16 13:27:07.306 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 81) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:07.306 Executor task launch worker for task 0.0 in stage 70.0 (TID 81) INFO Executor: Running task 0.0 in stage 70.0 (TID 81)
24/04/16 13:27:07.306 Executor task launch worker for task 0.0 in stage 70.0 (TID 81) INFO ShuffleBlockFetcherIterator: Getting 2 (31.9 KiB) non-empty blocks including 2 (31.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:07.306 Executor task launch worker for task 0.0 in stage 70.0 (TID 81) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:07.321 Executor task launch worker for task 0.0 in stage 70.0 (TID 81) INFO Executor: Finished task 0.0 in stage 70.0 (TID 81). 21465 bytes result sent to driver
24/04/16 13:27:07.321 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 82) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:07.321 Executor task launch worker for task 1.0 in stage 70.0 (TID 82) INFO Executor: Running task 1.0 in stage 70.0 (TID 82)
24/04/16 13:27:07.321 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 81) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:07.321 Executor task launch worker for task 1.0 in stage 70.0 (TID 82) INFO ShuffleBlockFetcherIterator: Getting 2 (31.4 KiB) non-empty blocks including 2 (31.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:07.321 Executor task launch worker for task 1.0 in stage 70.0 (TID 82) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:07.337 Executor task launch worker for task 1.0 in stage 70.0 (TID 82) INFO Executor: Finished task 1.0 in stage 70.0 (TID 82). 20598 bytes result sent to driver
24/04/16 13:27:07.337 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 82) in 16 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:07.337 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
24/04/16 13:27:07.337 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 70 (collectAsMap at RandomForest.scala:1054) finished in 0,047 s
24/04/16 13:27:07.337 dag-scheduler-event-loop INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:07.337 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished
24/04/16 13:27:07.337 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 52 finished: collectAsMap at RandomForest.scala:1054, took 0,468249 s
24/04/16 13:27:07.352 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 47.5 KiB, free 910.0 MiB)
24/04/16 13:27:07.352 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 910.0 MiB)
24/04/16 13:27:07.352 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 8.0 KiB, free: 911.4 MiB)
24/04/16 13:27:07.352 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 79 from broadcast at RandomForest.scala:293
24/04/16 13:27:07.352 nioEventLoopGroup-2-2 INFO Instrumentation: [4e4dd52b] {"numFeatures":545}
24/04/16 13:27:07.352 nioEventLoopGroup-2-2 INFO Instrumentation: [4e4dd52b] {"numClasses":0}
24/04/16 13:27:07.352 nioEventLoopGroup-2-2 INFO Instrumentation: [4e4dd52b] {"numExamples":159}
24/04/16 13:27:07.352 nioEventLoopGroup-2-2 INFO Instrumentation: [4e4dd52b] {"sumOfWeights":159.0}
24/04/16 13:27:07.352 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 16.1 KiB, free 909.9 MiB)
24/04/16 13:27:07.352 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 909.9 MiB)
24/04/16 13:27:07.352 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 10.3 KiB, free: 911.4 MiB)
24/04/16 13:27:07.352 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 80 from broadcast at RandomForest.scala:622
24/04/16 13:27:07.368 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 13:27:07.368 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 283 (mapPartitions at RandomForest.scala:644) as input to shuffle 19
24/04/16 13:27:07.368 dag-scheduler-event-loop INFO DAGScheduler: Got job 53 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 13:27:07.368 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 72 (collectAsMap at RandomForest.scala:663)
24/04/16 13:27:07.368 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
24/04/16 13:27:07.368 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 71)
24/04/16 13:27:07.368 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[283] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 13:27:07.384 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 561.9 KiB, free 909.4 MiB)
24/04/16 13:27:07.384 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 133.7 KiB, free 909.3 MiB)
24/04/16 13:27:07.384 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 133.7 KiB, free: 911.3 MiB)
24/04/16 13:27:07.384 dag-scheduler-event-loop INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:07.384 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[283] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:07.384 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 71.0 with 2 tasks resource profile 0
24/04/16 13:27:07.399 dispatcher-event-loop-1 WARN TaskSetManager: Stage 71 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:27:07.399 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 83) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:07.399 Executor task launch worker for task 0.0 in stage 71.0 (TID 83) INFO Executor: Running task 0.0 in stage 71.0 (TID 83)
24/04/16 13:27:07.399 Executor task launch worker for task 0.0 in stage 71.0 (TID 83) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:27:07.509 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_78_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 4.5 KiB, free: 911.3 MiB)
24/04/16 13:27:07.509 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_77_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 121.2 KiB, free: 911.4 MiB)
24/04/16 13:27:07.524 Executor task launch worker for task 0.0 in stage 71.0 (TID 83) INFO MemoryStore: Block rdd_282_0 stored as values in memory (estimated size 180.1 KiB, free 909.7 MiB)
24/04/16 13:27:07.524 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_282_0 in memory on DESKTOP-LH06ASP:56331 (size: 180.1 KiB, free: 911.2 MiB)
24/04/16 13:27:07.555 Executor task launch worker for task 0.0 in stage 71.0 (TID 83) INFO Executor: Finished task 0.0 in stage 71.0 (TID 83). 2291 bytes result sent to driver
24/04/16 13:27:07.555 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 84) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:07.555 Executor task launch worker for task 1.0 in stage 71.0 (TID 84) INFO Executor: Running task 1.0 in stage 71.0 (TID 84)
24/04/16 13:27:07.555 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 83) in 171 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:07.571 Executor task launch worker for task 1.0 in stage 71.0 (TID 84) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:27:07.665 Executor task launch worker for task 1.0 in stage 71.0 (TID 84) INFO MemoryStore: Block rdd_282_1 stored as values in memory (estimated size 187.0 KiB, free 909.5 MiB)
24/04/16 13:27:07.665 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_282_1 in memory on DESKTOP-LH06ASP:56331 (size: 187.0 KiB, free: 911.1 MiB)
24/04/16 13:27:07.680 Executor task launch worker for task 1.0 in stage 71.0 (TID 84) INFO Executor: Finished task 1.0 in stage 71.0 (TID 84). 2248 bytes result sent to driver
24/04/16 13:27:07.680 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 84) in 125 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:07.680 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
24/04/16 13:27:07.680 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 71 (mapPartitions at RandomForest.scala:644) finished in 0,312 s
24/04/16 13:27:07.680 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:27:07.680 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:27:07.680 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 72)
24/04/16 13:27:07.680 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:27:07.680 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[285] at map at RandomForest.scala:663), which has no missing parents
24/04/16 13:27:07.696 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 7.4 KiB, free 909.5 MiB)
24/04/16 13:27:07.696 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 909.5 MiB)
24/04/16 13:27:07.696 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 3.8 KiB, free: 911.1 MiB)
24/04/16 13:27:07.696 dag-scheduler-event-loop INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:07.696 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 72 (MapPartitionsRDD[285] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:07.696 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 72.0 with 2 tasks resource profile 0
24/04/16 13:27:07.696 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 85) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:07.696 Executor task launch worker for task 0.0 in stage 72.0 (TID 85) INFO Executor: Running task 0.0 in stage 72.0 (TID 85)
24/04/16 13:27:07.696 Executor task launch worker for task 0.0 in stage 72.0 (TID 85) INFO ShuffleBlockFetcherIterator: Getting 2 (92.9 KiB) non-empty blocks including 2 (92.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:07.696 Executor task launch worker for task 0.0 in stage 72.0 (TID 85) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:07.696 Executor task launch worker for task 0.0 in stage 72.0 (TID 85) INFO Executor: Finished task 0.0 in stage 72.0 (TID 85). 4223 bytes result sent to driver
24/04/16 13:27:07.696 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 86) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:07.696 Executor task launch worker for task 1.0 in stage 72.0 (TID 86) INFO Executor: Running task 1.0 in stage 72.0 (TID 86)
24/04/16 13:27:07.696 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 85) in 0 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:07.696 Executor task launch worker for task 1.0 in stage 72.0 (TID 86) INFO ShuffleBlockFetcherIterator: Getting 2 (92.9 KiB) non-empty blocks including 2 (92.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:07.712 Executor task launch worker for task 1.0 in stage 72.0 (TID 86) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:07.712 Executor task launch worker for task 1.0 in stage 72.0 (TID 86) INFO Executor: Finished task 1.0 in stage 72.0 (TID 86). 4236 bytes result sent to driver
24/04/16 13:27:07.712 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 86) in 16 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:07.712 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
24/04/16 13:27:07.712 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 72 (collectAsMap at RandomForest.scala:663) finished in 0,032 s
24/04/16 13:27:07.712 dag-scheduler-event-loop INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:07.712 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
24/04/16 13:27:07.712 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 53 finished: collectAsMap at RandomForest.scala:663, took 0,343685 s
24/04/16 13:27:07.712 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(80) (from destroy at RandomForest.scala:674)
24/04/16 13:27:07.712 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_80_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 10.3 KiB, free: 911.1 MiB)
24/04/16 13:27:07.712 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 30.1 KiB, free 909.5 MiB)
24/04/16 13:27:07.712 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 909.5 MiB)
24/04/16 13:27:07.712 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 18.8 KiB, free: 911.0 MiB)
24/04/16 13:27:07.712 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 83 from broadcast at RandomForest.scala:622
24/04/16 13:27:07.727 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 13:27:07.727 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 286 (mapPartitions at RandomForest.scala:644) as input to shuffle 20
24/04/16 13:27:07.727 dag-scheduler-event-loop INFO DAGScheduler: Got job 54 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 13:27:07.727 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 74 (collectAsMap at RandomForest.scala:663)
24/04/16 13:27:07.727 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
24/04/16 13:27:07.727 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 73)
24/04/16 13:27:07.727 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[286] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 13:27:07.743 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 580.7 KiB, free 908.9 MiB)
24/04/16 13:27:07.743 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 144.9 KiB, free 908.8 MiB)
24/04/16 13:27:07.743 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 144.9 KiB, free: 910.9 MiB)
24/04/16 13:27:07.743 dag-scheduler-event-loop INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:07.743 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[286] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:07.743 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 73.0 with 2 tasks resource profile 0
24/04/16 13:27:07.759 dispatcher-event-loop-1 WARN TaskSetManager: Stage 73 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:27:07.759 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 87) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:07.759 Executor task launch worker for task 0.0 in stage 73.0 (TID 87) INFO Executor: Running task 0.0 in stage 73.0 (TID 87)
24/04/16 13:27:07.774 Executor task launch worker for task 0.0 in stage 73.0 (TID 87) INFO BlockManager: Found block rdd_282_0 locally
24/04/16 13:27:07.791 Executor task launch worker for task 0.0 in stage 73.0 (TID 87) INFO Executor: Finished task 0.0 in stage 73.0 (TID 87). 2205 bytes result sent to driver
24/04/16 13:27:07.800 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 88) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:07.800 Executor task launch worker for task 1.0 in stage 73.0 (TID 88) INFO Executor: Running task 1.0 in stage 73.0 (TID 88)
24/04/16 13:27:07.800 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 87) in 57 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:07.812 Executor task launch worker for task 1.0 in stage 73.0 (TID 88) INFO BlockManager: Found block rdd_282_1 locally
24/04/16 13:27:07.827 Executor task launch worker for task 1.0 in stage 73.0 (TID 88) INFO Executor: Finished task 1.0 in stage 73.0 (TID 88). 2248 bytes result sent to driver
24/04/16 13:27:07.827 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 88) in 35 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:07.827 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
24/04/16 13:27:07.827 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 73 (mapPartitions at RandomForest.scala:644) finished in 0,100 s
24/04/16 13:27:07.827 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:27:07.827 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:27:07.827 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 74)
24/04/16 13:27:07.827 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:27:07.827 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[288] at map at RandomForest.scala:663), which has no missing parents
24/04/16 13:27:07.827 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 10.9 KiB, free 908.8 MiB)
24/04/16 13:27:07.827 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 908.8 MiB)
24/04/16 13:27:07.827 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.0 KiB, free: 910.9 MiB)
24/04/16 13:27:07.827 dag-scheduler-event-loop INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:07.827 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 74 (MapPartitionsRDD[288] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:07.827 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 74.0 with 2 tasks resource profile 0
24/04/16 13:27:07.827 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 89) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:07.827 Executor task launch worker for task 0.0 in stage 74.0 (TID 89) INFO Executor: Running task 0.0 in stage 74.0 (TID 89)
24/04/16 13:27:07.827 Executor task launch worker for task 0.0 in stage 74.0 (TID 89) INFO ShuffleBlockFetcherIterator: Getting 2 (149.6 KiB) non-empty blocks including 2 (149.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:07.827 Executor task launch worker for task 0.0 in stage 74.0 (TID 89) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:07.843 Executor task launch worker for task 0.0 in stage 74.0 (TID 89) INFO Executor: Finished task 0.0 in stage 74.0 (TID 89). 6122 bytes result sent to driver
24/04/16 13:27:07.843 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 90) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:07.843 Executor task launch worker for task 1.0 in stage 74.0 (TID 90) INFO Executor: Running task 1.0 in stage 74.0 (TID 90)
24/04/16 13:27:07.843 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 89) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:07.843 Executor task launch worker for task 1.0 in stage 74.0 (TID 90) INFO ShuffleBlockFetcherIterator: Getting 2 (136.7 KiB) non-empty blocks including 2 (136.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:07.843 Executor task launch worker for task 1.0 in stage 74.0 (TID 90) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:07.858 Executor task launch worker for task 1.0 in stage 74.0 (TID 90) INFO Executor: Finished task 1.0 in stage 74.0 (TID 90). 5903 bytes result sent to driver
24/04/16 13:27:07.858 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 90) in 15 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:07.858 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
24/04/16 13:27:07.858 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 74 (collectAsMap at RandomForest.scala:663) finished in 0,031 s
24/04/16 13:27:07.858 dag-scheduler-event-loop INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:07.858 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
24/04/16 13:27:07.858 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 54 finished: collectAsMap at RandomForest.scala:663, took 0,128384 s
24/04/16 13:27:07.858 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(83) (from destroy at RandomForest.scala:674)
24/04/16 13:27:07.858 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_83_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 18.8 KiB, free: 910.9 MiB)
24/04/16 13:27:07.858 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 42.5 KiB, free 908.8 MiB)
24/04/16 13:27:07.858 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 26.4 KiB, free 908.8 MiB)
24/04/16 13:27:07.858 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 26.4 KiB, free: 910.9 MiB)
24/04/16 13:27:07.858 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 86 from broadcast at RandomForest.scala:622
24/04/16 13:27:07.874 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 13:27:07.874 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 289 (mapPartitions at RandomForest.scala:644) as input to shuffle 21
24/04/16 13:27:07.874 dag-scheduler-event-loop INFO DAGScheduler: Got job 55 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 13:27:07.874 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 76 (collectAsMap at RandomForest.scala:663)
24/04/16 13:27:07.874 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
24/04/16 13:27:07.874 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 75)
24/04/16 13:27:07.874 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[289] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 13:27:07.890 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 601.7 KiB, free 908.2 MiB)
24/04/16 13:27:07.890 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 155.4 KiB, free 908.0 MiB)
24/04/16 13:27:07.890 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 155.4 KiB, free: 910.7 MiB)
24/04/16 13:27:07.890 dag-scheduler-event-loop INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:07.890 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[289] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:07.890 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 75.0 with 2 tasks resource profile 0
24/04/16 13:27:07.890 dispatcher-event-loop-1 WARN TaskSetManager: Stage 75 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:27:07.890 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 91) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:07.890 Executor task launch worker for task 0.0 in stage 75.0 (TID 91) INFO Executor: Running task 0.0 in stage 75.0 (TID 91)
24/04/16 13:27:07.905 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_85_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.0 KiB, free: 910.7 MiB)
24/04/16 13:27:07.905 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_84_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 144.9 KiB, free: 910.9 MiB)
24/04/16 13:27:07.905 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_82_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 3.8 KiB, free: 910.9 MiB)
24/04/16 13:27:07.921 Executor task launch worker for task 0.0 in stage 75.0 (TID 91) INFO BlockManager: Found block rdd_282_0 locally
24/04/16 13:27:07.937 Executor task launch worker for task 0.0 in stage 75.0 (TID 91) INFO Executor: Finished task 0.0 in stage 75.0 (TID 91). 2291 bytes result sent to driver
24/04/16 13:27:07.952 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 92) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:07.952 Executor task launch worker for task 1.0 in stage 75.0 (TID 92) INFO Executor: Running task 1.0 in stage 75.0 (TID 92)
24/04/16 13:27:07.952 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 91) in 62 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:07.968 Executor task launch worker for task 1.0 in stage 75.0 (TID 92) INFO BlockManager: Found block rdd_282_1 locally
24/04/16 13:27:07.983 Executor task launch worker for task 1.0 in stage 75.0 (TID 92) INFO Executor: Finished task 1.0 in stage 75.0 (TID 92). 2205 bytes result sent to driver
24/04/16 13:27:07.983 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 92) in 46 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:07.983 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
24/04/16 13:27:07.983 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 75 (mapPartitions at RandomForest.scala:644) finished in 0,109 s
24/04/16 13:27:07.983 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:27:07.983 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:27:07.983 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 76)
24/04/16 13:27:07.983 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:27:07.983 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[291] at map at RandomForest.scala:663), which has no missing parents
24/04/16 13:27:07.983 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 12.3 KiB, free 908.8 MiB)
24/04/16 13:27:07.983 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 908.7 MiB)
24/04/16 13:27:07.983 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.3 KiB, free: 910.9 MiB)
24/04/16 13:27:07.983 dag-scheduler-event-loop INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:07.983 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 76 (MapPartitionsRDD[291] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:07.983 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 76.0 with 2 tasks resource profile 0
24/04/16 13:27:07.983 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 93) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:07.983 Executor task launch worker for task 0.0 in stage 76.0 (TID 93) INFO Executor: Running task 0.0 in stage 76.0 (TID 93)
24/04/16 13:27:07.999 Executor task launch worker for task 0.0 in stage 76.0 (TID 93) INFO ShuffleBlockFetcherIterator: Getting 2 (181.9 KiB) non-empty blocks including 2 (181.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:07.999 Executor task launch worker for task 0.0 in stage 76.0 (TID 93) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:08.015 Executor task launch worker for task 0.0 in stage 76.0 (TID 93) INFO Executor: Finished task 0.0 in stage 76.0 (TID 93). 7606 bytes result sent to driver
24/04/16 13:27:08.015 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 94) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:08.015 Executor task launch worker for task 1.0 in stage 76.0 (TID 94) INFO Executor: Running task 1.0 in stage 76.0 (TID 94)
24/04/16 13:27:08.015 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 93) in 32 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:08.015 Executor task launch worker for task 1.0 in stage 76.0 (TID 94) INFO ShuffleBlockFetcherIterator: Getting 2 (174.4 KiB) non-empty blocks including 2 (174.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:08.015 Executor task launch worker for task 1.0 in stage 76.0 (TID 94) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:08.015 Executor task launch worker for task 1.0 in stage 76.0 (TID 94) INFO Executor: Finished task 1.0 in stage 76.0 (TID 94). 7563 bytes result sent to driver
24/04/16 13:27:08.030 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 94) in 15 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:08.030 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
24/04/16 13:27:08.030 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 76 (collectAsMap at RandomForest.scala:663) finished in 0,047 s
24/04/16 13:27:08.030 dag-scheduler-event-loop INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:08.030 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
24/04/16 13:27:08.030 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 55 finished: collectAsMap at RandomForest.scala:663, took 0,146856 s
24/04/16 13:27:08.030 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(86) (from destroy at RandomForest.scala:674)
24/04/16 13:27:08.030 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_86_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 26.4 KiB, free: 910.9 MiB)
24/04/16 13:27:08.030 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 36.7 KiB, free 908.8 MiB)
24/04/16 13:27:08.030 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 908.8 MiB)
24/04/16 13:27:08.030 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 22.9 KiB, free: 910.9 MiB)
24/04/16 13:27:08.030 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 89 from broadcast at RandomForest.scala:622
24/04/16 13:27:08.046 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 13:27:08.046 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 292 (mapPartitions at RandomForest.scala:644) as input to shuffle 22
24/04/16 13:27:08.046 dag-scheduler-event-loop INFO DAGScheduler: Got job 56 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 13:27:08.046 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 78 (collectAsMap at RandomForest.scala:663)
24/04/16 13:27:08.046 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
24/04/16 13:27:08.046 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 77)
24/04/16 13:27:08.046 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[292] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 13:27:08.067 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 610.2 KiB, free 908.2 MiB)
24/04/16 13:27:08.069 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 155.4 KiB, free 908.0 MiB)
24/04/16 13:27:08.069 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 155.4 KiB, free: 910.7 MiB)
24/04/16 13:27:08.070 dag-scheduler-event-loop INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:08.071 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[292] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:08.071 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 77.0 with 2 tasks resource profile 0
24/04/16 13:27:08.081 dispatcher-event-loop-1 WARN TaskSetManager: Stage 77 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:27:08.081 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 95) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:08.082 Executor task launch worker for task 0.0 in stage 77.0 (TID 95) INFO Executor: Running task 0.0 in stage 77.0 (TID 95)
24/04/16 13:27:08.097 Executor task launch worker for task 0.0 in stage 77.0 (TID 95) INFO BlockManager: Found block rdd_282_0 locally
24/04/16 13:27:08.120 Executor task launch worker for task 0.0 in stage 77.0 (TID 95) INFO Executor: Finished task 0.0 in stage 77.0 (TID 95). 2291 bytes result sent to driver
24/04/16 13:27:08.130 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 96) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:08.130 Executor task launch worker for task 1.0 in stage 77.0 (TID 96) INFO Executor: Running task 1.0 in stage 77.0 (TID 96)
24/04/16 13:27:08.130 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 95) in 59 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:08.145 Executor task launch worker for task 1.0 in stage 77.0 (TID 96) INFO BlockManager: Found block rdd_282_1 locally
24/04/16 13:27:08.170 Executor task launch worker for task 1.0 in stage 77.0 (TID 96) INFO Executor: Finished task 1.0 in stage 77.0 (TID 96). 2205 bytes result sent to driver
24/04/16 13:27:08.171 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 96) in 50 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:08.171 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
24/04/16 13:27:08.171 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 77 (mapPartitions at RandomForest.scala:644) finished in 0,125 s
24/04/16 13:27:08.171 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:27:08.171 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:27:08.172 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 78)
24/04/16 13:27:08.172 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:27:08.172 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[294] at map at RandomForest.scala:663), which has no missing parents
24/04/16 13:27:08.173 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 11.6 KiB, free 908.0 MiB)
24/04/16 13:27:08.174 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 908.0 MiB)
24/04/16 13:27:08.174 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.2 KiB, free: 910.7 MiB)
24/04/16 13:27:08.175 dag-scheduler-event-loop INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:08.175 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 78 (MapPartitionsRDD[294] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:08.175 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 78.0 with 2 tasks resource profile 0
24/04/16 13:27:08.175 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 97) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:08.176 Executor task launch worker for task 0.0 in stage 78.0 (TID 97) INFO Executor: Running task 0.0 in stage 78.0 (TID 97)
24/04/16 13:27:08.178 Executor task launch worker for task 0.0 in stage 78.0 (TID 97) INFO ShuffleBlockFetcherIterator: Getting 2 (150.3 KiB) non-empty blocks including 2 (150.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:08.179 Executor task launch worker for task 0.0 in stage 78.0 (TID 97) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:08.192 Executor task launch worker for task 0.0 in stage 78.0 (TID 97) INFO Executor: Finished task 0.0 in stage 78.0 (TID 97). 6943 bytes result sent to driver
24/04/16 13:27:08.192 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 98) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:08.192 Executor task launch worker for task 1.0 in stage 78.0 (TID 98) INFO Executor: Running task 1.0 in stage 78.0 (TID 98)
24/04/16 13:27:08.192 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 97) in 17 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:08.194 Executor task launch worker for task 1.0 in stage 78.0 (TID 98) INFO ShuffleBlockFetcherIterator: Getting 2 (152.4 KiB) non-empty blocks including 2 (152.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:08.194 Executor task launch worker for task 1.0 in stage 78.0 (TID 98) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:08.207 Executor task launch worker for task 1.0 in stage 78.0 (TID 98) INFO Executor: Finished task 1.0 in stage 78.0 (TID 98). 6775 bytes result sent to driver
24/04/16 13:27:08.208 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 98) in 16 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:08.208 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
24/04/16 13:27:08.208 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 78 (collectAsMap at RandomForest.scala:663) finished in 0,036 s
24/04/16 13:27:08.208 dag-scheduler-event-loop INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:08.209 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished
24/04/16 13:27:08.209 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 56 finished: collectAsMap at RandomForest.scala:663, took 0,155720 s
24/04/16 13:27:08.209 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(89) (from destroy at RandomForest.scala:674)
24/04/16 13:27:08.210 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_89_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 22.9 KiB, free: 910.8 MiB)
24/04/16 13:27:08.211 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 26.0 KiB, free 908.0 MiB)
24/04/16 13:27:08.211 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 908.0 MiB)
24/04/16 13:27:08.211 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 16.3 KiB, free: 910.7 MiB)
24/04/16 13:27:08.211 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 92 from broadcast at RandomForest.scala:622
24/04/16 13:27:08.232 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 13:27:08.232 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 295 (mapPartitions at RandomForest.scala:644) as input to shuffle 23
24/04/16 13:27:08.233 dag-scheduler-event-loop INFO DAGScheduler: Got job 57 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 13:27:08.233 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 80 (collectAsMap at RandomForest.scala:663)
24/04/16 13:27:08.233 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)
24/04/16 13:27:08.233 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 79)
24/04/16 13:27:08.233 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[295] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 13:27:08.244 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 609.7 KiB, free 907.4 MiB)
24/04/16 13:27:08.245 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 151.1 KiB, free 907.3 MiB)
24/04/16 13:27:08.245 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 151.1 KiB, free: 910.6 MiB)
24/04/16 13:27:08.245 dag-scheduler-event-loop INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:08.245 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[295] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:08.247 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 79.0 with 2 tasks resource profile 0
24/04/16 13:27:08.250 dispatcher-event-loop-1 WARN TaskSetManager: Stage 79 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:27:08.250 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 99) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:08.250 Executor task launch worker for task 0.0 in stage 79.0 (TID 99) INFO Executor: Running task 0.0 in stage 79.0 (TID 99)
24/04/16 13:27:08.267 Executor task launch worker for task 0.0 in stage 79.0 (TID 99) INFO BlockManager: Found block rdd_282_0 locally
24/04/16 13:27:08.300 Executor task launch worker for task 0.0 in stage 79.0 (TID 99) INFO Executor: Finished task 0.0 in stage 79.0 (TID 99). 2205 bytes result sent to driver
24/04/16 13:27:08.308 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 100) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 13:27:08.309 Executor task launch worker for task 1.0 in stage 79.0 (TID 100) INFO Executor: Running task 1.0 in stage 79.0 (TID 100)
24/04/16 13:27:08.309 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 99) in 62 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:08.325 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_90_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 155.4 KiB, free: 910.7 MiB)
24/04/16 13:27:08.328 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_88_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.3 KiB, free: 910.7 MiB)
24/04/16 13:27:08.333 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_91_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.2 KiB, free: 910.8 MiB)
24/04/16 13:27:08.337 Executor task launch worker for task 1.0 in stage 79.0 (TID 100) INFO BlockManager: Found block rdd_282_1 locally
24/04/16 13:27:08.357 Executor task launch worker for task 1.0 in stage 79.0 (TID 100) INFO Executor: Finished task 1.0 in stage 79.0 (TID 100). 2248 bytes result sent to driver
24/04/16 13:27:08.358 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 100) in 57 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:08.358 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
24/04/16 13:27:08.361 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 79 (mapPartitions at RandomForest.scala:644) finished in 0,127 s
24/04/16 13:27:08.361 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 13:27:08.361 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 13:27:08.361 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 80)
24/04/16 13:27:08.361 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 13:27:08.361 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[297] at map at RandomForest.scala:663), which has no missing parents
24/04/16 13:27:08.362 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 10.4 KiB, free 908.0 MiB)
24/04/16 13:27:08.363 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 908.0 MiB)
24/04/16 13:27:08.363 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 4.9 KiB, free: 910.7 MiB)
24/04/16 13:27:08.364 dag-scheduler-event-loop INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:08.364 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 80 (MapPartitionsRDD[297] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 13:27:08.364 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 80.0 with 2 tasks resource profile 0
24/04/16 13:27:08.365 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 101) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:08.365 Executor task launch worker for task 0.0 in stage 80.0 (TID 101) INFO Executor: Running task 0.0 in stage 80.0 (TID 101)
24/04/16 13:27:08.368 Executor task launch worker for task 0.0 in stage 80.0 (TID 101) INFO ShuffleBlockFetcherIterator: Getting 2 (108.3 KiB) non-empty blocks including 2 (108.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:08.368 Executor task launch worker for task 0.0 in stage 80.0 (TID 101) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:08.377 Executor task launch worker for task 0.0 in stage 80.0 (TID 101) INFO Executor: Finished task 0.0 in stage 80.0 (TID 101). 5552 bytes result sent to driver
24/04/16 13:27:08.378 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 102) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 13:27:08.378 Executor task launch worker for task 1.0 in stage 80.0 (TID 102) INFO Executor: Running task 1.0 in stage 80.0 (TID 102)
24/04/16 13:27:08.378 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 101) in 13 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 13:27:08.380 Executor task launch worker for task 1.0 in stage 80.0 (TID 102) INFO ShuffleBlockFetcherIterator: Getting 2 (112.9 KiB) non-empty blocks including 2 (112.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 13:27:08.380 Executor task launch worker for task 1.0 in stage 80.0 (TID 102) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 13:27:08.389 Executor task launch worker for task 1.0 in stage 80.0 (TID 102) INFO Executor: Finished task 1.0 in stage 80.0 (TID 102). 5539 bytes result sent to driver
24/04/16 13:27:08.390 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 102) in 12 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 13:27:08.391 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
24/04/16 13:27:08.391 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 80 (collectAsMap at RandomForest.scala:663) finished in 0,029 s
24/04/16 13:27:08.391 dag-scheduler-event-loop INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:08.391 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished
24/04/16 13:27:08.391 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 57 finished: collectAsMap at RandomForest.scala:663, took 0,159699 s
24/04/16 13:27:08.392 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(92) (from destroy at RandomForest.scala:674)
24/04/16 13:27:08.392 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 13:27:08.392 nioEventLoopGroup-2-2 INFO RandomForest:   init: 3.91E-5
  total: 1.0358758
  findBestSplits: 1.0282383
  chooseSplits: 1.0272337
24/04/16 13:27:08.393 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_92_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 16.3 KiB, free: 910.8 MiB)
24/04/16 13:27:08.394 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 282 from persistence list
24/04/16 13:27:08.395 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(79) (from destroy at RandomForest.scala:305)
24/04/16 13:27:08.396 block-manager-storage-async-thread-pool-359 INFO BlockManager: Removing RDD 282
24/04/16 13:27:08.397 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_79_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 8.0 KiB, free: 911.1 MiB)
24/04/16 13:27:08.398 nioEventLoopGroup-2-2 INFO Instrumentation: [4e4dd52b] {"numFeatures":545}
24/04/16 13:27:08.399 nioEventLoopGroup-2-2 INFO Instrumentation: [4e4dd52b] training finished
24/04/16 13:27:08.399 nioEventLoopGroup-2-2 INFO Instrumentation: [b8cec8af] training finished
24/04/16 13:27:09.151 nioEventLoopGroup-2-2 INFO Instrumentation: [8388772e] training finished
24/04/16 13:27:10.335 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 13:27:10.335 dag-scheduler-event-loop INFO DAGScheduler: Got job 58 (collect at utils.scala:26) with 1 output partitions
24/04/16 13:27:10.335 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 81 (collect at utils.scala:26)
24/04/16 13:27:10.335 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:27:10.335 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:27:10.335 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[300] at collect at utils.scala:26), which has no missing parents
24/04/16 13:27:10.335 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 62.5 KiB, free 908.4 MiB)
24/04/16 13:27:10.335 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 908.4 MiB)
24/04/16 13:27:10.335 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.1 MiB)
24/04/16 13:27:10.335 dag-scheduler-event-loop INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:10.335 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[300] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 13:27:10.335 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0
24/04/16 13:27:10.335 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 103) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 13:27:10.335 Executor task launch worker for task 0.0 in stage 81.0 (TID 103) INFO Executor: Running task 0.0 in stage 81.0 (TID 103)
24/04/16 13:27:10.382 Executor task launch worker for task 0.0 in stage 81.0 (TID 103) INFO Executor: Finished task 0.0 in stage 81.0 (TID 103). 1473 bytes result sent to driver
24/04/16 13:27:10.382 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_94_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 4.9 KiB, free: 911.1 MiB)
24/04/16 13:27:10.382 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 103) in 47 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 13:27:10.382 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
24/04/16 13:27:10.382 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 81 (collect at utils.scala:26) finished in 0,047 s
24/04/16 13:27:10.382 dag-scheduler-event-loop INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:10.382 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
24/04/16 13:27:10.382 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 58 finished: collect at utils.scala:26, took 0,041795 s
24/04/16 13:27:13.150 nioEventLoopGroup-2-2 INFO Instrumentation: [8c66ba48] training finished
24/04/16 13:27:13.209 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 448.6 KiB, free 908.0 MiB)
24/04/16 13:27:13.209 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 27.7 KiB, free 908.0 MiB)
24/04/16 13:27:13.209 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 27.7 KiB, free: 911.1 MiB)
24/04/16 13:27:13.209 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 96 from broadcast at RandomForestRegressor.scala:238
24/04/16 13:27:13.272 nioEventLoopGroup-2-2 INFO Instrumentation: [6b14d9c2] training finished
24/04/16 13:27:14.255 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 13:27:14.255 dag-scheduler-event-loop INFO DAGScheduler: Got job 59 (collect at utils.scala:26) with 1 output partitions
24/04/16 13:27:14.255 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 82 (collect at utils.scala:26)
24/04/16 13:27:14.255 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:27:14.255 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:27:14.255 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[303] at collect at utils.scala:26), which has no missing parents
24/04/16 13:27:14.255 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 62.6 KiB, free 907.9 MiB)
24/04/16 13:27:14.255 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 907.9 MiB)
24/04/16 13:27:14.255 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.8 KiB, free: 911.1 MiB)
24/04/16 13:27:14.255 dag-scheduler-event-loop INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:14.255 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[303] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 13:27:14.255 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
24/04/16 13:27:14.255 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 104) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 13:27:14.255 Executor task launch worker for task 0.0 in stage 82.0 (TID 104) INFO Executor: Running task 0.0 in stage 82.0 (TID 104)
24/04/16 13:27:14.297 Executor task launch worker for task 0.0 in stage 82.0 (TID 104) INFO Executor: Finished task 0.0 in stage 82.0 (TID 104). 1430 bytes result sent to driver
24/04/16 13:27:14.297 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 104) in 42 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 13:27:14.297 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
24/04/16 13:27:14.298 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 82 (collect at utils.scala:26) finished in 0,043 s
24/04/16 13:27:14.298 dag-scheduler-event-loop INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:14.298 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished
24/04/16 13:27:14.298 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 59 finished: collect at utils.scala:26, took 0,036580 s
24/04/16 13:27:19.122 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 13:27:19.122 dag-scheduler-event-loop INFO DAGScheduler: Got job 60 (collect at utils.scala:26) with 1 output partitions
24/04/16 13:27:19.122 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 83 (collect at utils.scala:26)
24/04/16 13:27:19.122 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 13:27:19.122 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 13:27:19.122 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[311] at collect at utils.scala:26), which has no missing parents
24/04/16 13:27:19.122 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 373.1 KiB, free 907.5 MiB)
24/04/16 13:27:19.122 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 75.3 KiB, free 907.5 MiB)
24/04/16 13:27:19.122 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 75.3 KiB, free: 911.0 MiB)
24/04/16 13:27:19.122 dag-scheduler-event-loop INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1535
24/04/16 13:27:19.122 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[311] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 13:27:19.122 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0
24/04/16 13:27:19.138 dispatcher-event-loop-0 WARN TaskSetManager: Stage 83 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 13:27:19.138 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 105) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 13:27:19.138 Executor task launch worker for task 0.0 in stage 83.0 (TID 105) INFO Executor: Running task 0.0 in stage 83.0 (TID 105)
24/04/16 13:27:19.138 Executor task launch worker for task 0.0 in stage 83.0 (TID 105) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 13:27:19.258 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_97_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.8 KiB, free: 911.0 MiB)
24/04/16 13:27:19.321 Executor task launch worker for task 0.0 in stage 83.0 (TID 105) INFO CodeGenerator: Code generated in 36.8055 ms
24/04/16 13:27:19.368 Executor task launch worker for task 0.0 in stage 83.0 (TID 105) INFO Executor: Finished task 0.0 in stage 83.0 (TID 105). 7111 bytes result sent to driver
24/04/16 13:27:19.368 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 105) in 246 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 13:27:19.368 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
24/04/16 13:27:19.368 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 83 (collect at utils.scala:26) finished in 0,246 s
24/04/16 13:27:19.368 dag-scheduler-event-loop INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 13:27:19.368 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished
24/04/16 13:27:19.368 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 60 finished: collect at utils.scala:26, took 0,245367 s
24/04/16 13:31:05.266 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_87_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 155.4 KiB, free: 911.2 MiB)
24/04/16 13:31:05.266 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_95_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.2 MiB)
24/04/16 13:31:05.282 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_81_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 133.7 KiB, free: 911.3 MiB)
24/04/16 13:31:05.282 block-manager-storage-async-thread-pool-384 INFO BlockManager: Removing RDD 282
24/04/16 13:31:05.297 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_98_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 75.3 KiB, free: 911.4 MiB)
24/04/16 13:31:05.313 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_93_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 151.1 KiB, free: 911.5 MiB)
24/04/16 14:22:10.601 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 14:22:10.603 dag-scheduler-event-loop INFO DAGScheduler: Got job 61 (collect at utils.scala:26) with 1 output partitions
24/04/16 14:22:10.603 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 84 (collect at utils.scala:26)
24/04/16 14:22:10.603 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 14:22:10.603 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 14:22:10.603 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[314] at collect at utils.scala:26), which has no missing parents
24/04/16 14:22:10.607 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 62.4 KiB, free 910.1 MiB)
24/04/16 14:22:10.613 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.1 MiB)
24/04/16 14:22:10.614 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 14:22:10.614 dag-scheduler-event-loop INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1535
24/04/16 14:22:10.619 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[314] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 14:22:10.620 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0
24/04/16 14:22:10.627 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 106) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 14:22:10.629 Executor task launch worker for task 0.0 in stage 84.0 (TID 106) INFO Executor: Running task 0.0 in stage 84.0 (TID 106)
24/04/16 14:22:10.665 Executor task launch worker for task 0.0 in stage 84.0 (TID 106) INFO Executor: Finished task 0.0 in stage 84.0 (TID 106). 1473 bytes result sent to driver
24/04/16 14:22:10.665 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 106) in 44 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 14:22:10.665 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
24/04/16 14:22:10.665 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 84 (collect at utils.scala:26) finished in 0,061 s
24/04/16 14:22:10.665 dag-scheduler-event-loop INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 14:22:10.665 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished
24/04/16 14:22:10.665 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 61 finished: collect at utils.scala:26, took 0,077720 s
24/04/16 14:22:13.945 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 14:22:13.945 dag-scheduler-event-loop INFO DAGScheduler: Got job 62 (collect at utils.scala:26) with 1 output partitions
24/04/16 14:22:13.945 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 85 (collect at utils.scala:26)
24/04/16 14:22:13.945 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 14:22:13.945 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 14:22:13.945 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[317] at collect at utils.scala:26), which has no missing parents
24/04/16 14:22:13.945 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 62.4 KiB, free 910.1 MiB)
24/04/16 14:22:13.961 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.1 MiB)
24/04/16 14:22:13.961 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 14:22:13.961 dag-scheduler-event-loop INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1535
24/04/16 14:22:13.961 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[317] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 14:22:13.961 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0
24/04/16 14:22:13.961 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 107) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 14:22:13.961 Executor task launch worker for task 0.0 in stage 85.0 (TID 107) INFO Executor: Running task 0.0 in stage 85.0 (TID 107)
24/04/16 14:22:13.992 Executor task launch worker for task 0.0 in stage 85.0 (TID 107) INFO Executor: Finished task 0.0 in stage 85.0 (TID 107). 1430 bytes result sent to driver
24/04/16 14:22:13.992 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 107) in 31 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 14:22:13.992 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
24/04/16 14:22:13.992 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 85 (collect at utils.scala:26) finished in 0,047 s
24/04/16 14:22:13.992 dag-scheduler-event-loop INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 14:22:13.992 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
24/04/16 14:22:13.992 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 62 finished: collect at utils.scala:26, took 0,049962 s
24/04/16 14:22:54.030 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_100_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 14:22:54.030 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_99_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 14:24:57.992 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 14:24:57.992 dag-scheduler-event-loop INFO DAGScheduler: Got job 63 (collect at utils.scala:26) with 1 output partitions
24/04/16 14:24:57.992 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 86 (collect at utils.scala:26)
24/04/16 14:24:57.992 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 14:24:57.992 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 14:24:57.992 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[323] at collect at utils.scala:26), which has no missing parents
24/04/16 14:24:57.992 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 123.2 KiB, free 910.1 MiB)
24/04/16 14:24:57.992 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 910.0 MiB)
24/04/16 14:24:57.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 14:24:57.992 dag-scheduler-event-loop INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1535
24/04/16 14:24:57.992 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[323] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 14:24:57.992 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0
24/04/16 14:24:58.007 dispatcher-event-loop-1 WARN TaskSetManager: Stage 86 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 14:24:58.007 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 108) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 14:24:58.007 Executor task launch worker for task 0.0 in stage 86.0 (TID 108) INFO Executor: Running task 0.0 in stage 86.0 (TID 108)
24/04/16 14:24:58.007 Executor task launch worker for task 0.0 in stage 86.0 (TID 108) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 14:24:58.092 Executor task launch worker for task 0.0 in stage 86.0 (TID 108) INFO Executor: Finished task 0.0 in stage 86.0 (TID 108). 245115 bytes result sent to driver
24/04/16 14:24:58.092 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 108) in 100 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 14:24:58.092 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
24/04/16 14:24:58.092 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 86 (collect at utils.scala:26) finished in 0,100 s
24/04/16 14:24:58.092 dag-scheduler-event-loop INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 14:24:58.092 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished
24/04/16 14:24:58.092 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 63 finished: collect at utils.scala:26, took 0,095685 s
24/04/16 14:27:25.847 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_101_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 14:27:25.960 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 14:27:25.960 dag-scheduler-event-loop INFO DAGScheduler: Got job 64 (collect at utils.scala:26) with 1 output partitions
24/04/16 14:27:25.960 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 87 (collect at utils.scala:26)
24/04/16 14:27:25.960 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 14:27:25.960 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 14:27:25.960 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[326] at collect at utils.scala:26), which has no missing parents
24/04/16 14:27:25.960 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 62.4 KiB, free 910.1 MiB)
24/04/16 14:27:25.960 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.1 MiB)
24/04/16 14:27:25.975 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 14:27:25.975 dag-scheduler-event-loop INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1535
24/04/16 14:27:25.975 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[326] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 14:27:25.975 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0
24/04/16 14:27:25.975 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 109) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 14:27:25.975 Executor task launch worker for task 0.0 in stage 87.0 (TID 109) INFO Executor: Running task 0.0 in stage 87.0 (TID 109)
24/04/16 14:27:26.008 Executor task launch worker for task 0.0 in stage 87.0 (TID 109) INFO Executor: Finished task 0.0 in stage 87.0 (TID 109). 1430 bytes result sent to driver
24/04/16 14:27:26.022 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 109) in 47 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 14:27:26.022 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
24/04/16 14:27:26.022 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 87 (collect at utils.scala:26) finished in 0,062 s
24/04/16 14:27:26.022 dag-scheduler-event-loop INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 14:27:26.022 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished
24/04/16 14:27:26.022 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 64 finished: collect at utils.scala:26, took 0,061731 s
24/04/16 14:27:29.236 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 14:27:29.236 dag-scheduler-event-loop INFO DAGScheduler: Got job 65 (collect at utils.scala:26) with 1 output partitions
24/04/16 14:27:29.236 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 88 (collect at utils.scala:26)
24/04/16 14:27:29.236 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 14:27:29.236 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 14:27:29.236 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[329] at collect at utils.scala:26), which has no missing parents
24/04/16 14:27:29.236 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 62.4 KiB, free 910.1 MiB)
24/04/16 14:27:29.252 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.1 MiB)
24/04/16 14:27:29.252 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 14:27:29.252 dag-scheduler-event-loop INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1535
24/04/16 14:27:29.252 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[329] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 14:27:29.252 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0
24/04/16 14:27:29.252 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 110) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 14:27:29.252 Executor task launch worker for task 0.0 in stage 88.0 (TID 110) INFO Executor: Running task 0.0 in stage 88.0 (TID 110)
24/04/16 14:27:29.268 Executor task launch worker for task 0.0 in stage 88.0 (TID 110) INFO Executor: Finished task 0.0 in stage 88.0 (TID 110). 1430 bytes result sent to driver
24/04/16 14:27:29.268 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 110) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 14:27:29.268 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
24/04/16 14:27:29.268 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 88 (collect at utils.scala:26) finished in 0,032 s
24/04/16 14:27:29.268 dag-scheduler-event-loop INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 14:27:29.268 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished
24/04/16 14:27:29.268 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 65 finished: collect at utils.scala:26, took 0,028169 s
24/04/16 14:27:37.973 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 14:27:37.973 dag-scheduler-event-loop INFO DAGScheduler: Got job 66 (collect at utils.scala:26) with 1 output partitions
24/04/16 14:27:37.973 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 89 (collect at utils.scala:26)
24/04/16 14:27:37.973 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 14:27:37.974 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 14:27:37.974 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[335] at collect at utils.scala:26), which has no missing parents
24/04/16 14:27:37.976 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 123.2 KiB, free 909.9 MiB)
24/04/16 14:27:37.977 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 909.9 MiB)
24/04/16 14:27:37.977 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 14:27:37.977 dag-scheduler-event-loop INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1535
24/04/16 14:27:37.977 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[335] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 14:27:37.977 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0
24/04/16 14:27:38.057 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_103_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 14:27:38.062 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_102_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 14:27:38.062 dispatcher-event-loop-0 WARN TaskSetManager: Stage 89 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 14:27:38.063 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 111) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 14:27:38.063 Executor task launch worker for task 0.0 in stage 89.0 (TID 111) INFO Executor: Running task 0.0 in stage 89.0 (TID 111)
24/04/16 14:27:38.071 Executor task launch worker for task 0.0 in stage 89.0 (TID 111) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 14:27:38.190 Executor task launch worker for task 0.0 in stage 89.0 (TID 111) INFO Executor: Finished task 0.0 in stage 89.0 (TID 111). 245115 bytes result sent to driver
24/04/16 14:27:38.192 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 111) in 212 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 14:27:38.192 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
24/04/16 14:27:38.192 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 89 (collect at utils.scala:26) finished in 0,218 s
24/04/16 14:27:38.192 dag-scheduler-event-loop INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 14:27:38.192 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished
24/04/16 14:27:38.193 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 66 finished: collect at utils.scala:26, took 0,219820 s
24/04/16 14:35:09.114 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_104_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 14:45:52.004 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 14:45:52.005 dag-scheduler-event-loop INFO DAGScheduler: Got job 67 (collect at utils.scala:26) with 1 output partitions
24/04/16 14:45:52.005 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 90 (collect at utils.scala:26)
24/04/16 14:45:52.005 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 14:45:52.006 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 14:45:52.007 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[338] at collect at utils.scala:26), which has no missing parents
24/04/16 14:45:52.017 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 62.4 KiB, free 910.1 MiB)
24/04/16 14:45:52.025 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 910.1 MiB)
24/04/16 14:45:52.026 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.6 KiB, free: 911.5 MiB)
24/04/16 14:45:52.026 dag-scheduler-event-loop INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1535
24/04/16 14:45:52.026 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[338] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 14:45:52.026 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0
24/04/16 14:45:52.027 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 112) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 14:45:52.031 Executor task launch worker for task 0.0 in stage 90.0 (TID 112) INFO Executor: Running task 0.0 in stage 90.0 (TID 112)
24/04/16 14:45:52.100 Executor task launch worker for task 0.0 in stage 90.0 (TID 112) INFO Executor: Finished task 0.0 in stage 90.0 (TID 112). 1473 bytes result sent to driver
24/04/16 14:45:52.100 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 112) in 73 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 14:45:52.100 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
24/04/16 14:45:52.100 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 90 (collect at utils.scala:26) finished in 0,091 s
24/04/16 14:45:52.100 dag-scheduler-event-loop INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 14:45:52.100 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished
24/04/16 14:45:52.100 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 67 finished: collect at utils.scala:26, took 0,107038 s
24/04/16 14:45:59.528 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 14:45:59.529 dag-scheduler-event-loop INFO DAGScheduler: Got job 68 (collect at utils.scala:26) with 1 output partitions
24/04/16 14:45:59.530 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 91 (collect at utils.scala:26)
24/04/16 14:45:59.530 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 14:45:59.530 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 14:45:59.530 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[341] at collect at utils.scala:26), which has no missing parents
24/04/16 14:45:59.536 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 62.4 KiB, free 910.1 MiB)
24/04/16 14:45:59.541 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.1 MiB)
24/04/16 14:45:59.542 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 14:45:59.543 dag-scheduler-event-loop INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1535
24/04/16 14:45:59.544 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[341] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 14:45:59.544 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0
24/04/16 14:45:59.546 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 113) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 14:45:59.546 Executor task launch worker for task 0.0 in stage 91.0 (TID 113) INFO Executor: Running task 0.0 in stage 91.0 (TID 113)
24/04/16 14:45:59.577 Executor task launch worker for task 0.0 in stage 91.0 (TID 113) INFO Executor: Finished task 0.0 in stage 91.0 (TID 113). 1430 bytes result sent to driver
24/04/16 14:45:59.577 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 113) in 32 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 14:45:59.578 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
24/04/16 14:45:59.578 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 91 (collect at utils.scala:26) finished in 0,047 s
24/04/16 14:45:59.578 dag-scheduler-event-loop INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 14:45:59.578 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished
24/04/16 14:45:59.578 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 68 finished: collect at utils.scala:26, took 0,049298 s
24/04/16 14:49:14.698 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_106_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 14:49:14.698 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_105_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.6 KiB, free: 911.5 MiB)
24/04/16 14:49:14.731 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 14:49:14.731 dag-scheduler-event-loop INFO DAGScheduler: Got job 69 (collect at utils.scala:26) with 1 output partitions
24/04/16 14:49:14.731 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 92 (collect at utils.scala:26)
24/04/16 14:49:14.731 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 14:49:14.731 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 14:49:14.731 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[347] at collect at utils.scala:26), which has no missing parents
24/04/16 14:49:14.731 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 123.2 KiB, free 910.1 MiB)
24/04/16 14:49:14.731 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 910.0 MiB)
24/04/16 14:49:14.731 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 14:49:14.731 dag-scheduler-event-loop INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1535
24/04/16 14:49:14.731 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[347] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 14:49:14.731 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0
24/04/16 14:49:14.746 dispatcher-event-loop-1 WARN TaskSetManager: Stage 92 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 14:49:14.746 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 114) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 14:49:14.746 Executor task launch worker for task 0.0 in stage 92.0 (TID 114) INFO Executor: Running task 0.0 in stage 92.0 (TID 114)
24/04/16 14:49:14.761 Executor task launch worker for task 0.0 in stage 92.0 (TID 114) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 14:49:14.872 Executor task launch worker for task 0.0 in stage 92.0 (TID 114) INFO Executor: Finished task 0.0 in stage 92.0 (TID 114). 245115 bytes result sent to driver
24/04/16 14:49:14.872 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 114) in 141 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 14:49:14.872 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
24/04/16 14:49:14.872 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 92 (collect at utils.scala:26) finished in 0,141 s
24/04/16 14:49:14.872 dag-scheduler-event-loop INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 14:49:14.872 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
24/04/16 14:49:14.872 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 69 finished: collect at utils.scala:26, took 0,154902 s
24/04/16 14:50:39.027 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 14:50:39.028 dag-scheduler-event-loop INFO DAGScheduler: Got job 70 (collect at utils.scala:26) with 1 output partitions
24/04/16 14:50:39.028 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 93 (collect at utils.scala:26)
24/04/16 14:50:39.028 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 14:50:39.028 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 14:50:39.029 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[353] at collect at utils.scala:26), which has no missing parents
24/04/16 14:50:39.033 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 123.2 KiB, free 909.9 MiB)
24/04/16 14:50:39.035 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 909.9 MiB)
24/04/16 14:50:39.035 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 14:50:39.036 dag-scheduler-event-loop INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1535
24/04/16 14:50:39.036 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[353] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 14:50:39.036 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0
24/04/16 14:50:39.045 dispatcher-event-loop-0 WARN TaskSetManager: Stage 93 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 14:50:39.045 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 115) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 14:50:39.045 Executor task launch worker for task 0.0 in stage 93.0 (TID 115) INFO Executor: Running task 0.0 in stage 93.0 (TID 115)
24/04/16 14:50:39.049 Executor task launch worker for task 0.0 in stage 93.0 (TID 115) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 14:50:39.177 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_107_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 14:50:39.249 Executor task launch worker for task 0.0 in stage 93.0 (TID 115) INFO Executor: Finished task 0.0 in stage 93.0 (TID 115). 245158 bytes result sent to driver
24/04/16 14:50:39.250 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 115) in 213 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 14:50:39.250 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
24/04/16 14:50:39.250 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 93 (collect at utils.scala:26) finished in 0,221 s
24/04/16 14:50:39.251 dag-scheduler-event-loop INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 14:50:39.251 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished
24/04/16 14:50:39.251 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 70 finished: collect at utils.scala:26, took 0,223361 s
24/04/16 14:51:10.728 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 14:51:10.743 dag-scheduler-event-loop INFO DAGScheduler: Got job 71 (collect at utils.scala:26) with 1 output partitions
24/04/16 14:51:10.743 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 94 (collect at utils.scala:26)
24/04/16 14:51:10.743 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 14:51:10.743 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 14:51:10.743 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[359] at collect at utils.scala:26), which has no missing parents
24/04/16 14:51:10.743 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 123.2 KiB, free 909.9 MiB)
24/04/16 14:51:10.743 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 909.9 MiB)
24/04/16 14:51:10.743 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 14:51:10.743 dag-scheduler-event-loop INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1535
24/04/16 14:51:10.743 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[359] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 14:51:10.743 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0
24/04/16 14:51:10.759 dispatcher-event-loop-0 WARN TaskSetManager: Stage 94 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 14:51:10.759 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 116) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 14:51:10.759 Executor task launch worker for task 0.0 in stage 94.0 (TID 116) INFO Executor: Running task 0.0 in stage 94.0 (TID 116)
24/04/16 14:51:10.775 Executor task launch worker for task 0.0 in stage 94.0 (TID 116) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 14:51:10.996 Executor task launch worker for task 0.0 in stage 94.0 (TID 116) INFO Executor: Finished task 0.0 in stage 94.0 (TID 116). 245158 bytes result sent to driver
24/04/16 14:51:10.996 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 116) in 253 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 14:51:10.996 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
24/04/16 14:51:10.996 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 94 (collect at utils.scala:26) finished in 0,253 s
24/04/16 14:51:10.996 dag-scheduler-event-loop INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 14:51:10.996 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished
24/04/16 14:51:10.996 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 71 finished: collect at utils.scala:26, took 0,258461 s
24/04/16 14:51:11.461 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_109_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 14:51:11.464 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_108_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 15:14:59.206 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:14:59.207 dag-scheduler-event-loop INFO DAGScheduler: Got job 72 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:14:59.207 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 95 (collect at utils.scala:26)
24/04/16 15:14:59.207 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:14:59.207 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:14:59.207 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[362] at collect at utils.scala:26), which has no missing parents
24/04/16 15:14:59.211 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 62.4 KiB, free 910.1 MiB)
24/04/16 15:14:59.214 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.1 MiB)
24/04/16 15:14:59.215 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:14:59.215 dag-scheduler-event-loop INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1535
24/04/16 15:14:59.215 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[362] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:14:59.216 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks resource profile 0
24/04/16 15:14:59.217 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 117) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:14:59.218 Executor task launch worker for task 0.0 in stage 95.0 (TID 117) INFO Executor: Running task 0.0 in stage 95.0 (TID 117)
24/04/16 15:14:59.263 Executor task launch worker for task 0.0 in stage 95.0 (TID 117) INFO Executor: Finished task 0.0 in stage 95.0 (TID 117). 1430 bytes result sent to driver
24/04/16 15:14:59.264 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 117) in 48 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:14:59.264 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
24/04/16 15:14:59.264 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 95 (collect at utils.scala:26) finished in 0,056 s
24/04/16 15:14:59.265 dag-scheduler-event-loop INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:14:59.265 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 95: Stage finished
24/04/16 15:14:59.265 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 72 finished: collect at utils.scala:26, took 0,059200 s
24/04/16 15:15:04.056 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:15:04.056 dag-scheduler-event-loop INFO DAGScheduler: Got job 73 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:15:04.056 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 96 (collect at utils.scala:26)
24/04/16 15:15:04.066 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:15:04.066 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:15:04.066 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[365] at collect at utils.scala:26), which has no missing parents
24/04/16 15:15:04.068 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 62.4 KiB, free 910.1 MiB)
24/04/16 15:15:04.072 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.1 MiB)
24/04/16 15:15:04.072 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:15:04.072 dag-scheduler-event-loop INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1535
24/04/16 15:15:04.072 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[365] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:15:04.072 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0
24/04/16 15:15:04.072 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 118) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:15:04.072 Executor task launch worker for task 0.0 in stage 96.0 (TID 118) INFO Executor: Running task 0.0 in stage 96.0 (TID 118)
24/04/16 15:15:04.135 Executor task launch worker for task 0.0 in stage 96.0 (TID 118) INFO Executor: Finished task 0.0 in stage 96.0 (TID 118). 1516 bytes result sent to driver
24/04/16 15:15:04.147 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 118) in 75 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:15:04.147 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
24/04/16 15:15:04.147 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 96 (collect at utils.scala:26) finished in 0,081 s
24/04/16 15:15:04.147 dag-scheduler-event-loop INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:15:04.147 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 96: Stage finished
24/04/16 15:15:04.149 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 73 finished: collect at utils.scala:26, took 0,083647 s
24/04/16 15:15:08.018 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:15:08.019 dag-scheduler-event-loop INFO DAGScheduler: Got job 74 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:15:08.019 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 97 (collect at utils.scala:26)
24/04/16 15:15:08.019 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:15:08.019 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:15:08.020 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[371] at collect at utils.scala:26), which has no missing parents
24/04/16 15:15:08.025 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 123.2 KiB, free 909.9 MiB)
24/04/16 15:15:08.029 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 909.9 MiB)
24/04/16 15:15:08.029 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:15:08.029 dag-scheduler-event-loop INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1535
24/04/16 15:15:08.030 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[371] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:15:08.030 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0
24/04/16 15:15:08.112 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_110_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:15:08.114 dispatcher-event-loop-1 WARN TaskSetManager: Stage 97 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:15:08.114 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 119) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:15:08.114 Executor task launch worker for task 0.0 in stage 97.0 (TID 119) INFO Executor: Running task 0.0 in stage 97.0 (TID 119)
24/04/16 15:15:08.115 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_111_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:15:08.124 Executor task launch worker for task 0.0 in stage 97.0 (TID 119) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 15:15:08.234 Executor task launch worker for task 0.0 in stage 97.0 (TID 119) INFO Executor: Finished task 0.0 in stage 97.0 (TID 119). 245115 bytes result sent to driver
24/04/16 15:15:08.234 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 119) in 204 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:15:08.234 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
24/04/16 15:15:08.234 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 97 (collect at utils.scala:26) finished in 0,214 s
24/04/16 15:15:08.234 dag-scheduler-event-loop INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:15:08.234 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished
24/04/16 15:15:08.234 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 74 finished: collect at utils.scala:26, took 0,226679 s
24/04/16 15:15:12.153 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:15:12.153 dag-scheduler-event-loop INFO DAGScheduler: Got job 75 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:15:12.153 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 98 (collect at utils.scala:26)
24/04/16 15:15:12.153 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:15:12.153 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:15:12.153 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[377] at collect at utils.scala:26), which has no missing parents
24/04/16 15:15:12.162 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 123.2 KiB, free 909.9 MiB)
24/04/16 15:15:12.162 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 909.9 MiB)
24/04/16 15:15:12.162 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 15:15:12.162 dag-scheduler-event-loop INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1535
24/04/16 15:15:12.167 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[377] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:15:12.167 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0
24/04/16 15:15:12.168 dispatcher-event-loop-1 WARN TaskSetManager: Stage 98 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:15:12.168 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 120) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:15:12.168 Executor task launch worker for task 0.0 in stage 98.0 (TID 120) INFO Executor: Running task 0.0 in stage 98.0 (TID 120)
24/04/16 15:15:12.180 Executor task launch worker for task 0.0 in stage 98.0 (TID 120) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 15:15:12.309 Executor task launch worker for task 0.0 in stage 98.0 (TID 120) INFO Executor: Finished task 0.0 in stage 98.0 (TID 120). 137627 bytes result sent to driver
24/04/16 15:15:12.309 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 120) in 142 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:15:12.309 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
24/04/16 15:15:12.312 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 98 (collect at utils.scala:26) finished in 0,159 s
24/04/16 15:15:12.312 dag-scheduler-event-loop INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:15:12.312 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished
24/04/16 15:15:12.312 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 75 finished: collect at utils.scala:26, took 0,151978 s
24/04/16 15:15:12.388 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_112_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:15:12.388 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_113_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 15:23:20.334 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:23:20.334 dag-scheduler-event-loop INFO DAGScheduler: Got job 76 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:23:20.350 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 99 (collect at utils.scala:26)
24/04/16 15:23:20.350 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:23:20.350 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:23:20.350 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[383] at collect at utils.scala:26), which has no missing parents
24/04/16 15:23:20.350 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 123.2 KiB, free 910.1 MiB)
24/04/16 15:23:20.394 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 910.0 MiB)
24/04/16 15:23:20.394 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:23:20.394 dag-scheduler-event-loop INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1535
24/04/16 15:23:20.397 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[383] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:23:20.397 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0
24/04/16 15:23:20.413 dispatcher-event-loop-0 WARN TaskSetManager: Stage 99 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:23:20.413 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 121) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:23:20.428 Executor task launch worker for task 0.0 in stage 99.0 (TID 121) INFO Executor: Running task 0.0 in stage 99.0 (TID 121)
24/04/16 15:23:20.444 Executor task launch worker for task 0.0 in stage 99.0 (TID 121) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 15:23:20.602 Executor task launch worker for task 0.0 in stage 99.0 (TID 121) INFO Executor: Finished task 0.0 in stage 99.0 (TID 121). 245115 bytes result sent to driver
24/04/16 15:23:20.617 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 121) in 216 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:23:20.617 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
24/04/16 15:23:20.617 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 99 (collect at utils.scala:26) finished in 0,267 s
24/04/16 15:23:20.617 dag-scheduler-event-loop INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:23:20.617 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished
24/04/16 15:23:20.617 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 76 finished: collect at utils.scala:26, took 0,272595 s
24/04/16 15:23:24.318 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:23:24.318 dag-scheduler-event-loop INFO DAGScheduler: Got job 77 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:23:24.318 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 100 (collect at utils.scala:26)
24/04/16 15:23:24.318 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:23:24.318 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:23:24.318 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[389] at collect at utils.scala:26), which has no missing parents
24/04/16 15:23:24.322 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 123.2 KiB, free 909.9 MiB)
24/04/16 15:23:24.325 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 909.9 MiB)
24/04/16 15:23:24.326 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:23:24.326 dag-scheduler-event-loop INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1535
24/04/16 15:23:24.326 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[389] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:23:24.326 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
24/04/16 15:23:24.334 dispatcher-event-loop-0 WARN TaskSetManager: Stage 100 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:23:24.334 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 122) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:23:24.334 Executor task launch worker for task 0.0 in stage 100.0 (TID 122) INFO Executor: Running task 0.0 in stage 100.0 (TID 122)
24/04/16 15:23:24.401 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_114_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:23:24.404 Executor task launch worker for task 0.0 in stage 100.0 (TID 122) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 15:23:24.539 Executor task launch worker for task 0.0 in stage 100.0 (TID 122) INFO Executor: Finished task 0.0 in stage 100.0 (TID 122). 245158 bytes result sent to driver
24/04/16 15:23:24.554 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 122) in 228 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:23:24.554 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
24/04/16 15:23:24.554 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 100 (collect at utils.scala:26) finished in 0,236 s
24/04/16 15:23:24.554 dag-scheduler-event-loop INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:23:24.554 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 100: Stage finished
24/04/16 15:23:24.554 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 77 finished: collect at utils.scala:26, took 0,236263 s
24/04/16 15:23:42.526 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:23:42.526 dag-scheduler-event-loop INFO DAGScheduler: Got job 78 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:23:42.526 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 101 (collect at utils.scala:26)
24/04/16 15:23:42.527 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:23:42.527 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:23:42.527 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[395] at collect at utils.scala:26), which has no missing parents
24/04/16 15:23:42.530 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 123.2 KiB, free 909.9 MiB)
24/04/16 15:23:42.531 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 909.9 MiB)
24/04/16 15:23:42.536 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:23:42.537 dag-scheduler-event-loop INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1535
24/04/16 15:23:42.537 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[395] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:23:42.537 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks resource profile 0
24/04/16 15:23:42.547 dispatcher-event-loop-1 WARN TaskSetManager: Stage 101 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:23:42.547 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 123) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:23:42.548 Executor task launch worker for task 0.0 in stage 101.0 (TID 123) INFO Executor: Running task 0.0 in stage 101.0 (TID 123)
24/04/16 15:23:42.556 Executor task launch worker for task 0.0 in stage 101.0 (TID 123) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 15:23:42.663 Executor task launch worker for task 0.0 in stage 101.0 (TID 123) INFO Executor: Finished task 0.0 in stage 101.0 (TID 123). 245115 bytes result sent to driver
24/04/16 15:23:42.664 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 123) in 126 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:23:42.664 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
24/04/16 15:23:42.665 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 101 (collect at utils.scala:26) finished in 0,138 s
24/04/16 15:23:42.665 dag-scheduler-event-loop INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:23:42.665 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 101: Stage finished
24/04/16 15:23:42.665 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 78 finished: collect at utils.scala:26, took 0,139385 s
24/04/16 15:23:42.873 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_116_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:23:42.880 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_115_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:23:45.889 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:23:45.889 dag-scheduler-event-loop INFO DAGScheduler: Got job 79 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:23:45.889 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 102 (collect at utils.scala:26)
24/04/16 15:23:45.889 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:23:45.889 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:23:45.889 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[401] at collect at utils.scala:26), which has no missing parents
24/04/16 15:23:45.897 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 123.2 KiB, free 910.1 MiB)
24/04/16 15:23:45.897 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 910.0 MiB)
24/04/16 15:23:45.897 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 15:23:45.897 dag-scheduler-event-loop INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1535
24/04/16 15:23:45.897 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[401] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:23:45.897 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0
24/04/16 15:23:45.909 dispatcher-event-loop-0 WARN TaskSetManager: Stage 102 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:23:45.910 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 124) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:23:45.910 Executor task launch worker for task 0.0 in stage 102.0 (TID 124) INFO Executor: Running task 0.0 in stage 102.0 (TID 124)
24/04/16 15:23:45.919 Executor task launch worker for task 0.0 in stage 102.0 (TID 124) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 15:23:46.053 Executor task launch worker for task 0.0 in stage 102.0 (TID 124) INFO Executor: Finished task 0.0 in stage 102.0 (TID 124). 245115 bytes result sent to driver
24/04/16 15:23:46.053 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 124) in 156 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:23:46.053 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
24/04/16 15:23:46.053 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 102 (collect at utils.scala:26) finished in 0,158 s
24/04/16 15:23:46.053 dag-scheduler-event-loop INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:23:46.053 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 102: Stage finished
24/04/16 15:23:46.053 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 79 finished: collect at utils.scala:26, took 0,164679 s
24/04/16 15:25:02.573 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:25:02.574 dag-scheduler-event-loop INFO DAGScheduler: Got job 80 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:25:02.574 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 103 (collect at utils.scala:26)
24/04/16 15:25:02.574 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:25:02.574 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:25:02.575 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[407] at collect at utils.scala:26), which has no missing parents
24/04/16 15:25:02.579 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 123.1 KiB, free 909.9 MiB)
24/04/16 15:25:02.580 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 909.9 MiB)
24/04/16 15:25:02.581 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:25:02.581 dag-scheduler-event-loop INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1535
24/04/16 15:25:02.582 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[407] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:25:02.582 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0
24/04/16 15:25:02.591 dispatcher-event-loop-1 WARN TaskSetManager: Stage 103 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:25:02.592 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 125) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:25:02.593 Executor task launch worker for task 0.0 in stage 103.0 (TID 125) INFO Executor: Running task 0.0 in stage 103.0 (TID 125)
24/04/16 15:25:02.603 Executor task launch worker for task 0.0 in stage 103.0 (TID 125) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 15:25:02.675 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_117_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 15:25:02.785 Executor task launch worker for task 0.0 in stage 103.0 (TID 125) INFO Executor: Finished task 0.0 in stage 103.0 (TID 125). 2209 bytes result sent to driver
24/04/16 15:25:02.786 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 125) in 203 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:25:02.786 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
24/04/16 15:25:02.786 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 103 (collect at utils.scala:26) finished in 0,211 s
24/04/16 15:25:02.787 dag-scheduler-event-loop INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:25:02.787 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
24/04/16 15:25:02.787 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 80 finished: collect at utils.scala:26, took 0,213473 s
24/04/16 15:30:41.438 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 22.4648 ms
24/04/16 15:30:41.455 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 411 (collect at utils.scala:26) as input to shuffle 24
24/04/16 15:30:41.455 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 81 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:30:41.457 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 104 (collect at utils.scala:26)
24/04/16 15:30:41.457 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:30:41.457 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:30:41.457 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[411] at collect at utils.scala:26), which has no missing parents
24/04/16 15:30:41.462 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 59.5 KiB, free 910.0 MiB)
24/04/16 15:30:41.462 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 910.0 MiB)
24/04/16 15:30:41.462 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 15.3 KiB, free: 911.5 MiB)
24/04/16 15:30:41.469 dag-scheduler-event-loop INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1535
24/04/16 15:30:41.469 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[411] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:30:41.469 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks resource profile 0
24/04/16 15:30:41.480 dispatcher-event-loop-0 WARN TaskSetManager: Stage 104 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:30:41.480 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 126) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 15:30:41.480 Executor task launch worker for task 0.0 in stage 104.0 (TID 126) INFO Executor: Running task 0.0 in stage 104.0 (TID 126)
24/04/16 15:30:41.549 Executor task launch worker for task 0.0 in stage 104.0 (TID 126) INFO CodeGenerator: Code generated in 4.0755 ms
24/04/16 15:30:41.746 Executor task launch worker for task 0.0 in stage 104.0 (TID 126) INFO Executor: Finished task 0.0 in stage 104.0 (TID 126). 1802 bytes result sent to driver
24/04/16 15:30:41.746 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 126) in 275 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:30:41.756 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
24/04/16 15:30:41.756 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 104 (collect at utils.scala:26) finished in 0,299 s
24/04/16 15:30:41.756 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:30:41.756 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:30:41.756 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 15:30:41.756 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:30:41.772 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:30:41.772 dag-scheduler-event-loop INFO DAGScheduler: Got job 82 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:30:41.772 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 106 (collect at utils.scala:26)
24/04/16 15:30:41.772 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 105)
24/04/16 15:30:41.772 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:30:41.772 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[414] at collect at utils.scala:26), which has no missing parents
24/04/16 15:30:41.772 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 12.1 KiB, free 910.0 MiB)
24/04/16 15:30:41.772 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.0 MiB)
24/04/16 15:30:41.772 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 15:30:41.772 dag-scheduler-event-loop INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1535
24/04/16 15:30:41.788 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[414] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:30:41.788 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
24/04/16 15:30:41.788 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 127) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 15:30:41.788 Executor task launch worker for task 0.0 in stage 106.0 (TID 127) INFO Executor: Running task 0.0 in stage 106.0 (TID 127)
24/04/16 15:30:41.793 Executor task launch worker for task 0.0 in stage 106.0 (TID 127) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:30:41.796 Executor task launch worker for task 0.0 in stage 106.0 (TID 127) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:30:41.800 Executor task launch worker for task 0.0 in stage 106.0 (TID 127) INFO Executor: Finished task 0.0 in stage 106.0 (TID 127). 3909 bytes result sent to driver
24/04/16 15:30:41.800 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 127) in 12 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:30:41.800 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
24/04/16 15:30:41.800 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 106 (collect at utils.scala:26) finished in 0,028 s
24/04/16 15:30:41.800 dag-scheduler-event-loop INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:30:41.800 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished
24/04/16 15:30:41.803 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 82 finished: collect at utils.scala:26, took 0,021311 s
24/04/16 15:30:41.808 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.9681 ms
24/04/16 15:35:09.645 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_119_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 15.3 KiB, free: 911.5 MiB)
24/04/16 15:35:09.647 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_118_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:35:09.649 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_120_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 15:35:38.499 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 418 (collect at utils.scala:26) as input to shuffle 25
24/04/16 15:35:38.499 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 83 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:35:38.500 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 107 (collect at utils.scala:26)
24/04/16 15:35:38.500 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:35:38.500 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:35:38.500 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[418] at collect at utils.scala:26), which has no missing parents
24/04/16 15:35:38.504 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 59.5 KiB, free 910.1 MiB)
24/04/16 15:35:38.508 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 910.1 MiB)
24/04/16 15:35:38.511 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 15.3 KiB, free: 911.5 MiB)
24/04/16 15:35:38.512 dag-scheduler-event-loop INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1535
24/04/16 15:35:38.512 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[418] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:35:38.512 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0
24/04/16 15:35:38.526 dispatcher-event-loop-1 WARN TaskSetManager: Stage 107 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:35:38.526 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 128) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 15:35:38.529 Executor task launch worker for task 0.0 in stage 107.0 (TID 128) INFO Executor: Running task 0.0 in stage 107.0 (TID 128)
24/04/16 15:35:38.821 Executor task launch worker for task 0.0 in stage 107.0 (TID 128) INFO Executor: Finished task 0.0 in stage 107.0 (TID 128). 1845 bytes result sent to driver
24/04/16 15:35:38.822 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 128) in 309 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:35:38.824 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
24/04/16 15:35:38.825 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 107 (collect at utils.scala:26) finished in 0,324 s
24/04/16 15:35:38.825 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:35:38.825 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:35:38.825 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 15:35:38.825 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:35:38.866 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:35:38.867 dag-scheduler-event-loop INFO DAGScheduler: Got job 84 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:35:38.867 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 109 (collect at utils.scala:26)
24/04/16 15:35:38.867 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)
24/04/16 15:35:38.868 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:35:38.868 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[421] at collect at utils.scala:26), which has no missing parents
24/04/16 15:35:38.870 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 12.1 KiB, free 910.1 MiB)
24/04/16 15:35:38.872 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.1 MiB)
24/04/16 15:35:38.873 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 15:35:38.873 dag-scheduler-event-loop INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1535
24/04/16 15:35:38.874 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[421] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:35:38.874 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks resource profile 0
24/04/16 15:35:38.881 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 129) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 15:35:38.881 Executor task launch worker for task 0.0 in stage 109.0 (TID 129) INFO Executor: Running task 0.0 in stage 109.0 (TID 129)
24/04/16 15:35:38.884 Executor task launch worker for task 0.0 in stage 109.0 (TID 129) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:35:38.885 Executor task launch worker for task 0.0 in stage 109.0 (TID 129) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:35:38.889 Executor task launch worker for task 0.0 in stage 109.0 (TID 129) INFO Executor: Finished task 0.0 in stage 109.0 (TID 129). 3909 bytes result sent to driver
24/04/16 15:35:38.890 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 129) in 10 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:35:38.890 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
24/04/16 15:35:38.891 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 109 (collect at utils.scala:26) finished in 0,022 s
24/04/16 15:35:38.892 dag-scheduler-event-loop INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:35:38.892 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 109: Stage finished
24/04/16 15:35:38.892 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 84 finished: collect at utils.scala:26, took 0,025590 s
24/04/16 15:36:13.771 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:36:13.772 dag-scheduler-event-loop INFO DAGScheduler: Got job 85 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:36:13.772 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 110 (collect at utils.scala:26)
24/04/16 15:36:13.772 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:36:13.772 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:36:13.773 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[427] at collect at utils.scala:26), which has no missing parents
24/04/16 15:36:13.777 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 123.2 KiB, free 910.0 MiB)
24/04/16 15:36:13.779 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 910.0 MiB)
24/04/16 15:36:13.780 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:36:13.780 dag-scheduler-event-loop INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1535
24/04/16 15:36:13.780 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[427] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:36:13.781 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0
24/04/16 15:36:13.792 dispatcher-event-loop-1 WARN TaskSetManager: Stage 110 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:36:13.792 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 130) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:36:13.793 Executor task launch worker for task 0.0 in stage 110.0 (TID 130) INFO Executor: Running task 0.0 in stage 110.0 (TID 130)
24/04/16 15:36:13.805 Executor task launch worker for task 0.0 in stage 110.0 (TID 130) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 15:36:13.951 Executor task launch worker for task 0.0 in stage 110.0 (TID 130) INFO Executor: Finished task 0.0 in stage 110.0 (TID 130). 245115 bytes result sent to driver
24/04/16 15:36:13.953 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 130) in 172 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:36:13.953 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
24/04/16 15:36:13.953 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 110 (collect at utils.scala:26) finished in 0,180 s
24/04/16 15:36:13.953 dag-scheduler-event-loop INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:36:13.953 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 110: Stage finished
24/04/16 15:36:13.956 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 85 finished: collect at utils.scala:26, took 0,184227 s
24/04/16 15:36:18.253 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_123_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 15:36:18.256 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_121_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 15.3 KiB, free: 911.5 MiB)
24/04/16 15:36:18.258 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_122_piece0 on DESKTOP-LH06ASP:56331 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 15:36:18.275 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:36:18.276 dag-scheduler-event-loop INFO DAGScheduler: Got job 86 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:36:18.276 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 111 (collect at utils.scala:26)
24/04/16 15:36:18.276 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:36:18.277 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:36:18.277 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[433] at collect at utils.scala:26), which has no missing parents
24/04/16 15:36:18.281 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 123.2 KiB, free 910.1 MiB)
24/04/16 15:36:18.282 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 910.0 MiB)
24/04/16 15:36:18.283 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on DESKTOP-LH06ASP:56331 (size: 31.1 KiB, free: 911.5 MiB)
24/04/16 15:36:18.283 dag-scheduler-event-loop INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1535
24/04/16 15:36:18.283 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[433] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:36:18.283 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks resource profile 0
24/04/16 15:36:18.292 dispatcher-event-loop-0 WARN TaskSetManager: Stage 111 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:36:18.292 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 131) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:36:18.293 Executor task launch worker for task 0.0 in stage 111.0 (TID 131) INFO Executor: Running task 0.0 in stage 111.0 (TID 131)
24/04/16 15:36:18.302 Executor task launch worker for task 0.0 in stage 111.0 (TID 131) INFO BlockManager: Found block rdd_22_0 locally
24/04/16 15:36:18.407 Executor task launch worker for task 0.0 in stage 111.0 (TID 131) INFO Executor: Finished task 0.0 in stage 111.0 (TID 131). 245115 bytes result sent to driver
24/04/16 15:36:18.407 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 131) in 123 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:36:18.408 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
24/04/16 15:36:18.408 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 111 (collect at utils.scala:26) finished in 0,131 s
24/04/16 15:36:18.408 dag-scheduler-event-loop INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:36:18.408 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished
24/04/16 15:36:18.408 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 86 finished: collect at utils.scala:26, took 0,132994 s
24/04/16 15:40:46.945 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/16 15:40:46.948 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/16 15:40:47.017 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/16 15:40:47.057 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/16 15:40:47.404 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/16 15:40:47.405 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/16 15:40:47.414 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/16 15:40:47.419 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/16 15:40:47.429 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-99de32a5-0760-4bde-9742-34745eaef5ef\userFiles-f1433f33-ccea-40d4-b466-34b5fd74bf7b
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-99de32a5-0760-4bde-9742-34745eaef5ef\userFiles-f1433f33-ccea-40d4-b466-34b5fd74bf7b\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/16 15:40:47.438 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/16 15:40:47.438 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/16 15:40:47.439 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-99de32a5-0760-4bde-9742-34745eaef5ef\userFiles-f1433f33-ccea-40d4-b466-34b5fd74bf7b
24/04/16 15:40:47.445 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-99de32a5-0760-4bde-9742-34745eaef5ef\userFiles-f1433f33-ccea-40d4-b466-34b5fd74bf7b
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-99de32a5-0760-4bde-9742-34745eaef5ef\userFiles-f1433f33-ccea-40d4-b466-34b5fd74bf7b\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/16 15:40:47.445 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-99de32a5-0760-4bde-9742-34745eaef5ef
24/04/16 15:40:47.451 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-99de32a5-0760-4bde-9742-34745eaef5ef
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-99de32a5-0760-4bde-9742-34745eaef5ef\userFiles-f1433f33-ccea-40d4-b466-34b5fd74bf7b\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/16 15:40:47.452 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-cf808d62-0c1d-490e-9bb7-8d8c5282558f
24/04/16 15:41:06.072 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/16 15:41:06.553 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/16 15:41:06.643 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/16 15:41:06.767 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/16 15:41:06.955 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/16 15:41:06.956 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/16 15:41:06.956 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/16 15:41:06.957 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/16 15:41:07.006 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/16 15:41:07.037 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/16 15:41:07.039 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/16 15:41:07.195 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/16 15:41:07.197 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/16 15:41:07.198 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/16 15:41:07.200 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/16 15:41:07.201 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/16 15:41:07.457 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 59031.
24/04/16 15:41:07.522 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/16 15:41:07.601 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/16 15:41:07.678 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/16 15:41:07.679 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/16 15:41:07.700 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/16 15:41:07.805 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-31e14630-f206-4e11-b23f-bbf8b26583cf
24/04/16 15:41:07.909 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/16 15:41:07.974 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/16 15:41:07.992 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/16 15:41:08.558 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/16 15:41:08.873 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/16 15:41:08.984 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:59031/jars/sparklyr-3.0-2.12.jar with timestamp 1713278466520
24/04/16 15:41:09.205 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/16 15:41:09.224 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/16 15:41:09.255 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:59031/jars/sparklyr-3.0-2.12.jar with timestamp 1713278466520
24/04/16 15:41:09.385 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:59031 after 60 ms (0 ms spent in bootstraps)
24/04/16 15:41:09.400 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:59031/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-64073a97-8312-4184-bce4-e0d2fa8c5d4e\userFiles-b95c242e-73b2-4cfd-bd2b-b5d06e2b3266\fetchFileTemp262218130190158167.tmp
24/04/16 15:41:09.852 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-64073a97-8312-4184-bce4-e0d2fa8c5d4e/userFiles-b95c242e-73b2-4cfd-bd2b-b5d06e2b3266/sparklyr-3.0-2.12.jar to class loader
24/04/16 15:41:09.881 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59061.
24/04/16 15:41:09.881 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:59061
24/04/16 15:41:09.885 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/16 15:41:09.910 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 59061, None)
24/04/16 15:41:09.920 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:59061 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 59061, None)
24/04/16 15:41:09.928 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 59061, None)
24/04/16 15:41:09.932 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 59061, None)
24/04/16 15:41:10.964 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/16 15:41:10.984 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/16 15:41:22.949 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/16 15:41:23.289 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/16 15:41:24.019 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/16 15:41:24.539 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/16 15:41:24.542 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/16 15:41:24.543 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/16 15:41:24.657 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/16 15:41:25.063 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/16 15:41:25.065 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/16 15:41:29.300 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/16 15:41:32.735 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/16 15:41:32.744 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/16 15:41:32.955 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/16 15:41:32.956 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/16 15:41:33.099 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/16 15:41:33.558 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/16 15:41:33.562 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/16 15:41:33.699 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/16 15:41:34.017 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 15:41:34.022 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 15:41:34.053 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/16 15:41:34.054 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/16 15:41:34.055 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/16 15:41:34.057 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 15:41:34.057 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 15:41:34.059 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 15:41:34.059 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 15:41:34.063 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 15:41:34.064 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 15:41:36.776 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 618.9052 ms
24/04/16 15:41:37.093 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:41:37.159 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,062637 s
24/04/16 15:41:50.904 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/16 15:41:56.232 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 28.5086 ms
24/04/16 15:41:56.493 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:41:56.530 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:41:56.531 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/16 15:41:56.531 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:41:56.533 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:41:56.539 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/16 15:41:56.699 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/16 15:41:57.132 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/16 15:41:57.138 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 15:41:57.149 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/16 15:41:57.176 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:41:57.179 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/16 15:41:57.280 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:41:57.303 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/16 15:41:58.889 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 418.5134 ms
24/04/16 15:41:58.932 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1516 bytes result sent to driver
24/04/16 15:41:58.949 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1689 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:41:58.953 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/16 15:41:58.964 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 2,396 s
24/04/16 15:41:58.969 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:41:58.970 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/16 15:41:58.972 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 2,477928 s
24/04/16 15:41:59.483 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 15:41:59.777 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 636.9199 ms
24/04/16 15:42:09.543 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:42:09.545 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:42:09.545 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/16 15:42:09.545 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:42:09.546 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:42:09.547 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/16 15:42:09.558 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/16 15:42:09.561 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/16 15:42:09.563 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 15:42:09.564 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/16 15:42:09.565 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:42:09.566 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/16 15:42:09.569 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:42:09.570 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/16 15:42:09.675 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1473 bytes result sent to driver
24/04/16 15:42:09.678 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 109 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:42:09.679 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/16 15:42:09.680 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,131 s
24/04/16 15:42:09.680 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:42:09.681 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/16 15:42:09.681 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,137161 s
24/04/16 15:42:09.860 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 15:42:16.318 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 15:42:16.319 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 15:42:16.326 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 15:42:16.328 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 15:42:16.334 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 15:42:16.335 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 15:42:16.604 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 154.7753 ms
24/04/16 15:42:16.703 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.2729 ms
24/04/16 15:42:16.736 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 16.9291 ms
24/04/16 15:43:14.087 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:43:14.089 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:43:14.089 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/16 15:43:14.089 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:43:14.092 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:43:14.093 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26), which has no missing parents
24/04/16 15:43:14.116 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 107.3 KiB, free 912.2 MiB)
24/04/16 15:43:14.118 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.0 KiB, free 912.2 MiB)
24/04/16 15:43:14.119 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 27.0 KiB, free: 912.3 MiB)
24/04/16 15:43:14.120 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/16 15:43:14.121 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:43:14.121 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/16 15:43:14.137 dispatcher-event-loop-0 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:43:14.137 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:43:14.140 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/16 15:43:14.457 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 200.0217 ms
24/04/16 15:43:15.052 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 686.4 KiB, free 911.5 MiB)
24/04/16 15:43:15.057 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on DESKTOP-LH06ASP:59061 (size: 686.4 KiB, free: 911.6 MiB)
24/04/16 15:43:15.069 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 5.0242 ms
24/04/16 15:43:15.220 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 138.0701 ms
24/04/16 15:43:15.261 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_13_0]
24/04/16 15:43:15.262 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2442 bytes result sent to driver
24/04/16 15:43:15.264 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1142 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:43:15.264 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/16 15:43:15.265 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 1,170 s
24/04/16 15:43:15.266 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:43:15.266 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/16 15:43:15.267 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 1,179598 s
24/04/16 15:43:15.627 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 27.0 KiB, free: 911.6 MiB)
24/04/16 15:43:15.861 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 508.1078 ms
24/04/16 15:54:36.462 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:54:36.463 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:54:36.464 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
24/04/16 15:54:36.464 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:54:36.464 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:54:36.465 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at collect at utils.scala:26), which has no missing parents
24/04/16 15:54:36.476 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 56.4 KiB, free 911.6 MiB)
24/04/16 15:54:36.480 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 911.6 MiB)
24/04/16 15:54:36.482 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 13.4 KiB, free: 911.6 MiB)
24/04/16 15:54:36.482 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
24/04/16 15:54:36.483 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:54:36.483 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/16 15:54:36.498 dispatcher-event-loop-1 WARN TaskSetManager: Stage 3 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:54:36.498 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:54:36.500 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/16 15:54:36.578 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 9.6183 ms
24/04/16 15:54:36.582 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1467 bytes result sent to driver
24/04/16 15:54:36.584 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 98 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:54:36.584 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/16 15:54:36.585 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0,118 s
24/04/16 15:54:36.585 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:54:36.585 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/04/16 15:54:36.585 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0,123458 s
24/04/16 15:54:36.605 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.091 ms
24/04/16 15:54:38.392 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 13.4 KiB, free: 911.6 MiB)
24/04/16 15:54:38.553 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:54:38.554 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:54:38.554 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
24/04/16 15:54:38.554 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:54:38.555 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:54:38.556 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:26), which has no missing parents
24/04/16 15:54:38.561 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 62.4 KiB, free 911.6 MiB)
24/04/16 15:54:38.563 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.6 MiB)
24/04/16 15:54:38.565 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 15:54:38.565 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
24/04/16 15:54:38.566 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:54:38.566 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/04/16 15:54:38.568 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:54:38.569 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/04/16 15:54:38.612 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1473 bytes result sent to driver
24/04/16 15:54:38.613 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 45 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:54:38.613 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/04/16 15:54:38.614 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0,058 s
24/04/16 15:54:38.614 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:54:38.614 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/04/16 15:54:38.615 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0,061789 s
24/04/16 15:54:43.489 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:54:43.490 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:54:43.490 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
24/04/16 15:54:43.490 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:54:43.490 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:54:43.491 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at collect at utils.scala:26), which has no missing parents
24/04/16 15:54:43.495 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 62.4 KiB, free 911.5 MiB)
24/04/16 15:54:43.497 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.5 MiB)
24/04/16 15:54:43.502 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 15:54:43.502 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
24/04/16 15:54:43.503 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:54:43.503 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/04/16 15:54:43.504 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:54:43.504 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/04/16 15:54:43.555 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 15:54:43.573 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1473 bytes result sent to driver
24/04/16 15:54:43.575 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 71 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:54:43.575 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/04/16 15:54:43.576 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0,083 s
24/04/16 15:54:43.576 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:54:43.576 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/04/16 15:54:43.576 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0,087494 s
24/04/16 15:54:47.222 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:54:47.223 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:54:47.223 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
24/04/16 15:54:47.223 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:54:47.225 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:54:47.226 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[32] at collect at utils.scala:26), which has no missing parents
24/04/16 15:54:47.231 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 123.2 KiB, free 911.4 MiB)
24/04/16 15:54:47.234 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 911.4 MiB)
24/04/16 15:54:47.235 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 15:54:47.235 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535
24/04/16 15:54:47.236 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[32] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:54:47.236 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
24/04/16 15:54:47.251 dispatcher-event-loop-1 WARN TaskSetManager: Stage 6 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:54:47.251 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:54:47.252 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/04/16 15:54:47.267 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:54:47.433 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 15:54:47.581 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 223.1895 ms
24/04/16 15:54:47.620 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 4.5406 ms
24/04/16 15:54:47.800 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 245201 bytes result sent to driver
24/04/16 15:54:47.801 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 559 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:54:47.802 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/04/16 15:54:47.803 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0,575 s
24/04/16 15:54:47.803 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:54:47.803 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
24/04/16 15:54:47.804 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0,581483 s
24/04/16 15:54:51.527 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 15:54:51.547 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:54:51.549 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:54:51.549 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
24/04/16 15:54:51.549 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:54:51.549 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:54:51.551 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[38] at collect at utils.scala:26), which has no missing parents
24/04/16 15:54:51.555 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 123.2 KiB, free 911.5 MiB)
24/04/16 15:54:51.558 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 911.5 MiB)
24/04/16 15:54:51.560 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 15:54:51.561 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535
24/04/16 15:54:51.561 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:54:51.562 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
24/04/16 15:54:51.574 dispatcher-event-loop-1 WARN TaskSetManager: Stage 7 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:54:51.574 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:54:51.575 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
24/04/16 15:54:51.584 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:54:51.820 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 137627 bytes result sent to driver
24/04/16 15:54:51.821 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 257 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:54:51.821 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/04/16 15:54:51.821 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0,269 s
24/04/16 15:54:51.822 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:54:51.822 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
24/04/16 15:54:51.822 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0,274132 s
24/04/16 15:54:56.591 nioEventLoopGroup-2-2 INFO Instrumentation: [dd10d2f7] training finished
24/04/16 15:54:57.126 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 15:54:57.502 nioEventLoopGroup-2-2 INFO Instrumentation: [5f9dcd21] training finished
24/04/16 15:54:58.330 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 66.8631 ms
24/04/16 15:54:58.414 nioEventLoopGroup-2-2 INFO Instrumentation: [68411158] Stage class: RandomForestRegressor
24/04/16 15:54:58.415 nioEventLoopGroup-2-2 INFO Instrumentation: [68411158] Stage uid: random_forest__f6ae3869_a124_47e3_9c39_0c6ee89d3ba4
24/04/16 15:54:58.415 nioEventLoopGroup-2-2 INFO Instrumentation: [68411158] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
24/04/16 15:54:58.437 nioEventLoopGroup-2-2 INFO Instrumentation: [68411158] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/16 15:54:58.551 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 15:54:58.553 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 15:54:58.553 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (take at DecisionTreeMetadata.scala:119)
24/04/16 15:54:58.553 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:54:58.554 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:54:58.555 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[51] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 15:54:58.567 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 398.0 KiB, free 911.2 MiB)
24/04/16 15:54:58.569 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 82.8 KiB, free 911.2 MiB)
24/04/16 15:54:58.571 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 82.8 KiB, free: 911.5 MiB)
24/04/16 15:54:58.571 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535
24/04/16 15:54:58.572 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[51] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 15:54:58.572 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
24/04/16 15:54:58.581 dispatcher-event-loop-0 WARN TaskSetManager: Stage 8 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:54:58.582 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:54:58.582 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
24/04/16 15:54:58.760 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:54:59.193 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 188.2351 ms
24/04/16 15:54:59.217 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 8.0481 ms
24/04/16 15:54:59.240 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 7.621 ms
24/04/16 15:54:59.257 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 6.4374 ms
24/04/16 15:54:59.263 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1657 bytes result sent to driver
24/04/16 15:54:59.264 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 690 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:54:59.264 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/04/16 15:54:59.265 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (take at DecisionTreeMetadata.scala:119) finished in 0,709 s
24/04/16 15:54:59.265 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:54:59.265 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/04/16 15:54:59.266 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: take at DecisionTreeMetadata.scala:119, took 0,714433 s
24/04/16 15:54:59.288 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 15:54:59.288 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions
24/04/16 15:54:59.289 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 15:54:59.289 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:54:59.289 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:54:59.291 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[50] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 15:54:59.307 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 398.0 KiB, free 910.8 MiB)
24/04/16 15:54:59.311 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 82.9 KiB, free 910.7 MiB)
24/04/16 15:54:59.313 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 82.9 KiB, free: 911.5 MiB)
24/04/16 15:54:59.313 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1535
24/04/16 15:54:59.314 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[50] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))
24/04/16 15:54:59.314 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
24/04/16 15:54:59.326 dispatcher-event-loop-1 WARN TaskSetManager: Stage 9 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:54:59.326 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:54:59.327 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
24/04/16 15:54:59.357 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:54:59.584 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 82.8 KiB, free: 911.5 MiB)
24/04/16 15:54:59.932 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1815 bytes result sent to driver
24/04/16 15:54:59.932 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 616 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:54:59.932 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
24/04/16 15:54:59.933 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,641 s
24/04/16 15:54:59.933 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:54:59.934 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
24/04/16 15:54:59.934 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,646521 s
24/04/16 15:55:00.069 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 15:55:00.108 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 53 (flatMap at RandomForest.scala:1039) as input to shuffle 0
24/04/16 15:55:00.116 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collectAsMap at RandomForest.scala:1054) with 1 output partitions
24/04/16 15:55:00.116 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 11 (collectAsMap at RandomForest.scala:1054)
24/04/16 15:55:00.116 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
24/04/16 15:55:00.118 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
24/04/16 15:55:00.120 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[53] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 15:55:00.142 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 407.1 KiB, free 910.8 MiB)
24/04/16 15:55:00.145 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 86.6 KiB, free 910.7 MiB)
24/04/16 15:55:00.146 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 86.6 KiB, free: 911.5 MiB)
24/04/16 15:55:00.147 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:00.148 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[53] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:00.149 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
24/04/16 15:55:00.158 dispatcher-event-loop-1 WARN TaskSetManager: Stage 10 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:55:00.158 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 15:55:00.159 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
24/04/16 15:55:00.299 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:55:00.811 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 82.9 KiB, free: 911.5 MiB)
24/04/16 15:55:01.221 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2040 bytes result sent to driver
24/04/16 15:55:01.224 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 1075 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:01.224 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
24/04/16 15:55:01.226 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 10 (flatMap at RandomForest.scala:1039) finished in 1,102 s
24/04/16 15:55:01.227 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:55:01.227 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:55:01.229 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 11)
24/04/16 15:55:01.229 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:55:01.232 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[55] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 15:55:01.241 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 11.9 KiB, free 911.1 MiB)
24/04/16 15:55:01.244 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 911.1 MiB)
24/04/16 15:55:01.245 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 4.5 KiB, free: 911.5 MiB)
24/04/16 15:55:01.246 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:01.246 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[55] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:01.246 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
24/04/16 15:55:01.250 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:55:01.250 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
24/04/16 15:55:01.295 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:55:01.297 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
24/04/16 15:55:01.518 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 48769 bytes result sent to driver
24/04/16 15:55:01.526 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 278 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:01.527 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
24/04/16 15:55:01.528 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 11 (collectAsMap at RandomForest.scala:1054) finished in 0,288 s
24/04/16 15:55:01.528 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:01.528 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
24/04/16 15:55:01.529 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collectAsMap at RandomForest.scala:1054, took 1,458605 s
24/04/16 15:55:01.550 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 59.1 KiB, free 911.1 MiB)
24/04/16 15:55:01.555 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 911.1 MiB)
24/04/16 15:55:01.557 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 10.0 KiB, free: 911.5 MiB)
24/04/16 15:55:01.558 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 12 from broadcast at RandomForest.scala:293
24/04/16 15:55:01.577 nioEventLoopGroup-2-2 INFO Instrumentation: [68411158] {"numFeatures":545}
24/04/16 15:55:01.577 nioEventLoopGroup-2-2 INFO Instrumentation: [68411158] {"numClasses":0}
24/04/16 15:55:01.577 nioEventLoopGroup-2-2 INFO Instrumentation: [68411158] {"numExamples":1429}
24/04/16 15:55:01.579 nioEventLoopGroup-2-2 INFO Instrumentation: [68411158] {"sumOfWeights":1429.0}
24/04/16 15:55:01.601 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 16.1 KiB, free 911.0 MiB)
24/04/16 15:55:01.605 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 911.0 MiB)
24/04/16 15:55:01.607 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 10.3 KiB, free: 911.5 MiB)
24/04/16 15:55:01.608 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 13 from broadcast at RandomForest.scala:622
24/04/16 15:55:01.652 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 15:55:01.654 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 58 (mapPartitions at RandomForest.scala:644) as input to shuffle 1
24/04/16 15:55:01.654 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 15:55:01.654 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 13 (collectAsMap at RandomForest.scala:663)
24/04/16 15:55:01.654 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
24/04/16 15:55:01.654 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
24/04/16 15:55:01.657 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 15:55:01.675 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 441.5 KiB, free 910.6 MiB)
24/04/16 15:55:01.679 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 99.1 KiB, free 910.5 MiB)
24/04/16 15:55:01.680 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 99.1 KiB, free: 911.4 MiB)
24/04/16 15:55:01.681 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:01.681 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:01.681 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
24/04/16 15:55:01.694 dispatcher-event-loop-1 WARN TaskSetManager: Stage 12 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:55:01.694 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 15:55:01.695 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
24/04/16 15:55:01.729 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:55:02.234 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 4.5 KiB, free: 911.4 MiB)
24/04/16 15:55:02.237 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 86.6 KiB, free: 911.5 MiB)
24/04/16 15:55:02.358 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO MemoryStore: Block rdd_57_0 stored as values in memory (estimated size 3.2 MiB, free 907.9 MiB)
24/04/16 15:55:02.359 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_57_0 in memory on DESKTOP-LH06ASP:59061 (size: 3.2 MiB, free: 908.4 MiB)
24/04/16 15:55:02.591 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1997 bytes result sent to driver
24/04/16 15:55:02.593 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 911 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:02.593 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
24/04/16 15:55:02.595 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 12 (mapPartitions at RandomForest.scala:644) finished in 0,937 s
24/04/16 15:55:02.596 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:55:02.596 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:55:02.596 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 13)
24/04/16 15:55:02.596 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:55:02.597 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[60] at map at RandomForest.scala:663), which has no missing parents
24/04/16 15:55:02.601 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.4 KiB, free 907.8 MiB)
24/04/16 15:55:02.603 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 907.8 MiB)
24/04/16 15:55:02.604 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 3.8 KiB, free: 908.4 MiB)
24/04/16 15:55:02.605 dag-scheduler-event-loop INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:02.606 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[60] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:02.606 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
24/04/16 15:55:02.608 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:55:02.609 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
24/04/16 15:55:02.616 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO ShuffleBlockFetcherIterator: Getting 1 (194.1 KiB) non-empty blocks including 1 (194.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:55:02.616 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/04/16 15:55:02.892 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 6380 bytes result sent to driver
24/04/16 15:55:02.894 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 286 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:02.895 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
24/04/16 15:55:02.896 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 13 (collectAsMap at RandomForest.scala:663) finished in 0,298 s
24/04/16 15:55:02.897 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:02.897 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
24/04/16 15:55:02.897 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collectAsMap at RandomForest.scala:663, took 1,245381 s
24/04/16 15:55:02.900 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(13) (from destroy at RandomForest.scala:674)
24/04/16 15:55:02.906 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 10.3 KiB, free: 908.4 MiB)
24/04/16 15:55:02.921 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.6 KiB, free 907.8 MiB)
24/04/16 15:55:02.925 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 907.8 MiB)
24/04/16 15:55:02.926 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 20.3 KiB, free: 908.3 MiB)
24/04/16 15:55:02.927 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 16 from broadcast at RandomForest.scala:622
24/04/16 15:55:02.963 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 15:55:02.964 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 61 (mapPartitions at RandomForest.scala:644) as input to shuffle 2
24/04/16 15:55:02.965 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 15:55:02.965 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 15 (collectAsMap at RandomForest.scala:663)
24/04/16 15:55:02.965 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
24/04/16 15:55:02.966 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
24/04/16 15:55:02.967 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[61] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 15:55:02.986 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 462.6 KiB, free 907.4 MiB)
24/04/16 15:55:02.990 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 112.2 KiB, free 907.3 MiB)
24/04/16 15:55:02.991 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 112.2 KiB, free: 908.2 MiB)
24/04/16 15:55:02.992 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:02.993 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[61] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:02.993 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
24/04/16 15:55:03.003 dispatcher-event-loop-1 WARN TaskSetManager: Stage 14 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:55:03.003 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 15:55:03.004 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
24/04/16 15:55:03.038 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 15:55:03.138 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1954 bytes result sent to driver
24/04/16 15:55:03.139 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 145 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:03.139 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
24/04/16 15:55:03.140 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 14 (mapPartitions at RandomForest.scala:644) finished in 0,172 s
24/04/16 15:55:03.140 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:55:03.140 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:55:03.140 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 15)
24/04/16 15:55:03.140 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:55:03.140 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at map at RandomForest.scala:663), which has no missing parents
24/04/16 15:55:03.142 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 11.1 KiB, free 907.2 MiB)
24/04/16 15:55:03.145 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 907.2 MiB)
24/04/16 15:55:03.145 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 5.2 KiB, free: 908.2 MiB)
24/04/16 15:55:03.145 dag-scheduler-event-loop INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:03.146 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:03.146 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
24/04/16 15:55:03.147 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:55:03.148 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
24/04/16 15:55:03.151 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO ShuffleBlockFetcherIterator: Getting 1 (312.6 KiB) non-empty blocks including 1 (312.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:55:03.152 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:55:03.181 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 10497 bytes result sent to driver
24/04/16 15:55:03.183 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 35 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:03.183 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
24/04/16 15:55:03.184 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 15 (collectAsMap at RandomForest.scala:663) finished in 0,041 s
24/04/16 15:55:03.184 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:03.184 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
24/04/16 15:55:03.184 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collectAsMap at RandomForest.scala:663, took 0,221371 s
24/04/16 15:55:03.185 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(16) (from destroy at RandomForest.scala:674)
24/04/16 15:55:03.187 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 20.3 KiB, free: 908.2 MiB)
24/04/16 15:55:03.199 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 54.7 KiB, free 907.2 MiB)
24/04/16 15:55:03.202 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 907.2 MiB)
24/04/16 15:55:03.203 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 33.9 KiB, free: 908.2 MiB)
24/04/16 15:55:03.204 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 19 from broadcast at RandomForest.scala:622
24/04/16 15:55:03.225 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 15:55:03.225 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 64 (mapPartitions at RandomForest.scala:644) as input to shuffle 3
24/04/16 15:55:03.226 dag-scheduler-event-loop INFO DAGScheduler: Got job 14 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 15:55:03.226 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 17 (collectAsMap at RandomForest.scala:663)
24/04/16 15:55:03.226 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
24/04/16 15:55:03.226 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
24/04/16 15:55:03.227 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[64] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 15:55:03.237 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 493.2 KiB, free 906.7 MiB)
24/04/16 15:55:03.240 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 129.7 KiB, free 906.6 MiB)
24/04/16 15:55:03.241 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 129.7 KiB, free: 908.1 MiB)
24/04/16 15:55:03.241 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:03.242 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[64] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:03.242 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
24/04/16 15:55:03.249 dispatcher-event-loop-1 WARN TaskSetManager: Stage 16 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:55:03.249 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 15:55:03.250 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
24/04/16 15:55:03.267 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 15:55:03.337 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1911 bytes result sent to driver
24/04/16 15:55:03.338 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 95 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:03.339 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
24/04/16 15:55:03.339 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 16 (mapPartitions at RandomForest.scala:644) finished in 0,112 s
24/04/16 15:55:03.339 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:55:03.340 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:55:03.340 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 17)
24/04/16 15:55:03.340 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:55:03.340 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[66] at map at RandomForest.scala:663), which has no missing parents
24/04/16 15:55:03.341 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 13.8 KiB, free 906.6 MiB)
24/04/16 15:55:03.343 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 906.6 MiB)
24/04/16 15:55:03.345 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 5.9 KiB, free: 908.1 MiB)
24/04/16 15:55:03.345 dag-scheduler-event-loop INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:03.345 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[66] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:03.346 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
24/04/16 15:55:03.346 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:55:03.347 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
24/04/16 15:55:03.350 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Getting 1 (416.0 KiB) non-empty blocks including 1 (416.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:55:03.350 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:55:03.389 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 16113 bytes result sent to driver
24/04/16 15:55:03.390 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 44 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:03.390 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
24/04/16 15:55:03.390 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 17 (collectAsMap at RandomForest.scala:663) finished in 0,049 s
24/04/16 15:55:03.391 dag-scheduler-event-loop INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:03.391 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
24/04/16 15:55:03.391 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 14 finished: collectAsMap at RandomForest.scala:663, took 0,166503 s
24/04/16 15:55:03.392 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(19) (from destroy at RandomForest.scala:674)
24/04/16 15:55:03.394 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 33.9 KiB, free: 908.1 MiB)
24/04/16 15:55:03.400 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 68.5 KiB, free 906.6 MiB)
24/04/16 15:55:03.402 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 42.3 KiB, free 906.6 MiB)
24/04/16 15:55:03.403 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 42.3 KiB, free: 908.1 MiB)
24/04/16 15:55:03.403 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 22 from broadcast at RandomForest.scala:622
24/04/16 15:55:03.422 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 15:55:03.422 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 67 (mapPartitions at RandomForest.scala:644) as input to shuffle 4
24/04/16 15:55:03.423 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 15:55:03.423 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 19 (collectAsMap at RandomForest.scala:663)
24/04/16 15:55:03.423 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
24/04/16 15:55:03.423 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
24/04/16 15:55:03.424 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[67] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 15:55:03.433 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 523.4 KiB, free 906.0 MiB)
24/04/16 15:55:03.435 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 143.4 KiB, free 905.9 MiB)
24/04/16 15:55:03.436 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 143.4 KiB, free: 907.9 MiB)
24/04/16 15:55:03.436 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:03.436 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[67] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:03.436 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
24/04/16 15:55:03.445 dispatcher-event-loop-1 WARN TaskSetManager: Stage 18 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:55:03.445 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 15:55:03.446 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
24/04/16 15:55:03.464 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 15:55:03.556 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1911 bytes result sent to driver
24/04/16 15:55:03.557 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 120 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:03.557 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
24/04/16 15:55:03.559 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 18 (mapPartitions at RandomForest.scala:644) finished in 0,135 s
24/04/16 15:55:03.559 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:55:03.559 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:55:03.559 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 19)
24/04/16 15:55:03.559 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:55:03.560 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[69] at map at RandomForest.scala:663), which has no missing parents
24/04/16 15:55:03.562 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 15.4 KiB, free 905.9 MiB)
24/04/16 15:55:03.564 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 905.9 MiB)
24/04/16 15:55:03.566 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 6.3 KiB, free: 907.9 MiB)
24/04/16 15:55:03.567 dag-scheduler-event-loop INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:03.571 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[69] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:03.571 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
24/04/16 15:55:03.572 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:55:03.573 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
24/04/16 15:55:03.580 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:55:03.582 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
24/04/16 15:55:03.707 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 5.9 KiB, free: 907.9 MiB)
24/04/16 15:55:03.709 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 19645 bytes result sent to driver
24/04/16 15:55:03.713 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 140 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:03.713 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
24/04/16 15:55:03.714 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 19 (collectAsMap at RandomForest.scala:663) finished in 0,153 s
24/04/16 15:55:03.715 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:03.715 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
24/04/16 15:55:03.716 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collectAsMap at RandomForest.scala:663, took 0,293728 s
24/04/16 15:55:03.717 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(22) (from destroy at RandomForest.scala:674)
24/04/16 15:55:03.721 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 42.3 KiB, free: 908.0 MiB)
24/04/16 15:55:03.722 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 143.4 KiB, free: 908.1 MiB)
24/04/16 15:55:03.738 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 5.2 KiB, free: 908.1 MiB)
24/04/16 15:55:03.751 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 112.2 KiB, free: 908.2 MiB)
24/04/16 15:55:03.753 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 79.1 KiB, free 907.2 MiB)
24/04/16 15:55:03.759 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 129.7 KiB, free: 908.4 MiB)
24/04/16 15:55:03.759 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 49.0 KiB, free 907.7 MiB)
24/04/16 15:55:03.760 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 49.0 KiB, free: 908.3 MiB)
24/04/16 15:55:03.762 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 25 from broadcast at RandomForest.scala:622
24/04/16 15:55:03.767 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 99.1 KiB, free: 908.4 MiB)
24/04/16 15:55:03.778 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 3.8 KiB, free: 908.4 MiB)
24/04/16 15:55:03.803 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 15:55:03.805 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 70 (mapPartitions at RandomForest.scala:644) as input to shuffle 5
24/04/16 15:55:03.806 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 15:55:03.806 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 21 (collectAsMap at RandomForest.scala:663)
24/04/16 15:55:03.806 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
24/04/16 15:55:03.806 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
24/04/16 15:55:03.807 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[70] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 15:55:03.829 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 555.0 KiB, free 907.7 MiB)
24/04/16 15:55:03.834 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 156.1 KiB, free 907.6 MiB)
24/04/16 15:55:03.835 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 156.1 KiB, free: 908.3 MiB)
24/04/16 15:55:03.835 dag-scheduler-event-loop INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:03.836 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[70] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:03.837 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
24/04/16 15:55:03.849 dispatcher-event-loop-1 WARN TaskSetManager: Stage 20 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:55:03.850 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 15:55:03.850 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
24/04/16 15:55:03.887 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 15:55:04.018 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1954 bytes result sent to driver
24/04/16 15:55:04.019 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 181 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:04.019 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
24/04/16 15:55:04.020 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 20 (mapPartitions at RandomForest.scala:644) finished in 0,211 s
24/04/16 15:55:04.020 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:55:04.020 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:55:04.021 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 21)
24/04/16 15:55:04.021 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:55:04.021 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[72] at map at RandomForest.scala:663), which has no missing parents
24/04/16 15:55:04.022 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.7 KiB, free 907.5 MiB)
24/04/16 15:55:04.025 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 907.5 MiB)
24/04/16 15:55:04.026 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 6.5 KiB, free: 908.3 MiB)
24/04/16 15:55:04.026 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:04.027 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[72] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:04.027 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
24/04/16 15:55:04.028 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:55:04.028 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
24/04/16 15:55:04.031 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:55:04.031 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:55:04.079 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 22314 bytes result sent to driver
24/04/16 15:55:04.081 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 53 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:04.082 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
24/04/16 15:55:04.082 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 21 (collectAsMap at RandomForest.scala:663) finished in 0,060 s
24/04/16 15:55:04.082 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:04.083 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
24/04/16 15:55:04.083 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collectAsMap at RandomForest.scala:663, took 0,278989 s
24/04/16 15:55:04.085 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(25) (from destroy at RandomForest.scala:674)
24/04/16 15:55:04.088 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 15:55:04.088 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_25_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 49.0 KiB, free: 908.3 MiB)
24/04/16 15:55:04.089 nioEventLoopGroup-2-2 INFO RandomForest:   init: 0.0063168
  total: 2.5118512
  findBestSplits: 2.4317988
  chooseSplits: 2.4155155
24/04/16 15:55:04.103 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 57 from persistence list
24/04/16 15:55:04.110 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(12) (from destroy at RandomForest.scala:305)
24/04/16 15:55:04.110 block-manager-storage-async-thread-pool-93 INFO BlockManager: Removing RDD 57
24/04/16 15:55:04.112 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 10.0 KiB, free: 911.5 MiB)
24/04/16 15:55:04.133 nioEventLoopGroup-2-2 INFO Instrumentation: [68411158] {"numFeatures":545}
24/04/16 15:55:04.140 nioEventLoopGroup-2-2 INFO Instrumentation: [68411158] training finished
24/04/16 15:55:04.145 nioEventLoopGroup-2-2 INFO Instrumentation: [68eaab4b] training finished
24/04/16 15:55:04.950 nioEventLoopGroup-2-2 INFO Instrumentation: [355c749e] training finished
24/04/16 15:55:06.637 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_26_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 156.1 KiB, free: 911.6 MiB)
24/04/16 15:55:06.647 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 6.5 KiB, free: 911.6 MiB)
24/04/16 15:55:06.652 block-manager-storage-async-thread-pool-15 INFO BlockManager: Removing RDD 57
24/04/16 15:55:06.657 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_24_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 6.3 KiB, free: 911.6 MiB)
24/04/16 15:55:06.702 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:55:06.703 dag-scheduler-event-loop INFO DAGScheduler: Got job 17 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:55:06.703 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:26)
24/04/16 15:55:06.703 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:55:06.703 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:55:06.703 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[75] at collect at utils.scala:26), which has no missing parents
24/04/16 15:55:06.706 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 62.5 KiB, free 911.6 MiB)
24/04/16 15:55:06.708 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.6 MiB)
24/04/16 15:55:06.708 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 15:55:06.709 dag-scheduler-event-loop INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:06.709 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[75] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:06.709 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
24/04/16 15:55:06.710 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:55:06.710 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
24/04/16 15:55:06.778 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO CodeGenerator: Code generated in 26.8621 ms
24/04/16 15:55:06.781 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1430 bytes result sent to driver
24/04/16 15:55:06.782 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 72 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:06.782 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
24/04/16 15:55:06.783 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 22 (collect at utils.scala:26) finished in 0,079 s
24/04/16 15:55:06.783 dag-scheduler-event-loop INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:06.783 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
24/04/16 15:55:06.783 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 17 finished: collect at utils.scala:26, took 0,081322 s
24/04/16 15:55:06.908 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 74.3144 ms
24/04/16 15:55:10.853 nioEventLoopGroup-2-2 INFO Instrumentation: [0e5cd268] training finished
24/04/16 15:55:10.981 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 476.3 KiB, free 911.1 MiB)
24/04/16 15:55:11.008 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 911.1 MiB)
24/04/16 15:55:11.009 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 37.0 KiB, free: 911.6 MiB)
24/04/16 15:55:11.010 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 29 from broadcast at RandomForestRegressor.scala:238
24/04/16 15:55:11.109 nioEventLoopGroup-2-2 INFO Instrumentation: [85934cd3] training finished
24/04/16 15:55:11.267 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_28_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 15:55:13.072 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:55:13.073 dag-scheduler-event-loop INFO DAGScheduler: Got job 18 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:55:13.073 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:26)
24/04/16 15:55:13.073 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:55:13.073 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:55:13.073 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[78] at collect at utils.scala:26), which has no missing parents
24/04/16 15:55:13.077 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 62.6 KiB, free 911.1 MiB)
24/04/16 15:55:13.079 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.1 MiB)
24/04/16 15:55:13.080 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 15:55:13.080 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:13.081 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[78] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:13.081 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
24/04/16 15:55:13.082 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:55:13.082 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
24/04/16 15:55:13.152 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO CodeGenerator: Code generated in 25.4074 ms
24/04/16 15:55:13.156 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1430 bytes result sent to driver
24/04/16 15:55:13.157 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 75 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:13.157 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
24/04/16 15:55:13.158 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 23 (collect at utils.scala:26) finished in 0,084 s
24/04/16 15:55:13.158 dag-scheduler-event-loop INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:13.158 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
24/04/16 15:55:13.158 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 18 finished: collect at utils.scala:26, took 0,086040 s
24/04/16 15:55:13.252 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 57.3293 ms
24/04/16 15:55:20.142 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.2965 ms
24/04/16 15:55:20.187 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:55:20.188 dag-scheduler-event-loop INFO DAGScheduler: Got job 19 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:55:20.188 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:26)
24/04/16 15:55:20.188 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:55:20.188 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:55:20.189 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[86] at collect at utils.scala:26), which has no missing parents
24/04/16 15:55:20.197 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 373.1 KiB, free 910.7 MiB)
24/04/16 15:55:20.199 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 75.3 KiB, free 910.6 MiB)
24/04/16 15:55:20.200 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 75.3 KiB, free: 911.5 MiB)
24/04/16 15:55:20.200 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:20.201 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[86] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:20.201 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
24/04/16 15:55:20.210 dispatcher-event-loop-1 WARN TaskSetManager: Stage 24 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:55:20.211 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:55:20.211 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
24/04/16 15:55:20.228 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:55:20.257 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:55:20.517 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 4805 bytes result sent to driver
24/04/16 15:55:20.518 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 317 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:20.519 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
24/04/16 15:55:20.519 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 24 (collect at utils.scala:26) finished in 0,330 s
24/04/16 15:55:20.519 dag-scheduler-event-loop INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:20.519 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
24/04/16 15:55:20.519 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 19 finished: collect at utils.scala:26, took 0,332239 s
24/04/16 15:55:20.525 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.3061 ms
24/04/16 15:55:21.482 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.678 ms
24/04/16 15:55:21.517 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 93 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
24/04/16 15:55:21.518 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 20 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 15:55:21.519 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0)
24/04/16 15:55:21.519 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:55:21.520 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:55:21.522 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 15:55:21.546 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 129.6 KiB, free 910.6 MiB)
24/04/16 15:55:21.548 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 910.5 MiB)
24/04/16 15:55:21.549 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 33.8 KiB, free: 911.5 MiB)
24/04/16 15:55:21.550 dag-scheduler-event-loop INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:21.551 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:21.551 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
24/04/16 15:55:21.567 dispatcher-event-loop-0 WARN TaskSetManager: Stage 25 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:55:21.568 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 15:55:21.569 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
24/04/16 15:55:21.613 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:55:21.782 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 75.3 KiB, free: 911.6 MiB)
24/04/16 15:55:21.935 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO CodeGenerator: Code generated in 10.6437 ms
24/04/16 15:55:22.060 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2481 bytes result sent to driver
24/04/16 15:55:22.063 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 509 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:22.063 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
24/04/16 15:55:22.065 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0,542 s
24/04/16 15:55:22.065 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:55:22.065 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:55:22.066 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 15:55:22.066 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:55:22.124 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.2173 ms
24/04/16 15:55:22.146 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 15:55:22.148 dag-scheduler-event-loop INFO DAGScheduler: Got job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 15:55:22.148 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 27 (count at NativeMethodAccessorImpl.java:0)
24/04/16 15:55:22.148 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
24/04/16 15:55:22.148 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:55:22.148 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[96] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 15:55:22.150 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 12.1 KiB, free 911.0 MiB)
24/04/16 15:55:22.152 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 911.0 MiB)
24/04/16 15:55:22.152 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 5.8 KiB, free: 911.6 MiB)
24/04/16 15:55:22.153 dag-scheduler-event-loop INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:22.153 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[96] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:22.153 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
24/04/16 15:55:22.155 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 26) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 15:55:22.155 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO Executor: Running task 0.0 in stage 27.0 (TID 26)
24/04/16 15:55:22.162 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:55:22.162 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:55:22.171 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO Executor: Finished task 0.0 in stage 27.0 (TID 26). 3909 bytes result sent to driver
24/04/16 15:55:22.172 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 26) in 18 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:22.172 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
24/04/16 15:55:22.173 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0,022 s
24/04/16 15:55:22.173 dag-scheduler-event-loop INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:22.173 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
24/04/16 15:55:22.173 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 21 finished: count at NativeMethodAccessorImpl.java:0, took 0,025725 s
24/04/16 15:55:22.629 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.1041 ms
24/04/16 15:55:22.640 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 103 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
24/04/16 15:55:22.640 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 15:55:22.640 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0)
24/04/16 15:55:22.640 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:55:22.641 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:55:22.641 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[103] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 15:55:22.646 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 129.6 KiB, free 910.8 MiB)
24/04/16 15:55:22.647 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 33.8 KiB, free 910.8 MiB)
24/04/16 15:55:22.648 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 33.8 KiB, free: 911.5 MiB)
24/04/16 15:55:22.648 dag-scheduler-event-loop INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:22.648 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[103] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:22.648 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
24/04/16 15:55:22.655 dispatcher-event-loop-0 WARN TaskSetManager: Stage 28 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:55:22.656 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 27) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 15:55:22.657 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO Executor: Running task 0.0 in stage 28.0 (TID 27)
24/04/16 15:55:22.665 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:55:22.843 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO Executor: Finished task 0.0 in stage 28.0 (TID 27). 2395 bytes result sent to driver
24/04/16 15:55:22.844 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 27) in 194 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:22.844 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
24/04/16 15:55:22.845 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 0,204 s
24/04/16 15:55:22.845 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:55:22.845 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:55:22.846 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 15:55:22.846 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:55:22.881 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 15:55:22.882 dag-scheduler-event-loop INFO DAGScheduler: Got job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 15:55:22.882 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:0)
24/04/16 15:55:22.882 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
24/04/16 15:55:22.882 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:55:22.883 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 15:55:22.885 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 12.1 KiB, free 910.8 MiB)
24/04/16 15:55:22.887 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.8 MiB)
24/04/16 15:55:22.888 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 15:55:22.888 dag-scheduler-event-loop INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:22.889 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:22.889 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
24/04/16 15:55:22.891 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 28) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 15:55:22.891 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO Executor: Running task 0.0 in stage 30.0 (TID 28)
24/04/16 15:55:22.894 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:55:22.895 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:55:22.899 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO Executor: Finished task 0.0 in stage 30.0 (TID 28). 3909 bytes result sent to driver
24/04/16 15:55:22.900 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 28) in 10 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:22.900 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
24/04/16 15:55:22.901 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:0) finished in 0,017 s
24/04/16 15:55:22.902 dag-scheduler-event-loop INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:22.902 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
24/04/16 15:55:22.903 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 23 finished: count at NativeMethodAccessorImpl.java:0, took 0,021442 s
24/04/16 15:55:24.614 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_33_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 15:55:24.617 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_35_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 15:55:24.621 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_34_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 33.8 KiB, free: 911.6 MiB)
24/04/16 15:55:24.808 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:55:24.810 dag-scheduler-event-loop INFO DAGScheduler: Got job 24 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:55:24.810 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:26)
24/04/16 15:55:24.810 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:55:24.810 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:55:24.810 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[109] at collect at utils.scala:26), which has no missing parents
24/04/16 15:55:24.813 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 62.4 KiB, free 910.9 MiB)
24/04/16 15:55:24.815 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.9 MiB)
24/04/16 15:55:24.815 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:55:24.815 dag-scheduler-event-loop INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:24.816 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[109] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:24.816 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
24/04/16 15:55:24.816 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 29) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:55:24.817 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO Executor: Running task 0.0 in stage 31.0 (TID 29)
24/04/16 15:55:24.852 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO Executor: Finished task 0.0 in stage 31.0 (TID 29). 1430 bytes result sent to driver
24/04/16 15:55:24.853 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 29) in 37 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:24.853 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
24/04/16 15:55:24.853 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 31 (collect at utils.scala:26) finished in 0,042 s
24/04/16 15:55:24.854 dag-scheduler-event-loop INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:24.854 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
24/04/16 15:55:24.854 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 24 finished: collect at utils.scala:26, took 0,045260 s
24/04/16 15:55:29.983 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:55:29.983 dag-scheduler-event-loop INFO DAGScheduler: Got job 25 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:55:29.983 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:26)
24/04/16 15:55:29.983 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:55:29.984 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:55:29.984 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[112] at collect at utils.scala:26), which has no missing parents
24/04/16 15:55:29.987 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 62.4 KiB, free 910.8 MiB)
24/04/16 15:55:29.988 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.8 MiB)
24/04/16 15:55:29.988 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:55:29.989 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:29.989 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[112] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:29.989 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
24/04/16 15:55:29.990 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 30) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:55:29.990 Executor task launch worker for task 0.0 in stage 32.0 (TID 30) INFO Executor: Running task 0.0 in stage 32.0 (TID 30)
24/04/16 15:55:30.031 Executor task launch worker for task 0.0 in stage 32.0 (TID 30) INFO Executor: Finished task 0.0 in stage 32.0 (TID 30). 1430 bytes result sent to driver
24/04/16 15:55:30.032 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 30) in 42 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:30.032 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
24/04/16 15:55:30.033 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 32 (collect at utils.scala:26) finished in 0,049 s
24/04/16 15:55:30.033 dag-scheduler-event-loop INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:30.033 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
24/04/16 15:55:30.033 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 25 finished: collect at utils.scala:26, took 0,050379 s
24/04/16 15:55:54.281 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:55:54.288 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 15:55:55.639 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:55:55.640 dag-scheduler-event-loop INFO DAGScheduler: Got job 26 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:55:55.640 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:26)
24/04/16 15:55:55.640 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:55:55.640 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:55:55.640 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[115] at collect at utils.scala:26), which has no missing parents
24/04/16 15:55:55.642 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 62.4 KiB, free 910.9 MiB)
24/04/16 15:55:55.644 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.9 MiB)
24/04/16 15:55:55.644 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:55:55.644 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1535
24/04/16 15:55:55.644 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[115] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:55:55.644 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
24/04/16 15:55:55.645 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 31) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:55:55.646 Executor task launch worker for task 0.0 in stage 33.0 (TID 31) INFO Executor: Running task 0.0 in stage 33.0 (TID 31)
24/04/16 15:55:55.676 Executor task launch worker for task 0.0 in stage 33.0 (TID 31) INFO Executor: Finished task 0.0 in stage 33.0 (TID 31). 1430 bytes result sent to driver
24/04/16 15:55:55.678 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 31) in 33 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:55:55.678 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
24/04/16 15:55:55.678 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 33 (collect at utils.scala:26) finished in 0,038 s
24/04/16 15:55:55.679 dag-scheduler-event-loop INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:55:55.679 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
24/04/16 15:55:55.679 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 26 finished: collect at utils.scala:26, took 0,039703 s
24/04/16 15:56:01.166 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:56:01.166 dag-scheduler-event-loop INFO DAGScheduler: Got job 27 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:56:01.166 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:26)
24/04/16 15:56:01.166 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:56:01.166 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:56:01.166 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[118] at collect at utils.scala:26), which has no missing parents
24/04/16 15:56:01.169 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 62.4 KiB, free 910.8 MiB)
24/04/16 15:56:01.170 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.8 MiB)
24/04/16 15:56:01.171 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:56:01.171 dag-scheduler-event-loop INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:01.171 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[118] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:56:01.171 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
24/04/16 15:56:01.172 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 32) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:56:01.172 Executor task launch worker for task 0.0 in stage 34.0 (TID 32) INFO Executor: Running task 0.0 in stage 34.0 (TID 32)
24/04/16 15:56:01.210 Executor task launch worker for task 0.0 in stage 34.0 (TID 32) INFO Executor: Finished task 0.0 in stage 34.0 (TID 32). 1430 bytes result sent to driver
24/04/16 15:56:01.210 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 32) in 38 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:56:01.211 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
24/04/16 15:56:01.211 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 34 (collect at utils.scala:26) finished in 0,044 s
24/04/16 15:56:01.211 dag-scheduler-event-loop INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:01.211 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
24/04/16 15:56:01.212 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 27 finished: collect at utils.scala:26, took 0,045369 s
24/04/16 15:56:08.967 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_38_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:56:08.971 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_39_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 15:56:10.977 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:56:10.978 dag-scheduler-event-loop INFO DAGScheduler: Got job 28 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:56:10.978 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:26)
24/04/16 15:56:10.978 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:56:10.978 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:56:10.979 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[121] at collect at utils.scala:26), which has no missing parents
24/04/16 15:56:10.982 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 62.4 KiB, free 910.9 MiB)
24/04/16 15:56:10.983 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.9 MiB)
24/04/16 15:56:10.983 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 15:56:10.984 dag-scheduler-event-loop INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:10.984 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[121] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:56:10.984 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
24/04/16 15:56:10.985 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 33) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:56:10.986 Executor task launch worker for task 0.0 in stage 35.0 (TID 33) INFO Executor: Running task 0.0 in stage 35.0 (TID 33)
24/04/16 15:56:11.036 Executor task launch worker for task 0.0 in stage 35.0 (TID 33) INFO Executor: Finished task 0.0 in stage 35.0 (TID 33). 1430 bytes result sent to driver
24/04/16 15:56:11.037 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 33) in 52 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:56:11.037 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
24/04/16 15:56:11.037 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 35 (collect at utils.scala:26) finished in 0,057 s
24/04/16 15:56:11.037 dag-scheduler-event-loop INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:11.037 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
24/04/16 15:56:11.038 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 28 finished: collect at utils.scala:26, took 0,059952 s
24/04/16 15:56:14.716 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_40_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 15:56:14.865 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.2841 ms
24/04/16 15:56:14.892 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 15.0295 ms
24/04/16 15:56:14.927 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.7422 ms
24/04/16 15:56:14.979 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 136 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8
24/04/16 15:56:14.980 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 29 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/16 15:56:14.980 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 36 (count at NativeMethodAccessorImpl.java:0)
24/04/16 15:56:14.980 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:56:14.981 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:56:14.982 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[136] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 15:56:15.016 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 226.3 KiB, free 910.7 MiB)
24/04/16 15:56:15.018 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 57.1 KiB, free 910.7 MiB)
24/04/16 15:56:15.019 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 57.1 KiB, free: 911.5 MiB)
24/04/16 15:56:15.019 dag-scheduler-event-loop INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:15.020 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[136] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:15.020 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 36.0 with 2 tasks resource profile 0
24/04/16 15:56:15.036 dispatcher-event-loop-0 WARN TaskSetManager: Stage 36 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:56:15.036 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 34) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 15:56:15.037 Executor task launch worker for task 0.0 in stage 36.0 (TID 34) INFO Executor: Running task 0.0 in stage 36.0 (TID 34)
24/04/16 15:56:15.055 Executor task launch worker for task 0.0 in stage 36.0 (TID 34) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:15.217 Executor task launch worker for task 0.0 in stage 36.0 (TID 34) INFO Executor: Finished task 0.0 in stage 36.0 (TID 34). 3011 bytes result sent to driver
24/04/16 15:56:15.227 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 35) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 15:56:15.228 Executor task launch worker for task 1.0 in stage 36.0 (TID 35) INFO Executor: Running task 1.0 in stage 36.0 (TID 35)
24/04/16 15:56:15.228 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 34) in 207 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:15.239 Executor task launch worker for task 1.0 in stage 36.0 (TID 35) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:15.398 Executor task launch worker for task 1.0 in stage 36.0 (TID 35) INFO Executor: Finished task 1.0 in stage 36.0 (TID 35). 3054 bytes result sent to driver
24/04/16 15:56:15.398 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 35) in 179 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:15.398 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
24/04/16 15:56:15.399 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 36 (count at NativeMethodAccessorImpl.java:0) finished in 0,416 s
24/04/16 15:56:15.399 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:56:15.399 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:56:15.399 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 15:56:15.400 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:56:15.428 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.7338 ms
24/04/16 15:56:15.438 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 15:56:15.439 dag-scheduler-event-loop INFO DAGScheduler: Got job 30 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 15:56:15.439 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 38 (count at NativeMethodAccessorImpl.java:0)
24/04/16 15:56:15.439 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
24/04/16 15:56:15.439 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:56:15.439 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[139] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 15:56:15.441 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 12.1 KiB, free 910.7 MiB)
24/04/16 15:56:15.443 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.7 MiB)
24/04/16 15:56:15.444 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 15:56:15.444 dag-scheduler-event-loop INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:15.444 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[139] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 15:56:15.444 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
24/04/16 15:56:15.445 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 36) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 15:56:15.446 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO Executor: Running task 0.0 in stage 38.0 (TID 36)
24/04/16 15:56:15.448 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:15.448 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:15.454 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO Executor: Finished task 0.0 in stage 38.0 (TID 36). 3909 bytes result sent to driver
24/04/16 15:56:15.455 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 36) in 10 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:56:15.455 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
24/04/16 15:56:15.456 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 38 (count at NativeMethodAccessorImpl.java:0) finished in 0,016 s
24/04/16 15:56:15.456 dag-scheduler-event-loop INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:15.456 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
24/04/16 15:56:15.456 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 30 finished: count at NativeMethodAccessorImpl.java:0, took 0,019025 s
24/04/16 15:56:15.902 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_41_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 57.1 KiB, free: 911.6 MiB)
24/04/16 15:56:15.906 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_42_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 5.8 KiB, free: 911.6 MiB)
24/04/16 15:56:16.190 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.0829 ms
24/04/16 15:56:16.213 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.9052 ms
24/04/16 15:56:16.235 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 154 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9
24/04/16 15:56:16.235 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 31 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/16 15:56:16.236 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0)
24/04/16 15:56:16.236 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:56:16.236 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:56:16.236 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[154] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 15:56:16.246 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 226.3 KiB, free 910.7 MiB)
24/04/16 15:56:16.248 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 57.2 KiB, free 910.7 MiB)
24/04/16 15:56:16.248 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 57.2 KiB, free: 911.5 MiB)
24/04/16 15:56:16.249 dag-scheduler-event-loop INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:16.249 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[154] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:16.249 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 39.0 with 2 tasks resource profile 0
24/04/16 15:56:16.261 dispatcher-event-loop-0 WARN TaskSetManager: Stage 39 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:56:16.261 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 37) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 15:56:16.262 Executor task launch worker for task 0.0 in stage 39.0 (TID 37) INFO Executor: Running task 0.0 in stage 39.0 (TID 37)
24/04/16 15:56:16.274 Executor task launch worker for task 0.0 in stage 39.0 (TID 37) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:16.432 Executor task launch worker for task 0.0 in stage 39.0 (TID 37) INFO Executor: Finished task 0.0 in stage 39.0 (TID 37). 3011 bytes result sent to driver
24/04/16 15:56:16.441 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 38) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 15:56:16.442 Executor task launch worker for task 1.0 in stage 39.0 (TID 38) INFO Executor: Running task 1.0 in stage 39.0 (TID 38)
24/04/16 15:56:16.442 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 37) in 191 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:16.456 Executor task launch worker for task 1.0 in stage 39.0 (TID 38) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:16.647 Executor task launch worker for task 1.0 in stage 39.0 (TID 38) INFO Executor: Finished task 1.0 in stage 39.0 (TID 38). 3054 bytes result sent to driver
24/04/16 15:56:16.648 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 38) in 215 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:16.648 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
24/04/16 15:56:16.648 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0) finished in 0,411 s
24/04/16 15:56:16.649 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:56:16.649 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:56:16.649 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 15:56:16.649 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:56:16.682 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 15:56:16.683 dag-scheduler-event-loop INFO DAGScheduler: Got job 32 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 15:56:16.683 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 41 (count at NativeMethodAccessorImpl.java:0)
24/04/16 15:56:16.683 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
24/04/16 15:56:16.683 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:56:16.684 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[157] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 15:56:16.685 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 12.1 KiB, free 910.7 MiB)
24/04/16 15:56:16.687 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.7 MiB)
24/04/16 15:56:16.687 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 15:56:16.687 dag-scheduler-event-loop INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:16.688 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[157] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 15:56:16.688 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
24/04/16 15:56:16.689 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 39) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 15:56:16.689 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO Executor: Running task 0.0 in stage 41.0 (TID 39)
24/04/16 15:56:16.691 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:16.692 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:16.695 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO Executor: Finished task 0.0 in stage 41.0 (TID 39). 3909 bytes result sent to driver
24/04/16 15:56:16.695 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 39) in 7 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:56:16.695 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
24/04/16 15:56:16.696 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 41 (count at NativeMethodAccessorImpl.java:0) finished in 0,012 s
24/04/16 15:56:16.696 dag-scheduler-event-loop INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:16.696 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
24/04/16 15:56:16.696 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 32 finished: count at NativeMethodAccessorImpl.java:0, took 0,013980 s
24/04/16 15:56:17.283 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_43_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 57.2 KiB, free: 911.6 MiB)
24/04/16 15:56:17.288 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_44_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 5.8 KiB, free: 911.6 MiB)
24/04/16 15:56:17.291 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_32_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 33.8 KiB, free: 911.6 MiB)
24/04/16 15:56:18.091 nioEventLoopGroup-2-2 INFO Instrumentation: [b3aa5376] training finished
24/04/16 15:56:18.561 nioEventLoopGroup-2-2 INFO Instrumentation: [fc64797b] training finished
24/04/16 15:56:19.199 nioEventLoopGroup-2-2 INFO Instrumentation: [b2f4472e] Stage class: RandomForestRegressor
24/04/16 15:56:19.199 nioEventLoopGroup-2-2 INFO Instrumentation: [b2f4472e] Stage uid: random_forest__69058222_8c20_4de5_93a8_7e8519ed37f9
24/04/16 15:56:19.200 nioEventLoopGroup-2-2 INFO Instrumentation: [b2f4472e] training: numPartitions=2 storageLevel=StorageLevel(1 replicas)
24/04/16 15:56:19.201 nioEventLoopGroup-2-2 INFO Instrumentation: [b2f4472e] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/16 15:56:19.285 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 15:56:19.287 dag-scheduler-event-loop INFO DAGScheduler: Got job 33 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 15:56:19.288 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 42 (take at DecisionTreeMetadata.scala:119)
24/04/16 15:56:19.288 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:56:19.288 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:56:19.289 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[180] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 15:56:19.309 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 521.9 KiB, free 910.6 MiB)
24/04/16 15:56:19.313 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 117.6 KiB, free 910.5 MiB)
24/04/16 15:56:19.314 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 117.6 KiB, free: 911.5 MiB)
24/04/16 15:56:19.315 dag-scheduler-event-loop INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:19.315 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[180] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 15:56:19.316 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
24/04/16 15:56:19.328 dispatcher-event-loop-0 WARN TaskSetManager: Stage 42 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:56:19.328 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 40) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 15:56:19.329 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO Executor: Running task 0.0 in stage 42.0 (TID 40)
24/04/16 15:56:19.370 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:19.460 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO CodeGenerator: Code generated in 3.98 ms
24/04/16 15:56:19.622 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO CodeGenerator: Code generated in 103.7979 ms
24/04/16 15:56:19.645 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO Executor: Finished task 0.0 in stage 42.0 (TID 40). 1993 bytes result sent to driver
24/04/16 15:56:19.646 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 40) in 329 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:56:19.647 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
24/04/16 15:56:19.647 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 42 (take at DecisionTreeMetadata.scala:119) finished in 0,356 s
24/04/16 15:56:19.647 dag-scheduler-event-loop INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:19.647 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
24/04/16 15:56:19.648 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 33 finished: take at DecisionTreeMetadata.scala:119, took 0,361503 s
24/04/16 15:56:19.655 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 15:56:19.656 dag-scheduler-event-loop INFO DAGScheduler: Got job 34 (aggregate at DecisionTreeMetadata.scala:125) with 2 output partitions
24/04/16 15:56:19.656 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 43 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 15:56:19.656 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:56:19.657 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:56:19.657 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[179] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 15:56:19.673 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 522.0 KiB, free 910.0 MiB)
24/04/16 15:56:19.676 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 117.6 KiB, free 909.9 MiB)
24/04/16 15:56:19.676 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 117.6 KiB, free: 911.4 MiB)
24/04/16 15:56:19.676 dag-scheduler-event-loop INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:19.677 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 43 (MapPartitionsRDD[179] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:19.677 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks resource profile 0
24/04/16 15:56:19.688 dispatcher-event-loop-1 WARN TaskSetManager: Stage 43 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:56:19.688 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 41) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 15:56:19.689 Executor task launch worker for task 0.0 in stage 43.0 (TID 41) INFO Executor: Running task 0.0 in stage 43.0 (TID 41)
24/04/16 15:56:19.714 Executor task launch worker for task 0.0 in stage 43.0 (TID 41) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:19.940 Executor task launch worker for task 0.0 in stage 43.0 (TID 41) INFO Executor: Finished task 0.0 in stage 43.0 (TID 41). 2108 bytes result sent to driver
24/04/16 15:56:19.951 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 42) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 15:56:19.952 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO Executor: Running task 1.0 in stage 43.0 (TID 42)
24/04/16 15:56:19.952 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 41) in 274 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:19.976 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:20.094 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO CodeGenerator: Code generated in 4.0141 ms
24/04/16 15:56:20.152 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO Executor: Finished task 1.0 in stage 43.0 (TID 42). 2151 bytes result sent to driver
24/04/16 15:56:20.153 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 42) in 213 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:20.153 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
24/04/16 15:56:20.154 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 43 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,496 s
24/04/16 15:56:20.154 dag-scheduler-event-loop INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:20.154 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
24/04/16 15:56:20.154 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 34 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,499237 s
24/04/16 15:56:20.181 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 15:56:20.182 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 182 (flatMap at RandomForest.scala:1039) as input to shuffle 10
24/04/16 15:56:20.182 dag-scheduler-event-loop INFO DAGScheduler: Got job 35 (collectAsMap at RandomForest.scala:1054) with 2 output partitions
24/04/16 15:56:20.182 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 45 (collectAsMap at RandomForest.scala:1054)
24/04/16 15:56:20.182 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
24/04/16 15:56:20.182 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
24/04/16 15:56:20.183 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[182] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 15:56:20.196 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 531.0 KiB, free 909.4 MiB)
24/04/16 15:56:20.198 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 121.4 KiB, free 909.2 MiB)
24/04/16 15:56:20.199 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 121.4 KiB, free: 911.2 MiB)
24/04/16 15:56:20.199 dag-scheduler-event-loop INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:20.200 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[182] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:20.200 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 44.0 with 2 tasks resource profile 0
24/04/16 15:56:20.209 dispatcher-event-loop-1 WARN TaskSetManager: Stage 44 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:56:20.209 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 43) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:20.209 Executor task launch worker for task 0.0 in stage 44.0 (TID 43) INFO Executor: Running task 0.0 in stage 44.0 (TID 43)
24/04/16 15:56:20.238 Executor task launch worker for task 0.0 in stage 44.0 (TID 43) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:20.490 Executor task launch worker for task 0.0 in stage 44.0 (TID 43) INFO Executor: Finished task 0.0 in stage 44.0 (TID 43). 2291 bytes result sent to driver
24/04/16 15:56:20.498 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 44) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:20.499 Executor task launch worker for task 1.0 in stage 44.0 (TID 44) INFO Executor: Running task 1.0 in stage 44.0 (TID 44)
24/04/16 15:56:20.499 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 43) in 298 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:20.514 Executor task launch worker for task 1.0 in stage 44.0 (TID 44) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:20.751 Executor task launch worker for task 1.0 in stage 44.0 (TID 44) INFO Executor: Finished task 1.0 in stage 44.0 (TID 44). 2291 bytes result sent to driver
24/04/16 15:56:20.752 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 44) in 261 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:20.752 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
24/04/16 15:56:20.752 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 44 (flatMap at RandomForest.scala:1039) finished in 0,568 s
24/04/16 15:56:20.753 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:56:20.753 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:56:20.753 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 45)
24/04/16 15:56:20.753 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:56:20.753 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[184] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 15:56:20.754 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 11.9 KiB, free 909.2 MiB)
24/04/16 15:56:20.755 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 909.2 MiB)
24/04/16 15:56:20.756 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 4.5 KiB, free: 911.2 MiB)
24/04/16 15:56:20.756 dag-scheduler-event-loop INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:20.757 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[184] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:20.757 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks resource profile 0
24/04/16 15:56:20.758 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 45) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:20.758 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO Executor: Running task 0.0 in stage 45.0 (TID 45)
24/04/16 15:56:20.760 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO ShuffleBlockFetcherIterator: Getting 2 (31.9 KiB) non-empty blocks including 2 (31.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:20.760 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:20.790 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO Executor: Finished task 0.0 in stage 45.0 (TID 45). 21389 bytes result sent to driver
24/04/16 15:56:20.790 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 46) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:20.791 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO Executor: Running task 1.0 in stage 45.0 (TID 46)
24/04/16 15:56:20.791 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 45) in 34 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:20.794 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO ShuffleBlockFetcherIterator: Getting 2 (30.1 KiB) non-empty blocks including 2 (30.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:20.794 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:20.820 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO Executor: Finished task 1.0 in stage 45.0 (TID 46). 20486 bytes result sent to driver
24/04/16 15:56:20.821 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 46) in 31 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:20.821 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
24/04/16 15:56:20.822 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 45 (collectAsMap at RandomForest.scala:1054) finished in 0,068 s
24/04/16 15:56:20.822 dag-scheduler-event-loop INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:20.822 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
24/04/16 15:56:20.822 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 35 finished: collectAsMap at RandomForest.scala:1054, took 0,640841 s
24/04/16 15:56:20.827 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 47.5 KiB, free 909.2 MiB)
24/04/16 15:56:20.828 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 909.2 MiB)
24/04/16 15:56:20.829 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 7.9 KiB, free: 911.2 MiB)
24/04/16 15:56:20.829 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 49 from broadcast at RandomForest.scala:293
24/04/16 15:56:20.831 nioEventLoopGroup-2-2 INFO Instrumentation: [b2f4472e] {"numFeatures":545}
24/04/16 15:56:20.831 nioEventLoopGroup-2-2 INFO Instrumentation: [b2f4472e] {"numClasses":0}
24/04/16 15:56:20.831 nioEventLoopGroup-2-2 INFO Instrumentation: [b2f4472e] {"numExamples":151}
24/04/16 15:56:20.831 nioEventLoopGroup-2-2 INFO Instrumentation: [b2f4472e] {"sumOfWeights":151.0}
24/04/16 15:56:20.834 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 16.1 KiB, free 909.2 MiB)
24/04/16 15:56:20.835 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 909.1 MiB)
24/04/16 15:56:20.836 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 10.3 KiB, free: 911.2 MiB)
24/04/16 15:56:20.836 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 50 from broadcast at RandomForest.scala:622
24/04/16 15:56:20.856 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 15:56:20.857 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 187 (mapPartitions at RandomForest.scala:644) as input to shuffle 11
24/04/16 15:56:20.857 dag-scheduler-event-loop INFO DAGScheduler: Got job 36 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 15:56:20.857 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 47 (collectAsMap at RandomForest.scala:663)
24/04/16 15:56:20.858 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
24/04/16 15:56:20.858 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
24/04/16 15:56:20.858 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[187] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 15:56:20.872 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 561.8 KiB, free 908.6 MiB)
24/04/16 15:56:20.874 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 133.5 KiB, free 908.5 MiB)
24/04/16 15:56:20.874 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 133.5 KiB, free: 911.1 MiB)
24/04/16 15:56:20.875 dag-scheduler-event-loop INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:20.875 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[187] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:20.875 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 46.0 with 2 tasks resource profile 0
24/04/16 15:56:20.883 dispatcher-event-loop-1 WARN TaskSetManager: Stage 46 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:56:20.884 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 47) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:20.884 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO Executor: Running task 0.0 in stage 46.0 (TID 47)
24/04/16 15:56:20.905 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:21.084 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO MemoryStore: Block rdd_186_0 stored as values in memory (estimated size 180.1 KiB, free 908.3 MiB)
24/04/16 15:56:21.085 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_186_0 in memory on DESKTOP-LH06ASP:59061 (size: 180.1 KiB, free: 910.9 MiB)
24/04/16 15:56:21.106 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO Executor: Finished task 0.0 in stage 46.0 (TID 47). 2291 bytes result sent to driver
24/04/16 15:56:21.114 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 48) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:21.115 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO Executor: Running task 1.0 in stage 46.0 (TID 48)
24/04/16 15:56:21.115 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 47) in 239 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:21.133 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:21.307 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO MemoryStore: Block rdd_186_1 stored as values in memory (estimated size 168.5 KiB, free 908.1 MiB)
24/04/16 15:56:21.308 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_186_1 in memory on DESKTOP-LH06ASP:59061 (size: 168.5 KiB, free: 910.8 MiB)
24/04/16 15:56:21.324 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO Executor: Finished task 1.0 in stage 46.0 (TID 48). 2291 bytes result sent to driver
24/04/16 15:56:21.325 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 48) in 218 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:21.325 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
24/04/16 15:56:21.326 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 46 (mapPartitions at RandomForest.scala:644) finished in 0,467 s
24/04/16 15:56:21.326 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:56:21.326 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:56:21.326 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 47)
24/04/16 15:56:21.326 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:56:21.326 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[189] at map at RandomForest.scala:663), which has no missing parents
24/04/16 15:56:21.328 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 7.4 KiB, free 908.1 MiB)
24/04/16 15:56:21.329 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 908.1 MiB)
24/04/16 15:56:21.329 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 3.8 KiB, free: 910.7 MiB)
24/04/16 15:56:21.329 dag-scheduler-event-loop INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:21.330 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[189] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:21.330 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 47.0 with 2 tasks resource profile 0
24/04/16 15:56:21.331 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:21.331 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO Executor: Running task 0.0 in stage 47.0 (TID 49)
24/04/16 15:56:21.333 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO ShuffleBlockFetcherIterator: Getting 2 (92.9 KiB) non-empty blocks including 2 (92.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:21.334 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:21.344 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO Executor: Finished task 0.0 in stage 47.0 (TID 49). 4292 bytes result sent to driver
24/04/16 15:56:21.346 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 50) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:21.347 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO Executor: Running task 1.0 in stage 47.0 (TID 50)
24/04/16 15:56:21.347 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:21.348 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO ShuffleBlockFetcherIterator: Getting 2 (92.9 KiB) non-empty blocks including 2 (92.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:21.348 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:21.358 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO Executor: Finished task 1.0 in stage 47.0 (TID 50). 4296 bytes result sent to driver
24/04/16 15:56:21.359 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 50) in 13 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:21.359 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
24/04/16 15:56:21.359 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 47 (collectAsMap at RandomForest.scala:663) finished in 0,031 s
24/04/16 15:56:21.360 dag-scheduler-event-loop INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:21.360 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
24/04/16 15:56:21.360 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 36 finished: collectAsMap at RandomForest.scala:663, took 0,504226 s
24/04/16 15:56:21.360 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(50) (from destroy at RandomForest.scala:674)
24/04/16 15:56:21.363 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_50_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 10.3 KiB, free: 910.8 MiB)
24/04/16 15:56:21.364 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 32.6 KiB, free 908.1 MiB)
24/04/16 15:56:21.366 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 908.1 MiB)
24/04/16 15:56:21.366 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 20.3 KiB, free: 910.7 MiB)
24/04/16 15:56:21.366 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 53 from broadcast at RandomForest.scala:622
24/04/16 15:56:21.386 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 15:56:21.387 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 190 (mapPartitions at RandomForest.scala:644) as input to shuffle 12
24/04/16 15:56:21.387 dag-scheduler-event-loop INFO DAGScheduler: Got job 37 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 15:56:21.388 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 49 (collectAsMap at RandomForest.scala:663)
24/04/16 15:56:21.388 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
24/04/16 15:56:21.388 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 48)
24/04/16 15:56:21.388 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[190] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 15:56:21.404 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 582.8 KiB, free 907.5 MiB)
24/04/16 15:56:21.407 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 146.3 KiB, free 907.4 MiB)
24/04/16 15:56:21.407 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 146.3 KiB, free: 910.6 MiB)
24/04/16 15:56:21.408 dag-scheduler-event-loop INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:21.409 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[190] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:21.409 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 48.0 with 2 tasks resource profile 0
24/04/16 15:56:21.424 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_51_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 133.5 KiB, free: 910.7 MiB)
24/04/16 15:56:21.430 dispatcher-event-loop-1 WARN TaskSetManager: Stage 48 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:56:21.430 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 51) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:21.430 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_48_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 4.5 KiB, free: 910.7 MiB)
24/04/16 15:56:21.431 Executor task launch worker for task 0.0 in stage 48.0 (TID 51) INFO Executor: Running task 0.0 in stage 48.0 (TID 51)
24/04/16 15:56:21.436 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_52_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 3.8 KiB, free: 910.7 MiB)
24/04/16 15:56:21.461 Executor task launch worker for task 0.0 in stage 48.0 (TID 51) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 15:56:21.493 Executor task launch worker for task 0.0 in stage 48.0 (TID 51) INFO Executor: Finished task 0.0 in stage 48.0 (TID 51). 2248 bytes result sent to driver
24/04/16 15:56:21.502 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 52) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:21.503 Executor task launch worker for task 1.0 in stage 48.0 (TID 52) INFO Executor: Running task 1.0 in stage 48.0 (TID 52)
24/04/16 15:56:21.503 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 51) in 93 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:21.530 Executor task launch worker for task 1.0 in stage 48.0 (TID 52) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 15:56:21.562 Executor task launch worker for task 1.0 in stage 48.0 (TID 52) INFO Executor: Finished task 1.0 in stage 48.0 (TID 52). 2291 bytes result sent to driver
24/04/16 15:56:21.564 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 52) in 69 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:21.564 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
24/04/16 15:56:21.565 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 48 (mapPartitions at RandomForest.scala:644) finished in 0,175 s
24/04/16 15:56:21.565 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:56:21.565 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:56:21.565 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 49)
24/04/16 15:56:21.565 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:56:21.565 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[192] at map at RandomForest.scala:663), which has no missing parents
24/04/16 15:56:21.568 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 11.1 KiB, free 908.1 MiB)
24/04/16 15:56:21.569 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 908.1 MiB)
24/04/16 15:56:21.569 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 5.1 KiB, free: 910.7 MiB)
24/04/16 15:56:21.570 dag-scheduler-event-loop INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:21.571 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 49 (MapPartitionsRDD[192] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:21.571 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 49.0 with 2 tasks resource profile 0
24/04/16 15:56:21.572 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 53) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:21.572 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO Executor: Running task 0.0 in stage 49.0 (TID 53)
24/04/16 15:56:21.576 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO ShuffleBlockFetcherIterator: Getting 2 (172.8 KiB) non-empty blocks including 2 (172.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:21.577 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:21.601 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO Executor: Finished task 0.0 in stage 49.0 (TID 53). 6376 bytes result sent to driver
24/04/16 15:56:21.602 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 54) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:21.603 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO Executor: Running task 1.0 in stage 49.0 (TID 54)
24/04/16 15:56:21.603 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 53) in 31 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:21.606 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO ShuffleBlockFetcherIterator: Getting 2 (138.5 KiB) non-empty blocks including 2 (138.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:21.606 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:21.627 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO Executor: Finished task 1.0 in stage 49.0 (TID 54). 6337 bytes result sent to driver
24/04/16 15:56:21.628 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 54) in 26 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:21.629 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
24/04/16 15:56:21.629 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 49 (collectAsMap at RandomForest.scala:663) finished in 0,062 s
24/04/16 15:56:21.630 dag-scheduler-event-loop INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:21.630 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
24/04/16 15:56:21.630 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 37 finished: collectAsMap at RandomForest.scala:663, took 0,243444 s
24/04/16 15:56:21.632 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(53) (from destroy at RandomForest.scala:674)
24/04/16 15:56:21.635 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_53_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 20.3 KiB, free: 910.7 MiB)
24/04/16 15:56:21.640 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 41.7 KiB, free 908.1 MiB)
24/04/16 15:56:21.642 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 25.9 KiB, free 908.1 MiB)
24/04/16 15:56:21.643 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 25.9 KiB, free: 910.7 MiB)
24/04/16 15:56:21.644 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 56 from broadcast at RandomForest.scala:622
24/04/16 15:56:21.676 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 15:56:21.678 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 193 (mapPartitions at RandomForest.scala:644) as input to shuffle 13
24/04/16 15:56:21.678 dag-scheduler-event-loop INFO DAGScheduler: Got job 38 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 15:56:21.678 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 51 (collectAsMap at RandomForest.scala:663)
24/04/16 15:56:21.678 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
24/04/16 15:56:21.679 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
24/04/16 15:56:21.679 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[193] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 15:56:21.700 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 601.4 KiB, free 907.5 MiB)
24/04/16 15:56:21.703 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 154.9 KiB, free 907.3 MiB)
24/04/16 15:56:21.704 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 154.9 KiB, free: 910.6 MiB)
24/04/16 15:56:21.704 dag-scheduler-event-loop INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:21.705 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[193] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:21.705 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 50.0 with 2 tasks resource profile 0
24/04/16 15:56:21.715 dispatcher-event-loop-1 WARN TaskSetManager: Stage 50 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:56:21.716 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 55) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:21.716 Executor task launch worker for task 0.0 in stage 50.0 (TID 55) INFO Executor: Running task 0.0 in stage 50.0 (TID 55)
24/04/16 15:56:21.744 Executor task launch worker for task 0.0 in stage 50.0 (TID 55) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 15:56:21.789 Executor task launch worker for task 0.0 in stage 50.0 (TID 55) INFO Executor: Finished task 0.0 in stage 50.0 (TID 55). 2291 bytes result sent to driver
24/04/16 15:56:21.799 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 56) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:21.800 Executor task launch worker for task 1.0 in stage 50.0 (TID 56) INFO Executor: Running task 1.0 in stage 50.0 (TID 56)
24/04/16 15:56:21.800 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 55) in 94 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:21.825 Executor task launch worker for task 1.0 in stage 50.0 (TID 56) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 15:56:21.874 Executor task launch worker for task 1.0 in stage 50.0 (TID 56) INFO Executor: Finished task 1.0 in stage 50.0 (TID 56). 2291 bytes result sent to driver
24/04/16 15:56:21.875 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 56) in 85 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:21.876 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
24/04/16 15:56:21.876 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 50 (mapPartitions at RandomForest.scala:644) finished in 0,196 s
24/04/16 15:56:21.877 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:56:21.877 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:56:21.877 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 51)
24/04/16 15:56:21.877 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:56:21.878 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[195] at map at RandomForest.scala:663), which has no missing parents
24/04/16 15:56:21.880 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 12.2 KiB, free 907.3 MiB)
24/04/16 15:56:21.881 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 907.3 MiB)
24/04/16 15:56:21.882 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 5.3 KiB, free: 910.6 MiB)
24/04/16 15:56:21.883 dag-scheduler-event-loop INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:21.883 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (MapPartitionsRDD[195] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:21.884 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks resource profile 0
24/04/16 15:56:21.884 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 57) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:21.885 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO Executor: Running task 0.0 in stage 51.0 (TID 57)
24/04/16 15:56:21.890 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO ShuffleBlockFetcherIterator: Getting 2 (181.9 KiB) non-empty blocks including 2 (181.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:21.890 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:21.921 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO Executor: Finished task 0.0 in stage 51.0 (TID 57). 7623 bytes result sent to driver
24/04/16 15:56:21.922 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 58) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:21.923 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO Executor: Running task 1.0 in stage 51.0 (TID 58)
24/04/16 15:56:21.924 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 57) in 39 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:21.928 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO ShuffleBlockFetcherIterator: Getting 2 (174.4 KiB) non-empty blocks including 2 (174.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:21.929 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/04/16 15:56:21.959 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO Executor: Finished task 1.0 in stage 51.0 (TID 58). 7455 bytes result sent to driver
24/04/16 15:56:21.960 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 58) in 38 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:21.960 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
24/04/16 15:56:21.961 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 51 (collectAsMap at RandomForest.scala:663) finished in 0,082 s
24/04/16 15:56:21.961 dag-scheduler-event-loop INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:21.961 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
24/04/16 15:56:21.961 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 38 finished: collectAsMap at RandomForest.scala:663, took 0,285508 s
24/04/16 15:56:21.964 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at RandomForest.scala:674)
24/04/16 15:56:21.967 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_56_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 25.9 KiB, free: 910.6 MiB)
24/04/16 15:56:21.971 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 40.0 KiB, free 907.3 MiB)
24/04/16 15:56:21.973 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 907.3 MiB)
24/04/16 15:56:21.974 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 25.0 KiB, free: 910.6 MiB)
24/04/16 15:56:21.975 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 59 from broadcast at RandomForest.scala:622
24/04/16 15:56:22.009 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 15:56:22.011 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 196 (mapPartitions at RandomForest.scala:644) as input to shuffle 14
24/04/16 15:56:22.011 dag-scheduler-event-loop INFO DAGScheduler: Got job 39 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 15:56:22.011 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 53 (collectAsMap at RandomForest.scala:663)
24/04/16 15:56:22.011 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
24/04/16 15:56:22.011 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
24/04/16 15:56:22.011 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[196] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 15:56:22.028 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 613.5 KiB, free 906.7 MiB)
24/04/16 15:56:22.030 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 157.8 KiB, free 906.5 MiB)
24/04/16 15:56:22.031 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 157.8 KiB, free: 910.4 MiB)
24/04/16 15:56:22.031 dag-scheduler-event-loop INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:22.034 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[196] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:22.035 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 52.0 with 2 tasks resource profile 0
24/04/16 15:56:22.043 dispatcher-event-loop-1 WARN TaskSetManager: Stage 52 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:56:22.043 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 59) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:22.044 Executor task launch worker for task 0.0 in stage 52.0 (TID 59) INFO Executor: Running task 0.0 in stage 52.0 (TID 59)
24/04/16 15:56:22.061 Executor task launch worker for task 0.0 in stage 52.0 (TID 59) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 15:56:22.090 Executor task launch worker for task 0.0 in stage 52.0 (TID 59) INFO Executor: Finished task 0.0 in stage 52.0 (TID 59). 2248 bytes result sent to driver
24/04/16 15:56:22.099 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 60) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:22.099 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 59) in 64 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:22.099 Executor task launch worker for task 1.0 in stage 52.0 (TID 60) INFO Executor: Running task 1.0 in stage 52.0 (TID 60)
24/04/16 15:56:22.119 Executor task launch worker for task 1.0 in stage 52.0 (TID 60) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 15:56:22.148 Executor task launch worker for task 1.0 in stage 52.0 (TID 60) INFO Executor: Finished task 1.0 in stage 52.0 (TID 60). 2248 bytes result sent to driver
24/04/16 15:56:22.149 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 60) in 58 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:22.149 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
24/04/16 15:56:22.150 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 52 (mapPartitions at RandomForest.scala:644) finished in 0,138 s
24/04/16 15:56:22.150 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:56:22.150 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:56:22.150 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 53)
24/04/16 15:56:22.150 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:56:22.150 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[198] at map at RandomForest.scala:663), which has no missing parents
24/04/16 15:56:22.152 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 12.0 KiB, free 906.5 MiB)
24/04/16 15:56:22.152 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 906.5 MiB)
24/04/16 15:56:22.153 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 5.3 KiB, free: 910.4 MiB)
24/04/16 15:56:22.153 dag-scheduler-event-loop INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:22.153 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[198] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:22.154 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 53.0 with 2 tasks resource profile 0
24/04/16 15:56:22.154 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 61) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:22.154 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO Executor: Running task 0.0 in stage 53.0 (TID 61)
24/04/16 15:56:22.157 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO ShuffleBlockFetcherIterator: Getting 2 (158.6 KiB) non-empty blocks including 2 (158.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:22.157 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:22.175 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO Executor: Finished task 0.0 in stage 53.0 (TID 61). 7403 bytes result sent to driver
24/04/16 15:56:22.176 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 62) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:22.176 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO Executor: Running task 1.0 in stage 53.0 (TID 62)
24/04/16 15:56:22.176 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 61) in 22 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:22.178 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO ShuffleBlockFetcherIterator: Getting 2 (164.6 KiB) non-empty blocks including 2 (164.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:22.178 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:22.196 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO Executor: Finished task 1.0 in stage 53.0 (TID 62). 7209 bytes result sent to driver
24/04/16 15:56:22.196 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 62) in 20 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:22.197 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
24/04/16 15:56:22.197 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 53 (collectAsMap at RandomForest.scala:663) finished in 0,046 s
24/04/16 15:56:22.197 dag-scheduler-event-loop INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:22.197 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
24/04/16 15:56:22.197 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 39 finished: collectAsMap at RandomForest.scala:663, took 0,187988 s
24/04/16 15:56:22.198 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(59) (from destroy at RandomForest.scala:674)
24/04/16 15:56:22.200 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_59_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 25.0 KiB, free: 910.4 MiB)
24/04/16 15:56:22.203 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 26.0 KiB, free 906.6 MiB)
24/04/16 15:56:22.204 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 906.6 MiB)
24/04/16 15:56:22.205 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 16.3 KiB, free: 910.4 MiB)
24/04/16 15:56:22.205 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 62 from broadcast at RandomForest.scala:622
24/04/16 15:56:22.228 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 15:56:22.228 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 199 (mapPartitions at RandomForest.scala:644) as input to shuffle 15
24/04/16 15:56:22.229 dag-scheduler-event-loop INFO DAGScheduler: Got job 40 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 15:56:22.229 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 55 (collectAsMap at RandomForest.scala:663)
24/04/16 15:56:22.229 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
24/04/16 15:56:22.229 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)
24/04/16 15:56:22.230 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[199] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 15:56:22.247 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_57_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 154.9 KiB, free: 910.6 MiB)
24/04/16 15:56:22.252 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_60_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 157.8 KiB, free: 910.7 MiB)
24/04/16 15:56:22.253 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 611.4 KiB, free 907.4 MiB)
24/04/16 15:56:22.256 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 151.4 KiB, free 907.3 MiB)
24/04/16 15:56:22.257 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 151.4 KiB, free: 910.6 MiB)
24/04/16 15:56:22.258 dag-scheduler-event-loop INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:22.258 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[199] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:22.259 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks resource profile 0
24/04/16 15:56:22.265 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_58_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 5.3 KiB, free: 910.6 MiB)
24/04/16 15:56:22.272 dispatcher-event-loop-1 WARN TaskSetManager: Stage 54 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:56:22.272 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_55_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 5.1 KiB, free: 910.6 MiB)
24/04/16 15:56:22.273 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 63) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:22.273 Executor task launch worker for task 0.0 in stage 54.0 (TID 63) INFO Executor: Running task 0.0 in stage 54.0 (TID 63)
24/04/16 15:56:22.276 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_61_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 5.3 KiB, free: 910.6 MiB)
24/04/16 15:56:22.296 Executor task launch worker for task 0.0 in stage 54.0 (TID 63) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 15:56:22.314 Executor task launch worker for task 0.0 in stage 54.0 (TID 63) INFO Executor: Finished task 0.0 in stage 54.0 (TID 63). 2248 bytes result sent to driver
24/04/16 15:56:22.323 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 64) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 15:56:22.323 Executor task launch worker for task 1.0 in stage 54.0 (TID 64) INFO Executor: Running task 1.0 in stage 54.0 (TID 64)
24/04/16 15:56:22.324 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 63) in 64 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:22.340 Executor task launch worker for task 1.0 in stage 54.0 (TID 64) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 15:56:22.357 Executor task launch worker for task 1.0 in stage 54.0 (TID 64) INFO Executor: Finished task 1.0 in stage 54.0 (TID 64). 2248 bytes result sent to driver
24/04/16 15:56:22.359 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 64) in 45 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:22.359 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
24/04/16 15:56:22.360 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 54 (mapPartitions at RandomForest.scala:644) finished in 0,130 s
24/04/16 15:56:22.360 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 15:56:22.360 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 15:56:22.360 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 55)
24/04/16 15:56:22.360 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 15:56:22.360 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[201] at map at RandomForest.scala:663), which has no missing parents
24/04/16 15:56:22.362 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 10.4 KiB, free 907.3 MiB)
24/04/16 15:56:22.363 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 907.3 MiB)
24/04/16 15:56:22.363 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 4.8 KiB, free: 910.6 MiB)
24/04/16 15:56:22.363 dag-scheduler-event-loop INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:22.364 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[201] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 15:56:22.364 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks resource profile 0
24/04/16 15:56:22.364 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 65) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:22.365 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO Executor: Running task 0.0 in stage 55.0 (TID 65)
24/04/16 15:56:22.367 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO ShuffleBlockFetcherIterator: Getting 2 (107.3 KiB) non-empty blocks including 2 (107.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:22.367 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:22.379 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO Executor: Finished task 0.0 in stage 55.0 (TID 65). 5552 bytes result sent to driver
24/04/16 15:56:22.380 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 66) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 15:56:22.380 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO Executor: Running task 1.0 in stage 55.0 (TID 66)
24/04/16 15:56:22.380 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 65) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 15:56:22.382 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO ShuffleBlockFetcherIterator: Getting 2 (98.5 KiB) non-empty blocks including 2 (98.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 15:56:22.382 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 15:56:22.392 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO Executor: Finished task 1.0 in stage 55.0 (TID 66). 5432 bytes result sent to driver
24/04/16 15:56:22.393 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 66) in 13 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 15:56:22.393 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
24/04/16 15:56:22.393 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 55 (collectAsMap at RandomForest.scala:663) finished in 0,032 s
24/04/16 15:56:22.394 dag-scheduler-event-loop INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:22.394 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
24/04/16 15:56:22.394 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 40 finished: collectAsMap at RandomForest.scala:663, took 0,165862 s
24/04/16 15:56:22.394 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(62) (from destroy at RandomForest.scala:674)
24/04/16 15:56:22.395 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 15:56:22.395 nioEventLoopGroup-2-2 INFO RandomForest:   init: 5.22E-5
  total: 1.5637147
  findBestSplits: 1.5455316
  chooseSplits: 1.5427829
24/04/16 15:56:22.395 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_62_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 16.3 KiB, free: 910.6 MiB)
24/04/16 15:56:22.397 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 186 from persistence list
24/04/16 15:56:22.398 block-manager-storage-async-thread-pool-35 INFO BlockManager: Removing RDD 186
24/04/16 15:56:22.399 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(49) (from destroy at RandomForest.scala:305)
24/04/16 15:56:22.399 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_49_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 7.9 KiB, free: 910.9 MiB)
24/04/16 15:56:22.406 nioEventLoopGroup-2-2 INFO Instrumentation: [b2f4472e] {"numFeatures":545}
24/04/16 15:56:22.406 nioEventLoopGroup-2-2 INFO Instrumentation: [b2f4472e] training finished
24/04/16 15:56:22.407 nioEventLoopGroup-2-2 INFO Instrumentation: [d7b3ce1a] training finished
24/04/16 15:56:23.179 nioEventLoopGroup-2-2 INFO Instrumentation: [39e7e9b2] training finished
24/04/16 15:56:25.051 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_64_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 4.8 KiB, free: 911.0 MiB)
24/04/16 15:56:25.056 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_63_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 151.4 KiB, free: 911.1 MiB)
24/04/16 15:56:25.062 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:56:25.062 dag-scheduler-event-loop INFO DAGScheduler: Got job 41 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:56:25.063 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 56 (collect at utils.scala:26)
24/04/16 15:56:25.063 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:56:25.063 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:56:25.063 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[204] at collect at utils.scala:26), which has no missing parents
24/04/16 15:56:25.066 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 62.5 KiB, free 908.5 MiB)
24/04/16 15:56:25.067 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 908.5 MiB)
24/04/16 15:56:25.067 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 911.1 MiB)
24/04/16 15:56:25.068 dag-scheduler-event-loop INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:25.068 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[204] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:56:25.068 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
24/04/16 15:56:25.069 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 67) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:56:25.070 Executor task launch worker for task 0.0 in stage 56.0 (TID 67) INFO Executor: Running task 0.0 in stage 56.0 (TID 67)
24/04/16 15:56:25.115 Executor task launch worker for task 0.0 in stage 56.0 (TID 67) INFO Executor: Finished task 0.0 in stage 56.0 (TID 67). 1430 bytes result sent to driver
24/04/16 15:56:25.116 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 67) in 47 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:56:25.116 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
24/04/16 15:56:25.117 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 56 (collect at utils.scala:26) finished in 0,054 s
24/04/16 15:56:25.117 dag-scheduler-event-loop INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:25.117 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
24/04/16 15:56:25.117 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 41 finished: collect at utils.scala:26, took 0,054716 s
24/04/16 15:56:29.633 nioEventLoopGroup-2-2 INFO Instrumentation: [26d0da8d] training finished
24/04/16 15:56:29.705 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 449.6 KiB, free 908.0 MiB)
24/04/16 15:56:29.708 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 908.0 MiB)
24/04/16 15:56:29.708 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 27.6 KiB, free: 911.1 MiB)
24/04/16 15:56:29.708 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 66 from broadcast at RandomForestRegressor.scala:238
24/04/16 15:56:29.776 nioEventLoopGroup-2-2 INFO Instrumentation: [6f53e7a3] training finished
24/04/16 15:56:31.428 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:56:31.428 dag-scheduler-event-loop INFO DAGScheduler: Got job 42 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:56:31.428 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:26)
24/04/16 15:56:31.428 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:56:31.428 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:56:31.428 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[207] at collect at utils.scala:26), which has no missing parents
24/04/16 15:56:31.430 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 62.6 KiB, free 907.9 MiB)
24/04/16 15:56:31.431 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 907.9 MiB)
24/04/16 15:56:31.432 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 12.7 KiB, free: 911.1 MiB)
24/04/16 15:56:31.432 dag-scheduler-event-loop INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:31.433 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[207] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:56:31.433 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
24/04/16 15:56:31.433 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 68) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 15:56:31.434 Executor task launch worker for task 0.0 in stage 57.0 (TID 68) INFO Executor: Running task 0.0 in stage 57.0 (TID 68)
24/04/16 15:56:31.474 Executor task launch worker for task 0.0 in stage 57.0 (TID 68) INFO Executor: Finished task 0.0 in stage 57.0 (TID 68). 1430 bytes result sent to driver
24/04/16 15:56:31.475 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 68) in 42 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:56:31.475 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
24/04/16 15:56:31.476 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 57 (collect at utils.scala:26) finished in 0,046 s
24/04/16 15:56:31.476 dag-scheduler-event-loop INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:31.476 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
24/04/16 15:56:31.476 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 42 finished: collect at utils.scala:26, took 0,048912 s
24/04/16 15:56:31.539 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_67_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 911.1 MiB)
24/04/16 15:56:31.544 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_65_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 12.7 KiB, free: 911.1 MiB)
24/04/16 15:56:39.114 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:56:39.114 dag-scheduler-event-loop INFO DAGScheduler: Got job 43 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:56:39.114 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:26)
24/04/16 15:56:39.114 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:56:39.115 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:56:39.115 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[215] at collect at utils.scala:26), which has no missing parents
24/04/16 15:56:39.124 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 373.1 KiB, free 907.7 MiB)
24/04/16 15:56:39.126 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 75.3 KiB, free 907.6 MiB)
24/04/16 15:56:39.126 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 75.3 KiB, free: 911.0 MiB)
24/04/16 15:56:39.127 dag-scheduler-event-loop INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1535
24/04/16 15:56:39.127 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[215] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:56:39.127 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
24/04/16 15:56:39.138 dispatcher-event-loop-0 WARN TaskSetManager: Stage 58 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:56:39.138 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 69) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:56:39.139 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO Executor: Running task 0.0 in stage 58.0 (TID 69)
24/04/16 15:56:39.154 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:56:39.461 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO CodeGenerator: Code generated in 109.2487 ms
24/04/16 15:56:39.613 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO Executor: Finished task 0.0 in stage 58.0 (TID 69). 5631 bytes result sent to driver
24/04/16 15:56:39.616 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 69) in 488 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:56:39.616 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
24/04/16 15:56:39.617 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 58 (collect at utils.scala:26) finished in 0,502 s
24/04/16 15:56:39.617 dag-scheduler-event-loop INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:56:39.617 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
24/04/16 15:56:39.617 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 43 finished: collect at utils.scala:26, took 0,503400 s
24/04/16 15:56:51.412 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_68_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 75.3 KiB, free: 911.1 MiB)
24/04/16 15:58:26.343 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:58:26.344 dag-scheduler-event-loop INFO DAGScheduler: Got job 44 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:58:26.344 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:26)
24/04/16 15:58:26.344 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:58:26.344 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:58:26.345 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[221] at collect at utils.scala:26), which has no missing parents
24/04/16 15:58:26.349 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 123.2 KiB, free 907.9 MiB)
24/04/16 15:58:26.350 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 907.9 MiB)
24/04/16 15:58:26.350 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 31.0 KiB, free: 911.0 MiB)
24/04/16 15:58:26.351 dag-scheduler-event-loop INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1535
24/04/16 15:58:26.351 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[221] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:58:26.351 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0
24/04/16 15:58:26.360 dispatcher-event-loop-0 WARN TaskSetManager: Stage 59 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:58:26.360 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 70) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:58:26.361 Executor task launch worker for task 0.0 in stage 59.0 (TID 70) INFO Executor: Running task 0.0 in stage 59.0 (TID 70)
24/04/16 15:58:26.369 Executor task launch worker for task 0.0 in stage 59.0 (TID 70) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:58:26.474 Executor task launch worker for task 0.0 in stage 59.0 (TID 70) INFO Executor: Finished task 0.0 in stage 59.0 (TID 70). 245115 bytes result sent to driver
24/04/16 15:58:26.475 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 70) in 123 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:58:26.475 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
24/04/16 15:58:26.475 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 59 (collect at utils.scala:26) finished in 0,130 s
24/04/16 15:58:26.475 dag-scheduler-event-loop INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:58:26.475 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
24/04/16 15:58:26.476 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 44 finished: collect at utils.scala:26, took 0,131784 s
24/04/16 15:59:00.079 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:59:00.080 dag-scheduler-event-loop INFO DAGScheduler: Got job 45 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:59:00.080 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 60 (collect at utils.scala:26)
24/04/16 15:59:00.080 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:59:00.080 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:59:00.081 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[227] at collect at utils.scala:26), which has no missing parents
24/04/16 15:59:00.085 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 123.2 KiB, free 907.8 MiB)
24/04/16 15:59:00.088 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 907.8 MiB)
24/04/16 15:59:00.089 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 31.0 KiB, free: 911.0 MiB)
24/04/16 15:59:00.090 dag-scheduler-event-loop INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1535
24/04/16 15:59:00.090 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[227] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:59:00.090 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
24/04/16 15:59:00.100 dispatcher-event-loop-1 WARN TaskSetManager: Stage 60 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:59:00.100 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 71) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:59:00.100 Executor task launch worker for task 0.0 in stage 60.0 (TID 71) INFO Executor: Running task 0.0 in stage 60.0 (TID 71)
24/04/16 15:59:00.111 Executor task launch worker for task 0.0 in stage 60.0 (TID 71) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:59:00.161 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_69_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 31.0 KiB, free: 911.0 MiB)
24/04/16 15:59:00.266 Executor task launch worker for task 0.0 in stage 60.0 (TID 71) INFO Executor: Finished task 0.0 in stage 60.0 (TID 71). 245201 bytes result sent to driver
24/04/16 15:59:00.267 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 71) in 176 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:59:00.267 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
24/04/16 15:59:00.267 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 60 (collect at utils.scala:26) finished in 0,186 s
24/04/16 15:59:00.269 dag-scheduler-event-loop INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:59:00.269 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
24/04/16 15:59:00.269 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 45 finished: collect at utils.scala:26, took 0,188821 s
24/04/16 15:59:18.275 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 15:59:18.276 dag-scheduler-event-loop INFO DAGScheduler: Got job 46 (collect at utils.scala:26) with 1 output partitions
24/04/16 15:59:18.276 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:26)
24/04/16 15:59:18.276 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 15:59:18.276 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 15:59:18.276 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[233] at collect at utils.scala:26), which has no missing parents
24/04/16 15:59:18.281 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 123.2 KiB, free 907.8 MiB)
24/04/16 15:59:18.283 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 907.8 MiB)
24/04/16 15:59:18.283 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 31.0 KiB, free: 911.0 MiB)
24/04/16 15:59:18.283 dag-scheduler-event-loop INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1535
24/04/16 15:59:18.284 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[233] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 15:59:18.284 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
24/04/16 15:59:18.291 dispatcher-event-loop-1 WARN TaskSetManager: Stage 61 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 15:59:18.291 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 72) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 15:59:18.292 Executor task launch worker for task 0.0 in stage 61.0 (TID 72) INFO Executor: Running task 0.0 in stage 61.0 (TID 72)
24/04/16 15:59:18.299 Executor task launch worker for task 0.0 in stage 61.0 (TID 72) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 15:59:18.478 Executor task launch worker for task 0.0 in stage 61.0 (TID 72) INFO Executor: Finished task 0.0 in stage 61.0 (TID 72). 245115 bytes result sent to driver
24/04/16 15:59:18.480 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 72) in 196 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 15:59:18.480 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
24/04/16 15:59:18.481 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 61 (collect at utils.scala:26) finished in 0,204 s
24/04/16 15:59:18.481 dag-scheduler-event-loop INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 15:59:18.481 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
24/04/16 15:59:18.481 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 46 finished: collect at utils.scala:26, took 0,206184 s
24/04/16 15:59:18.753 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_71_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 31.0 KiB, free: 911.0 MiB)
24/04/16 15:59:18.757 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_70_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 31.0 KiB, free: 911.1 MiB)
24/04/16 16:01:50.751 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:01:50.751 dag-scheduler-event-loop INFO DAGScheduler: Got job 47 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:01:50.751 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:26)
24/04/16 16:01:50.751 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:01:50.753 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:01:50.753 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[239] at collect at utils.scala:26), which has no missing parents
24/04/16 16:01:50.756 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 123.2 KiB, free 907.9 MiB)
24/04/16 16:01:50.757 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 907.9 MiB)
24/04/16 16:01:50.758 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 31.0 KiB, free: 911.0 MiB)
24/04/16 16:01:50.758 dag-scheduler-event-loop INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1535
24/04/16 16:01:50.758 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[239] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:01:50.759 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
24/04/16 16:01:50.768 dispatcher-event-loop-0 WARN TaskSetManager: Stage 62 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:01:50.768 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 73) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:01:50.769 Executor task launch worker for task 0.0 in stage 62.0 (TID 73) INFO Executor: Running task 0.0 in stage 62.0 (TID 73)
24/04/16 16:01:50.778 Executor task launch worker for task 0.0 in stage 62.0 (TID 73) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:01:50.907 Executor task launch worker for task 0.0 in stage 62.0 (TID 73) INFO Executor: Finished task 0.0 in stage 62.0 (TID 73). 245115 bytes result sent to driver
24/04/16 16:01:50.907 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 73) in 148 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:01:50.908 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
24/04/16 16:01:50.909 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 62 (collect at utils.scala:26) finished in 0,155 s
24/04/16 16:01:50.909 dag-scheduler-event-loop INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:01:50.909 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished
24/04/16 16:01:50.909 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 47 finished: collect at utils.scala:26, took 0,157226 s
24/04/16 16:11:11.097 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_72_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 31.0 KiB, free: 911.1 MiB)
24/04/16 16:11:11.101 block-manager-storage-async-thread-pool-222 INFO BlockManager: Removing RDD 186
24/04/16 16:11:11.109 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_47_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 121.4 KiB, free: 911.2 MiB)
24/04/16 16:11:11.112 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_46_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 117.6 KiB, free: 911.3 MiB)
24/04/16 16:11:11.119 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_54_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 146.3 KiB, free: 911.5 MiB)
24/04/16 16:11:11.123 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_45_piece0 on DESKTOP-LH06ASP:59061 in memory (size: 117.6 KiB, free: 911.6 MiB)
24/04/16 16:17:53.688 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:17:53.689 dag-scheduler-event-loop INFO DAGScheduler: Got job 48 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:17:53.689 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:26)
24/04/16 16:17:53.689 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:17:53.689 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:17:53.689 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[245] at collect at utils.scala:26), which has no missing parents
24/04/16 16:17:53.692 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 123.2 KiB, free 910.5 MiB)
24/04/16 16:17:53.693 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 910.5 MiB)
24/04/16 16:17:53.694 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on DESKTOP-LH06ASP:59061 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 16:17:53.694 dag-scheduler-event-loop INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1535
24/04/16 16:17:53.694 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[245] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:17:53.694 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
24/04/16 16:17:53.703 dispatcher-event-loop-1 WARN TaskSetManager: Stage 63 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:17:53.703 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 74) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:17:53.704 Executor task launch worker for task 0.0 in stage 63.0 (TID 74) INFO Executor: Running task 0.0 in stage 63.0 (TID 74)
24/04/16 16:17:53.709 Executor task launch worker for task 0.0 in stage 63.0 (TID 74) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:17:53.788 Executor task launch worker for task 0.0 in stage 63.0 (TID 74) INFO Executor: Finished task 0.0 in stage 63.0 (TID 74). 245115 bytes result sent to driver
24/04/16 16:17:53.789 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 74) in 94 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:17:53.789 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
24/04/16 16:17:53.789 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 63 (collect at utils.scala:26) finished in 0,099 s
24/04/16 16:17:53.790 dag-scheduler-event-loop INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:17:53.790 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
24/04/16 16:17:53.790 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 48 finished: collect at utils.scala:26, took 0,101863 s
24/04/16 16:18:09.168 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/16 16:18:09.168 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/16 16:18:09.185 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/16 16:18:09.202 dispatcher-event-loop-0 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/16 16:18:09.360 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/16 16:18:09.361 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/16 16:18:09.364 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/16 16:18:09.367 dispatcher-event-loop-1 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/16 16:18:09.372 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-64073a97-8312-4184-bce4-e0d2fa8c5d4e\userFiles-b95c242e-73b2-4cfd-bd2b-b5d06e2b3266
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-64073a97-8312-4184-bce4-e0d2fa8c5d4e\userFiles-b95c242e-73b2-4cfd-bd2b-b5d06e2b3266\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/16 16:18:09.373 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/16 16:18:09.374 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/16 16:18:09.374 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-64073a97-8312-4184-bce4-e0d2fa8c5d4e\userFiles-b95c242e-73b2-4cfd-bd2b-b5d06e2b3266
24/04/16 16:18:09.376 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-64073a97-8312-4184-bce4-e0d2fa8c5d4e\userFiles-b95c242e-73b2-4cfd-bd2b-b5d06e2b3266
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-64073a97-8312-4184-bce4-e0d2fa8c5d4e\userFiles-b95c242e-73b2-4cfd-bd2b-b5d06e2b3266\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/16 16:18:09.377 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-64073a97-8312-4184-bce4-e0d2fa8c5d4e
24/04/16 16:18:09.380 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-64073a97-8312-4184-bce4-e0d2fa8c5d4e
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-64073a97-8312-4184-bce4-e0d2fa8c5d4e\userFiles-b95c242e-73b2-4cfd-bd2b-b5d06e2b3266\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/16 16:18:09.381 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-f5d2c152-115a-44f9-9223-cb4b86f41528
24/04/16 16:19:33.197 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/16 16:19:33.469 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/16 16:19:33.485 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/16 16:19:33.563 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/16 16:19:33.672 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/16 16:19:33.673 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/16 16:19:33.674 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/16 16:19:33.675 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/16 16:19:33.719 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/16 16:19:33.742 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/16 16:19:33.743 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/16 16:19:33.836 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/16 16:19:33.837 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/16 16:19:33.838 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/16 16:19:33.839 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/16 16:19:33.839 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/16 16:19:33.999 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 62811.
24/04/16 16:19:34.046 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/16 16:19:34.104 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/16 16:19:34.143 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/16 16:19:34.143 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/16 16:19:34.143 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/16 16:19:34.174 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-033dabeb-b06c-4f54-8eb6-b29e66350426
24/04/16 16:19:34.190 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/16 16:19:34.206 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/16 16:19:34.206 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/16 16:19:34.377 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/16 16:19:34.456 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/16 16:19:34.502 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:62811/jars/sparklyr-3.0-2.12.jar with timestamp 1713280773461
24/04/16 16:19:34.581 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/16 16:19:34.596 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/16 16:19:34.596 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:62811/jars/sparklyr-3.0-2.12.jar with timestamp 1713280773461
24/04/16 16:19:34.643 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:62811 after 20 ms (0 ms spent in bootstraps)
24/04/16 16:19:34.643 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:62811/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-1ec82fe9-8167-44e2-963e-f578c6befc40\userFiles-abbc191a-d0b5-4f34-9c9b-8b4d2dff8417\fetchFileTemp2496424837716910133.tmp
24/04/16 16:19:34.806 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-1ec82fe9-8167-44e2-963e-f578c6befc40/userFiles-abbc191a-d0b5-4f34-9c9b-8b4d2dff8417/sparklyr-3.0-2.12.jar to class loader
24/04/16 16:19:34.822 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62831.
24/04/16 16:19:34.822 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:62831
24/04/16 16:19:34.822 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/16 16:19:34.837 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 62831, None)
24/04/16 16:19:34.837 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:62831 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 62831, None)
24/04/16 16:19:34.847 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 62831, None)
24/04/16 16:19:34.848 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 62831, None)
24/04/16 16:19:35.112 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/16 16:19:35.133 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/16 16:19:39.045 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/16 16:19:39.216 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/16 16:19:39.605 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/16 16:19:39.809 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/16 16:19:39.809 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/16 16:19:39.809 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/16 16:19:39.861 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/16 16:19:40.038 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/16 16:19:40.039 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/16 16:19:41.094 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/16 16:19:42.511 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/16 16:19:42.511 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/16 16:19:42.710 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/16 16:19:42.710 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/16 16:19:42.777 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/16 16:19:42.964 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/16 16:19:42.966 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/16 16:19:43.024 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/16 16:19:43.344 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 16:19:43.344 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 16:19:43.385 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/16 16:19:43.385 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/16 16:19:43.386 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/16 16:19:43.386 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 16:19:43.386 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 16:19:43.388 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 16:19:43.388 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 16:19:43.389 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 16:19:43.389 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 16:19:44.143 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 182.4704 ms
24/04/16 16:19:44.270 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:19:44.277 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,005437 s
24/04/16 16:19:48.958 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/16 16:19:50.328 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.0164 ms
24/04/16 16:19:50.388 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:19:50.392 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:19:50.392 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/16 16:19:50.392 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:19:50.408 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:19:50.412 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/16 16:19:50.492 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/16 16:19:50.578 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/16 16:19:50.581 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 16:19:50.585 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/16 16:19:50.590 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:19:50.590 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/16 16:19:50.640 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:19:50.661 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/16 16:19:51.237 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 218.3244 ms
24/04/16 16:19:51.256 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1559 bytes result sent to driver
24/04/16 16:19:51.256 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 616 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:19:51.272 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/16 16:19:51.272 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,839 s
24/04/16 16:19:51.272 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:19:51.272 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/16 16:19:51.272 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,895551 s
24/04/16 16:19:51.618 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 242.6617 ms
24/04/16 16:19:55.388 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:19:55.388 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:19:55.388 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/16 16:19:55.388 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:19:55.388 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:19:55.388 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/16 16:19:55.388 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/16 16:19:55.388 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/16 16:19:55.404 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 16:19:55.405 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/16 16:19:55.406 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:19:55.406 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/16 16:19:55.406 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:19:55.406 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/16 16:19:55.450 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1430 bytes result sent to driver
24/04/16 16:19:55.453 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 46 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:19:55.453 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/16 16:19:55.454 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,066 s
24/04/16 16:19:55.454 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:19:55.454 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/16 16:19:55.454 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,060393 s
24/04/16 16:19:57.654 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 16:19:57.654 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 16:19:58.062 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:19:58.062 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:19:58.062 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/16 16:19:58.062 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:19:58.068 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:19:58.070 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26), which has no missing parents
24/04/16 16:19:58.097 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 107.3 KiB, free 912.2 MiB)
24/04/16 16:19:58.099 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 912.2 MiB)
24/04/16 16:19:58.101 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 27.1 KiB, free: 912.3 MiB)
24/04/16 16:19:58.101 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/16 16:19:58.101 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:19:58.102 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/16 16:19:58.122 dispatcher-event-loop-0 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:19:58.122 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:19:58.122 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/16 16:19:58.405 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 171.5845 ms
24/04/16 16:19:59.075 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 686.4 KiB, free 911.5 MiB)
24/04/16 16:19:59.081 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on DESKTOP-LH06ASP:62831 (size: 686.4 KiB, free: 911.6 MiB)
24/04/16 16:19:59.096 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 5.6572 ms
24/04/16 16:19:59.238 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 134.6869 ms
24/04/16 16:19:59.282 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_13_0]
24/04/16 16:19:59.283 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2442 bytes result sent to driver
24/04/16 16:19:59.285 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1182 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:19:59.285 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/16 16:19:59.286 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 1,215 s
24/04/16 16:19:59.286 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:19:59.286 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/16 16:19:59.286 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 1,223285 s
24/04/16 16:19:59.353 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 27.1 KiB, free: 911.6 MiB)
24/04/16 16:19:59.577 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 164.4028 ms
24/04/16 16:20:02.184 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:20:02.185 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:20:02.185 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
24/04/16 16:20:02.185 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:02.185 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:02.187 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at collect at utils.scala:26), which has no missing parents
24/04/16 16:20:02.195 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 56.4 KiB, free 911.6 MiB)
24/04/16 16:20:02.200 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 911.6 MiB)
24/04/16 16:20:02.202 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 13.5 KiB, free: 911.6 MiB)
24/04/16 16:20:02.202 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:02.203 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:02.203 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/16 16:20:02.215 dispatcher-event-loop-0 WARN TaskSetManager: Stage 3 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:02.215 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:20:02.216 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/16 16:20:02.318 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 12.5523 ms
24/04/16 16:20:02.323 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1467 bytes result sent to driver
24/04/16 16:20:02.326 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 122 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:02.326 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/16 16:20:02.326 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0,139 s
24/04/16 16:20:02.326 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:02.326 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/04/16 16:20:02.326 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0,142442 s
24/04/16 16:20:02.351 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 16.4262 ms
24/04/16 16:20:03.800 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:20:03.800 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:20:03.800 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
24/04/16 16:20:03.800 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:03.800 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:03.800 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:26), which has no missing parents
24/04/16 16:20:03.800 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 62.4 KiB, free 911.5 MiB)
24/04/16 16:20:03.816 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.5 MiB)
24/04/16 16:20:03.817 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:20:03.818 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:03.819 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:03.819 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/04/16 16:20:03.819 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:20:03.819 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/04/16 16:20:03.857 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1430 bytes result sent to driver
24/04/16 16:20:03.858 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 39 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:03.858 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/04/16 16:20:03.859 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0,059 s
24/04/16 16:20:03.859 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:03.859 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/04/16 16:20:03.860 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0,050231 s
24/04/16 16:20:04.088 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 13.5 KiB, free: 911.6 MiB)
24/04/16 16:20:04.092 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:20:07.465 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:20:07.465 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:20:07.465 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
24/04/16 16:20:07.465 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:07.465 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:07.465 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at collect at utils.scala:26), which has no missing parents
24/04/16 16:20:07.465 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 62.4 KiB, free 911.6 MiB)
24/04/16 16:20:07.482 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.6 MiB)
24/04/16 16:20:07.501 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:20:07.502 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:07.502 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:07.502 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/04/16 16:20:07.503 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:20:07.504 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/04/16 16:20:07.532 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1430 bytes result sent to driver
24/04/16 16:20:07.532 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 29 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:07.532 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/04/16 16:20:07.532 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0,067 s
24/04/16 16:20:07.532 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:07.532 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/04/16 16:20:07.532 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0,067501 s
24/04/16 16:20:09.781 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:20:09.781 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:20:09.781 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
24/04/16 16:20:09.781 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:09.781 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:09.781 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[32] at collect at utils.scala:26), which has no missing parents
24/04/16 16:20:09.781 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 123.2 KiB, free 911.4 MiB)
24/04/16 16:20:09.781 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 911.4 MiB)
24/04/16 16:20:09.781 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 16:20:09.781 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:09.781 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[32] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:09.781 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
24/04/16 16:20:09.797 dispatcher-event-loop-0 WARN TaskSetManager: Stage 6 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:09.797 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:20:09.797 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/04/16 16:20:09.816 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:20:10.030 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:20:10.084 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 186.3166 ms
24/04/16 16:20:10.116 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 6.0706 ms
24/04/16 16:20:10.305 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 245158 bytes result sent to driver
24/04/16 16:20:10.307 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 510 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:10.307 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/04/16 16:20:10.308 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0,527 s
24/04/16 16:20:10.308 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:10.308 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
24/04/16 16:20:10.309 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0,524513 s
24/04/16 16:20:13.747 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:20:13.748 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:20:13.748 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
24/04/16 16:20:13.748 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:13.749 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:13.750 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[38] at collect at utils.scala:26), which has no missing parents
24/04/16 16:20:13.753 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 123.2 KiB, free 911.4 MiB)
24/04/16 16:20:13.755 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 911.3 MiB)
24/04/16 16:20:13.756 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 16:20:13.756 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:13.757 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:13.757 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
24/04/16 16:20:13.766 dispatcher-event-loop-1 WARN TaskSetManager: Stage 7 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:13.766 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:20:13.767 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
24/04/16 16:20:13.773 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:20:13.864 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 137627 bytes result sent to driver
24/04/16 16:20:13.864 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 106 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:13.864 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/04/16 16:20:13.864 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0,114 s
24/04/16 16:20:13.879 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:13.879 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
24/04/16 16:20:13.879 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0,131932 s
24/04/16 16:20:13.995 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 16:20:13.995 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 16:20:16.855 nioEventLoopGroup-2-2 INFO Instrumentation: [2ff36a4e] training finished
24/04/16 16:20:17.632 nioEventLoopGroup-2-2 INFO Instrumentation: [60ab2035] training finished
24/04/16 16:20:18.149 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 67.0589 ms
24/04/16 16:20:18.212 nioEventLoopGroup-2-2 INFO Instrumentation: [ad4d03a3] Stage class: RandomForestRegressor
24/04/16 16:20:18.212 nioEventLoopGroup-2-2 INFO Instrumentation: [ad4d03a3] Stage uid: random_forest__c10ace68_91bb_4009_a1e1_51ad0702c9fd
24/04/16 16:20:18.212 nioEventLoopGroup-2-2 INFO Instrumentation: [ad4d03a3] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
24/04/16 16:20:18.233 nioEventLoopGroup-2-2 INFO Instrumentation: [ad4d03a3] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/16 16:20:18.327 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 16:20:18.327 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 16:20:18.327 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (take at DecisionTreeMetadata.scala:119)
24/04/16 16:20:18.327 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:18.327 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:18.327 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[51] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 16:20:18.343 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 398.0 KiB, free 911.2 MiB)
24/04/16 16:20:18.343 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 82.8 KiB, free 911.2 MiB)
24/04/16 16:20:18.343 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 82.8 KiB, free: 911.5 MiB)
24/04/16 16:20:18.343 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:18.343 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[51] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:18.343 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
24/04/16 16:20:18.343 dispatcher-event-loop-0 WARN TaskSetManager: Stage 8 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:18.343 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:20:18.343 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
24/04/16 16:20:18.444 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:20:18.793 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 114.3719 ms
24/04/16 16:20:18.827 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 5.7391 ms
24/04/16 16:20:18.846 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 6.7978 ms
24/04/16 16:20:18.856 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 4.8141 ms
24/04/16 16:20:18.860 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1700 bytes result sent to driver
24/04/16 16:20:18.860 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 517 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:18.860 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/04/16 16:20:18.860 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (take at DecisionTreeMetadata.scala:119) finished in 0,533 s
24/04/16 16:20:18.860 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:18.860 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/04/16 16:20:18.860 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: take at DecisionTreeMetadata.scala:119, took 0,534197 s
24/04/16 16:20:18.877 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 16:20:18.879 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions
24/04/16 16:20:18.879 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 16:20:18.879 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:18.879 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:18.879 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[50] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 16:20:18.879 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 398.0 KiB, free 910.8 MiB)
24/04/16 16:20:18.879 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 82.9 KiB, free 910.7 MiB)
24/04/16 16:20:18.897 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 82.9 KiB, free: 911.5 MiB)
24/04/16 16:20:18.898 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:18.898 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[50] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:18.899 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
24/04/16 16:20:18.909 dispatcher-event-loop-0 WARN TaskSetManager: Stage 9 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:18.910 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:20:18.911 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
24/04/16 16:20:18.927 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:20:19.326 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1772 bytes result sent to driver
24/04/16 16:20:19.326 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 427 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:19.326 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
24/04/16 16:20:19.326 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,447 s
24/04/16 16:20:19.326 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:19.326 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
24/04/16 16:20:19.326 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,452589 s
24/04/16 16:20:19.423 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 16:20:19.460 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 53 (flatMap at RandomForest.scala:1039) as input to shuffle 0
24/04/16 16:20:19.467 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collectAsMap at RandomForest.scala:1054) with 1 output partitions
24/04/16 16:20:19.467 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 11 (collectAsMap at RandomForest.scala:1054)
24/04/16 16:20:19.467 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
24/04/16 16:20:19.468 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
24/04/16 16:20:19.471 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[53] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 16:20:19.488 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 407.0 KiB, free 910.3 MiB)
24/04/16 16:20:19.492 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 86.5 KiB, free 910.2 MiB)
24/04/16 16:20:19.493 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 86.5 KiB, free: 911.4 MiB)
24/04/16 16:20:19.494 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:19.496 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[53] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:19.496 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
24/04/16 16:20:19.508 dispatcher-event-loop-1 WARN TaskSetManager: Stage 10 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:19.508 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:20:19.509 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
24/04/16 16:20:19.604 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:20:19.760 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 82.9 KiB, free: 911.5 MiB)
24/04/16 16:20:19.760 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 82.8 KiB, free: 911.5 MiB)
24/04/16 16:20:20.271 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2040 bytes result sent to driver
24/04/16 16:20:20.273 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 776 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:20.274 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
24/04/16 16:20:20.276 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 10 (flatMap at RandomForest.scala:1039) finished in 0,802 s
24/04/16 16:20:20.277 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:20:20.277 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:20:20.278 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 11)
24/04/16 16:20:20.278 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:20:20.281 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[55] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 16:20:20.289 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 11.9 KiB, free 911.1 MiB)
24/04/16 16:20:20.292 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 911.1 MiB)
24/04/16 16:20:20.293 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 4.5 KiB, free: 911.5 MiB)
24/04/16 16:20:20.293 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:20.293 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[55] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:20.293 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
24/04/16 16:20:20.293 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:20:20.293 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
24/04/16 16:20:20.339 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:20:20.341 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
24/04/16 16:20:20.462 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 48769 bytes result sent to driver
24/04/16 16:20:20.462 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 169 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:20.462 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
24/04/16 16:20:20.462 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 11 (collectAsMap at RandomForest.scala:1054) finished in 0,175 s
24/04/16 16:20:20.462 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:20.462 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
24/04/16 16:20:20.462 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collectAsMap at RandomForest.scala:1054, took 1,045354 s
24/04/16 16:20:20.487 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 59.1 KiB, free 911.1 MiB)
24/04/16 16:20:20.491 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 911.1 MiB)
24/04/16 16:20:20.493 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 10.0 KiB, free: 911.5 MiB)
24/04/16 16:20:20.494 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 12 from broadcast at RandomForest.scala:293
24/04/16 16:20:20.510 nioEventLoopGroup-2-2 INFO Instrumentation: [ad4d03a3] {"numFeatures":545}
24/04/16 16:20:20.510 nioEventLoopGroup-2-2 INFO Instrumentation: [ad4d03a3] {"numClasses":0}
24/04/16 16:20:20.510 nioEventLoopGroup-2-2 INFO Instrumentation: [ad4d03a3] {"numExamples":1429}
24/04/16 16:20:20.510 nioEventLoopGroup-2-2 INFO Instrumentation: [ad4d03a3] {"sumOfWeights":1429.0}
24/04/16 16:20:20.525 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 16.1 KiB, free 911.0 MiB)
24/04/16 16:20:20.525 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 911.0 MiB)
24/04/16 16:20:20.525 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 10.3 KiB, free: 911.5 MiB)
24/04/16 16:20:20.525 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 13 from broadcast at RandomForest.scala:622
24/04/16 16:20:20.576 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:20:20.579 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 58 (mapPartitions at RandomForest.scala:644) as input to shuffle 1
24/04/16 16:20:20.580 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 16:20:20.580 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 13 (collectAsMap at RandomForest.scala:663)
24/04/16 16:20:20.580 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
24/04/16 16:20:20.580 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
24/04/16 16:20:20.582 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:20:20.597 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 441.5 KiB, free 910.6 MiB)
24/04/16 16:20:20.599 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 99.2 KiB, free 910.5 MiB)
24/04/16 16:20:20.599 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 99.2 KiB, free: 911.4 MiB)
24/04/16 16:20:20.599 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:20.599 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:20.599 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
24/04/16 16:20:20.599 dispatcher-event-loop-1 WARN TaskSetManager: Stage 12 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:20.599 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:20:20.599 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
24/04/16 16:20:20.644 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:20:21.094 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 4.5 KiB, free: 911.4 MiB)
24/04/16 16:20:21.110 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 86.5 KiB, free: 911.5 MiB)
24/04/16 16:20:21.174 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO MemoryStore: Block rdd_57_0 stored as values in memory (estimated size 3.2 MiB, free 907.9 MiB)
24/04/16 16:20:21.175 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_57_0 in memory on DESKTOP-LH06ASP:62831 (size: 3.2 MiB, free: 908.4 MiB)
24/04/16 16:20:21.259 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1997 bytes result sent to driver
24/04/16 16:20:21.259 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 660 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:21.259 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
24/04/16 16:20:21.259 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 12 (mapPartitions at RandomForest.scala:644) finished in 0,676 s
24/04/16 16:20:21.259 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:20:21.259 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:20:21.259 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 13)
24/04/16 16:20:21.259 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:20:21.259 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[60] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:20:21.259 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.4 KiB, free 907.8 MiB)
24/04/16 16:20:21.259 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 907.8 MiB)
24/04/16 16:20:21.259 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 3.8 KiB, free: 908.4 MiB)
24/04/16 16:20:21.259 dag-scheduler-event-loop INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:21.259 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[60] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:21.275 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
24/04/16 16:20:21.275 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:20:21.275 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
24/04/16 16:20:21.275 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO ShuffleBlockFetcherIterator: Getting 1 (194.1 KiB) non-empty blocks including 1 (194.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:20:21.275 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:20:21.445 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 6380 bytes result sent to driver
24/04/16 16:20:21.445 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 170 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:21.445 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
24/04/16 16:20:21.445 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 13 (collectAsMap at RandomForest.scala:663) finished in 0,186 s
24/04/16 16:20:21.445 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:21.445 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
24/04/16 16:20:21.445 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collectAsMap at RandomForest.scala:663, took 0,874606 s
24/04/16 16:20:21.445 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(13) (from destroy at RandomForest.scala:674)
24/04/16 16:20:21.445 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 10.3 KiB, free: 908.4 MiB)
24/04/16 16:20:21.465 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.6 KiB, free 907.8 MiB)
24/04/16 16:20:21.468 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 907.8 MiB)
24/04/16 16:20:21.469 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 20.3 KiB, free: 908.3 MiB)
24/04/16 16:20:21.469 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 16 from broadcast at RandomForest.scala:622
24/04/16 16:20:21.491 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:20:21.493 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 61 (mapPartitions at RandomForest.scala:644) as input to shuffle 2
24/04/16 16:20:21.493 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 16:20:21.493 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 15 (collectAsMap at RandomForest.scala:663)
24/04/16 16:20:21.493 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
24/04/16 16:20:21.493 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
24/04/16 16:20:21.494 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[61] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:20:21.494 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 462.6 KiB, free 907.4 MiB)
24/04/16 16:20:21.494 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 112.3 KiB, free 907.3 MiB)
24/04/16 16:20:21.494 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 112.3 KiB, free: 908.2 MiB)
24/04/16 16:20:21.494 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:21.494 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[61] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:21.494 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
24/04/16 16:20:21.510 dispatcher-event-loop-1 WARN TaskSetManager: Stage 14 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:21.510 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:20:21.510 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
24/04/16 16:20:21.526 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 16:20:21.576 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1911 bytes result sent to driver
24/04/16 16:20:21.576 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 82 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:21.576 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
24/04/16 16:20:21.576 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 14 (mapPartitions at RandomForest.scala:644) finished in 0,082 s
24/04/16 16:20:21.576 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:20:21.576 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:20:21.576 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 15)
24/04/16 16:20:21.576 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:20:21.576 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:20:21.576 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 11.1 KiB, free 907.2 MiB)
24/04/16 16:20:21.576 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 907.2 MiB)
24/04/16 16:20:21.576 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 5.2 KiB, free: 908.2 MiB)
24/04/16 16:20:21.576 dag-scheduler-event-loop INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:21.576 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:21.576 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
24/04/16 16:20:21.576 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:20:21.576 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
24/04/16 16:20:21.576 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO ShuffleBlockFetcherIterator: Getting 1 (312.6 KiB) non-empty blocks including 1 (312.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:20:21.576 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:20:21.615 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 10454 bytes result sent to driver
24/04/16 16:20:21.616 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 40 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:21.616 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
24/04/16 16:20:21.617 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 15 (collectAsMap at RandomForest.scala:663) finished in 0,041 s
24/04/16 16:20:21.617 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:21.617 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
24/04/16 16:20:21.618 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collectAsMap at RandomForest.scala:663, took 0,126062 s
24/04/16 16:20:21.618 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(16) (from destroy at RandomForest.scala:674)
24/04/16 16:20:21.620 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 20.3 KiB, free: 908.2 MiB)
24/04/16 16:20:21.627 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 54.7 KiB, free 907.2 MiB)
24/04/16 16:20:21.629 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 907.2 MiB)
24/04/16 16:20:21.630 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 33.9 KiB, free: 908.2 MiB)
24/04/16 16:20:21.631 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 19 from broadcast at RandomForest.scala:622
24/04/16 16:20:21.642 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:20:21.642 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 64 (mapPartitions at RandomForest.scala:644) as input to shuffle 3
24/04/16 16:20:21.642 dag-scheduler-event-loop INFO DAGScheduler: Got job 14 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 16:20:21.642 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 17 (collectAsMap at RandomForest.scala:663)
24/04/16 16:20:21.642 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
24/04/16 16:20:21.642 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
24/04/16 16:20:21.642 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[64] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:20:21.642 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 493.2 KiB, free 906.7 MiB)
24/04/16 16:20:21.642 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 129.8 KiB, free 906.6 MiB)
24/04/16 16:20:21.642 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 129.8 KiB, free: 908.1 MiB)
24/04/16 16:20:21.658 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:21.658 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[64] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:21.658 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
24/04/16 16:20:21.661 dispatcher-event-loop-1 WARN TaskSetManager: Stage 16 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:21.661 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:20:21.661 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
24/04/16 16:20:21.677 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 16:20:21.725 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1911 bytes result sent to driver
24/04/16 16:20:21.725 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 66 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:21.725 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
24/04/16 16:20:21.725 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 16 (mapPartitions at RandomForest.scala:644) finished in 0,083 s
24/04/16 16:20:21.725 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:20:21.725 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:20:21.725 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 17)
24/04/16 16:20:21.725 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:20:21.725 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[66] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:20:21.725 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 13.8 KiB, free 906.6 MiB)
24/04/16 16:20:21.725 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 906.6 MiB)
24/04/16 16:20:21.725 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 5.9 KiB, free: 908.1 MiB)
24/04/16 16:20:21.725 dag-scheduler-event-loop INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:21.725 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[66] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:21.725 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
24/04/16 16:20:21.725 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:20:21.725 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
24/04/16 16:20:21.740 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Getting 1 (416.0 KiB) non-empty blocks including 1 (416.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:20:21.740 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:20:21.765 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 16070 bytes result sent to driver
24/04/16 16:20:21.766 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 41 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:21.766 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
24/04/16 16:20:21.767 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 17 (collectAsMap at RandomForest.scala:663) finished in 0,042 s
24/04/16 16:20:21.767 dag-scheduler-event-loop INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:21.767 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
24/04/16 16:20:21.768 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 14 finished: collectAsMap at RandomForest.scala:663, took 0,121834 s
24/04/16 16:20:21.768 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(19) (from destroy at RandomForest.scala:674)
24/04/16 16:20:21.770 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 33.9 KiB, free: 908.1 MiB)
24/04/16 16:20:21.776 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 68.5 KiB, free 906.6 MiB)
24/04/16 16:20:21.778 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 42.3 KiB, free 906.6 MiB)
24/04/16 16:20:21.779 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 42.3 KiB, free: 908.1 MiB)
24/04/16 16:20:21.780 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 22 from broadcast at RandomForest.scala:622
24/04/16 16:20:21.792 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:20:21.792 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 67 (mapPartitions at RandomForest.scala:644) as input to shuffle 4
24/04/16 16:20:21.792 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 16:20:21.792 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 19 (collectAsMap at RandomForest.scala:663)
24/04/16 16:20:21.792 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
24/04/16 16:20:21.792 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
24/04/16 16:20:21.792 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[67] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:20:21.792 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 523.4 KiB, free 906.0 MiB)
24/04/16 16:20:21.792 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 143.5 KiB, free 905.9 MiB)
24/04/16 16:20:21.792 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 143.5 KiB, free: 907.9 MiB)
24/04/16 16:20:21.792 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:21.792 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[67] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:21.792 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
24/04/16 16:20:21.812 dispatcher-event-loop-1 WARN TaskSetManager: Stage 18 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:21.812 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:20:21.812 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
24/04/16 16:20:21.829 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 16:20:21.875 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1911 bytes result sent to driver
24/04/16 16:20:21.875 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 83 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:21.875 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
24/04/16 16:20:21.875 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 18 (mapPartitions at RandomForest.scala:644) finished in 0,083 s
24/04/16 16:20:21.875 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:20:21.875 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:20:21.875 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 19)
24/04/16 16:20:21.875 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:20:21.875 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[69] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:20:21.875 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 15.4 KiB, free 905.9 MiB)
24/04/16 16:20:21.875 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 905.9 MiB)
24/04/16 16:20:21.875 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 6.3 KiB, free: 907.9 MiB)
24/04/16 16:20:21.875 dag-scheduler-event-loop INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:21.875 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[69] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:21.875 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
24/04/16 16:20:21.875 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:20:21.875 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
24/04/16 16:20:21.875 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:20:21.875 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:20:21.894 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 19559 bytes result sent to driver
24/04/16 16:20:21.909 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 34 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:21.909 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
24/04/16 16:20:21.910 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 19 (collectAsMap at RandomForest.scala:663) finished in 0,035 s
24/04/16 16:20:21.910 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:21.910 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
24/04/16 16:20:21.910 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collectAsMap at RandomForest.scala:663, took 0,116173 s
24/04/16 16:20:21.911 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(22) (from destroy at RandomForest.scala:674)
24/04/16 16:20:21.912 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 42.3 KiB, free: 908.0 MiB)
24/04/16 16:20:21.917 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 79.1 KiB, free 905.9 MiB)
24/04/16 16:20:21.919 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 49.0 KiB, free 905.9 MiB)
24/04/16 16:20:21.920 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 49.0 KiB, free: 907.9 MiB)
24/04/16 16:20:21.920 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 25 from broadcast at RandomForest.scala:622
24/04/16 16:20:21.936 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:20:21.936 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 70 (mapPartitions at RandomForest.scala:644) as input to shuffle 5
24/04/16 16:20:21.937 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 16:20:21.937 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 21 (collectAsMap at RandomForest.scala:663)
24/04/16 16:20:21.937 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
24/04/16 16:20:21.937 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
24/04/16 16:20:21.937 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[70] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:20:21.942 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 555.0 KiB, free 905.3 MiB)
24/04/16 16:20:21.942 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 156.2 KiB, free 905.2 MiB)
24/04/16 16:20:21.942 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 156.2 KiB, free: 907.8 MiB)
24/04/16 16:20:21.942 dag-scheduler-event-loop INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:21.942 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[70] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:21.942 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
24/04/16 16:20:21.942 dispatcher-event-loop-1 WARN TaskSetManager: Stage 20 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:21.942 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:20:21.942 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
24/04/16 16:20:21.960 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 16:20:22.009 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1911 bytes result sent to driver
24/04/16 16:20:22.009 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 67 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:22.009 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
24/04/16 16:20:22.009 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 20 (mapPartitions at RandomForest.scala:644) finished in 0,071 s
24/04/16 16:20:22.009 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:20:22.009 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:20:22.009 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 21)
24/04/16 16:20:22.009 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:20:22.009 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[72] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:20:22.009 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.7 KiB, free 905.2 MiB)
24/04/16 16:20:22.009 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 905.1 MiB)
24/04/16 16:20:22.009 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 6.5 KiB, free: 907.8 MiB)
24/04/16 16:20:22.009 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:22.025 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[72] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:22.025 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
24/04/16 16:20:22.025 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:20:22.025 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
24/04/16 16:20:22.025 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:20:22.025 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:20:22.277 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 143.5 KiB, free: 907.9 MiB)
24/04/16 16:20:22.283 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 129.8 KiB, free: 908.0 MiB)
24/04/16 16:20:22.285 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_26_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 156.2 KiB, free: 908.2 MiB)
24/04/16 16:20:22.289 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 5.2 KiB, free: 908.2 MiB)
24/04/16 16:20:22.292 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 3.8 KiB, free: 908.2 MiB)
24/04/16 16:20:22.295 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 112.3 KiB, free: 908.3 MiB)
24/04/16 16:20:22.298 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 99.2 KiB, free: 908.4 MiB)
24/04/16 16:20:22.302 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 22314 bytes result sent to driver
24/04/16 16:20:22.302 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_24_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 6.3 KiB, free: 908.4 MiB)
24/04/16 16:20:22.303 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 278 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:22.303 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
24/04/16 16:20:22.304 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 21 (collectAsMap at RandomForest.scala:663) finished in 0,295 s
24/04/16 16:20:22.304 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:22.304 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
24/04/16 16:20:22.305 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collectAsMap at RandomForest.scala:663, took 0,369207 s
24/04/16 16:20:22.306 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(25) (from destroy at RandomForest.scala:674)
24/04/16 16:20:22.306 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 5.9 KiB, free: 908.4 MiB)
24/04/16 16:20:22.309 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 16:20:22.309 nioEventLoopGroup-2-2 INFO RandomForest:   init: 0.004587
  total: 1.7998166
  findBestSplits: 1.7602958
  chooseSplits: 1.748862
24/04/16 16:20:22.309 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_25_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 49.0 KiB, free: 908.5 MiB)
24/04/16 16:20:22.309 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 57 from persistence list
24/04/16 16:20:22.309 block-manager-storage-async-thread-pool-5 INFO BlockManager: Removing RDD 57
24/04/16 16:20:22.309 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(12) (from destroy at RandomForest.scala:305)
24/04/16 16:20:22.309 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 10.0 KiB, free: 911.6 MiB)
24/04/16 16:20:22.324 nioEventLoopGroup-2-2 INFO Instrumentation: [ad4d03a3] {"numFeatures":545}
24/04/16 16:20:22.324 nioEventLoopGroup-2-2 INFO Instrumentation: [ad4d03a3] training finished
24/04/16 16:20:22.340 nioEventLoopGroup-2-2 INFO Instrumentation: [aa62dea6] training finished
24/04/16 16:20:22.960 nioEventLoopGroup-2-2 INFO Instrumentation: [65df6275] training finished
24/04/16 16:20:24.174 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:20:24.175 dag-scheduler-event-loop INFO DAGScheduler: Got job 17 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:20:24.175 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:26)
24/04/16 16:20:24.175 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:24.175 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:24.175 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[75] at collect at utils.scala:26), which has no missing parents
24/04/16 16:20:24.177 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 62.5 KiB, free 911.5 MiB)
24/04/16 16:20:24.178 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.5 MiB)
24/04/16 16:20:24.178 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:20:24.179 dag-scheduler-event-loop INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:24.179 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[75] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:24.179 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
24/04/16 16:20:24.180 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:20:24.180 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
24/04/16 16:20:24.210 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO CodeGenerator: Code generated in 21.0741 ms
24/04/16 16:20:24.226 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1430 bytes result sent to driver
24/04/16 16:20:24.227 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 48 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:24.228 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
24/04/16 16:20:24.228 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 22 (collect at utils.scala:26) finished in 0,053 s
24/04/16 16:20:24.228 dag-scheduler-event-loop INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:24.228 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
24/04/16 16:20:24.228 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 17 finished: collect at utils.scala:26, took 0,053555 s
24/04/16 16:20:24.291 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_28_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:20:24.341 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 79.3273 ms
24/04/16 16:20:27.551 nioEventLoopGroup-2-2 INFO Instrumentation: [8132ec9d] training finished
24/04/16 16:20:27.616 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 476.3 KiB, free 911.1 MiB)
24/04/16 16:20:27.627 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 911.1 MiB)
24/04/16 16:20:27.628 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 37.4 KiB, free: 911.6 MiB)
24/04/16 16:20:27.629 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 29 from broadcast at RandomForestRegressor.scala:238
24/04/16 16:20:27.677 nioEventLoopGroup-2-2 INFO Instrumentation: [538d2010] training finished
24/04/16 16:20:28.777 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:20:28.777 dag-scheduler-event-loop INFO DAGScheduler: Got job 18 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:20:28.777 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:26)
24/04/16 16:20:28.777 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:28.777 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:28.777 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[78] at collect at utils.scala:26), which has no missing parents
24/04/16 16:20:28.777 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 62.6 KiB, free 911.0 MiB)
24/04/16 16:20:28.777 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.0 MiB)
24/04/16 16:20:28.777 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:20:28.777 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:28.777 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[78] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:28.777 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
24/04/16 16:20:28.777 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:20:28.777 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
24/04/16 16:20:28.858 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO CodeGenerator: Code generated in 54.9034 ms
24/04/16 16:20:28.858 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1473 bytes result sent to driver
24/04/16 16:20:28.858 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 81 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:28.858 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
24/04/16 16:20:28.858 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 23 (collect at utils.scala:26) finished in 0,081 s
24/04/16 16:20:28.873 dag-scheduler-event-loop INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:28.873 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
24/04/16 16:20:28.873 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 18 finished: collect at utils.scala:26, took 0,093548 s
24/04/16 16:20:29.006 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 87.7599 ms
24/04/16 16:20:34.188 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.6777 ms
24/04/16 16:20:34.225 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:20:34.226 dag-scheduler-event-loop INFO DAGScheduler: Got job 19 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:20:34.226 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:26)
24/04/16 16:20:34.226 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:34.226 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:34.227 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[86] at collect at utils.scala:26), which has no missing parents
24/04/16 16:20:34.233 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 373.1 KiB, free 910.7 MiB)
24/04/16 16:20:34.235 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 75.3 KiB, free 910.6 MiB)
24/04/16 16:20:34.235 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 75.3 KiB, free: 911.5 MiB)
24/04/16 16:20:34.235 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:34.236 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[86] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:34.236 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
24/04/16 16:20:34.237 dispatcher-event-loop-0 WARN TaskSetManager: Stage 24 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:34.237 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:20:34.237 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
24/04/16 16:20:34.254 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:20:34.470 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 4805 bytes result sent to driver
24/04/16 16:20:34.486 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 249 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:34.486 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
24/04/16 16:20:34.487 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 24 (collect at utils.scala:26) finished in 0,260 s
24/04/16 16:20:34.487 dag-scheduler-event-loop INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:34.487 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
24/04/16 16:20:34.487 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 19 finished: collect at utils.scala:26, took 0,261931 s
24/04/16 16:20:34.488 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.6677 ms
24/04/16 16:20:34.987 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.0678 ms
24/04/16 16:20:35.005 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 93 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
24/04/16 16:20:35.005 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 20 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:20:35.005 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:20:35.005 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:35.005 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:35.005 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:20:35.024 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 129.6 KiB, free 910.5 MiB)
24/04/16 16:20:35.025 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 910.4 MiB)
24/04/16 16:20:35.026 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 33.9 KiB, free: 911.5 MiB)
24/04/16 16:20:35.026 dag-scheduler-event-loop INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:35.027 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:35.027 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
24/04/16 16:20:35.038 dispatcher-event-loop-1 WARN TaskSetManager: Stage 25 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:35.038 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:20:35.039 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
24/04/16 16:20:35.053 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:20:35.178 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO CodeGenerator: Code generated in 5.6466 ms
24/04/16 16:20:35.243 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2395 bytes result sent to driver
24/04/16 16:20:35.253 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 225 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:35.253 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
24/04/16 16:20:35.254 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0,249 s
24/04/16 16:20:35.255 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:20:35.255 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:20:35.255 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 16:20:35.255 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:20:35.295 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.742 ms
24/04/16 16:20:35.321 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 16:20:35.321 dag-scheduler-event-loop INFO DAGScheduler: Got job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:20:35.322 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 27 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:20:35.322 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
24/04/16 16:20:35.322 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:35.322 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[96] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:20:35.325 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 12.1 KiB, free 910.4 MiB)
24/04/16 16:20:35.326 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.4 MiB)
24/04/16 16:20:35.326 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 16:20:35.326 dag-scheduler-event-loop INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:35.327 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[96] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:35.327 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
24/04/16 16:20:35.328 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 26) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 16:20:35.329 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO Executor: Running task 0.0 in stage 27.0 (TID 26)
24/04/16 16:20:35.335 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:20:35.335 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:20:35.343 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO Executor: Finished task 0.0 in stage 27.0 (TID 26). 3909 bytes result sent to driver
24/04/16 16:20:35.344 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 26) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:35.344 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
24/04/16 16:20:35.344 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0,021 s
24/04/16 16:20:35.345 dag-scheduler-event-loop INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:35.345 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
24/04/16 16:20:35.345 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 21 finished: count at NativeMethodAccessorImpl.java:0, took 0,024357 s
24/04/16 16:20:35.636 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_32_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 33.9 KiB, free: 911.5 MiB)
24/04/16 16:20:35.639 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_33_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 16:20:35.707 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.6242 ms
24/04/16 16:20:35.722 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 103 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
24/04/16 16:20:35.722 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:20:35.722 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:20:35.723 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:35.723 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:35.723 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[103] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:20:35.729 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 129.6 KiB, free 910.5 MiB)
24/04/16 16:20:35.731 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 910.4 MiB)
24/04/16 16:20:35.731 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 33.9 KiB, free: 911.5 MiB)
24/04/16 16:20:35.732 dag-scheduler-event-loop INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:35.732 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[103] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:35.732 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
24/04/16 16:20:35.736 dispatcher-event-loop-1 WARN TaskSetManager: Stage 28 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:20:35.736 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 27) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:20:35.736 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO Executor: Running task 0.0 in stage 28.0 (TID 27)
24/04/16 16:20:35.751 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:20:35.838 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO Executor: Finished task 0.0 in stage 28.0 (TID 27). 2438 bytes result sent to driver
24/04/16 16:20:35.838 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 27) in 105 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:35.838 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
24/04/16 16:20:35.838 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 0,114 s
24/04/16 16:20:35.838 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:20:35.838 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:20:35.838 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 16:20:35.838 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:20:35.866 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 16:20:35.867 dag-scheduler-event-loop INFO DAGScheduler: Got job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:20:35.867 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:20:35.867 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
24/04/16 16:20:35.867 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:35.867 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:20:35.869 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 12.1 KiB, free 910.4 MiB)
24/04/16 16:20:35.870 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.4 MiB)
24/04/16 16:20:35.870 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 16:20:35.871 dag-scheduler-event-loop INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:35.871 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:35.871 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
24/04/16 16:20:35.872 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 28) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 16:20:35.872 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO Executor: Running task 0.0 in stage 30.0 (TID 28)
24/04/16 16:20:35.874 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:20:35.874 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:20:35.876 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO Executor: Finished task 0.0 in stage 30.0 (TID 28). 3909 bytes result sent to driver
24/04/16 16:20:35.876 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 28) in 5 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:35.876 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
24/04/16 16:20:35.877 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:0) finished in 0,009 s
24/04/16 16:20:35.877 dag-scheduler-event-loop INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:35.877 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
24/04/16 16:20:35.877 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 23 finished: count at NativeMethodAccessorImpl.java:0, took 0,010862 s
24/04/16 16:20:37.235 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:20:37.235 dag-scheduler-event-loop INFO DAGScheduler: Got job 24 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:20:37.235 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:26)
24/04/16 16:20:37.235 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:37.235 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:37.235 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[109] at collect at utils.scala:26), which has no missing parents
24/04/16 16:20:37.235 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 62.4 KiB, free 910.4 MiB)
24/04/16 16:20:37.235 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.3 MiB)
24/04/16 16:20:37.235 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:20:37.235 dag-scheduler-event-loop INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:37.235 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[109] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:37.235 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
24/04/16 16:20:37.235 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 29) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:20:37.235 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO Executor: Running task 0.0 in stage 31.0 (TID 29)
24/04/16 16:20:37.269 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO Executor: Finished task 0.0 in stage 31.0 (TID 29). 1430 bytes result sent to driver
24/04/16 16:20:37.269 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 29) in 34 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:37.269 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
24/04/16 16:20:37.270 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 31 (collect at utils.scala:26) finished in 0,035 s
24/04/16 16:20:37.270 dag-scheduler-event-loop INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:37.270 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
24/04/16 16:20:37.270 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 24 finished: collect at utils.scala:26, took 0,031335 s
24/04/16 16:20:39.687 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_34_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 33.9 KiB, free: 911.5 MiB)
24/04/16 16:20:39.691 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 16:20:39.694 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_35_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 16:20:40.823 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:20:40.824 dag-scheduler-event-loop INFO DAGScheduler: Got job 25 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:20:40.824 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:26)
24/04/16 16:20:40.824 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:40.824 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:40.824 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[112] at collect at utils.scala:26), which has no missing parents
24/04/16 16:20:40.826 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 62.4 KiB, free 910.5 MiB)
24/04/16 16:20:40.827 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.5 MiB)
24/04/16 16:20:40.827 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 16:20:40.827 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:40.828 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[112] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:40.828 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
24/04/16 16:20:40.828 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 30) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:20:40.828 Executor task launch worker for task 0.0 in stage 32.0 (TID 30) INFO Executor: Running task 0.0 in stage 32.0 (TID 30)
24/04/16 16:20:40.849 Executor task launch worker for task 0.0 in stage 32.0 (TID 30) INFO Executor: Finished task 0.0 in stage 32.0 (TID 30). 1387 bytes result sent to driver
24/04/16 16:20:40.849 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 30) in 21 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:40.849 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
24/04/16 16:20:40.849 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 32 (collect at utils.scala:26) finished in 0,024 s
24/04/16 16:20:40.849 dag-scheduler-event-loop INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:40.849 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
24/04/16 16:20:40.849 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 25 finished: collect at utils.scala:26, took 0,028494 s
24/04/16 16:20:58.261 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:20:58.261 dag-scheduler-event-loop INFO DAGScheduler: Got job 26 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:20:58.261 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:26)
24/04/16 16:20:58.261 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:20:58.261 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:20:58.261 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[115] at collect at utils.scala:26), which has no missing parents
24/04/16 16:20:58.261 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 62.4 KiB, free 910.5 MiB)
24/04/16 16:20:58.261 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.4 MiB)
24/04/16 16:20:58.261 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 16:20:58.261 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1535
24/04/16 16:20:58.261 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[115] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:20:58.261 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
24/04/16 16:20:58.261 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 31) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:20:58.261 Executor task launch worker for task 0.0 in stage 33.0 (TID 31) INFO Executor: Running task 0.0 in stage 33.0 (TID 31)
24/04/16 16:20:58.293 Executor task launch worker for task 0.0 in stage 33.0 (TID 31) INFO Executor: Finished task 0.0 in stage 33.0 (TID 31). 1430 bytes result sent to driver
24/04/16 16:20:58.294 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 31) in 33 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:20:58.295 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
24/04/16 16:20:58.295 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 33 (collect at utils.scala:26) finished in 0,034 s
24/04/16 16:20:58.295 dag-scheduler-event-loop INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:20:58.295 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
24/04/16 16:20:58.295 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 26 finished: collect at utils.scala:26, took 0,029139 s
24/04/16 16:21:00.696 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 16:21:00.699 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_38_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 16:21:01.608 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:21:01.608 dag-scheduler-event-loop INFO DAGScheduler: Got job 27 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:21:01.608 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:26)
24/04/16 16:21:01.608 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:21:01.608 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:01.608 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[118] at collect at utils.scala:26), which has no missing parents
24/04/16 16:21:01.608 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 62.4 KiB, free 910.5 MiB)
24/04/16 16:21:01.608 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.5 MiB)
24/04/16 16:21:01.608 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 16:21:01.608 dag-scheduler-event-loop INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:01.608 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[118] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:21:01.608 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
24/04/16 16:21:01.608 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 32) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:21:01.608 Executor task launch worker for task 0.0 in stage 34.0 (TID 32) INFO Executor: Running task 0.0 in stage 34.0 (TID 32)
24/04/16 16:21:01.641 Executor task launch worker for task 0.0 in stage 34.0 (TID 32) INFO Executor: Finished task 0.0 in stage 34.0 (TID 32). 1430 bytes result sent to driver
24/04/16 16:21:01.643 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 32) in 35 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:21:01.643 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
24/04/16 16:21:01.643 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 34 (collect at utils.scala:26) finished in 0,035 s
24/04/16 16:21:01.643 dag-scheduler-event-loop INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:01.643 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
24/04/16 16:21:01.643 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 27 finished: collect at utils.scala:26, took 0,029925 s
24/04/16 16:21:07.891 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_39_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 16:21:07.921 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:21:07.921 dag-scheduler-event-loop INFO DAGScheduler: Got job 28 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:21:07.921 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:26)
24/04/16 16:21:07.921 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:21:07.921 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:07.921 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[121] at collect at utils.scala:26), which has no missing parents
24/04/16 16:21:07.921 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 62.4 KiB, free 910.5 MiB)
24/04/16 16:21:07.921 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.5 MiB)
24/04/16 16:21:07.921 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 16:21:07.921 dag-scheduler-event-loop INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:07.921 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[121] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:21:07.921 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
24/04/16 16:21:07.921 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 33) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:21:07.921 Executor task launch worker for task 0.0 in stage 35.0 (TID 33) INFO Executor: Running task 0.0 in stage 35.0 (TID 33)
24/04/16 16:21:07.940 Executor task launch worker for task 0.0 in stage 35.0 (TID 33) INFO Executor: Finished task 0.0 in stage 35.0 (TID 33). 1430 bytes result sent to driver
24/04/16 16:21:07.940 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 33) in 19 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:21:07.940 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
24/04/16 16:21:07.940 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 35 (collect at utils.scala:26) finished in 0,019 s
24/04/16 16:21:07.940 dag-scheduler-event-loop INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:07.940 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
24/04/16 16:21:07.940 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 28 finished: collect at utils.scala:26, took 0,029662 s
24/04/16 16:21:10.592 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.9006 ms
24/04/16 16:21:10.622 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 24.8434 ms
24/04/16 16:21:10.642 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.0114 ms
24/04/16 16:21:10.679 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 136 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8
24/04/16 16:21:10.679 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 29 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/16 16:21:10.679 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 36 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:21:10.679 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:21:10.679 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:10.679 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[136] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:21:10.691 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 226.3 KiB, free 910.3 MiB)
24/04/16 16:21:10.692 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 57.1 KiB, free 910.2 MiB)
24/04/16 16:21:10.693 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 57.1 KiB, free: 911.4 MiB)
24/04/16 16:21:10.693 dag-scheduler-event-loop INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:10.693 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[136] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:10.694 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 36.0 with 2 tasks resource profile 0
24/04/16 16:21:10.704 dispatcher-event-loop-0 WARN TaskSetManager: Stage 36 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:10.704 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 34) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 16:21:10.705 Executor task launch worker for task 0.0 in stage 36.0 (TID 34) INFO Executor: Running task 0.0 in stage 36.0 (TID 34)
24/04/16 16:21:10.705 Executor task launch worker for task 0.0 in stage 36.0 (TID 34) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:10.766 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_40_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:21:10.875 Executor task launch worker for task 0.0 in stage 36.0 (TID 34) INFO Executor: Finished task 0.0 in stage 36.0 (TID 34). 3054 bytes result sent to driver
24/04/16 16:21:10.887 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 35) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 16:21:10.888 Executor task launch worker for task 1.0 in stage 36.0 (TID 35) INFO Executor: Running task 1.0 in stage 36.0 (TID 35)
24/04/16 16:21:10.888 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 34) in 194 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:10.894 Executor task launch worker for task 1.0 in stage 36.0 (TID 35) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:11.009 Executor task launch worker for task 1.0 in stage 36.0 (TID 35) INFO Executor: Finished task 1.0 in stage 36.0 (TID 35). 3011 bytes result sent to driver
24/04/16 16:21:11.009 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 35) in 133 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:11.009 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
24/04/16 16:21:11.009 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 36 (count at NativeMethodAccessorImpl.java:0) finished in 0,329 s
24/04/16 16:21:11.009 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:21:11.009 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:21:11.009 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 16:21:11.009 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:21:11.030 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.9293 ms
24/04/16 16:21:11.036 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 16:21:11.038 dag-scheduler-event-loop INFO DAGScheduler: Got job 30 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:21:11.038 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 38 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:21:11.038 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
24/04/16 16:21:11.038 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:11.038 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[139] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:21:11.039 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 12.1 KiB, free 910.3 MiB)
24/04/16 16:21:11.040 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.3 MiB)
24/04/16 16:21:11.041 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 5.8 KiB, free: 911.4 MiB)
24/04/16 16:21:11.041 dag-scheduler-event-loop INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:11.041 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[139] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:21:11.041 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
24/04/16 16:21:11.042 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 36) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 16:21:11.042 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO Executor: Running task 0.0 in stage 38.0 (TID 36)
24/04/16 16:21:11.043 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:11.044 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:11.048 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO Executor: Finished task 0.0 in stage 38.0 (TID 36). 3866 bytes result sent to driver
24/04/16 16:21:11.048 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 36) in 6 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:21:11.048 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
24/04/16 16:21:11.049 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 38 (count at NativeMethodAccessorImpl.java:0) finished in 0,010 s
24/04/16 16:21:11.049 dag-scheduler-event-loop INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:11.049 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
24/04/16 16:21:11.049 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 30 finished: count at NativeMethodAccessorImpl.java:0, took 0,011521 s
24/04/16 16:21:11.453 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_41_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 57.1 KiB, free: 911.5 MiB)
24/04/16 16:21:11.468 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_42_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 16:21:11.472 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.8375 ms
24/04/16 16:21:11.498 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.2507 ms
24/04/16 16:21:11.510 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 154 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9
24/04/16 16:21:11.510 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 31 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/16 16:21:11.510 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:21:11.510 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:21:11.511 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:11.511 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[154] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:21:11.517 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 226.3 KiB, free 910.4 MiB)
24/04/16 16:21:11.518 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 57.2 KiB, free 910.3 MiB)
24/04/16 16:21:11.519 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 57.2 KiB, free: 911.4 MiB)
24/04/16 16:21:11.519 dag-scheduler-event-loop INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:11.519 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[154] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:11.519 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 39.0 with 2 tasks resource profile 0
24/04/16 16:21:11.520 dispatcher-event-loop-0 WARN TaskSetManager: Stage 39 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:11.520 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 37) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 16:21:11.520 Executor task launch worker for task 0.0 in stage 39.0 (TID 37) INFO Executor: Running task 0.0 in stage 39.0 (TID 37)
24/04/16 16:21:11.520 Executor task launch worker for task 0.0 in stage 39.0 (TID 37) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:11.622 Executor task launch worker for task 0.0 in stage 39.0 (TID 37) INFO Executor: Finished task 0.0 in stage 39.0 (TID 37). 3011 bytes result sent to driver
24/04/16 16:21:11.630 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 38) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 16:21:11.631 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 37) in 111 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:11.631 Executor task launch worker for task 1.0 in stage 39.0 (TID 38) INFO Executor: Running task 1.0 in stage 39.0 (TID 38)
24/04/16 16:21:11.639 Executor task launch worker for task 1.0 in stage 39.0 (TID 38) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:11.746 Executor task launch worker for task 1.0 in stage 39.0 (TID 38) INFO Executor: Finished task 1.0 in stage 39.0 (TID 38). 3011 bytes result sent to driver
24/04/16 16:21:11.747 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 38) in 125 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:11.747 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
24/04/16 16:21:11.747 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0) finished in 0,236 s
24/04/16 16:21:11.747 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:21:11.748 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:21:11.748 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 16:21:11.748 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:21:11.773 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 16:21:11.774 dag-scheduler-event-loop INFO DAGScheduler: Got job 32 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:21:11.774 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 41 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:21:11.774 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
24/04/16 16:21:11.774 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:11.774 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[157] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:21:11.776 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 12.1 KiB, free 910.3 MiB)
24/04/16 16:21:11.778 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.3 MiB)
24/04/16 16:21:11.778 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 5.8 KiB, free: 911.4 MiB)
24/04/16 16:21:11.779 dag-scheduler-event-loop INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:11.779 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[157] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:21:11.779 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
24/04/16 16:21:11.780 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 39) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 16:21:11.780 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO Executor: Running task 0.0 in stage 41.0 (TID 39)
24/04/16 16:21:11.782 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:11.782 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:11.785 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO Executor: Finished task 0.0 in stage 41.0 (TID 39). 3909 bytes result sent to driver
24/04/16 16:21:11.786 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 39) in 6 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:21:11.786 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
24/04/16 16:21:11.787 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 41 (count at NativeMethodAccessorImpl.java:0) finished in 0,012 s
24/04/16 16:21:11.787 dag-scheduler-event-loop INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:11.787 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
24/04/16 16:21:11.787 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 32 finished: count at NativeMethodAccessorImpl.java:0, took 0,013555 s
24/04/16 16:21:12.496 nioEventLoopGroup-2-2 INFO Instrumentation: [37401b3a] training finished
24/04/16 16:21:12.727 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_43_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 57.2 KiB, free: 911.5 MiB)
24/04/16 16:21:12.727 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_44_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 5.8 KiB, free: 911.5 MiB)
24/04/16 16:21:12.917 nioEventLoopGroup-2-2 INFO Instrumentation: [b8c7f575] training finished
24/04/16 16:21:13.337 nioEventLoopGroup-2-2 INFO Instrumentation: [a311ca8f] Stage class: RandomForestRegressor
24/04/16 16:21:13.337 nioEventLoopGroup-2-2 INFO Instrumentation: [a311ca8f] Stage uid: random_forest__35620b0d_5f24_473c_a88d_b5416a542357
24/04/16 16:21:13.337 nioEventLoopGroup-2-2 INFO Instrumentation: [a311ca8f] training: numPartitions=2 storageLevel=StorageLevel(1 replicas)
24/04/16 16:21:13.353 nioEventLoopGroup-2-2 INFO Instrumentation: [a311ca8f] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/16 16:21:13.386 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 16:21:13.386 dag-scheduler-event-loop INFO DAGScheduler: Got job 33 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 16:21:13.386 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 42 (take at DecisionTreeMetadata.scala:119)
24/04/16 16:21:13.386 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:21:13.386 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:13.386 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[180] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 16:21:13.404 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 521.9 KiB, free 910.1 MiB)
24/04/16 16:21:13.404 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 117.5 KiB, free 910.0 MiB)
24/04/16 16:21:13.404 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 117.5 KiB, free: 911.4 MiB)
24/04/16 16:21:13.404 dag-scheduler-event-loop INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:13.404 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[180] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 16:21:13.404 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
24/04/16 16:21:13.404 dispatcher-event-loop-0 WARN TaskSetManager: Stage 42 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:13.404 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 40) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 16:21:13.404 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO Executor: Running task 0.0 in stage 42.0 (TID 40)
24/04/16 16:21:13.426 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:13.503 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO CodeGenerator: Code generated in 2.6352 ms
24/04/16 16:21:13.586 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO CodeGenerator: Code generated in 55.5815 ms
24/04/16 16:21:13.595 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO Executor: Finished task 0.0 in stage 42.0 (TID 40). 1993 bytes result sent to driver
24/04/16 16:21:13.596 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 40) in 192 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:21:13.596 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
24/04/16 16:21:13.597 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 42 (take at DecisionTreeMetadata.scala:119) finished in 0,211 s
24/04/16 16:21:13.597 dag-scheduler-event-loop INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:13.597 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
24/04/16 16:21:13.597 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 33 finished: take at DecisionTreeMetadata.scala:119, took 0,205125 s
24/04/16 16:21:13.601 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 16:21:13.603 dag-scheduler-event-loop INFO DAGScheduler: Got job 34 (aggregate at DecisionTreeMetadata.scala:125) with 2 output partitions
24/04/16 16:21:13.603 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 43 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 16:21:13.603 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:21:13.603 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:13.603 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[179] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 16:21:13.603 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 521.9 KiB, free 909.5 MiB)
24/04/16 16:21:13.603 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 117.6 KiB, free 909.3 MiB)
24/04/16 16:21:13.603 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 117.6 KiB, free: 911.3 MiB)
24/04/16 16:21:13.603 dag-scheduler-event-loop INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:13.603 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 43 (MapPartitionsRDD[179] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:13.603 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks resource profile 0
24/04/16 16:21:13.618 dispatcher-event-loop-1 WARN TaskSetManager: Stage 43 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:13.618 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 41) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 16:21:13.618 Executor task launch worker for task 0.0 in stage 43.0 (TID 41) INFO Executor: Running task 0.0 in stage 43.0 (TID 41)
24/04/16 16:21:13.637 Executor task launch worker for task 0.0 in stage 43.0 (TID 41) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:13.745 Executor task launch worker for task 0.0 in stage 43.0 (TID 41) INFO Executor: Finished task 0.0 in stage 43.0 (TID 41). 2108 bytes result sent to driver
24/04/16 16:21:13.755 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 42) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 16:21:13.756 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO Executor: Running task 1.0 in stage 43.0 (TID 42)
24/04/16 16:21:13.756 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 41) in 153 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:13.768 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:13.825 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO CodeGenerator: Code generated in 2.4895 ms
24/04/16 16:21:13.891 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO Executor: Finished task 1.0 in stage 43.0 (TID 42). 2108 bytes result sent to driver
24/04/16 16:21:13.891 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 42) in 145 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:13.891 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
24/04/16 16:21:13.892 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 43 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,289 s
24/04/16 16:21:13.892 dag-scheduler-event-loop INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:13.892 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
24/04/16 16:21:13.892 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 34 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,290507 s
24/04/16 16:21:13.903 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 16:21:13.903 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 182 (flatMap at RandomForest.scala:1039) as input to shuffle 10
24/04/16 16:21:13.903 dag-scheduler-event-loop INFO DAGScheduler: Got job 35 (collectAsMap at RandomForest.scala:1054) with 2 output partitions
24/04/16 16:21:13.903 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 45 (collectAsMap at RandomForest.scala:1054)
24/04/16 16:21:13.903 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
24/04/16 16:21:13.903 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
24/04/16 16:21:13.903 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[182] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 16:21:13.903 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 531.0 KiB, free 908.8 MiB)
24/04/16 16:21:13.903 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 121.3 KiB, free 908.7 MiB)
24/04/16 16:21:13.903 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 121.3 KiB, free: 911.2 MiB)
24/04/16 16:21:13.918 dag-scheduler-event-loop INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:13.918 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[182] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:13.918 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 44.0 with 2 tasks resource profile 0
24/04/16 16:21:13.918 dispatcher-event-loop-0 WARN TaskSetManager: Stage 44 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:13.918 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 43) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:13.918 Executor task launch worker for task 0.0 in stage 44.0 (TID 43) INFO Executor: Running task 0.0 in stage 44.0 (TID 43)
24/04/16 16:21:13.936 Executor task launch worker for task 0.0 in stage 44.0 (TID 43) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:14.078 Executor task launch worker for task 0.0 in stage 44.0 (TID 43) INFO Executor: Finished task 0.0 in stage 44.0 (TID 43). 2248 bytes result sent to driver
24/04/16 16:21:14.086 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 44) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:14.087 Executor task launch worker for task 1.0 in stage 44.0 (TID 44) INFO Executor: Running task 1.0 in stage 44.0 (TID 44)
24/04/16 16:21:14.087 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 43) in 169 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:14.088 Executor task launch worker for task 1.0 in stage 44.0 (TID 44) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:14.435 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_45_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 117.5 KiB, free: 911.3 MiB)
24/04/16 16:21:14.451 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 6.5 KiB, free: 911.3 MiB)
24/04/16 16:21:14.453 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 75.3 KiB, free: 911.3 MiB)
24/04/16 16:21:14.453 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_46_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 117.6 KiB, free: 911.5 MiB)
24/04/16 16:21:14.453 block-manager-storage-async-thread-pool-72 INFO BlockManager: Removing RDD 57
24/04/16 16:21:14.453 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 16:21:14.502 Executor task launch worker for task 1.0 in stage 44.0 (TID 44) INFO Executor: Finished task 1.0 in stage 44.0 (TID 44). 2291 bytes result sent to driver
24/04/16 16:21:14.502 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 44) in 424 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:14.502 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
24/04/16 16:21:14.502 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 44 (flatMap at RandomForest.scala:1039) finished in 0,599 s
24/04/16 16:21:14.502 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:21:14.502 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:21:14.502 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 45)
24/04/16 16:21:14.502 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:21:14.502 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[184] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 16:21:14.518 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 11.9 KiB, free 910.5 MiB)
24/04/16 16:21:14.518 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 910.5 MiB)
24/04/16 16:21:14.518 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 4.5 KiB, free: 911.5 MiB)
24/04/16 16:21:14.518 dag-scheduler-event-loop INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:14.518 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[184] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:14.518 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks resource profile 0
24/04/16 16:21:14.518 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 45) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:14.518 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO Executor: Running task 0.0 in stage 45.0 (TID 45)
24/04/16 16:21:14.518 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO ShuffleBlockFetcherIterator: Getting 2 (31.9 KiB) non-empty blocks including 2 (31.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:14.518 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:14.537 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO Executor: Finished task 0.0 in stage 45.0 (TID 45). 21098 bytes result sent to driver
24/04/16 16:21:14.537 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 46) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:14.537 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO Executor: Running task 1.0 in stage 45.0 (TID 46)
24/04/16 16:21:14.537 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 45) in 19 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:14.537 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO ShuffleBlockFetcherIterator: Getting 2 (30.1 KiB) non-empty blocks including 2 (30.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:14.537 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:14.563 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO Executor: Finished task 1.0 in stage 45.0 (TID 46). 19963 bytes result sent to driver
24/04/16 16:21:14.563 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 46) in 26 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:14.563 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
24/04/16 16:21:14.564 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 45 (collectAsMap at RandomForest.scala:1054) finished in 0,046 s
24/04/16 16:21:14.564 dag-scheduler-event-loop INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:14.564 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
24/04/16 16:21:14.564 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 35 finished: collectAsMap at RandomForest.scala:1054, took 0,657346 s
24/04/16 16:21:14.566 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 46.3 KiB, free 910.4 MiB)
24/04/16 16:21:14.568 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 910.4 MiB)
24/04/16 16:21:14.568 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 7.8 KiB, free: 911.5 MiB)
24/04/16 16:21:14.569 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 49 from broadcast at RandomForest.scala:293
24/04/16 16:21:14.569 nioEventLoopGroup-2-2 INFO Instrumentation: [a311ca8f] {"numFeatures":545}
24/04/16 16:21:14.570 nioEventLoopGroup-2-2 INFO Instrumentation: [a311ca8f] {"numClasses":0}
24/04/16 16:21:14.570 nioEventLoopGroup-2-2 INFO Instrumentation: [a311ca8f] {"numExamples":145}
24/04/16 16:21:14.570 nioEventLoopGroup-2-2 INFO Instrumentation: [a311ca8f] {"sumOfWeights":145.0}
24/04/16 16:21:14.572 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 16.1 KiB, free 910.4 MiB)
24/04/16 16:21:14.573 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 910.4 MiB)
24/04/16 16:21:14.573 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 10.3 KiB, free: 911.5 MiB)
24/04/16 16:21:14.573 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 50 from broadcast at RandomForest.scala:622
24/04/16 16:21:14.585 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:21:14.585 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 187 (mapPartitions at RandomForest.scala:644) as input to shuffle 11
24/04/16 16:21:14.585 dag-scheduler-event-loop INFO DAGScheduler: Got job 36 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 16:21:14.585 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 47 (collectAsMap at RandomForest.scala:663)
24/04/16 16:21:14.585 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
24/04/16 16:21:14.585 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
24/04/16 16:21:14.585 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[187] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:21:14.585 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 561.5 KiB, free 909.8 MiB)
24/04/16 16:21:14.585 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 133.6 KiB, free 909.7 MiB)
24/04/16 16:21:14.585 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 133.6 KiB, free: 911.3 MiB)
24/04/16 16:21:14.585 dag-scheduler-event-loop INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:14.585 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[187] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:14.585 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 46.0 with 2 tasks resource profile 0
24/04/16 16:21:14.603 dispatcher-event-loop-0 WARN TaskSetManager: Stage 46 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:14.603 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 47) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:14.604 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO Executor: Running task 0.0 in stage 46.0 (TID 47)
24/04/16 16:21:14.604 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:14.711 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO MemoryStore: Block rdd_186_0 stored as values in memory (estimated size 170.9 KiB, free 909.6 MiB)
24/04/16 16:21:14.712 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_186_0 in memory on DESKTOP-LH06ASP:62831 (size: 170.9 KiB, free: 911.2 MiB)
24/04/16 16:21:14.730 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO Executor: Finished task 0.0 in stage 46.0 (TID 47). 2248 bytes result sent to driver
24/04/16 16:21:14.736 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 48) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:14.736 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 47) in 151 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:14.736 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO Executor: Running task 1.0 in stage 46.0 (TID 48)
24/04/16 16:21:14.736 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:14.833 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_48_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 4.5 KiB, free: 911.2 MiB)
24/04/16 16:21:14.853 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO MemoryStore: Block rdd_186_1 stored as values in memory (estimated size 163.9 KiB, free 909.4 MiB)
24/04/16 16:21:14.853 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_186_1 in memory on DESKTOP-LH06ASP:62831 (size: 163.9 KiB, free: 911.0 MiB)
24/04/16 16:21:14.853 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO Executor: Finished task 1.0 in stage 46.0 (TID 48). 2291 bytes result sent to driver
24/04/16 16:21:14.869 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 48) in 138 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:14.869 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
24/04/16 16:21:14.870 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 46 (mapPartitions at RandomForest.scala:644) finished in 0,285 s
24/04/16 16:21:14.870 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:21:14.870 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:21:14.870 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 47)
24/04/16 16:21:14.870 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:21:14.870 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[189] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:21:14.871 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 7.4 KiB, free 909.4 MiB)
24/04/16 16:21:14.872 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 909.4 MiB)
24/04/16 16:21:14.872 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 3.8 KiB, free: 911.0 MiB)
24/04/16 16:21:14.872 dag-scheduler-event-loop INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:14.872 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[189] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:14.873 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 47.0 with 2 tasks resource profile 0
24/04/16 16:21:14.873 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:14.873 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO Executor: Running task 0.0 in stage 47.0 (TID 49)
24/04/16 16:21:14.875 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO ShuffleBlockFetcherIterator: Getting 2 (92.9 KiB) non-empty blocks including 2 (92.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:14.875 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:14.882 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO Executor: Finished task 0.0 in stage 47.0 (TID 49). 4197 bytes result sent to driver
24/04/16 16:21:14.882 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 50) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:14.882 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO Executor: Running task 1.0 in stage 47.0 (TID 50)
24/04/16 16:21:14.883 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 9 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:14.884 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO ShuffleBlockFetcherIterator: Getting 2 (88.7 KiB) non-empty blocks including 2 (88.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:14.884 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:14.890 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO Executor: Finished task 1.0 in stage 47.0 (TID 50). 4236 bytes result sent to driver
24/04/16 16:21:14.892 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 50) in 10 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:14.892 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
24/04/16 16:21:14.892 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 47 (collectAsMap at RandomForest.scala:663) finished in 0,021 s
24/04/16 16:21:14.892 dag-scheduler-event-loop INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:14.892 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
24/04/16 16:21:14.892 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 36 finished: collectAsMap at RandomForest.scala:663, took 0,307509 s
24/04/16 16:21:14.893 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(50) (from destroy at RandomForest.scala:674)
24/04/16 16:21:14.894 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_50_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 10.3 KiB, free: 911.0 MiB)
24/04/16 16:21:14.896 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 32.6 KiB, free 909.4 MiB)
24/04/16 16:21:14.897 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 909.4 MiB)
24/04/16 16:21:14.898 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 20.3 KiB, free: 911.0 MiB)
24/04/16 16:21:14.898 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 53 from broadcast at RandomForest.scala:622
24/04/16 16:21:14.902 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:21:14.902 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 190 (mapPartitions at RandomForest.scala:644) as input to shuffle 12
24/04/16 16:21:14.902 dag-scheduler-event-loop INFO DAGScheduler: Got job 37 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 16:21:14.902 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 49 (collectAsMap at RandomForest.scala:663)
24/04/16 16:21:14.902 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
24/04/16 16:21:14.902 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 48)
24/04/16 16:21:14.902 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[190] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:21:14.920 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 582.5 KiB, free 908.8 MiB)
24/04/16 16:21:14.920 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 146.2 KiB, free 908.7 MiB)
24/04/16 16:21:14.920 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 146.2 KiB, free: 910.8 MiB)
24/04/16 16:21:14.920 dag-scheduler-event-loop INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:14.920 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[190] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:14.920 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 48.0 with 2 tasks resource profile 0
24/04/16 16:21:14.920 dispatcher-event-loop-0 WARN TaskSetManager: Stage 48 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:14.920 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 51) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:14.920 Executor task launch worker for task 0.0 in stage 48.0 (TID 51) INFO Executor: Running task 0.0 in stage 48.0 (TID 51)
24/04/16 16:21:14.941 Executor task launch worker for task 0.0 in stage 48.0 (TID 51) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 16:21:14.956 Executor task launch worker for task 0.0 in stage 48.0 (TID 51) INFO Executor: Finished task 0.0 in stage 48.0 (TID 51). 2205 bytes result sent to driver
24/04/16 16:21:14.962 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 52) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:14.962 Executor task launch worker for task 1.0 in stage 48.0 (TID 52) INFO Executor: Running task 1.0 in stage 48.0 (TID 52)
24/04/16 16:21:14.962 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 51) in 42 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:14.969 Executor task launch worker for task 1.0 in stage 48.0 (TID 52) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 16:21:14.987 Executor task launch worker for task 1.0 in stage 48.0 (TID 52) INFO Executor: Finished task 1.0 in stage 48.0 (TID 52). 2205 bytes result sent to driver
24/04/16 16:21:14.987 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 52) in 31 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:14.987 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
24/04/16 16:21:14.988 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 48 (mapPartitions at RandomForest.scala:644) finished in 0,086 s
24/04/16 16:21:14.988 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:21:14.988 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:21:14.988 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 49)
24/04/16 16:21:14.988 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:21:14.988 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[192] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:21:14.989 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 11.1 KiB, free 908.6 MiB)
24/04/16 16:21:14.990 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 908.6 MiB)
24/04/16 16:21:14.990 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 5.1 KiB, free: 910.8 MiB)
24/04/16 16:21:14.990 dag-scheduler-event-loop INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:14.991 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 49 (MapPartitionsRDD[192] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:14.991 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 49.0 with 2 tasks resource profile 0
24/04/16 16:21:14.991 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 53) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:14.992 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO Executor: Running task 0.0 in stage 49.0 (TID 53)
24/04/16 16:21:14.993 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO ShuffleBlockFetcherIterator: Getting 2 (165.4 KiB) non-empty blocks including 2 (165.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:14.993 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:15.004 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO Executor: Finished task 0.0 in stage 49.0 (TID 53). 6277 bytes result sent to driver
24/04/16 16:21:15.004 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 54) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:15.004 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO Executor: Running task 1.0 in stage 49.0 (TID 54)
24/04/16 16:21:15.005 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 53) in 13 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:15.006 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO ShuffleBlockFetcherIterator: Getting 2 (133.4 KiB) non-empty blocks including 2 (133.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:15.006 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:15.013 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO Executor: Finished task 1.0 in stage 49.0 (TID 54). 6251 bytes result sent to driver
24/04/16 16:21:15.013 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 54) in 9 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:15.014 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
24/04/16 16:21:15.014 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 49 (collectAsMap at RandomForest.scala:663) finished in 0,025 s
24/04/16 16:21:15.014 dag-scheduler-event-loop INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:15.014 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
24/04/16 16:21:15.014 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 37 finished: collectAsMap at RandomForest.scala:663, took 0,104069 s
24/04/16 16:21:15.015 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(53) (from destroy at RandomForest.scala:674)
24/04/16 16:21:15.016 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_53_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 20.3 KiB, free: 910.9 MiB)
24/04/16 16:21:15.018 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 40.9 KiB, free 908.7 MiB)
24/04/16 16:21:15.019 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 25.5 KiB, free 908.6 MiB)
24/04/16 16:21:15.019 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 25.5 KiB, free: 910.8 MiB)
24/04/16 16:21:15.020 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 56 from broadcast at RandomForest.scala:622
24/04/16 16:21:15.032 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:21:15.032 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 193 (mapPartitions at RandomForest.scala:644) as input to shuffle 13
24/04/16 16:21:15.033 dag-scheduler-event-loop INFO DAGScheduler: Got job 38 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 16:21:15.033 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 51 (collectAsMap at RandomForest.scala:663)
24/04/16 16:21:15.033 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
24/04/16 16:21:15.033 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
24/04/16 16:21:15.033 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[193] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:21:15.035 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 600.4 KiB, free 908.0 MiB)
24/04/16 16:21:15.035 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 154.6 KiB, free 907.9 MiB)
24/04/16 16:21:15.035 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 154.6 KiB, free: 910.7 MiB)
24/04/16 16:21:15.035 dag-scheduler-event-loop INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:15.035 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[193] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:15.035 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 50.0 with 2 tasks resource profile 0
24/04/16 16:21:15.053 dispatcher-event-loop-0 WARN TaskSetManager: Stage 50 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:15.054 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 55) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:15.054 Executor task launch worker for task 0.0 in stage 50.0 (TID 55) INFO Executor: Running task 0.0 in stage 50.0 (TID 55)
24/04/16 16:21:15.054 Executor task launch worker for task 0.0 in stage 50.0 (TID 55) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 16:21:15.082 Executor task launch worker for task 0.0 in stage 50.0 (TID 55) INFO Executor: Finished task 0.0 in stage 50.0 (TID 55). 2205 bytes result sent to driver
24/04/16 16:21:15.090 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 56) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:15.090 Executor task launch worker for task 1.0 in stage 50.0 (TID 56) INFO Executor: Running task 1.0 in stage 50.0 (TID 56)
24/04/16 16:21:15.090 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 55) in 55 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:15.101 Executor task launch worker for task 1.0 in stage 50.0 (TID 56) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 16:21:15.102 Executor task launch worker for task 1.0 in stage 50.0 (TID 56) INFO Executor: Finished task 1.0 in stage 50.0 (TID 56). 2205 bytes result sent to driver
24/04/16 16:21:15.117 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 56) in 34 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:15.117 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
24/04/16 16:21:15.117 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 50 (mapPartitions at RandomForest.scala:644) finished in 0,083 s
24/04/16 16:21:15.117 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:21:15.117 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:21:15.117 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 51)
24/04/16 16:21:15.117 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:21:15.117 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[195] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:21:15.117 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 12.1 KiB, free 907.9 MiB)
24/04/16 16:21:15.117 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 907.9 MiB)
24/04/16 16:21:15.117 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 5.3 KiB, free: 910.7 MiB)
24/04/16 16:21:15.117 dag-scheduler-event-loop INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:15.117 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (MapPartitionsRDD[195] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:15.117 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks resource profile 0
24/04/16 16:21:15.117 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 57) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:15.117 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO Executor: Running task 0.0 in stage 51.0 (TID 57)
24/04/16 16:21:15.117 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO ShuffleBlockFetcherIterator: Getting 2 (165.4 KiB) non-empty blocks including 2 (165.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:15.117 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:15.117 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO Executor: Finished task 0.0 in stage 51.0 (TID 57). 7356 bytes result sent to driver
24/04/16 16:21:15.133 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 58) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:15.133 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO Executor: Running task 1.0 in stage 51.0 (TID 58)
24/04/16 16:21:15.133 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 57) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:15.135 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO ShuffleBlockFetcherIterator: Getting 2 (172.8 KiB) non-empty blocks including 2 (172.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:15.135 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:15.136 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO Executor: Finished task 1.0 in stage 51.0 (TID 58). 7399 bytes result sent to driver
24/04/16 16:21:15.136 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 58) in 3 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:15.136 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
24/04/16 16:21:15.136 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 51 (collectAsMap at RandomForest.scala:663) finished in 0,019 s
24/04/16 16:21:15.136 dag-scheduler-event-loop INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:15.136 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
24/04/16 16:21:15.136 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 38 finished: collectAsMap at RandomForest.scala:663, took 0,113354 s
24/04/16 16:21:15.136 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at RandomForest.scala:674)
24/04/16 16:21:15.136 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_56_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 25.5 KiB, free: 910.7 MiB)
24/04/16 16:21:15.136 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 31.8 KiB, free 907.9 MiB)
24/04/16 16:21:15.136 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 907.9 MiB)
24/04/16 16:21:15.136 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 19.8 KiB, free: 910.7 MiB)
24/04/16 16:21:15.136 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 59 from broadcast at RandomForest.scala:622
24/04/16 16:21:15.163 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:21:15.164 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 196 (mapPartitions at RandomForest.scala:644) as input to shuffle 14
24/04/16 16:21:15.164 dag-scheduler-event-loop INFO DAGScheduler: Got job 39 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 16:21:15.164 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 53 (collectAsMap at RandomForest.scala:663)
24/04/16 16:21:15.164 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
24/04/16 16:21:15.164 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
24/04/16 16:21:15.165 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[196] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:21:15.175 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 605.3 KiB, free 907.3 MiB)
24/04/16 16:21:15.177 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 152.0 KiB, free 907.2 MiB)
24/04/16 16:21:15.177 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 152.0 KiB, free: 910.5 MiB)
24/04/16 16:21:15.177 dag-scheduler-event-loop INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:15.178 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[196] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:15.178 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 52.0 with 2 tasks resource profile 0
24/04/16 16:21:15.185 dispatcher-event-loop-0 WARN TaskSetManager: Stage 52 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:15.185 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 59) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:15.185 Executor task launch worker for task 0.0 in stage 52.0 (TID 59) INFO Executor: Running task 0.0 in stage 52.0 (TID 59)
24/04/16 16:21:15.185 Executor task launch worker for task 0.0 in stage 52.0 (TID 59) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 16:21:15.203 Executor task launch worker for task 0.0 in stage 52.0 (TID 59) INFO Executor: Finished task 0.0 in stage 52.0 (TID 59). 2205 bytes result sent to driver
24/04/16 16:21:15.224 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_55_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 5.1 KiB, free: 910.5 MiB)
24/04/16 16:21:15.224 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 60) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:15.225 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 59) in 47 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:15.225 Executor task launch worker for task 1.0 in stage 52.0 (TID 60) INFO Executor: Running task 1.0 in stage 52.0 (TID 60)
24/04/16 16:21:15.226 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_52_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 3.8 KiB, free: 910.5 MiB)
24/04/16 16:21:15.228 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_58_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 5.3 KiB, free: 910.5 MiB)
24/04/16 16:21:15.232 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_54_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 146.2 KiB, free: 910.7 MiB)
24/04/16 16:21:15.233 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_57_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 154.6 KiB, free: 910.8 MiB)
24/04/16 16:21:15.243 Executor task launch worker for task 1.0 in stage 52.0 (TID 60) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 16:21:15.252 Executor task launch worker for task 1.0 in stage 52.0 (TID 60) INFO Executor: Finished task 1.0 in stage 52.0 (TID 60). 2205 bytes result sent to driver
24/04/16 16:21:15.252 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 60) in 49 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:15.252 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
24/04/16 16:21:15.252 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 52 (mapPartitions at RandomForest.scala:644) finished in 0,087 s
24/04/16 16:21:15.252 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:21:15.252 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:21:15.252 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 53)
24/04/16 16:21:15.252 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:21:15.252 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[198] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:21:15.252 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 11.0 KiB, free 908.6 MiB)
24/04/16 16:21:15.252 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 908.6 MiB)
24/04/16 16:21:15.252 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 5.0 KiB, free: 910.8 MiB)
24/04/16 16:21:15.252 dag-scheduler-event-loop INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:15.252 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[198] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:15.252 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 53.0 with 2 tasks resource profile 0
24/04/16 16:21:15.252 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 61) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:15.252 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO Executor: Running task 0.0 in stage 53.0 (TID 61)
24/04/16 16:21:15.252 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO ShuffleBlockFetcherIterator: Getting 2 (124.2 KiB) non-empty blocks including 2 (124.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:15.252 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:15.267 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO Executor: Finished task 0.0 in stage 53.0 (TID 61). 6316 bytes result sent to driver
24/04/16 16:21:15.267 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 62) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:15.267 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO Executor: Running task 1.0 in stage 53.0 (TID 62)
24/04/16 16:21:15.267 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 61) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:15.267 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO ShuffleBlockFetcherIterator: Getting 2 (124.2 KiB) non-empty blocks including 2 (124.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:15.267 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:15.267 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO Executor: Finished task 1.0 in stage 53.0 (TID 62). 6109 bytes result sent to driver
24/04/16 16:21:15.267 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 62) in 0 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:15.267 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
24/04/16 16:21:15.267 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 53 (collectAsMap at RandomForest.scala:663) finished in 0,015 s
24/04/16 16:21:15.267 dag-scheduler-event-loop INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:15.267 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
24/04/16 16:21:15.267 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 39 finished: collectAsMap at RandomForest.scala:663, took 0,114836 s
24/04/16 16:21:15.267 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(59) (from destroy at RandomForest.scala:674)
24/04/16 16:21:15.267 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_59_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 19.8 KiB, free: 910.9 MiB)
24/04/16 16:21:15.267 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 14.5 KiB, free 908.7 MiB)
24/04/16 16:21:15.267 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 908.7 MiB)
24/04/16 16:21:15.267 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 9.3 KiB, free: 910.8 MiB)
24/04/16 16:21:15.267 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 62 from broadcast at RandomForest.scala:622
24/04/16 16:21:15.286 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:21:15.286 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 199 (mapPartitions at RandomForest.scala:644) as input to shuffle 15
24/04/16 16:21:15.286 dag-scheduler-event-loop INFO DAGScheduler: Got job 40 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 16:21:15.286 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 55 (collectAsMap at RandomForest.scala:663)
24/04/16 16:21:15.286 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
24/04/16 16:21:15.286 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)
24/04/16 16:21:15.286 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[199] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:21:15.305 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 587.6 KiB, free 908.1 MiB)
24/04/16 16:21:15.306 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 140.7 KiB, free 907.9 MiB)
24/04/16 16:21:15.307 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 140.7 KiB, free: 910.7 MiB)
24/04/16 16:21:15.307 dag-scheduler-event-loop INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:15.309 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[199] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:15.310 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks resource profile 0
24/04/16 16:21:15.316 dispatcher-event-loop-0 WARN TaskSetManager: Stage 54 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:15.316 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 63) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:15.316 Executor task launch worker for task 0.0 in stage 54.0 (TID 63) INFO Executor: Running task 0.0 in stage 54.0 (TID 63)
24/04/16 16:21:15.327 Executor task launch worker for task 0.0 in stage 54.0 (TID 63) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 16:21:15.335 Executor task launch worker for task 0.0 in stage 54.0 (TID 63) INFO Executor: Finished task 0.0 in stage 54.0 (TID 63). 2205 bytes result sent to driver
24/04/16 16:21:15.335 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 64) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:21:15.335 Executor task launch worker for task 1.0 in stage 54.0 (TID 64) INFO Executor: Running task 1.0 in stage 54.0 (TID 64)
24/04/16 16:21:15.335 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 63) in 25 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:15.353 Executor task launch worker for task 1.0 in stage 54.0 (TID 64) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 16:21:15.368 Executor task launch worker for task 1.0 in stage 54.0 (TID 64) INFO Executor: Finished task 1.0 in stage 54.0 (TID 64). 2205 bytes result sent to driver
24/04/16 16:21:15.369 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 64) in 34 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:15.369 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
24/04/16 16:21:15.369 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 54 (mapPartitions at RandomForest.scala:644) finished in 0,083 s
24/04/16 16:21:15.369 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:21:15.369 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:21:15.369 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 55)
24/04/16 16:21:15.369 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:21:15.370 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[201] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:21:15.370 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 9.0 KiB, free 907.9 MiB)
24/04/16 16:21:15.371 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 907.9 MiB)
24/04/16 16:21:15.372 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 4.5 KiB, free: 910.7 MiB)
24/04/16 16:21:15.372 dag-scheduler-event-loop INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:15.372 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[201] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:21:15.372 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks resource profile 0
24/04/16 16:21:15.373 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 65) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:15.373 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO Executor: Running task 0.0 in stage 55.0 (TID 65)
24/04/16 16:21:15.374 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO ShuffleBlockFetcherIterator: Getting 2 (55.6 KiB) non-empty blocks including 2 (55.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:15.374 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:15.380 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO Executor: Finished task 0.0 in stage 55.0 (TID 65). 4055 bytes result sent to driver
24/04/16 16:21:15.380 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 66) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:21:15.381 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO Executor: Running task 1.0 in stage 55.0 (TID 66)
24/04/16 16:21:15.381 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 65) in 8 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:21:15.382 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO ShuffleBlockFetcherIterator: Getting 2 (63.8 KiB) non-empty blocks including 2 (63.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:21:15.382 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:21:15.386 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO Executor: Finished task 1.0 in stage 55.0 (TID 66). 4042 bytes result sent to driver
24/04/16 16:21:15.387 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 66) in 7 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:21:15.387 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
24/04/16 16:21:15.387 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 55 (collectAsMap at RandomForest.scala:663) finished in 0,017 s
24/04/16 16:21:15.387 dag-scheduler-event-loop INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:15.387 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
24/04/16 16:21:15.388 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 40 finished: collectAsMap at RandomForest.scala:663, took 0,093098 s
24/04/16 16:21:15.388 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(62) (from destroy at RandomForest.scala:674)
24/04/16 16:21:15.389 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 16:21:15.389 nioEventLoopGroup-2-2 INFO RandomForest:   init: 3.31E-5
  total: 0.8193178
  findBestSplits: 0.8123302
  chooseSplits: 0.8107396
24/04/16 16:21:15.389 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_62_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 9.3 KiB, free: 910.7 MiB)
24/04/16 16:21:15.390 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 186 from persistence list
24/04/16 16:21:15.391 block-manager-storage-async-thread-pool-102 INFO BlockManager: Removing RDD 186
24/04/16 16:21:15.391 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(49) (from destroy at RandomForest.scala:305)
24/04/16 16:21:15.392 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_49_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 7.8 KiB, free: 911.0 MiB)
24/04/16 16:21:15.395 nioEventLoopGroup-2-2 INFO Instrumentation: [a311ca8f] {"numFeatures":545}
24/04/16 16:21:15.395 nioEventLoopGroup-2-2 INFO Instrumentation: [a311ca8f] training finished
24/04/16 16:21:15.395 nioEventLoopGroup-2-2 INFO Instrumentation: [9671be19] training finished
24/04/16 16:21:15.868 nioEventLoopGroup-2-2 INFO Instrumentation: [15585f63] training finished
24/04/16 16:21:16.018 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_63_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 140.7 KiB, free: 911.2 MiB)
24/04/16 16:21:16.018 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_64_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 4.5 KiB, free: 911.2 MiB)
24/04/16 16:21:16.036 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_61_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 5.0 KiB, free: 911.2 MiB)
24/04/16 16:21:16.933 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:21:16.933 dag-scheduler-event-loop INFO DAGScheduler: Got job 41 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:21:16.933 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 56 (collect at utils.scala:26)
24/04/16 16:21:16.933 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:21:16.933 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:16.935 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[204] at collect at utils.scala:26), which has no missing parents
24/04/16 16:21:16.936 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 62.5 KiB, free 909.0 MiB)
24/04/16 16:21:16.936 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.0 MiB)
24/04/16 16:21:16.936 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 911.2 MiB)
24/04/16 16:21:16.936 dag-scheduler-event-loop INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:16.936 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[204] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:21:16.936 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
24/04/16 16:21:16.936 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 67) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:21:16.936 Executor task launch worker for task 0.0 in stage 56.0 (TID 67) INFO Executor: Running task 0.0 in stage 56.0 (TID 67)
24/04/16 16:21:16.961 Executor task launch worker for task 0.0 in stage 56.0 (TID 67) INFO Executor: Finished task 0.0 in stage 56.0 (TID 67). 1430 bytes result sent to driver
24/04/16 16:21:16.962 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 67) in 26 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:21:16.962 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
24/04/16 16:21:16.962 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 56 (collect at utils.scala:26) finished in 0,027 s
24/04/16 16:21:16.962 dag-scheduler-event-loop INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:16.962 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
24/04/16 16:21:16.962 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 41 finished: collect at utils.scala:26, took 0,029131 s
24/04/16 16:21:19.934 nioEventLoopGroup-2-2 INFO Instrumentation: [407004ea] training finished
24/04/16 16:21:19.983 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 444.1 KiB, free 908.6 MiB)
24/04/16 16:21:19.983 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 26.5 KiB, free 908.5 MiB)
24/04/16 16:21:19.983 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 26.5 KiB, free: 911.2 MiB)
24/04/16 16:21:19.983 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 66 from broadcast at RandomForestRegressor.scala:238
24/04/16 16:21:20.041 nioEventLoopGroup-2-2 INFO Instrumentation: [8856cf62] training finished
24/04/16 16:21:20.914 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_65_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 911.2 MiB)
24/04/16 16:21:21.018 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:21:21.019 dag-scheduler-event-loop INFO DAGScheduler: Got job 42 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:21:21.019 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:26)
24/04/16 16:21:21.019 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:21:21.019 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:21.019 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[207] at collect at utils.scala:26), which has no missing parents
24/04/16 16:21:21.021 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 62.6 KiB, free 908.6 MiB)
24/04/16 16:21:21.022 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 908.5 MiB)
24/04/16 16:21:21.022 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 12.7 KiB, free: 911.2 MiB)
24/04/16 16:21:21.022 dag-scheduler-event-loop INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:21.022 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[207] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:21:21.022 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
24/04/16 16:21:21.023 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 68) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:21:21.023 Executor task launch worker for task 0.0 in stage 57.0 (TID 68) INFO Executor: Running task 0.0 in stage 57.0 (TID 68)
24/04/16 16:21:21.048 Executor task launch worker for task 0.0 in stage 57.0 (TID 68) INFO Executor: Finished task 0.0 in stage 57.0 (TID 68). 1430 bytes result sent to driver
24/04/16 16:21:21.048 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 68) in 25 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:21:21.048 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
24/04/16 16:21:21.048 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 57 (collect at utils.scala:26) finished in 0,029 s
24/04/16 16:21:21.048 dag-scheduler-event-loop INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:21.048 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
24/04/16 16:21:21.048 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 42 finished: collect at utils.scala:26, took 0,034466 s
24/04/16 16:21:25.565 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:21:25.565 dag-scheduler-event-loop INFO DAGScheduler: Got job 43 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:21:25.565 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:26)
24/04/16 16:21:25.565 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:21:25.565 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:25.565 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[215] at collect at utils.scala:26), which has no missing parents
24/04/16 16:21:25.586 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 373.1 KiB, free 908.2 MiB)
24/04/16 16:21:25.588 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 75.3 KiB, free 908.1 MiB)
24/04/16 16:21:25.588 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 75.3 KiB, free: 911.1 MiB)
24/04/16 16:21:25.588 dag-scheduler-event-loop INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:25.589 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[215] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:21:25.589 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
24/04/16 16:21:25.596 dispatcher-event-loop-1 WARN TaskSetManager: Stage 58 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:25.596 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 69) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:21:25.597 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO Executor: Running task 0.0 in stage 58.0 (TID 69)
24/04/16 16:21:25.605 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:25.728 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_67_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 12.7 KiB, free: 911.1 MiB)
24/04/16 16:21:25.797 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO CodeGenerator: Code generated in 91.4273 ms
24/04/16 16:21:25.886 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO Executor: Finished task 0.0 in stage 58.0 (TID 69). 5587 bytes result sent to driver
24/04/16 16:21:25.887 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 69) in 298 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:21:25.887 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
24/04/16 16:21:25.888 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 58 (collect at utils.scala:26) finished in 0,307 s
24/04/16 16:21:25.888 dag-scheduler-event-loop INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:25.888 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
24/04/16 16:21:25.888 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 43 finished: collect at utils.scala:26, took 0,309519 s
24/04/16 16:21:26.118 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:21:26.119 dag-scheduler-event-loop INFO DAGScheduler: Got job 44 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:21:26.119 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:26)
24/04/16 16:21:26.119 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:21:26.119 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:21:26.120 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[221] at collect at utils.scala:26), which has no missing parents
24/04/16 16:21:26.122 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 123.2 KiB, free 908.1 MiB)
24/04/16 16:21:26.123 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 908.0 MiB)
24/04/16 16:21:26.123 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 31.1 KiB, free: 911.1 MiB)
24/04/16 16:21:26.124 dag-scheduler-event-loop INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1535
24/04/16 16:21:26.124 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[221] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:21:26.124 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0
24/04/16 16:21:26.130 dispatcher-event-loop-0 WARN TaskSetManager: Stage 59 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:21:26.130 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 70) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:21:26.130 Executor task launch worker for task 0.0 in stage 59.0 (TID 70) INFO Executor: Running task 0.0 in stage 59.0 (TID 70)
24/04/16 16:21:26.130 Executor task launch worker for task 0.0 in stage 59.0 (TID 70) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:21:26.210 Executor task launch worker for task 0.0 in stage 59.0 (TID 70) INFO Executor: Finished task 0.0 in stage 59.0 (TID 70). 245115 bytes result sent to driver
24/04/16 16:21:26.212 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 70) in 87 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:21:26.212 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
24/04/16 16:21:26.212 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 59 (collect at utils.scala:26) finished in 0,092 s
24/04/16 16:21:26.212 dag-scheduler-event-loop INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:21:26.212 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
24/04/16 16:21:26.213 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 44 finished: collect at utils.scala:26, took 0,094189 s
24/04/16 16:21:29.081 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 16:21:29.081 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 16:21:29.081 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 16:21:29.081 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 16:21:29.081 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 16:21:29.081 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 16:21:29.117 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.3689 ms
24/04/16 16:21:29.129 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 2.95 ms
24/04/16 16:21:29.129 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.2534 ms
24/04/16 16:25:32.177 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_69_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 31.1 KiB, free: 911.1 MiB)
24/04/16 16:27:54.100 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:27:54.100 dag-scheduler-event-loop INFO DAGScheduler: Got job 45 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:27:54.100 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 60 (collect at utils.scala:26)
24/04/16 16:27:54.100 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:27:54.100 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:27:54.100 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[228] at collect at utils.scala:26), which has no missing parents
24/04/16 16:27:54.100 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 131.1 KiB, free 908.0 MiB)
24/04/16 16:27:54.100 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 35.2 KiB, free 908.0 MiB)
24/04/16 16:27:54.100 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 35.2 KiB, free: 911.1 MiB)
24/04/16 16:27:54.100 dag-scheduler-event-loop INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1535
24/04/16 16:27:54.100 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[228] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:27:54.100 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
24/04/16 16:27:54.115 dispatcher-event-loop-1 WARN TaskSetManager: Stage 60 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:27:54.115 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 71) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:27:54.115 Executor task launch worker for task 0.0 in stage 60.0 (TID 71) INFO Executor: Running task 0.0 in stage 60.0 (TID 71)
24/04/16 16:27:54.131 Executor task launch worker for task 0.0 in stage 60.0 (TID 71) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:27:54.193 Executor task launch worker for task 0.0 in stage 60.0 (TID 71) INFO Executor: Finished task 0.0 in stage 60.0 (TID 71). 32308 bytes result sent to driver
24/04/16 16:27:54.193 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 71) in 93 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:27:54.193 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
24/04/16 16:27:54.193 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 60 (collect at utils.scala:26) finished in 0,093 s
24/04/16 16:27:54.193 dag-scheduler-event-loop INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:27:54.193 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
24/04/16 16:27:54.193 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 45 finished: collect at utils.scala:26, took 0,098844 s
24/04/16 16:28:47.379 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_70_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 35.2 KiB, free: 911.1 MiB)
24/04/16 16:28:47.498 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:28:47.498 dag-scheduler-event-loop INFO DAGScheduler: Got job 46 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:28:47.498 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:26)
24/04/16 16:28:47.498 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:28:47.498 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:28:47.498 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[234] at collect at utils.scala:26), which has no missing parents
24/04/16 16:28:47.498 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 123.2 KiB, free 908.1 MiB)
24/04/16 16:28:47.498 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 908.0 MiB)
24/04/16 16:28:47.498 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 31.1 KiB, free: 911.1 MiB)
24/04/16 16:28:47.498 dag-scheduler-event-loop INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1535
24/04/16 16:28:47.498 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[234] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:28:47.498 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
24/04/16 16:28:47.513 dispatcher-event-loop-1 WARN TaskSetManager: Stage 61 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:28:47.513 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 72) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:28:47.513 Executor task launch worker for task 0.0 in stage 61.0 (TID 72) INFO Executor: Running task 0.0 in stage 61.0 (TID 72)
24/04/16 16:28:47.513 Executor task launch worker for task 0.0 in stage 61.0 (TID 72) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:28:47.576 Executor task launch worker for task 0.0 in stage 61.0 (TID 72) INFO Executor: Finished task 0.0 in stage 61.0 (TID 72). 245115 bytes result sent to driver
24/04/16 16:28:47.591 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 72) in 93 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:28:47.591 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
24/04/16 16:28:47.591 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 61 (collect at utils.scala:26) finished in 0,093 s
24/04/16 16:28:47.591 dag-scheduler-event-loop INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:28:47.591 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
24/04/16 16:28:47.591 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 46 finished: collect at utils.scala:26, took 0,090731 s
24/04/16 16:29:50.371 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:29:50.371 dag-scheduler-event-loop INFO DAGScheduler: Got job 47 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:29:50.371 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:26)
24/04/16 16:29:50.371 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:29:50.371 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:29:50.371 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[240] at collect at utils.scala:26), which has no missing parents
24/04/16 16:29:50.371 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 123.2 KiB, free 907.9 MiB)
24/04/16 16:29:50.371 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 907.9 MiB)
24/04/16 16:29:50.371 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 31.1 KiB, free: 911.0 MiB)
24/04/16 16:29:50.371 dag-scheduler-event-loop INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1535
24/04/16 16:29:50.371 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[240] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:29:50.371 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
24/04/16 16:29:50.387 dispatcher-event-loop-1 WARN TaskSetManager: Stage 62 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:29:50.387 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 73) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:29:50.387 Executor task launch worker for task 0.0 in stage 62.0 (TID 73) INFO Executor: Running task 0.0 in stage 62.0 (TID 73)
24/04/16 16:29:50.387 Executor task launch worker for task 0.0 in stage 62.0 (TID 73) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:29:50.436 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_71_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 31.1 KiB, free: 911.1 MiB)
24/04/16 16:29:50.490 Executor task launch worker for task 0.0 in stage 62.0 (TID 73) INFO Executor: Finished task 0.0 in stage 62.0 (TID 73). 245158 bytes result sent to driver
24/04/16 16:29:50.490 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 73) in 119 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:29:50.491 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
24/04/16 16:29:50.491 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 62 (collect at utils.scala:26) finished in 0,120 s
24/04/16 16:29:50.491 dag-scheduler-event-loop INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:29:50.491 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished
24/04/16 16:29:50.491 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 47 finished: collect at utils.scala:26, took 0,110658 s
24/04/16 16:34:20.001 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:34:20.001 dag-scheduler-event-loop INFO DAGScheduler: Got job 48 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:34:20.001 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:26)
24/04/16 16:34:20.001 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:34:20.001 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:34:20.001 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[246] at collect at utils.scala:26), which has no missing parents
24/04/16 16:34:20.001 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 123.2 KiB, free 907.9 MiB)
24/04/16 16:34:20.001 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 907.9 MiB)
24/04/16 16:34:20.001 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on DESKTOP-LH06ASP:62831 (size: 31.1 KiB, free: 911.0 MiB)
24/04/16 16:34:20.001 dag-scheduler-event-loop INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1535
24/04/16 16:34:20.001 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[246] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:34:20.001 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
24/04/16 16:34:20.001 dispatcher-event-loop-1 WARN TaskSetManager: Stage 63 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:34:20.001 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 74) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:34:20.001 Executor task launch worker for task 0.0 in stage 63.0 (TID 74) INFO Executor: Running task 0.0 in stage 63.0 (TID 74)
24/04/16 16:34:20.017 Executor task launch worker for task 0.0 in stage 63.0 (TID 74) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:34:20.095 Executor task launch worker for task 0.0 in stage 63.0 (TID 74) INFO Executor: Finished task 0.0 in stage 63.0 (TID 74). 245115 bytes result sent to driver
24/04/16 16:34:20.095 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 74) in 94 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:34:20.095 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
24/04/16 16:34:20.095 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 63 (collect at utils.scala:26) finished in 0,094 s
24/04/16 16:34:20.095 dag-scheduler-event-loop INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:34:20.095 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
24/04/16 16:34:20.095 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 48 finished: collect at utils.scala:26, took 0,096415 s
24/04/16 16:34:20.251 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_73_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 31.1 KiB, free: 911.1 MiB)
24/04/16 16:34:20.251 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_72_piece0 on DESKTOP-LH06ASP:62831 in memory (size: 31.1 KiB, free: 911.1 MiB)
24/04/16 16:38:21.761 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/16 16:38:21.761 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/16 16:38:21.794 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/16 16:38:21.822 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/16 16:39:35.019 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/16 16:39:35.219 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.4.2
24/04/16 16:39:35.235 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/04/16 16:39:35.297 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
24/04/16 16:39:35.377 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/16 16:39:35.377 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/16 16:39:35.377 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
24/04/16 16:39:35.377 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
24/04/16 16:39:35.408 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/16 16:39:35.408 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
24/04/16 16:39:35.424 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/16 16:39:35.471 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: pedro
24/04/16 16:39:35.486 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: pedro
24/04/16 16:39:35.486 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
24/04/16 16:39:35.486 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
24/04/16 16:39:35.486 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pedro; groups with view permissions: EMPTY; users with modify permissions: pedro; groups with modify permissions: EMPTY
24/04/16 16:39:35.580 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 64569.
24/04/16 16:39:35.611 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
24/04/16 16:39:35.642 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
24/04/16 16:39:35.695 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/16 16:39:35.695 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/16 16:39:35.698 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/16 16:39:35.710 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\blockmgr-5e25ba6f-74b8-4992-ae8a-728c22d754d1
24/04/16 16:39:35.740 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
24/04/16 16:39:35.756 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/16 16:39:35.756 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local]. Please check your configured local directories.
24/04/16 16:39:35.926 nioEventLoopGroup-2-2 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/16 16:39:36.004 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/16 16:39:36.035 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/pedro/AppData/Local/R/win-library/4.3/sparklyr/java/sparklyr-3.0-2.12.jar at spark://DESKTOP-LH06ASP:64569/jars/sparklyr-3.0-2.12.jar with timestamp 1713281975204
24/04/16 16:39:36.109 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host DESKTOP-LH06ASP
24/04/16 16:39:36.124 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/04/16 16:39:36.140 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://DESKTOP-LH06ASP:64569/jars/sparklyr-3.0-2.12.jar with timestamp 1713281975204
24/04/16 16:39:36.171 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to DESKTOP-LH06ASP/192.168.59.1:64569 after 18 ms (0 ms spent in bootstraps)
24/04/16 16:39:36.171 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://DESKTOP-LH06ASP:64569/jars/sparklyr-3.0-2.12.jar to C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-45b0042a-6e74-47da-a1b0-d100da5302ea\userFiles-ffb43f20-c1da-4fa8-b223-eea17f6823a1\fetchFileTemp444279452339945195.tmp
24/04/16 16:39:36.328 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/local/spark-45b0042a-6e74-47da-a1b0-d100da5302ea/userFiles-ffb43f20-c1da-4fa8-b223-eea17f6823a1/sparklyr-3.0-2.12.jar to class loader
24/04/16 16:39:36.343 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64589.
24/04/16 16:39:36.343 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on DESKTOP-LH06ASP:64589
24/04/16 16:39:36.343 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/16 16:39:36.359 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64589, None)
24/04/16 16:39:36.359 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-LH06ASP:64589 with 912.3 MiB RAM, BlockManagerId(driver, DESKTOP-LH06ASP, 64589, None)
24/04/16 16:39:36.359 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-LH06ASP, 64589, None)
24/04/16 16:39:36.359 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-LH06ASP, 64589, None)
24/04/16 16:39:36.643 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
24/04/16 16:39:36.659 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive'.
24/04/16 16:39:40.887 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
24/04/16 16:39:41.014 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/conf/hive-site.xml
24/04/16 16:39:41.424 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/pedro/AppData/Local/spark/spark-3.4.2-bin-hadoop3/tmp/hive
24/04/16 16:39:41.613 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
24/04/16 16:39:41.613 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
24/04/16 16:39:41.613 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
24/04/16 16:39:41.640 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
24/04/16 16:39:41.781 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
24/04/16 16:39:41.782 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
24/04/16 16:39:42.761 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
24/04/16 16:39:44.251 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
24/04/16 16:39:44.254 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
24/04/16 16:39:44.339 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
24/04/16 16:39:44.339 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.59.1
24/04/16 16:39:44.374 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
24/04/16 16:39:44.547 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
24/04/16 16:39:44.549 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
24/04/16 16:39:44.603 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
24/04/16 16:39:44.745 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 16:39:44.748 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 16:39:44.771 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
24/04/16 16:39:44.771 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: global_temp	
24/04/16 16:39:44.772 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
24/04/16 16:39:44.773 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 16:39:44.773 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 16:39:44.775 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 16:39:44.775 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 16:39:44.778 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 16:39:44.778 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 16:39:45.518 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 190.2647 ms
24/04/16 16:39:45.637 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:39:45.640 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,006593 s
24/04/16 16:39:50.114 nioEventLoopGroup-2-2 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/04/16 16:39:51.700 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.7318 ms
24/04/16 16:39:51.765 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:39:51.769 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:39:51.769 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
24/04/16 16:39:51.785 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:39:51.785 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:39:51.785 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26), which has no missing parents
24/04/16 16:39:51.868 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/16 16:39:51.935 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/16 16:39:51.935 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 16:39:51.950 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1535
24/04/16 16:39:51.954 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:39:51.954 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/04/16 16:39:52.002 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:39:52.020 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/04/16 16:39:52.534 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 167.5312 ms
24/04/16 16:39:52.570 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1559 bytes result sent to driver
24/04/16 16:39:52.580 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 577 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:39:52.582 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/16 16:39:52.588 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,784 s
24/04/16 16:39:52.592 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:39:52.593 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/04/16 16:39:52.593 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,828278 s
24/04/16 16:39:52.898 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 217.737 ms
24/04/16 16:39:56.177 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:39:56.178 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:39:56.178 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
24/04/16 16:39:56.178 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:39:56.179 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:39:56.181 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
24/04/16 16:39:56.187 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 62.4 KiB, free 912.2 MiB)
24/04/16 16:39:56.190 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 912.2 MiB)
24/04/16 16:39:56.191 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 16:39:56.192 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
24/04/16 16:39:56.193 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:39:56.193 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/04/16 16:39:56.194 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:39:56.195 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/04/16 16:39:56.250 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1473 bytes result sent to driver
24/04/16 16:39:56.255 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 61 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:39:56.256 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/16 16:39:56.256 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,074 s
24/04/16 16:39:56.256 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:39:56.257 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/04/16 16:39:56.258 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,080483 s
24/04/16 16:39:56.529 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 912.3 MiB)
24/04/16 16:39:59.251 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:39:59.252 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:39:59.252 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
24/04/16 16:39:59.253 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:39:59.255 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:39:59.256 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26), which has no missing parents
24/04/16 16:39:59.266 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 107.3 KiB, free 912.1 MiB)
24/04/16 16:39:59.281 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 912.1 MiB)
24/04/16 16:39:59.281 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 27.1 KiB, free: 912.3 MiB)
24/04/16 16:39:59.281 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1535
24/04/16 16:39:59.281 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:39:59.281 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/04/16 16:39:59.301 dispatcher-event-loop-1 WARN TaskSetManager: Stage 2 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:39:59.301 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:39:59.301 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/04/16 16:39:59.499 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 142.4057 ms
24/04/16 16:39:59.934 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 686.4 KiB, free 911.4 MiB)
24/04/16 16:39:59.936 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on DESKTOP-LH06ASP:64589 (size: 686.4 KiB, free: 911.6 MiB)
24/04/16 16:39:59.936 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 5.3641 ms
24/04/16 16:40:00.099 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO CodeGenerator: Code generated in 135.7971 ms
24/04/16 16:40:00.117 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: 1 block locks were not released by task 0.0 in stage 2.0 (TID 2)
[rdd_13_0]
24/04/16 16:40:00.117 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2399 bytes result sent to driver
24/04/16 16:40:00.117 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 836 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:00.117 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/16 16:40:00.117 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0,860 s
24/04/16 16:40:00.132 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:00.132 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/04/16 16:40:00.133 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0,880532 s
24/04/16 16:40:00.181 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 27.1 KiB, free: 911.6 MiB)
24/04/16 16:40:00.455 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 189.8156 ms
24/04/16 16:40:03.190 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:03.191 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:03.191 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:26)
24/04/16 16:40:03.191 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:03.191 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:03.192 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:03.203 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 56.4 KiB, free 911.5 MiB)
24/04/16 16:40:03.207 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 911.5 MiB)
24/04/16 16:40:03.207 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 13.5 KiB, free: 911.6 MiB)
24/04/16 16:40:03.208 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:03.208 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:03.209 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/04/16 16:40:03.221 dispatcher-event-loop-0 WARN TaskSetManager: Stage 3 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:03.221 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:40:03.222 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/04/16 16:40:03.305 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 11.0673 ms
24/04/16 16:40:03.310 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1467 bytes result sent to driver
24/04/16 16:40:03.312 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 103 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:03.313 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/16 16:40:03.313 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 3 (collect at utils.scala:26) finished in 0,120 s
24/04/16 16:40:03.314 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:03.314 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/04/16 16:40:03.314 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: collect at utils.scala:26, took 0,124130 s
24/04/16 16:40:03.337 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.5516 ms
24/04/16 16:40:04.830 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:04.830 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:04.830 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:26)
24/04/16 16:40:04.830 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:04.830 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:04.845 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:04.848 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 62.4 KiB, free 911.4 MiB)
24/04/16 16:40:04.848 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.4 MiB)
24/04/16 16:40:04.858 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:40:04.858 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:04.858 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:04.858 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/04/16 16:40:04.858 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:40:04.858 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
24/04/16 16:40:04.895 Executor task launch worker for task 0.0 in stage 4.0 (TID 4) INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1430 bytes result sent to driver
24/04/16 16:40:04.897 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 39 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:04.897 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/04/16 16:40:04.897 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (collect at utils.scala:26) finished in 0,052 s
24/04/16 16:40:04.897 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:04.897 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/04/16 16:40:04.897 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0,055070 s
24/04/16 16:40:05.165 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:40:05.173 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 13.5 KiB, free: 911.6 MiB)
24/04/16 16:40:05.178 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:40:08.211 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:08.211 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:08.211 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
24/04/16 16:40:08.211 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:08.226 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:08.226 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:08.230 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 62.4 KiB, free 911.6 MiB)
24/04/16 16:40:08.230 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 911.6 MiB)
24/04/16 16:40:08.237 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:40:08.237 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:08.237 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:08.237 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/04/16 16:40:08.237 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:40:08.237 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
24/04/16 16:40:08.272 Executor task launch worker for task 0.0 in stage 5.0 (TID 5) INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1430 bytes result sent to driver
24/04/16 16:40:08.273 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 36 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:08.273 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/04/16 16:40:08.274 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0,048 s
24/04/16 16:40:08.274 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:08.274 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/04/16 16:40:08.274 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0,049628 s
24/04/16 16:40:10.798 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:10.799 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:10.799 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
24/04/16 16:40:10.799 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:10.801 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:10.802 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[32] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:10.806 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 123.2 KiB, free 911.4 MiB)
24/04/16 16:40:10.808 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 911.4 MiB)
24/04/16 16:40:10.809 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 16:40:10.809 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:10.810 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[32] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:10.810 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
24/04/16 16:40:10.819 dispatcher-event-loop-0 WARN TaskSetManager: Stage 6 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:10.820 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:40:10.820 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
24/04/16 16:40:10.827 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:40:11.011 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.6 MiB)
24/04/16 16:40:11.079 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 181.1372 ms
24/04/16 16:40:11.109 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO CodeGenerator: Code generated in 5.6984 ms
24/04/16 16:40:11.248 Executor task launch worker for task 0.0 in stage 6.0 (TID 6) INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 245158 bytes result sent to driver
24/04/16 16:40:11.249 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 436 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:11.250 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/04/16 16:40:11.250 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0,447 s
24/04/16 16:40:11.251 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:11.251 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
24/04/16 16:40:11.251 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0,452506 s
24/04/16 16:40:13.798 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:13.799 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:13.800 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
24/04/16 16:40:13.800 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:13.800 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:13.801 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[38] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:13.807 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 123.2 KiB, free 911.4 MiB)
24/04/16 16:40:13.812 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 911.3 MiB)
24/04/16 16:40:13.814 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 16:40:13.815 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:13.816 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:13.816 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
24/04/16 16:40:13.826 dispatcher-event-loop-1 WARN TaskSetManager: Stage 7 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:13.827 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:40:13.828 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
24/04/16 16:40:13.837 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:40:13.994 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 137627 bytes result sent to driver
24/04/16 16:40:13.994 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 177 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:13.994 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/04/16 16:40:13.994 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0,192 s
24/04/16 16:40:13.994 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:13.994 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
24/04/16 16:40:13.994 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0,207463 s
24/04/16 16:40:16.757 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 31.0 KiB, free: 911.6 MiB)
24/04/16 16:40:16.973 nioEventLoopGroup-2-2 INFO Instrumentation: [f37b9933] training finished
24/04/16 16:40:17.499 nioEventLoopGroup-2-2 INFO Instrumentation: [e7480e0d] training finished
24/04/16 16:40:17.956 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 67.1983 ms
24/04/16 16:40:18.025 nioEventLoopGroup-2-2 INFO Instrumentation: [845e20a4] Stage class: RandomForestRegressor
24/04/16 16:40:18.025 nioEventLoopGroup-2-2 INFO Instrumentation: [845e20a4] Stage uid: random_forest__09b1bebb_254c_42c5_ba38_effe9818f8c0
24/04/16 16:40:18.025 nioEventLoopGroup-2-2 INFO Instrumentation: [845e20a4] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
24/04/16 16:40:18.042 nioEventLoopGroup-2-2 INFO Instrumentation: [845e20a4] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/16 16:40:18.126 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 16:40:18.126 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 16:40:18.126 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (take at DecisionTreeMetadata.scala:119)
24/04/16 16:40:18.126 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:18.126 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:18.126 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[51] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 16:40:18.146 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 398.0 KiB, free 911.1 MiB)
24/04/16 16:40:18.149 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 82.8 KiB, free 911.0 MiB)
24/04/16 16:40:18.150 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 82.8 KiB, free: 911.5 MiB)
24/04/16 16:40:18.150 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:18.150 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[51] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:18.151 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
24/04/16 16:40:18.160 dispatcher-event-loop-1 WARN TaskSetManager: Stage 8 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:18.160 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:40:18.161 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
24/04/16 16:40:18.238 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:40:18.592 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 16:40:18.707 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 89.8038 ms
24/04/16 16:40:18.725 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 5.5566 ms
24/04/16 16:40:18.753 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 6.6462 ms
24/04/16 16:40:18.762 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO CodeGenerator: Code generated in 3.8637 ms
24/04/16 16:40:18.766 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1700 bytes result sent to driver
24/04/16 16:40:18.766 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 615 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:18.767 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/04/16 16:40:18.767 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (take at DecisionTreeMetadata.scala:119) finished in 0,641 s
24/04/16 16:40:18.767 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:18.768 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/04/16 16:40:18.768 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: take at DecisionTreeMetadata.scala:119, took 0,634601 s
24/04/16 16:40:18.774 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 16:40:18.774 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions
24/04/16 16:40:18.774 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 16:40:18.774 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:18.774 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:18.774 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[50] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 16:40:18.792 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 398.0 KiB, free 910.8 MiB)
24/04/16 16:40:18.792 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 82.9 KiB, free 910.7 MiB)
24/04/16 16:40:18.792 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 82.9 KiB, free: 911.5 MiB)
24/04/16 16:40:18.792 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:18.792 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[50] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:18.792 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
24/04/16 16:40:18.811 dispatcher-event-loop-0 WARN TaskSetManager: Stage 9 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:18.812 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:40:18.812 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
24/04/16 16:40:18.829 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:40:19.128 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1772 bytes result sent to driver
24/04/16 16:40:19.128 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 336 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:19.128 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
24/04/16 16:40:19.129 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,355 s
24/04/16 16:40:19.129 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:19.129 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
24/04/16 16:40:19.129 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,350206 s
24/04/16 16:40:19.223 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 16:40:19.242 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 53 (flatMap at RandomForest.scala:1039) as input to shuffle 0
24/04/16 16:40:19.261 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collectAsMap at RandomForest.scala:1054) with 1 output partitions
24/04/16 16:40:19.261 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 11 (collectAsMap at RandomForest.scala:1054)
24/04/16 16:40:19.262 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
24/04/16 16:40:19.263 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
24/04/16 16:40:19.265 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[53] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 16:40:19.280 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 407.0 KiB, free 910.3 MiB)
24/04/16 16:40:19.283 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 86.5 KiB, free 910.2 MiB)
24/04/16 16:40:19.284 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 86.5 KiB, free: 911.4 MiB)
24/04/16 16:40:19.285 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:19.286 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[53] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:19.286 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
24/04/16 16:40:19.290 dispatcher-event-loop-1 WARN TaskSetManager: Stage 10 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:19.290 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:40:19.290 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
24/04/16 16:40:19.356 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:40:19.483 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 82.9 KiB, free: 911.5 MiB)
24/04/16 16:40:19.973 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1997 bytes result sent to driver
24/04/16 16:40:19.990 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 702 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:19.990 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
24/04/16 16:40:19.992 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 10 (flatMap at RandomForest.scala:1039) finished in 0,724 s
24/04/16 16:40:19.992 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:40:19.992 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:40:19.992 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 11)
24/04/16 16:40:19.992 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:40:19.992 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[55] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 16:40:19.992 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 11.9 KiB, free 910.7 MiB)
24/04/16 16:40:19.992 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 910.7 MiB)
24/04/16 16:40:19.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 4.5 KiB, free: 911.5 MiB)
24/04/16 16:40:20.006 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:20.006 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[55] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:20.006 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
24/04/16 16:40:20.009 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:40:20.009 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
24/04/16 16:40:20.036 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:40:20.037 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
24/04/16 16:40:20.113 Executor task launch worker for task 0.0 in stage 11.0 (TID 11) INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 48726 bytes result sent to driver
24/04/16 16:40:20.118 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 110 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:20.119 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
24/04/16 16:40:20.119 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 11 (collectAsMap at RandomForest.scala:1054) finished in 0,127 s
24/04/16 16:40:20.120 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:20.120 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
24/04/16 16:40:20.120 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collectAsMap at RandomForest.scala:1054, took 0,892794 s
24/04/16 16:40:20.133 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 59.1 KiB, free 910.6 MiB)
24/04/16 16:40:20.136 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.0 KiB, free 910.6 MiB)
24/04/16 16:40:20.137 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 10.0 KiB, free: 911.5 MiB)
24/04/16 16:40:20.137 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 12 from broadcast at RandomForest.scala:293
24/04/16 16:40:20.141 nioEventLoopGroup-2-2 INFO Instrumentation: [845e20a4] {"numFeatures":545}
24/04/16 16:40:20.141 nioEventLoopGroup-2-2 INFO Instrumentation: [845e20a4] {"numClasses":0}
24/04/16 16:40:20.141 nioEventLoopGroup-2-2 INFO Instrumentation: [845e20a4] {"numExamples":1429}
24/04/16 16:40:20.141 nioEventLoopGroup-2-2 INFO Instrumentation: [845e20a4] {"sumOfWeights":1429.0}
24/04/16 16:40:20.161 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 16.1 KiB, free 910.6 MiB)
24/04/16 16:40:20.163 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 910.6 MiB)
24/04/16 16:40:20.164 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 10.3 KiB, free: 911.4 MiB)
24/04/16 16:40:20.164 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 13 from broadcast at RandomForest.scala:622
24/04/16 16:40:20.190 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:40:20.190 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 58 (mapPartitions at RandomForest.scala:644) as input to shuffle 1
24/04/16 16:40:20.190 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 16:40:20.190 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 13 (collectAsMap at RandomForest.scala:663)
24/04/16 16:40:20.190 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
24/04/16 16:40:20.190 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
24/04/16 16:40:20.190 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:40:20.190 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 441.5 KiB, free 910.1 MiB)
24/04/16 16:40:20.205 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 99.2 KiB, free 910.0 MiB)
24/04/16 16:40:20.205 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 99.2 KiB, free: 911.3 MiB)
24/04/16 16:40:20.205 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:20.205 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:20.205 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
24/04/16 16:40:20.205 dispatcher-event-loop-1 WARN TaskSetManager: Stage 12 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:20.205 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:40:20.205 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
24/04/16 16:40:20.224 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:40:20.550 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO MemoryStore: Block rdd_57_0 stored as values in memory (estimated size 3.2 MiB, free 906.9 MiB)
24/04/16 16:40:20.551 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_57_0 in memory on DESKTOP-LH06ASP:64589 (size: 3.2 MiB, free: 908.2 MiB)
24/04/16 16:40:20.551 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 4.5 KiB, free: 908.2 MiB)
24/04/16 16:40:20.606 Executor task launch worker for task 0.0 in stage 12.0 (TID 12) INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1954 bytes result sent to driver
24/04/16 16:40:20.607 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 402 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:20.607 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
24/04/16 16:40:20.608 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 12 (mapPartitions at RandomForest.scala:644) finished in 0,418 s
24/04/16 16:40:20.608 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:40:20.608 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:40:20.608 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 13)
24/04/16 16:40:20.608 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:40:20.609 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[60] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:40:20.610 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.4 KiB, free 906.9 MiB)
24/04/16 16:40:20.611 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 906.9 MiB)
24/04/16 16:40:20.612 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 3.8 KiB, free: 908.2 MiB)
24/04/16 16:40:20.612 dag-scheduler-event-loop INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:20.612 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[60] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:20.612 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
24/04/16 16:40:20.613 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:40:20.613 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
24/04/16 16:40:20.615 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO ShuffleBlockFetcherIterator: Getting 1 (194.1 KiB) non-empty blocks including 1 (194.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:40:20.616 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:40:20.746 Executor task launch worker for task 0.0 in stage 13.0 (TID 13) INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 6380 bytes result sent to driver
24/04/16 16:40:20.747 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 134 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:20.747 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
24/04/16 16:40:20.748 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 13 (collectAsMap at RandomForest.scala:663) finished in 0,139 s
24/04/16 16:40:20.748 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:20.748 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
24/04/16 16:40:20.749 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collectAsMap at RandomForest.scala:663, took 0,557083 s
24/04/16 16:40:20.750 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(13) (from destroy at RandomForest.scala:674)
24/04/16 16:40:20.752 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 10.3 KiB, free: 908.2 MiB)
24/04/16 16:40:20.762 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.6 KiB, free 906.9 MiB)
24/04/16 16:40:20.765 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 906.9 MiB)
24/04/16 16:40:20.765 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 20.3 KiB, free: 908.2 MiB)
24/04/16 16:40:20.766 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 16 from broadcast at RandomForest.scala:622
24/04/16 16:40:20.788 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:40:20.789 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 61 (mapPartitions at RandomForest.scala:644) as input to shuffle 2
24/04/16 16:40:20.790 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 16:40:20.790 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 15 (collectAsMap at RandomForest.scala:663)
24/04/16 16:40:20.790 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
24/04/16 16:40:20.790 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
24/04/16 16:40:20.791 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[61] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:40:20.801 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 462.6 KiB, free 906.4 MiB)
24/04/16 16:40:20.804 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 112.3 KiB, free 906.3 MiB)
24/04/16 16:40:20.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 112.3 KiB, free: 908.1 MiB)
24/04/16 16:40:20.804 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:20.805 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[61] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:20.805 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
24/04/16 16:40:20.813 dispatcher-event-loop-1 WARN TaskSetManager: Stage 14 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:20.813 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:40:20.813 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
24/04/16 16:40:20.828 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 16:40:20.920 Executor task launch worker for task 0.0 in stage 14.0 (TID 14) INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1954 bytes result sent to driver
24/04/16 16:40:20.921 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 116 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:20.921 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
24/04/16 16:40:20.922 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 14 (mapPartitions at RandomForest.scala:644) finished in 0,130 s
24/04/16 16:40:20.922 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:40:20.922 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:40:20.922 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 15)
24/04/16 16:40:20.922 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:40:20.923 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:40:20.925 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 11.1 KiB, free 906.3 MiB)
24/04/16 16:40:20.927 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 906.3 MiB)
24/04/16 16:40:20.928 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.2 KiB, free: 908.1 MiB)
24/04/16 16:40:20.928 dag-scheduler-event-loop INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:20.929 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:20.929 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
24/04/16 16:40:20.930 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:40:20.930 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
24/04/16 16:40:20.934 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO ShuffleBlockFetcherIterator: Getting 1 (312.6 KiB) non-empty blocks including 1 (312.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:40:20.935 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:40:20.972 Executor task launch worker for task 0.0 in stage 15.0 (TID 15) INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 10497 bytes result sent to driver
24/04/16 16:40:20.974 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 43 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:20.974 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
24/04/16 16:40:20.975 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 15 (collectAsMap at RandomForest.scala:663) finished in 0,050 s
24/04/16 16:40:20.975 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:20.975 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
24/04/16 16:40:20.975 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collectAsMap at RandomForest.scala:663, took 0,187296 s
24/04/16 16:40:20.975 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(16) (from destroy at RandomForest.scala:674)
24/04/16 16:40:20.979 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 20.3 KiB, free: 908.1 MiB)
24/04/16 16:40:20.990 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 54.7 KiB, free 906.3 MiB)
24/04/16 16:40:20.992 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 906.3 MiB)
24/04/16 16:40:20.994 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 33.9 KiB, free: 908.0 MiB)
24/04/16 16:40:20.995 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 19 from broadcast at RandomForest.scala:622
24/04/16 16:40:21.016 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:40:21.017 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 64 (mapPartitions at RandomForest.scala:644) as input to shuffle 3
24/04/16 16:40:21.017 dag-scheduler-event-loop INFO DAGScheduler: Got job 14 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 16:40:21.017 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 17 (collectAsMap at RandomForest.scala:663)
24/04/16 16:40:21.017 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
24/04/16 16:40:21.017 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
24/04/16 16:40:21.018 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[64] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:40:21.028 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 493.2 KiB, free 905.8 MiB)
24/04/16 16:40:21.030 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 129.8 KiB, free 905.6 MiB)
24/04/16 16:40:21.032 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 129.8 KiB, free: 907.9 MiB)
24/04/16 16:40:21.032 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:21.032 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[64] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:21.032 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
24/04/16 16:40:21.039 dispatcher-event-loop-1 WARN TaskSetManager: Stage 16 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:21.039 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:40:21.040 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
24/04/16 16:40:21.057 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 16:40:21.139 Executor task launch worker for task 0.0 in stage 16.0 (TID 16) INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1911 bytes result sent to driver
24/04/16 16:40:21.140 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 107 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:21.140 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
24/04/16 16:40:21.140 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 16 (mapPartitions at RandomForest.scala:644) finished in 0,122 s
24/04/16 16:40:21.140 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:40:21.141 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:40:21.141 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 17)
24/04/16 16:40:21.141 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:40:21.141 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[66] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:40:21.144 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 13.8 KiB, free 905.6 MiB)
24/04/16 16:40:21.145 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 905.6 MiB)
24/04/16 16:40:21.146 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.9 KiB, free: 907.9 MiB)
24/04/16 16:40:21.147 dag-scheduler-event-loop INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:21.147 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[66] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:21.147 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
24/04/16 16:40:21.149 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:40:21.149 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
24/04/16 16:40:21.151 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Getting 1 (416.0 KiB) non-empty blocks including 1 (416.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:40:21.151 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:40:21.196 Executor task launch worker for task 0.0 in stage 17.0 (TID 17) INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 16113 bytes result sent to driver
24/04/16 16:40:21.198 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 49 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:21.198 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
24/04/16 16:40:21.199 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 17 (collectAsMap at RandomForest.scala:663) finished in 0,056 s
24/04/16 16:40:21.199 dag-scheduler-event-loop INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:21.199 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
24/04/16 16:40:21.199 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 14 finished: collectAsMap at RandomForest.scala:663, took 0,183743 s
24/04/16 16:40:21.200 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(19) (from destroy at RandomForest.scala:674)
24/04/16 16:40:21.200 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 33.9 KiB, free: 908.0 MiB)
24/04/16 16:40:21.211 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 68.5 KiB, free 905.6 MiB)
24/04/16 16:40:21.214 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 42.3 KiB, free 905.6 MiB)
24/04/16 16:40:21.215 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 42.3 KiB, free: 907.9 MiB)
24/04/16 16:40:21.215 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 22 from broadcast at RandomForest.scala:622
24/04/16 16:40:21.239 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:40:21.239 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 67 (mapPartitions at RandomForest.scala:644) as input to shuffle 4
24/04/16 16:40:21.239 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 16:40:21.239 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 19 (collectAsMap at RandomForest.scala:663)
24/04/16 16:40:21.239 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
24/04/16 16:40:21.239 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
24/04/16 16:40:21.239 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[67] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:40:21.239 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 523.4 KiB, free 905.1 MiB)
24/04/16 16:40:21.255 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 143.5 KiB, free 905.0 MiB)
24/04/16 16:40:21.255 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 143.5 KiB, free: 907.8 MiB)
24/04/16 16:40:21.255 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:21.255 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[67] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:21.255 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
24/04/16 16:40:21.255 dispatcher-event-loop-1 WARN TaskSetManager: Stage 18 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:21.255 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:40:21.255 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
24/04/16 16:40:21.291 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 16:40:21.380 Executor task launch worker for task 0.0 in stage 18.0 (TID 18) INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1954 bytes result sent to driver
24/04/16 16:40:21.381 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 126 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:21.381 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
24/04/16 16:40:21.382 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 18 (mapPartitions at RandomForest.scala:644) finished in 0,143 s
24/04/16 16:40:21.382 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:40:21.382 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:40:21.382 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 19)
24/04/16 16:40:21.383 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:40:21.383 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[69] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:40:21.385 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 15.4 KiB, free 904.9 MiB)
24/04/16 16:40:21.386 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 904.9 MiB)
24/04/16 16:40:21.387 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 6.3 KiB, free: 907.8 MiB)
24/04/16 16:40:21.387 dag-scheduler-event-loop INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:21.389 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[69] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:21.389 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
24/04/16 16:40:21.389 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:40:21.389 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
24/04/16 16:40:21.389 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:40:21.389 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:40:21.428 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 19559 bytes result sent to driver
24/04/16 16:40:21.428 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 39 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:21.428 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
24/04/16 16:40:21.428 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 19 (collectAsMap at RandomForest.scala:663) finished in 0,044 s
24/04/16 16:40:21.428 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:21.428 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
24/04/16 16:40:21.428 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collectAsMap at RandomForest.scala:663, took 0,191721 s
24/04/16 16:40:21.428 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(22) (from destroy at RandomForest.scala:674)
24/04/16 16:40:21.428 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 42.3 KiB, free: 907.8 MiB)
24/04/16 16:40:21.448 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 79.1 KiB, free 905.0 MiB)
24/04/16 16:40:21.451 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 49.0 KiB, free 904.9 MiB)
24/04/16 16:40:21.451 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 49.0 KiB, free: 907.8 MiB)
24/04/16 16:40:21.452 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 25 from broadcast at RandomForest.scala:622
24/04/16 16:40:21.471 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:40:21.472 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 70 (mapPartitions at RandomForest.scala:644) as input to shuffle 5
24/04/16 16:40:21.472 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 16:40:21.472 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 21 (collectAsMap at RandomForest.scala:663)
24/04/16 16:40:21.472 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
24/04/16 16:40:21.472 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
24/04/16 16:40:21.472 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[70] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:40:21.472 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 555.0 KiB, free 904.4 MiB)
24/04/16 16:40:21.472 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 156.1 KiB, free 904.2 MiB)
24/04/16 16:40:21.472 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 156.1 KiB, free: 907.6 MiB)
24/04/16 16:40:21.488 dag-scheduler-event-loop INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:21.488 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[70] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:21.488 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
24/04/16 16:40:21.491 dispatcher-event-loop-1 WARN TaskSetManager: Stage 20 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:21.491 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:40:21.491 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
24/04/16 16:40:21.523 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO BlockManager: Found block rdd_57_0 locally
24/04/16 16:40:21.599 Executor task launch worker for task 0.0 in stage 20.0 (TID 20) INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1954 bytes result sent to driver
24/04/16 16:40:21.600 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 111 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:21.600 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
24/04/16 16:40:21.601 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 20 (mapPartitions at RandomForest.scala:644) finished in 0,129 s
24/04/16 16:40:21.601 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:40:21.601 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:40:21.601 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 21)
24/04/16 16:40:21.601 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:40:21.602 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[72] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:40:21.604 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.7 KiB, free 904.2 MiB)
24/04/16 16:40:21.607 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 904.2 MiB)
24/04/16 16:40:21.607 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 6.5 KiB, free: 907.6 MiB)
24/04/16 16:40:21.608 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:21.608 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[72] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:21.608 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
24/04/16 16:40:21.609 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:40:21.610 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
24/04/16 16:40:21.613 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO ShuffleBlockFetcherIterator: Getting 1 (503.4 KiB) non-empty blocks including 1 (503.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:40:21.613 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:40:21.662 Executor task launch worker for task 0.0 in stage 21.0 (TID 21) INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 22400 bytes result sent to driver
24/04/16 16:40:21.663 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 54 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:21.664 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
24/04/16 16:40:21.664 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 21 (collectAsMap at RandomForest.scala:663) finished in 0,061 s
24/04/16 16:40:21.665 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:21.665 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
24/04/16 16:40:21.665 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collectAsMap at RandomForest.scala:663, took 0,193598 s
24/04/16 16:40:21.666 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(25) (from destroy at RandomForest.scala:674)
24/04/16 16:40:21.667 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 16:40:21.670 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 112.3 KiB, free: 907.7 MiB)
24/04/16 16:40:21.670 nioEventLoopGroup-2-2 INFO RandomForest:   init: 0.003018
  total: 1.5177046
  findBestSplits: 1.4695372
  chooseSplits: 1.4610382
24/04/16 16:40:21.670 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_25_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 49.0 KiB, free: 907.8 MiB)
24/04/16 16:40:21.674 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.2 KiB, free: 907.8 MiB)
24/04/16 16:40:21.678 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 143.5 KiB, free: 907.9 MiB)
24/04/16 16:40:21.682 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 129.8 KiB, free: 908.0 MiB)
24/04/16 16:40:21.685 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 57 from persistence list
24/04/16 16:40:21.693 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(12) (from destroy at RandomForest.scala:305)
24/04/16 16:40:21.694 block-manager-storage-async-thread-pool-63 INFO BlockManager: Removing RDD 57
24/04/16 16:40:21.698 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_24_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 6.3 KiB, free: 911.2 MiB)
24/04/16 16:40:21.699 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 10.0 KiB, free: 911.2 MiB)
24/04/16 16:40:21.707 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 99.2 KiB, free: 911.3 MiB)
24/04/16 16:40:21.717 nioEventLoopGroup-2-2 INFO Instrumentation: [845e20a4] {"numFeatures":545}
24/04/16 16:40:21.721 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_26_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 156.1 KiB, free: 911.4 MiB)
24/04/16 16:40:21.723 nioEventLoopGroup-2-2 INFO Instrumentation: [845e20a4] training finished
24/04/16 16:40:21.727 nioEventLoopGroup-2-2 INFO Instrumentation: [2d18b0b6] training finished
24/04/16 16:40:21.732 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 3.8 KiB, free: 911.5 MiB)
24/04/16 16:40:21.735 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.9 KiB, free: 911.5 MiB)
24/04/16 16:40:22.534 nioEventLoopGroup-2-2 INFO Instrumentation: [18a0f036] training finished
24/04/16 16:40:23.706 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:23.707 dag-scheduler-event-loop INFO DAGScheduler: Got job 17 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:23.707 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:26)
24/04/16 16:40:23.707 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:23.707 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:23.707 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[75] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:23.709 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 62.5 KiB, free 910.6 MiB)
24/04/16 16:40:23.710 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.6 MiB)
24/04/16 16:40:23.711 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:40:23.711 dag-scheduler-event-loop INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:23.711 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[75] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:23.711 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
24/04/16 16:40:23.712 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:40:23.712 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
24/04/16 16:40:23.757 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO CodeGenerator: Code generated in 26.99 ms
24/04/16 16:40:23.760 Executor task launch worker for task 0.0 in stage 22.0 (TID 22) INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1430 bytes result sent to driver
24/04/16 16:40:23.761 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 49 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:23.761 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
24/04/16 16:40:23.762 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 22 (collect at utils.scala:26) finished in 0,054 s
24/04/16 16:40:23.762 dag-scheduler-event-loop INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:23.762 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
24/04/16 16:40:23.762 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 17 finished: collect at utils.scala:26, took 0,055244 s
24/04/16 16:40:23.853 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 58.4911 ms
24/04/16 16:40:26.350 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 6.5 KiB, free: 911.5 MiB)
24/04/16 16:40:26.354 block-manager-storage-async-thread-pool-5 INFO BlockManager: Removing RDD 57
24/04/16 16:40:26.358 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_28_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 16:40:26.499 nioEventLoopGroup-2-2 INFO Instrumentation: [f03fc559] training finished
24/04/16 16:40:26.558 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 476.3 KiB, free 910.2 MiB)
24/04/16 16:40:26.570 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 910.2 MiB)
24/04/16 16:40:26.570 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 37.2 KiB, free: 911.4 MiB)
24/04/16 16:40:26.570 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 29 from broadcast at RandomForestRegressor.scala:238
24/04/16 16:40:26.632 nioEventLoopGroup-2-2 INFO Instrumentation: [83327bb7] training finished
24/04/16 16:40:27.755 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:27.756 dag-scheduler-event-loop INFO DAGScheduler: Got job 18 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:27.756 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:26)
24/04/16 16:40:27.756 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:27.756 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:27.756 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[78] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:27.759 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 62.6 KiB, free 910.1 MiB)
24/04/16 16:40:27.761 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.1 MiB)
24/04/16 16:40:27.762 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:40:27.762 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:27.763 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[78] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:27.763 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
24/04/16 16:40:27.764 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:40:27.764 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
24/04/16 16:40:27.826 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO CodeGenerator: Code generated in 29.7135 ms
24/04/16 16:40:27.831 Executor task launch worker for task 0.0 in stage 23.0 (TID 23) INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1430 bytes result sent to driver
24/04/16 16:40:27.832 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 69 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:27.832 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
24/04/16 16:40:27.832 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 23 (collect at utils.scala:26) finished in 0,075 s
24/04/16 16:40:27.833 dag-scheduler-event-loop INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:27.833 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
24/04/16 16:40:27.834 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 18 finished: collect at utils.scala:26, took 0,078112 s
24/04/16 16:40:28.002 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 111.71 ms
24/04/16 16:40:32.819 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.8994 ms
24/04/16 16:40:32.883 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:40:32.883 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:32.883 dag-scheduler-event-loop INFO DAGScheduler: Got job 19 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:32.883 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:26)
24/04/16 16:40:32.883 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:32.883 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:32.883 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[86] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:32.883 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 373.1 KiB, free 909.8 MiB)
24/04/16 16:40:32.899 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 75.3 KiB, free 909.7 MiB)
24/04/16 16:40:32.899 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 75.3 KiB, free: 911.4 MiB)
24/04/16 16:40:32.901 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:32.901 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[86] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:32.901 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
24/04/16 16:40:32.902 dispatcher-event-loop-0 WARN TaskSetManager: Stage 24 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:32.902 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:40:32.902 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
24/04/16 16:40:32.921 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:40:33.085 Executor task launch worker for task 0.0 in stage 24.0 (TID 24) INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 4762 bytes result sent to driver
24/04/16 16:40:33.086 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 184 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:33.086 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
24/04/16 16:40:33.086 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 24 (collect at utils.scala:26) finished in 0,203 s
24/04/16 16:40:33.087 dag-scheduler-event-loop INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:33.087 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
24/04/16 16:40:33.087 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 19 finished: collect at utils.scala:26, took 0,196695 s
24/04/16 16:40:33.092 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.6959 ms
24/04/16 16:40:33.767 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 13.3327 ms
24/04/16 16:40:33.802 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 93 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
24/04/16 16:40:33.803 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 20 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:40:33.804 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:40:33.804 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:33.806 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:33.806 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:40:33.823 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 129.6 KiB, free 909.6 MiB)
24/04/16 16:40:33.825 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 909.6 MiB)
24/04/16 16:40:33.825 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 33.9 KiB, free: 911.3 MiB)
24/04/16 16:40:33.826 dag-scheduler-event-loop INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:33.826 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[93] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:33.826 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
24/04/16 16:40:33.837 dispatcher-event-loop-1 WARN TaskSetManager: Stage 25 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:33.838 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:40:33.839 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
24/04/16 16:40:33.861 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:40:33.986 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO CodeGenerator: Code generated in 6.7844 ms
24/04/16 16:40:34.056 Executor task launch worker for task 0.0 in stage 25.0 (TID 25) INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2438 bytes result sent to driver
24/04/16 16:40:34.057 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 230 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:34.057 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
24/04/16 16:40:34.057 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0,251 s
24/04/16 16:40:34.057 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:40:34.057 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:40:34.057 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 16:40:34.057 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:40:34.113 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.4518 ms
24/04/16 16:40:34.139 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 16:40:34.139 dag-scheduler-event-loop INFO DAGScheduler: Got job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:40:34.139 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 27 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:40:34.139 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
24/04/16 16:40:34.139 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:34.139 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[96] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:40:34.139 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 12.1 KiB, free 909.6 MiB)
24/04/16 16:40:34.139 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 909.6 MiB)
24/04/16 16:40:34.139 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.8 KiB, free: 911.3 MiB)
24/04/16 16:40:34.139 dag-scheduler-event-loop INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:34.139 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[96] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:34.150 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
24/04/16 16:40:34.152 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 26) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 16:40:34.152 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO Executor: Running task 0.0 in stage 27.0 (TID 26)
24/04/16 16:40:34.157 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:40:34.157 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/04/16 16:40:34.174 Executor task launch worker for task 0.0 in stage 27.0 (TID 26) INFO Executor: Finished task 0.0 in stage 27.0 (TID 26). 3909 bytes result sent to driver
24/04/16 16:40:34.174 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 26) in 23 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:34.174 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
24/04/16 16:40:34.174 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0,035 s
24/04/16 16:40:34.174 dag-scheduler-event-loop INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:34.174 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
24/04/16 16:40:34.174 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 21 finished: count at NativeMethodAccessorImpl.java:0, took 0,036686 s
24/04/16 16:40:34.367 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_33_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.8 KiB, free: 911.3 MiB)
24/04/16 16:40:34.382 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 75.3 KiB, free: 911.4 MiB)
24/04/16 16:40:34.382 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_32_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 33.9 KiB, free: 911.4 MiB)
24/04/16 16:40:34.565 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.5104 ms
24/04/16 16:40:34.582 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 103 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
24/04/16 16:40:34.582 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:40:34.582 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:40:34.582 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:34.582 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:34.583 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[103] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:40:34.590 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 129.6 KiB, free 910.1 MiB)
24/04/16 16:40:34.591 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 910.0 MiB)
24/04/16 16:40:34.592 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 33.9 KiB, free: 911.4 MiB)
24/04/16 16:40:34.592 dag-scheduler-event-loop INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:34.592 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[103] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:34.593 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
24/04/16 16:40:34.604 dispatcher-event-loop-0 WARN TaskSetManager: Stage 28 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:40:34.604 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 27) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:40:34.605 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO Executor: Running task 0.0 in stage 28.0 (TID 27)
24/04/16 16:40:34.614 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:40:34.766 Executor task launch worker for task 0.0 in stage 28.0 (TID 27) INFO Executor: Finished task 0.0 in stage 28.0 (TID 27). 2438 bytes result sent to driver
24/04/16 16:40:34.767 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 27) in 173 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:34.767 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
24/04/16 16:40:34.768 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 0,184 s
24/04/16 16:40:34.768 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:40:34.768 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:40:34.769 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 16:40:34.769 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:40:34.795 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 16:40:34.796 dag-scheduler-event-loop INFO DAGScheduler: Got job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:40:34.796 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:40:34.796 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
24/04/16 16:40:34.796 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:34.796 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:40:34.798 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 12.1 KiB, free 910.0 MiB)
24/04/16 16:40:34.799 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 910.0 MiB)
24/04/16 16:40:34.800 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.8 KiB, free: 911.4 MiB)
24/04/16 16:40:34.800 dag-scheduler-event-loop INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:34.801 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:34.801 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
24/04/16 16:40:34.802 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 28) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 16:40:34.802 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO Executor: Running task 0.0 in stage 30.0 (TID 28)
24/04/16 16:40:34.804 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:40:34.805 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:40:34.808 Executor task launch worker for task 0.0 in stage 30.0 (TID 28) INFO Executor: Finished task 0.0 in stage 30.0 (TID 28). 3909 bytes result sent to driver
24/04/16 16:40:34.809 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 28) in 7 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:34.809 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
24/04/16 16:40:34.809 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:0) finished in 0,012 s
24/04/16 16:40:34.810 dag-scheduler-event-loop INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:34.810 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
24/04/16 16:40:34.810 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 23 finished: count at NativeMethodAccessorImpl.java:0, took 0,015312 s
24/04/16 16:40:36.004 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:36.004 dag-scheduler-event-loop INFO DAGScheduler: Got job 24 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:36.004 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:26)
24/04/16 16:40:36.004 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:36.004 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:36.005 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[109] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:36.007 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 62.4 KiB, free 909.9 MiB)
24/04/16 16:40:36.008 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.9 MiB)
24/04/16 16:40:36.008 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:40:36.008 dag-scheduler-event-loop INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:36.008 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[109] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:36.008 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
24/04/16 16:40:36.009 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 29) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:40:36.009 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO Executor: Running task 0.0 in stage 31.0 (TID 29)
24/04/16 16:40:36.016 Executor task launch worker for task 0.0 in stage 31.0 (TID 29) INFO Executor: Finished task 0.0 in stage 31.0 (TID 29). 1387 bytes result sent to driver
24/04/16 16:40:36.016 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 29) in 7 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:36.016 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
24/04/16 16:40:36.016 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 31 (collect at utils.scala:26) finished in 0,011 s
24/04/16 16:40:36.016 dag-scheduler-event-loop INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:36.016 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
24/04/16 16:40:36.016 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 24 finished: collect at utils.scala:26, took 0,021168 s
24/04/16 16:40:38.964 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_35_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.8 KiB, free: 911.4 MiB)
24/04/16 16:40:38.965 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:40:38.965 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_34_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 33.9 KiB, free: 911.4 MiB)
24/04/16 16:40:39.066 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:39.066 dag-scheduler-event-loop INFO DAGScheduler: Got job 25 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:39.066 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:26)
24/04/16 16:40:39.066 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:39.066 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:39.066 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[112] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:39.081 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 62.4 KiB, free 910.1 MiB)
24/04/16 16:40:39.082 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.1 MiB)
24/04/16 16:40:39.082 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:40:39.082 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:39.082 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[112] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:39.082 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
24/04/16 16:40:39.082 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 30) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:40:39.082 Executor task launch worker for task 0.0 in stage 32.0 (TID 30) INFO Executor: Running task 0.0 in stage 32.0 (TID 30)
24/04/16 16:40:39.103 Executor task launch worker for task 0.0 in stage 32.0 (TID 30) INFO Executor: Finished task 0.0 in stage 32.0 (TID 30). 1387 bytes result sent to driver
24/04/16 16:40:39.103 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 30) in 21 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:39.103 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
24/04/16 16:40:39.104 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 32 (collect at utils.scala:26) finished in 0,037 s
24/04/16 16:40:39.104 dag-scheduler-event-loop INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:39.104 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
24/04/16 16:40:39.104 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 25 finished: collect at utils.scala:26, took 0,025760 s
24/04/16 16:40:56.640 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:56.640 dag-scheduler-event-loop INFO DAGScheduler: Got job 26 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:56.640 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:26)
24/04/16 16:40:56.640 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:56.640 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:56.640 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[115] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:56.640 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 62.4 KiB, free 910.0 MiB)
24/04/16 16:40:56.640 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.0 MiB)
24/04/16 16:40:56.640 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:40:56.640 dag-scheduler-event-loop INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:56.640 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[115] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:56.640 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
24/04/16 16:40:56.640 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 31) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:40:56.640 Executor task launch worker for task 0.0 in stage 33.0 (TID 31) INFO Executor: Running task 0.0 in stage 33.0 (TID 31)
24/04/16 16:40:56.656 Executor task launch worker for task 0.0 in stage 33.0 (TID 31) INFO Executor: Finished task 0.0 in stage 33.0 (TID 31). 1387 bytes result sent to driver
24/04/16 16:40:56.656 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 31) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:56.656 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
24/04/16 16:40:56.656 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 33 (collect at utils.scala:26) finished in 0,016 s
24/04/16 16:40:56.656 dag-scheduler-event-loop INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:56.656 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
24/04/16 16:40:56.656 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 26 finished: collect at utils.scala:26, took 0,022072 s
24/04/16 16:40:59.939 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:40:59.939 dag-scheduler-event-loop INFO DAGScheduler: Got job 27 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:40:59.939 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:26)
24/04/16 16:40:59.939 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:40:59.939 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:40:59.939 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[118] at collect at utils.scala:26), which has no missing parents
24/04/16 16:40:59.939 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 62.4 KiB, free 910.0 MiB)
24/04/16 16:40:59.972 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.0 MiB)
24/04/16 16:40:59.974 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:40:59.974 dag-scheduler-event-loop INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1535
24/04/16 16:40:59.974 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:40:59.974 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[118] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:40:59.974 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
24/04/16 16:40:59.974 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 32) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:40:59.974 Executor task launch worker for task 0.0 in stage 34.0 (TID 32) INFO Executor: Running task 0.0 in stage 34.0 (TID 32)
24/04/16 16:40:59.974 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_38_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:40:59.991 Executor task launch worker for task 0.0 in stage 34.0 (TID 32) INFO Executor: Finished task 0.0 in stage 34.0 (TID 32). 1387 bytes result sent to driver
24/04/16 16:40:59.992 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 32) in 18 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:40:59.992 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
24/04/16 16:40:59.992 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 34 (collect at utils.scala:26) finished in 0,053 s
24/04/16 16:40:59.992 dag-scheduler-event-loop INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:40:59.993 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
24/04/16 16:40:59.993 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 27 finished: collect at utils.scala:26, took 0,045054 s
24/04/16 16:41:06.307 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:41:06.308 dag-scheduler-event-loop INFO DAGScheduler: Got job 28 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:41:06.308 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:26)
24/04/16 16:41:06.308 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:41:06.308 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:41:06.308 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[121] at collect at utils.scala:26), which has no missing parents
24/04/16 16:41:06.310 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 62.4 KiB, free 910.0 MiB)
24/04/16 16:41:06.311 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.0 MiB)
24/04/16 16:41:06.312 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:41:06.312 dag-scheduler-event-loop INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:06.312 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[121] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:41:06.312 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
24/04/16 16:41:06.313 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 33) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:41:06.313 Executor task launch worker for task 0.0 in stage 35.0 (TID 33) INFO Executor: Running task 0.0 in stage 35.0 (TID 33)
24/04/16 16:41:06.335 Executor task launch worker for task 0.0 in stage 35.0 (TID 33) INFO Executor: Finished task 0.0 in stage 35.0 (TID 33). 1387 bytes result sent to driver
24/04/16 16:41:06.335 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 33) in 22 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:41:06.335 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
24/04/16 16:41:06.335 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 35 (collect at utils.scala:26) finished in 0,026 s
24/04/16 16:41:06.335 dag-scheduler-event-loop INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:06.335 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
24/04/16 16:41:06.335 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 28 finished: collect at utils.scala:26, took 0,029238 s
24/04/16 16:41:08.568 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_39_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:41:08.568 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_40_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:41:08.800 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.0583 ms
24/04/16 16:41:08.811 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.6046 ms
24/04/16 16:41:08.819 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.7741 ms
24/04/16 16:41:08.847 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 136 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8
24/04/16 16:41:08.847 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 29 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/16 16:41:08.847 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 36 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:41:08.847 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:41:08.848 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:41:08.848 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[136] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:41:08.865 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 226.3 KiB, free 910.0 MiB)
24/04/16 16:41:08.867 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 57.1 KiB, free 909.9 MiB)
24/04/16 16:41:08.867 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 57.1 KiB, free: 911.4 MiB)
24/04/16 16:41:08.868 dag-scheduler-event-loop INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:08.868 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[136] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:08.868 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 36.0 with 2 tasks resource profile 0
24/04/16 16:41:08.868 dispatcher-event-loop-0 WARN TaskSetManager: Stage 36 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:41:08.868 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 34) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 16:41:08.868 Executor task launch worker for task 0.0 in stage 36.0 (TID 34) INFO Executor: Running task 0.0 in stage 36.0 (TID 34)
24/04/16 16:41:08.884 Executor task launch worker for task 0.0 in stage 36.0 (TID 34) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:08.970 Executor task launch worker for task 0.0 in stage 36.0 (TID 34) INFO Executor: Finished task 0.0 in stage 36.0 (TID 34). 3054 bytes result sent to driver
24/04/16 16:41:08.970 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 35) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 16:41:08.970 Executor task launch worker for task 1.0 in stage 36.0 (TID 35) INFO Executor: Running task 1.0 in stage 36.0 (TID 35)
24/04/16 16:41:08.970 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 34) in 102 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:08.991 Executor task launch worker for task 1.0 in stage 36.0 (TID 35) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:09.068 Executor task launch worker for task 1.0 in stage 36.0 (TID 35) INFO Executor: Finished task 1.0 in stage 36.0 (TID 35). 3011 bytes result sent to driver
24/04/16 16:41:09.068 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 35) in 98 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:09.068 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
24/04/16 16:41:09.068 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 36 (count at NativeMethodAccessorImpl.java:0) finished in 0,219 s
24/04/16 16:41:09.068 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:41:09.068 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:41:09.068 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 16:41:09.068 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:41:09.095 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.5934 ms
24/04/16 16:41:09.102 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 16:41:09.103 dag-scheduler-event-loop INFO DAGScheduler: Got job 30 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:41:09.103 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 38 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:41:09.103 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
24/04/16 16:41:09.103 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:41:09.103 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[139] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:41:09.104 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 12.1 KiB, free 909.9 MiB)
24/04/16 16:41:09.105 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 909.9 MiB)
24/04/16 16:41:09.105 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.8 KiB, free: 911.4 MiB)
24/04/16 16:41:09.106 dag-scheduler-event-loop INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:09.106 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[139] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:41:09.106 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
24/04/16 16:41:09.107 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 36) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 16:41:09.107 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO Executor: Running task 0.0 in stage 38.0 (TID 36)
24/04/16 16:41:09.108 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:09.108 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:09.112 Executor task launch worker for task 0.0 in stage 38.0 (TID 36) INFO Executor: Finished task 0.0 in stage 38.0 (TID 36). 3909 bytes result sent to driver
24/04/16 16:41:09.113 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 36) in 7 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:41:09.113 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
24/04/16 16:41:09.113 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 38 (count at NativeMethodAccessorImpl.java:0) finished in 0,010 s
24/04/16 16:41:09.113 dag-scheduler-event-loop INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:09.113 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
24/04/16 16:41:09.113 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 30 finished: count at NativeMethodAccessorImpl.java:0, took 0,011028 s
24/04/16 16:41:09.267 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_41_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 57.1 KiB, free: 911.4 MiB)
24/04/16 16:41:09.267 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_42_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.8 KiB, free: 911.4 MiB)
24/04/16 16:41:09.479 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.4629 ms
24/04/16 16:41:09.484 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.7019 ms
24/04/16 16:41:09.502 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 154 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9
24/04/16 16:41:09.502 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 31 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/16 16:41:09.502 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:41:09.502 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:41:09.502 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:41:09.502 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[154] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:41:09.502 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 226.3 KiB, free 910.0 MiB)
24/04/16 16:41:09.502 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 57.2 KiB, free 909.9 MiB)
24/04/16 16:41:09.502 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 57.2 KiB, free: 911.4 MiB)
24/04/16 16:41:09.502 dag-scheduler-event-loop INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:09.502 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[154] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:09.502 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 39.0 with 2 tasks resource profile 0
24/04/16 16:41:09.520 dispatcher-event-loop-0 WARN TaskSetManager: Stage 39 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:41:09.520 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 37) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 16:41:09.521 Executor task launch worker for task 0.0 in stage 39.0 (TID 37) INFO Executor: Running task 0.0 in stage 39.0 (TID 37)
24/04/16 16:41:09.527 Executor task launch worker for task 0.0 in stage 39.0 (TID 37) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:09.596 Executor task launch worker for task 0.0 in stage 39.0 (TID 37) INFO Executor: Finished task 0.0 in stage 39.0 (TID 37). 3011 bytes result sent to driver
24/04/16 16:41:09.603 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 38) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 16:41:09.603 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 37) in 101 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:09.603 Executor task launch worker for task 1.0 in stage 39.0 (TID 38) INFO Executor: Running task 1.0 in stage 39.0 (TID 38)
24/04/16 16:41:09.612 Executor task launch worker for task 1.0 in stage 39.0 (TID 38) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:09.668 Executor task launch worker for task 1.0 in stage 39.0 (TID 38) INFO Executor: Finished task 1.0 in stage 39.0 (TID 38). 3054 bytes result sent to driver
24/04/16 16:41:09.684 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 38) in 88 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:09.684 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
24/04/16 16:41:09.684 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 39 (count at NativeMethodAccessorImpl.java:0) finished in 0,182 s
24/04/16 16:41:09.684 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:41:09.684 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:41:09.684 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 16:41:09.684 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:41:09.702 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 16:41:09.702 dag-scheduler-event-loop INFO DAGScheduler: Got job 32 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:41:09.702 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 41 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:41:09.702 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
24/04/16 16:41:09.702 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:41:09.703 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[157] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:41:09.704 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 12.1 KiB, free 909.9 MiB)
24/04/16 16:41:09.705 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 909.9 MiB)
24/04/16 16:41:09.705 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.8 KiB, free: 911.4 MiB)
24/04/16 16:41:09.706 dag-scheduler-event-loop INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:09.706 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[157] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:41:09.706 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
24/04/16 16:41:09.707 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 39) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 16:41:09.707 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO Executor: Running task 0.0 in stage 41.0 (TID 39)
24/04/16 16:41:09.709 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:09.709 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:09.712 Executor task launch worker for task 0.0 in stage 41.0 (TID 39) INFO Executor: Finished task 0.0 in stage 41.0 (TID 39). 3909 bytes result sent to driver
24/04/16 16:41:09.712 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 39) in 5 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:41:09.713 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
24/04/16 16:41:09.713 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 41 (count at NativeMethodAccessorImpl.java:0) finished in 0,010 s
24/04/16 16:41:09.713 dag-scheduler-event-loop INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:09.713 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
24/04/16 16:41:09.713 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 32 finished: count at NativeMethodAccessorImpl.java:0, took 0,011487 s
24/04/16 16:41:10.233 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_43_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 57.2 KiB, free: 911.4 MiB)
24/04/16 16:41:10.249 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_44_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.8 KiB, free: 911.4 MiB)
24/04/16 16:41:10.249 nioEventLoopGroup-2-2 INFO Instrumentation: [687f2988] training finished
24/04/16 16:41:10.537 nioEventLoopGroup-2-2 INFO Instrumentation: [5f13c91e] training finished
24/04/16 16:41:11.014 nioEventLoopGroup-2-2 INFO Instrumentation: [c490121d] Stage class: RandomForestRegressor
24/04/16 16:41:11.014 nioEventLoopGroup-2-2 INFO Instrumentation: [c490121d] Stage uid: random_forest__35f338e2_2214_46f8_b55f_76bdb4bab07d
24/04/16 16:41:11.014 nioEventLoopGroup-2-2 INFO Instrumentation: [c490121d] training: numPartitions=2 storageLevel=StorageLevel(1 replicas)
24/04/16 16:41:11.015 nioEventLoopGroup-2-2 INFO Instrumentation: [c490121d] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/16 16:41:11.083 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 16:41:11.084 dag-scheduler-event-loop INFO DAGScheduler: Got job 33 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 16:41:11.084 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 42 (take at DecisionTreeMetadata.scala:119)
24/04/16 16:41:11.084 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:41:11.084 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:41:11.085 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[180] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 16:41:11.097 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 521.9 KiB, free 909.7 MiB)
24/04/16 16:41:11.099 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 117.5 KiB, free 909.6 MiB)
24/04/16 16:41:11.099 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 117.5 KiB, free: 911.3 MiB)
24/04/16 16:41:11.099 dag-scheduler-event-loop INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:11.100 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[180] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 16:41:11.100 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
24/04/16 16:41:11.109 dispatcher-event-loop-0 WARN TaskSetManager: Stage 42 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:41:11.109 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 40) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 16:41:11.109 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO Executor: Running task 0.0 in stage 42.0 (TID 40)
24/04/16 16:41:11.117 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:11.239 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO CodeGenerator: Code generated in 3.6061 ms
24/04/16 16:41:11.350 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO CodeGenerator: Code generated in 68.2488 ms
24/04/16 16:41:11.368 Executor task launch worker for task 0.0 in stage 42.0 (TID 40) INFO Executor: Finished task 0.0 in stage 42.0 (TID 40). 1993 bytes result sent to driver
24/04/16 16:41:11.368 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 40) in 268 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:41:11.368 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
24/04/16 16:41:11.368 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 42 (take at DecisionTreeMetadata.scala:119) finished in 0,283 s
24/04/16 16:41:11.368 dag-scheduler-event-loop INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:11.368 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
24/04/16 16:41:11.368 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 33 finished: take at DecisionTreeMetadata.scala:119, took 0,296246 s
24/04/16 16:41:11.385 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 16:41:11.386 dag-scheduler-event-loop INFO DAGScheduler: Got job 34 (aggregate at DecisionTreeMetadata.scala:125) with 2 output partitions
24/04/16 16:41:11.386 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 43 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 16:41:11.386 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:41:11.387 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:41:11.387 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[179] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 16:41:11.404 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 521.9 KiB, free 909.0 MiB)
24/04/16 16:41:11.406 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 117.6 KiB, free 908.9 MiB)
24/04/16 16:41:11.407 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 117.6 KiB, free: 911.2 MiB)
24/04/16 16:41:11.407 dag-scheduler-event-loop INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:11.408 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 43 (MapPartitionsRDD[179] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:11.408 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks resource profile 0
24/04/16 16:41:11.418 dispatcher-event-loop-1 WARN TaskSetManager: Stage 43 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:41:11.418 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 41) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 16:41:11.418 Executor task launch worker for task 0.0 in stage 43.0 (TID 41) INFO Executor: Running task 0.0 in stage 43.0 (TID 41)
24/04/16 16:41:11.433 Executor task launch worker for task 0.0 in stage 43.0 (TID 41) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:11.622 Executor task launch worker for task 0.0 in stage 43.0 (TID 41) INFO Executor: Finished task 0.0 in stage 43.0 (TID 41). 2065 bytes result sent to driver
24/04/16 16:41:11.633 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 42) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 16:41:11.633 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 41) in 225 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:11.633 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO Executor: Running task 1.0 in stage 43.0 (TID 42)
24/04/16 16:41:11.658 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:11.786 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO CodeGenerator: Code generated in 4.2387 ms
24/04/16 16:41:11.852 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_45_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 117.5 KiB, free: 911.3 MiB)
24/04/16 16:41:11.902 Executor task launch worker for task 1.0 in stage 43.0 (TID 42) INFO Executor: Finished task 1.0 in stage 43.0 (TID 42). 2151 bytes result sent to driver
24/04/16 16:41:11.903 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 42) in 280 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:11.903 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
24/04/16 16:41:11.903 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 43 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,515 s
24/04/16 16:41:11.903 dag-scheduler-event-loop INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:11.903 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
24/04/16 16:41:11.904 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 34 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,517903 s
24/04/16 16:41:11.928 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 16:41:11.929 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 182 (flatMap at RandomForest.scala:1039) as input to shuffle 10
24/04/16 16:41:11.929 dag-scheduler-event-loop INFO DAGScheduler: Got job 35 (collectAsMap at RandomForest.scala:1054) with 2 output partitions
24/04/16 16:41:11.930 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 45 (collectAsMap at RandomForest.scala:1054)
24/04/16 16:41:11.930 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
24/04/16 16:41:11.930 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
24/04/16 16:41:11.930 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[182] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 16:41:11.943 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 531.0 KiB, free 909.0 MiB)
24/04/16 16:41:11.946 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 121.2 KiB, free 908.9 MiB)
24/04/16 16:41:11.946 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 121.2 KiB, free: 911.2 MiB)
24/04/16 16:41:11.947 dag-scheduler-event-loop INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:11.947 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[182] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:11.947 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 44.0 with 2 tasks resource profile 0
24/04/16 16:41:11.956 dispatcher-event-loop-0 WARN TaskSetManager: Stage 44 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:41:11.957 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 43) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:11.957 Executor task launch worker for task 0.0 in stage 44.0 (TID 43) INFO Executor: Running task 0.0 in stage 44.0 (TID 43)
24/04/16 16:41:11.975 Executor task launch worker for task 0.0 in stage 44.0 (TID 43) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:12.146 Executor task launch worker for task 0.0 in stage 44.0 (TID 43) INFO Executor: Finished task 0.0 in stage 44.0 (TID 43). 2291 bytes result sent to driver
24/04/16 16:41:12.153 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 44) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:12.153 Executor task launch worker for task 1.0 in stage 44.0 (TID 44) INFO Executor: Running task 1.0 in stage 44.0 (TID 44)
24/04/16 16:41:12.153 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 43) in 205 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:12.165 Executor task launch worker for task 1.0 in stage 44.0 (TID 44) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:12.315 Executor task launch worker for task 1.0 in stage 44.0 (TID 44) INFO Executor: Finished task 1.0 in stage 44.0 (TID 44). 2248 bytes result sent to driver
24/04/16 16:41:12.316 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 44) in 170 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:12.316 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
24/04/16 16:41:12.316 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 44 (flatMap at RandomForest.scala:1039) finished in 0,385 s
24/04/16 16:41:12.316 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:41:12.316 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:41:12.316 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 45)
24/04/16 16:41:12.316 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:41:12.316 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[184] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 16:41:12.316 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 11.9 KiB, free 908.9 MiB)
24/04/16 16:41:12.316 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 908.9 MiB)
24/04/16 16:41:12.316 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 4.5 KiB, free: 911.2 MiB)
24/04/16 16:41:12.316 dag-scheduler-event-loop INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:12.316 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[184] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:12.316 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks resource profile 0
24/04/16 16:41:12.316 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 45) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:12.316 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO Executor: Running task 0.0 in stage 45.0 (TID 45)
24/04/16 16:41:12.316 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO ShuffleBlockFetcherIterator: Getting 2 (31.9 KiB) non-empty blocks including 2 (31.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:12.316 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:12.348 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_47_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 121.2 KiB, free: 911.3 MiB)
24/04/16 16:41:12.363 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_46_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 117.6 KiB, free: 911.4 MiB)
24/04/16 16:41:12.368 Executor task launch worker for task 0.0 in stage 45.0 (TID 45) INFO Executor: Finished task 0.0 in stage 45.0 (TID 45). 21677 bytes result sent to driver
24/04/16 16:41:12.368 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 46) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:12.368 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO Executor: Running task 1.0 in stage 45.0 (TID 46)
24/04/16 16:41:12.368 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 45) in 52 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:12.368 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO ShuffleBlockFetcherIterator: Getting 2 (31.9 KiB) non-empty blocks including 2 (31.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:12.368 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:12.401 Executor task launch worker for task 1.0 in stage 45.0 (TID 46) INFO Executor: Finished task 1.0 in stage 45.0 (TID 46). 20551 bytes result sent to driver
24/04/16 16:41:12.402 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 46) in 34 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:12.402 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
24/04/16 16:41:12.402 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 45 (collectAsMap at RandomForest.scala:1054) finished in 0,086 s
24/04/16 16:41:12.402 dag-scheduler-event-loop INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:12.402 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
24/04/16 16:41:12.402 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 35 finished: collectAsMap at RandomForest.scala:1054, took 0,474240 s
24/04/16 16:41:12.405 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 48.7 KiB, free 910.1 MiB)
24/04/16 16:41:12.406 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 910.1 MiB)
24/04/16 16:41:12.407 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 8.0 KiB, free: 911.4 MiB)
24/04/16 16:41:12.407 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 49 from broadcast at RandomForest.scala:293
24/04/16 16:41:12.408 nioEventLoopGroup-2-2 INFO Instrumentation: [c490121d] {"numFeatures":545}
24/04/16 16:41:12.408 nioEventLoopGroup-2-2 INFO Instrumentation: [c490121d] {"numClasses":0}
24/04/16 16:41:12.408 nioEventLoopGroup-2-2 INFO Instrumentation: [c490121d] {"numExamples":136}
24/04/16 16:41:12.408 nioEventLoopGroup-2-2 INFO Instrumentation: [c490121d] {"sumOfWeights":136.0}
24/04/16 16:41:12.409 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 16.1 KiB, free 910.1 MiB)
24/04/16 16:41:12.411 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 910.1 MiB)
24/04/16 16:41:12.411 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 10.3 KiB, free: 911.4 MiB)
24/04/16 16:41:12.411 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 50 from broadcast at RandomForest.scala:622
24/04/16 16:41:12.418 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:41:12.418 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 187 (mapPartitions at RandomForest.scala:644) as input to shuffle 11
24/04/16 16:41:12.418 dag-scheduler-event-loop INFO DAGScheduler: Got job 36 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 16:41:12.418 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 47 (collectAsMap at RandomForest.scala:663)
24/04/16 16:41:12.418 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
24/04/16 16:41:12.418 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
24/04/16 16:41:12.418 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[187] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:41:12.436 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 562.0 KiB, free 909.5 MiB)
24/04/16 16:41:12.438 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 133.7 KiB, free 909.4 MiB)
24/04/16 16:41:12.438 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 133.7 KiB, free: 911.3 MiB)
24/04/16 16:41:12.438 dag-scheduler-event-loop INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:12.439 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[187] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:12.439 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 46.0 with 2 tasks resource profile 0
24/04/16 16:41:12.444 dispatcher-event-loop-0 WARN TaskSetManager: Stage 46 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:41:12.445 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 47) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:12.445 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO Executor: Running task 0.0 in stage 46.0 (TID 47)
24/04/16 16:41:12.457 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:12.550 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO MemoryStore: Block rdd_186_0 stored as values in memory (estimated size 154.7 KiB, free 909.2 MiB)
24/04/16 16:41:12.550 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_186_0 in memory on DESKTOP-LH06ASP:64589 (size: 154.7 KiB, free: 911.1 MiB)
24/04/16 16:41:12.552 Executor task launch worker for task 0.0 in stage 46.0 (TID 47) INFO Executor: Finished task 0.0 in stage 46.0 (TID 47). 2248 bytes result sent to driver
24/04/16 16:41:12.567 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 48) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:12.567 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO Executor: Running task 1.0 in stage 46.0 (TID 48)
24/04/16 16:41:12.567 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 47) in 128 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:12.567 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:12.667 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO MemoryStore: Block rdd_186_1 stored as values in memory (estimated size 159.3 KiB, free 909.1 MiB)
24/04/16 16:41:12.667 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_186_1 in memory on DESKTOP-LH06ASP:64589 (size: 159.3 KiB, free: 911.0 MiB)
24/04/16 16:41:12.704 Executor task launch worker for task 1.0 in stage 46.0 (TID 48) INFO Executor: Finished task 1.0 in stage 46.0 (TID 48). 2248 bytes result sent to driver
24/04/16 16:41:12.704 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 48) in 152 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:12.704 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
24/04/16 16:41:12.705 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 46 (mapPartitions at RandomForest.scala:644) finished in 0,287 s
24/04/16 16:41:12.705 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:41:12.705 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:41:12.705 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 47)
24/04/16 16:41:12.705 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:41:12.705 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[189] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:41:12.706 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 7.4 KiB, free 909.1 MiB)
24/04/16 16:41:12.707 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 909.1 MiB)
24/04/16 16:41:12.707 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 3.8 KiB, free: 911.0 MiB)
24/04/16 16:41:12.707 dag-scheduler-event-loop INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:12.708 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[189] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:12.708 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 47.0 with 2 tasks resource profile 0
24/04/16 16:41:12.708 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:12.709 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO Executor: Running task 0.0 in stage 47.0 (TID 49)
24/04/16 16:41:12.710 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO ShuffleBlockFetcherIterator: Getting 2 (92.9 KiB) non-empty blocks including 2 (92.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:12.710 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:12.717 Executor task launch worker for task 0.0 in stage 47.0 (TID 49) INFO Executor: Finished task 0.0 in stage 47.0 (TID 49). 4210 bytes result sent to driver
24/04/16 16:41:12.717 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 50) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:12.717 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO Executor: Running task 1.0 in stage 47.0 (TID 50)
24/04/16 16:41:12.717 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 9 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:12.717 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO ShuffleBlockFetcherIterator: Getting 2 (92.9 KiB) non-empty blocks including 2 (92.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:12.717 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:12.717 Executor task launch worker for task 1.0 in stage 47.0 (TID 50) INFO Executor: Finished task 1.0 in stage 47.0 (TID 50). 4223 bytes result sent to driver
24/04/16 16:41:12.717 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 50) in 0 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:12.717 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
24/04/16 16:41:12.717 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 47 (collectAsMap at RandomForest.scala:663) finished in 0,012 s
24/04/16 16:41:12.717 dag-scheduler-event-loop INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:12.717 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
24/04/16 16:41:12.717 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 36 finished: collectAsMap at RandomForest.scala:663, took 0,305842 s
24/04/16 16:41:12.717 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(50) (from destroy at RandomForest.scala:674)
24/04/16 16:41:12.733 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_50_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 10.3 KiB, free: 911.0 MiB)
24/04/16 16:41:12.735 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 32.6 KiB, free 909.1 MiB)
24/04/16 16:41:12.736 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 909.1 MiB)
24/04/16 16:41:12.736 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 20.3 KiB, free: 911.0 MiB)
24/04/16 16:41:12.737 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 53 from broadcast at RandomForest.scala:622
24/04/16 16:41:12.748 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:41:12.749 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 190 (mapPartitions at RandomForest.scala:644) as input to shuffle 12
24/04/16 16:41:12.749 dag-scheduler-event-loop INFO DAGScheduler: Got job 37 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 16:41:12.750 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 49 (collectAsMap at RandomForest.scala:663)
24/04/16 16:41:12.750 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
24/04/16 16:41:12.750 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 48)
24/04/16 16:41:12.750 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[190] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:41:12.757 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 583.0 KiB, free 908.5 MiB)
24/04/16 16:41:12.759 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 146.4 KiB, free 908.3 MiB)
24/04/16 16:41:12.759 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 146.4 KiB, free: 910.8 MiB)
24/04/16 16:41:12.760 dag-scheduler-event-loop INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:12.760 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[190] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:12.760 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 48.0 with 2 tasks resource profile 0
24/04/16 16:41:12.781 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_48_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 4.5 KiB, free: 910.8 MiB)
24/04/16 16:41:12.781 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_51_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 133.7 KiB, free: 910.9 MiB)
24/04/16 16:41:12.781 dispatcher-event-loop-0 WARN TaskSetManager: Stage 48 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:41:12.781 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 51) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:12.781 Executor task launch worker for task 0.0 in stage 48.0 (TID 51) INFO Executor: Running task 0.0 in stage 48.0 (TID 51)
24/04/16 16:41:12.797 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_52_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 3.8 KiB, free: 911.0 MiB)
24/04/16 16:41:12.802 Executor task launch worker for task 0.0 in stage 48.0 (TID 51) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 16:41:12.829 Executor task launch worker for task 0.0 in stage 48.0 (TID 51) INFO Executor: Finished task 0.0 in stage 48.0 (TID 51). 2205 bytes result sent to driver
24/04/16 16:41:12.836 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 52) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:12.836 Executor task launch worker for task 1.0 in stage 48.0 (TID 52) INFO Executor: Running task 1.0 in stage 48.0 (TID 52)
24/04/16 16:41:12.836 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 51) in 75 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:12.847 Executor task launch worker for task 1.0 in stage 48.0 (TID 52) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 16:41:12.849 Executor task launch worker for task 1.0 in stage 48.0 (TID 52) INFO Executor: Finished task 1.0 in stage 48.0 (TID 52). 2205 bytes result sent to driver
24/04/16 16:41:12.865 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 52) in 36 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:12.865 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
24/04/16 16:41:12.865 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 48 (mapPartitions at RandomForest.scala:644) finished in 0,115 s
24/04/16 16:41:12.866 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:41:12.866 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:41:12.866 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 49)
24/04/16 16:41:12.866 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:41:12.866 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[192] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:41:12.867 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 11.1 KiB, free 909.0 MiB)
24/04/16 16:41:12.867 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 909.0 MiB)
24/04/16 16:41:12.867 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.1 KiB, free: 910.9 MiB)
24/04/16 16:41:12.867 dag-scheduler-event-loop INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:12.867 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 49 (MapPartitionsRDD[192] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:12.867 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 49.0 with 2 tasks resource profile 0
24/04/16 16:41:12.867 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 53) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:12.867 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO Executor: Running task 0.0 in stage 49.0 (TID 53)
24/04/16 16:41:12.867 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO ShuffleBlockFetcherIterator: Getting 2 (172.8 KiB) non-empty blocks including 2 (172.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:12.867 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:12.884 Executor task launch worker for task 0.0 in stage 49.0 (TID 53) INFO Executor: Finished task 0.0 in stage 49.0 (TID 53). 6333 bytes result sent to driver
24/04/16 16:41:12.885 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 54) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:12.885 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO Executor: Running task 1.0 in stage 49.0 (TID 54)
24/04/16 16:41:12.885 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 53) in 18 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:12.887 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO ShuffleBlockFetcherIterator: Getting 2 (133.4 KiB) non-empty blocks including 2 (133.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:12.887 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:12.895 Executor task launch worker for task 1.0 in stage 49.0 (TID 54) INFO Executor: Finished task 1.0 in stage 49.0 (TID 54). 6268 bytes result sent to driver
24/04/16 16:41:12.895 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 54) in 10 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:12.896 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
24/04/16 16:41:12.896 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 49 (collectAsMap at RandomForest.scala:663) finished in 0,030 s
24/04/16 16:41:12.896 dag-scheduler-event-loop INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:12.896 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
24/04/16 16:41:12.896 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 37 finished: collectAsMap at RandomForest.scala:663, took 0,147427 s
24/04/16 16:41:12.897 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(53) (from destroy at RandomForest.scala:674)
24/04/16 16:41:12.898 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_53_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 20.3 KiB, free: 911.0 MiB)
24/04/16 16:41:12.900 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 40.0 KiB, free 909.0 MiB)
24/04/16 16:41:12.901 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 909.0 MiB)
24/04/16 16:41:12.901 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 25.0 KiB, free: 910.9 MiB)
24/04/16 16:41:12.902 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 56 from broadcast at RandomForest.scala:622
24/04/16 16:41:12.914 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:41:12.915 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 193 (mapPartitions at RandomForest.scala:644) as input to shuffle 13
24/04/16 16:41:12.915 dag-scheduler-event-loop INFO DAGScheduler: Got job 38 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 16:41:12.915 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 51 (collectAsMap at RandomForest.scala:663)
24/04/16 16:41:12.915 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
24/04/16 16:41:12.915 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
24/04/16 16:41:12.916 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[193] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:41:12.916 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 600.2 KiB, free 908.4 MiB)
24/04/16 16:41:12.916 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 154.2 KiB, free 908.3 MiB)
24/04/16 16:41:12.916 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 154.2 KiB, free: 910.8 MiB)
24/04/16 16:41:12.916 dag-scheduler-event-loop INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:12.916 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[193] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:12.916 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 50.0 with 2 tasks resource profile 0
24/04/16 16:41:12.932 dispatcher-event-loop-0 WARN TaskSetManager: Stage 50 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:41:12.932 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 55) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:12.932 Executor task launch worker for task 0.0 in stage 50.0 (TID 55) INFO Executor: Running task 0.0 in stage 50.0 (TID 55)
24/04/16 16:41:12.932 Executor task launch worker for task 0.0 in stage 50.0 (TID 55) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 16:41:12.951 Executor task launch worker for task 0.0 in stage 50.0 (TID 55) INFO Executor: Finished task 0.0 in stage 50.0 (TID 55). 2248 bytes result sent to driver
24/04/16 16:41:12.951 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 56) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:12.951 Executor task launch worker for task 1.0 in stage 50.0 (TID 56) INFO Executor: Running task 1.0 in stage 50.0 (TID 56)
24/04/16 16:41:12.951 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 55) in 35 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:12.975 Executor task launch worker for task 1.0 in stage 50.0 (TID 56) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 16:41:12.989 Executor task launch worker for task 1.0 in stage 50.0 (TID 56) INFO Executor: Finished task 1.0 in stage 50.0 (TID 56). 2205 bytes result sent to driver
24/04/16 16:41:12.990 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 56) in 39 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:12.990 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
24/04/16 16:41:12.990 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 50 (mapPartitions at RandomForest.scala:644) finished in 0,074 s
24/04/16 16:41:12.990 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:41:12.990 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:41:12.990 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 51)
24/04/16 16:41:12.990 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:41:12.991 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[195] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:41:12.991 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 12.0 KiB, free 908.3 MiB)
24/04/16 16:41:12.992 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 908.3 MiB)
24/04/16 16:41:12.993 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.3 KiB, free: 910.8 MiB)
24/04/16 16:41:12.993 dag-scheduler-event-loop INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:12.993 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (MapPartitionsRDD[195] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:12.993 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks resource profile 0
24/04/16 16:41:12.994 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 57) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:12.994 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO Executor: Running task 0.0 in stage 51.0 (TID 57)
24/04/16 16:41:12.995 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO ShuffleBlockFetcherIterator: Getting 2 (165.4 KiB) non-empty blocks including 2 (165.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:12.996 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:12.999 Executor task launch worker for task 0.0 in stage 51.0 (TID 57) INFO Executor: Finished task 0.0 in stage 51.0 (TID 57). 7356 bytes result sent to driver
24/04/16 16:41:12.999 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 58) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:12.999 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO Executor: Running task 1.0 in stage 51.0 (TID 58)
24/04/16 16:41:12.999 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 57) in 5 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:12.999 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO ShuffleBlockFetcherIterator: Getting 2 (172.8 KiB) non-empty blocks including 2 (172.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:12.999 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:13.017 Executor task launch worker for task 1.0 in stage 51.0 (TID 58) INFO Executor: Finished task 1.0 in stage 51.0 (TID 58). 7235 bytes result sent to driver
24/04/16 16:41:13.017 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 58) in 18 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:13.017 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
24/04/16 16:41:13.017 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 51 (collectAsMap at RandomForest.scala:663) finished in 0,026 s
24/04/16 16:41:13.017 dag-scheduler-event-loop INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:13.017 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
24/04/16 16:41:13.017 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 38 finished: collectAsMap at RandomForest.scala:663, took 0,107335 s
24/04/16 16:41:13.017 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(56) (from destroy at RandomForest.scala:674)
24/04/16 16:41:13.017 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_56_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 25.0 KiB, free: 910.8 MiB)
24/04/16 16:41:13.017 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 29.3 KiB, free 908.3 MiB)
24/04/16 16:41:13.017 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 18.2 KiB, free 908.3 MiB)
24/04/16 16:41:13.017 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 18.2 KiB, free: 910.8 MiB)
24/04/16 16:41:13.017 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 59 from broadcast at RandomForest.scala:622
24/04/16 16:41:13.039 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:41:13.040 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 196 (mapPartitions at RandomForest.scala:644) as input to shuffle 14
24/04/16 16:41:13.040 dag-scheduler-event-loop INFO DAGScheduler: Got job 39 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 16:41:13.040 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 53 (collectAsMap at RandomForest.scala:663)
24/04/16 16:41:13.040 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
24/04/16 16:41:13.040 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
24/04/16 16:41:13.041 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[196] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:41:13.049 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 603.3 KiB, free 907.7 MiB)
24/04/16 16:41:13.051 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 150.4 KiB, free 907.6 MiB)
24/04/16 16:41:13.051 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 150.4 KiB, free: 910.6 MiB)
24/04/16 16:41:13.051 dag-scheduler-event-loop INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:13.052 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[196] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:13.052 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 52.0 with 2 tasks resource profile 0
24/04/16 16:41:13.058 dispatcher-event-loop-0 WARN TaskSetManager: Stage 52 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:41:13.058 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 59) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:13.059 Executor task launch worker for task 0.0 in stage 52.0 (TID 59) INFO Executor: Running task 0.0 in stage 52.0 (TID 59)
24/04/16 16:41:13.066 Executor task launch worker for task 0.0 in stage 52.0 (TID 59) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 16:41:13.098 Executor task launch worker for task 0.0 in stage 52.0 (TID 59) INFO Executor: Finished task 0.0 in stage 52.0 (TID 59). 2205 bytes result sent to driver
24/04/16 16:41:13.102 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 60) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:13.102 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 59) in 50 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:13.102 Executor task launch worker for task 1.0 in stage 52.0 (TID 60) INFO Executor: Running task 1.0 in stage 52.0 (TID 60)
24/04/16 16:41:13.121 Executor task launch worker for task 1.0 in stage 52.0 (TID 60) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 16:41:13.137 Executor task launch worker for task 1.0 in stage 52.0 (TID 60) INFO Executor: Finished task 1.0 in stage 52.0 (TID 60). 2205 bytes result sent to driver
24/04/16 16:41:13.137 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 60) in 39 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:13.138 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
24/04/16 16:41:13.138 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 52 (mapPartitions at RandomForest.scala:644) finished in 0,097 s
24/04/16 16:41:13.138 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:41:13.138 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:41:13.138 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 53)
24/04/16 16:41:13.138 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:41:13.138 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[198] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:41:13.139 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 10.8 KiB, free 907.5 MiB)
24/04/16 16:41:13.140 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 907.5 MiB)
24/04/16 16:41:13.141 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 4.9 KiB, free: 910.6 MiB)
24/04/16 16:41:13.141 dag-scheduler-event-loop INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:13.142 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[198] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:13.142 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 53.0 with 2 tasks resource profile 0
24/04/16 16:41:13.142 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 61) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:13.143 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO Executor: Running task 0.0 in stage 53.0 (TID 61)
24/04/16 16:41:13.144 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO ShuffleBlockFetcherIterator: Getting 2 (124.2 KiB) non-empty blocks including 2 (124.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:13.144 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:13.152 Executor task launch worker for task 0.0 in stage 53.0 (TID 61) INFO Executor: Finished task 0.0 in stage 53.0 (TID 61). 5971 bytes result sent to driver
24/04/16 16:41:13.172 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 62) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:13.173 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO Executor: Running task 1.0 in stage 53.0 (TID 62)
24/04/16 16:41:13.173 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 61) in 31 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:13.173 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_58_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.3 KiB, free: 910.6 MiB)
24/04/16 16:41:13.175 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_54_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 146.4 KiB, free: 910.8 MiB)
24/04/16 16:41:13.176 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO ShuffleBlockFetcherIterator: Getting 2 (129.9 KiB) non-empty blocks including 2 (129.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:13.176 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:13.179 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_57_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 154.2 KiB, free: 910.9 MiB)
24/04/16 16:41:13.180 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_55_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.1 KiB, free: 910.9 MiB)
24/04/16 16:41:13.182 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_60_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 150.4 KiB, free: 911.1 MiB)
24/04/16 16:41:13.193 Executor task launch worker for task 1.0 in stage 53.0 (TID 62) INFO Executor: Finished task 1.0 in stage 53.0 (TID 62). 5945 bytes result sent to driver
24/04/16 16:41:13.194 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 62) in 22 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:13.194 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
24/04/16 16:41:13.194 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 53 (collectAsMap at RandomForest.scala:663) finished in 0,055 s
24/04/16 16:41:13.194 dag-scheduler-event-loop INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:13.194 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
24/04/16 16:41:13.194 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 39 finished: collectAsMap at RandomForest.scala:663, took 0,154810 s
24/04/16 16:41:13.195 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(59) (from destroy at RandomForest.scala:674)
24/04/16 16:41:13.196 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_59_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 18.2 KiB, free: 911.1 MiB)
24/04/16 16:41:13.198 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 17.7 KiB, free 909.8 MiB)
24/04/16 16:41:13.199 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 11.3 KiB, free 909.8 MiB)
24/04/16 16:41:13.199 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 11.3 KiB, free: 911.1 MiB)
24/04/16 16:41:13.199 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 62 from broadcast at RandomForest.scala:622
24/04/16 16:41:13.215 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 16:41:13.215 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 199 (mapPartitions at RandomForest.scala:644) as input to shuffle 15
24/04/16 16:41:13.216 dag-scheduler-event-loop INFO DAGScheduler: Got job 40 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 16:41:13.216 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 55 (collectAsMap at RandomForest.scala:663)
24/04/16 16:41:13.216 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
24/04/16 16:41:13.216 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)
24/04/16 16:41:13.216 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[199] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 16:41:13.227 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 596.2 KiB, free 909.2 MiB)
24/04/16 16:41:13.230 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 144.2 KiB, free 909.0 MiB)
24/04/16 16:41:13.230 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 144.2 KiB, free: 911.0 MiB)
24/04/16 16:41:13.230 dag-scheduler-event-loop INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:13.234 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[199] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:13.234 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks resource profile 0
24/04/16 16:41:13.241 dispatcher-event-loop-0 WARN TaskSetManager: Stage 54 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:41:13.241 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 63) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:13.242 Executor task launch worker for task 0.0 in stage 54.0 (TID 63) INFO Executor: Running task 0.0 in stage 54.0 (TID 63)
24/04/16 16:41:13.259 Executor task launch worker for task 0.0 in stage 54.0 (TID 63) INFO BlockManager: Found block rdd_186_0 locally
24/04/16 16:41:13.275 Executor task launch worker for task 0.0 in stage 54.0 (TID 63) INFO Executor: Finished task 0.0 in stage 54.0 (TID 63). 2248 bytes result sent to driver
24/04/16 16:41:13.284 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 64) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 16:41:13.285 Executor task launch worker for task 1.0 in stage 54.0 (TID 64) INFO Executor: Running task 1.0 in stage 54.0 (TID 64)
24/04/16 16:41:13.285 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 63) in 51 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:13.304 Executor task launch worker for task 1.0 in stage 54.0 (TID 64) INFO BlockManager: Found block rdd_186_1 locally
24/04/16 16:41:13.318 Executor task launch worker for task 1.0 in stage 54.0 (TID 64) INFO Executor: Finished task 1.0 in stage 54.0 (TID 64). 2248 bytes result sent to driver
24/04/16 16:41:13.318 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 64) in 42 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:13.319 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
24/04/16 16:41:13.319 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 54 (mapPartitions at RandomForest.scala:644) finished in 0,102 s
24/04/16 16:41:13.320 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:41:13.320 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:41:13.320 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 55)
24/04/16 16:41:13.320 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:41:13.320 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[201] at map at RandomForest.scala:663), which has no missing parents
24/04/16 16:41:13.321 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 9.4 KiB, free 909.0 MiB)
24/04/16 16:41:13.322 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 909.0 MiB)
24/04/16 16:41:13.322 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 4.6 KiB, free: 911.0 MiB)
24/04/16 16:41:13.322 dag-scheduler-event-loop INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:13.323 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[201] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 16:41:13.323 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks resource profile 0
24/04/16 16:41:13.323 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 65) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:13.324 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO Executor: Running task 0.0 in stage 55.0 (TID 65)
24/04/16 16:41:13.326 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO ShuffleBlockFetcherIterator: Getting 2 (70.1 KiB) non-empty blocks including 2 (70.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:13.326 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:13.335 Executor task launch worker for task 0.0 in stage 55.0 (TID 65) INFO Executor: Finished task 0.0 in stage 55.0 (TID 65). 4512 bytes result sent to driver
24/04/16 16:41:13.336 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 66) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 16:41:13.336 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO Executor: Running task 1.0 in stage 55.0 (TID 66)
24/04/16 16:41:13.336 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 65) in 13 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 16:41:13.338 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO ShuffleBlockFetcherIterator: Getting 2 (80.6 KiB) non-empty blocks including 2 (80.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:41:13.338 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:41:13.345 Executor task launch worker for task 1.0 in stage 55.0 (TID 66) INFO Executor: Finished task 1.0 in stage 55.0 (TID 66). 4512 bytes result sent to driver
24/04/16 16:41:13.346 task-result-getter-2 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 66) in 9 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 16:41:13.346 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
24/04/16 16:41:13.346 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 55 (collectAsMap at RandomForest.scala:663) finished in 0,026 s
24/04/16 16:41:13.346 dag-scheduler-event-loop INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:13.346 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
24/04/16 16:41:13.346 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 40 finished: collectAsMap at RandomForest.scala:663, took 0,131519 s
24/04/16 16:41:13.347 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(62) (from destroy at RandomForest.scala:674)
24/04/16 16:41:13.348 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 16:41:13.348 nioEventLoopGroup-2-2 INFO RandomForest:   init: 3.55E-5
  total: 0.9397252
  findBestSplits: 0.9320254
  chooseSplits: 0.9292477
24/04/16 16:41:13.348 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_62_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 11.3 KiB, free: 911.0 MiB)
24/04/16 16:41:13.350 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 186 from persistence list
24/04/16 16:41:13.350 block-manager-storage-async-thread-pool-44 INFO BlockManager: Removing RDD 186
24/04/16 16:41:13.351 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(49) (from destroy at RandomForest.scala:305)
24/04/16 16:41:13.352 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_49_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 8.0 KiB, free: 911.3 MiB)
24/04/16 16:41:13.356 nioEventLoopGroup-2-2 INFO Instrumentation: [c490121d] {"numFeatures":545}
24/04/16 16:41:13.356 nioEventLoopGroup-2-2 INFO Instrumentation: [c490121d] training finished
24/04/16 16:41:13.357 nioEventLoopGroup-2-2 INFO Instrumentation: [d037b0c7] training finished
24/04/16 16:41:13.880 nioEventLoopGroup-2-2 INFO Instrumentation: [1e3fb96f] training finished
24/04/16 16:41:14.814 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_61_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 4.9 KiB, free: 911.3 MiB)
24/04/16 16:41:14.814 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_63_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 144.2 KiB, free: 911.4 MiB)
24/04/16 16:41:14.814 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_64_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 4.6 KiB, free: 911.4 MiB)
24/04/16 16:41:14.830 block-manager-storage-async-thread-pool-58 INFO BlockManager: Removing RDD 186
24/04/16 16:41:14.882 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:41:14.882 dag-scheduler-event-loop INFO DAGScheduler: Got job 41 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:41:14.882 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 56 (collect at utils.scala:26)
24/04/16 16:41:14.882 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:41:14.882 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:41:14.882 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[204] at collect at utils.scala:26), which has no missing parents
24/04/16 16:41:14.899 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 62.5 KiB, free 910.1 MiB)
24/04/16 16:41:14.900 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.1 MiB)
24/04/16 16:41:14.900 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:41:14.900 dag-scheduler-event-loop INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:14.900 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[204] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:41:14.900 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
24/04/16 16:41:14.900 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 67) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:41:14.900 Executor task launch worker for task 0.0 in stage 56.0 (TID 67) INFO Executor: Running task 0.0 in stage 56.0 (TID 67)
24/04/16 16:41:14.916 Executor task launch worker for task 0.0 in stage 56.0 (TID 67) INFO Executor: Finished task 0.0 in stage 56.0 (TID 67). 1387 bytes result sent to driver
24/04/16 16:41:14.917 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 67) in 17 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:41:14.917 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
24/04/16 16:41:14.917 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 56 (collect at utils.scala:26) finished in 0,035 s
24/04/16 16:41:14.917 dag-scheduler-event-loop INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:14.917 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
24/04/16 16:41:14.918 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 41 finished: collect at utils.scala:26, took 0,021644 s
24/04/16 16:41:17.744 nioEventLoopGroup-2-2 INFO Instrumentation: [0465eb5d] training finished
24/04/16 16:41:17.787 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 444.1 KiB, free 909.7 MiB)
24/04/16 16:41:17.790 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 26.1 KiB, free 909.6 MiB)
24/04/16 16:41:17.790 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 26.1 KiB, free: 911.4 MiB)
24/04/16 16:41:17.791 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 66 from broadcast at RandomForestRegressor.scala:238
24/04/16 16:41:17.842 nioEventLoopGroup-2-2 INFO Instrumentation: [a3501a26] training finished
24/04/16 16:41:18.862 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_65_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:41:18.930 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:41:18.930 dag-scheduler-event-loop INFO DAGScheduler: Got job 42 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:41:18.930 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:26)
24/04/16 16:41:18.930 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:41:18.930 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:41:18.930 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[207] at collect at utils.scala:26), which has no missing parents
24/04/16 16:41:18.930 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 62.6 KiB, free 909.7 MiB)
24/04/16 16:41:18.930 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.6 MiB)
24/04/16 16:41:18.930 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.4 MiB)
24/04/16 16:41:18.930 dag-scheduler-event-loop INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:18.930 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[207] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:41:18.930 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
24/04/16 16:41:18.930 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 68) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 16:41:18.930 Executor task launch worker for task 0.0 in stage 57.0 (TID 68) INFO Executor: Running task 0.0 in stage 57.0 (TID 68)
24/04/16 16:41:18.951 Executor task launch worker for task 0.0 in stage 57.0 (TID 68) INFO Executor: Finished task 0.0 in stage 57.0 (TID 68). 1430 bytes result sent to driver
24/04/16 16:41:18.951 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 68) in 21 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:41:18.951 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
24/04/16 16:41:18.951 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 57 (collect at utils.scala:26) finished in 0,021 s
24/04/16 16:41:18.951 dag-scheduler-event-loop INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:18.951 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
24/04/16 16:41:18.951 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 42 finished: collect at utils.scala:26, took 0,022841 s
24/04/16 16:41:23.341 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 16:41:23.342 dag-scheduler-event-loop INFO DAGScheduler: Got job 43 (collect at utils.scala:26) with 1 output partitions
24/04/16 16:41:23.342 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:26)
24/04/16 16:41:23.342 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:41:23.342 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:41:23.342 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[215] at collect at utils.scala:26), which has no missing parents
24/04/16 16:41:23.350 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 373.1 KiB, free 909.3 MiB)
24/04/16 16:41:23.351 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 75.3 KiB, free 909.2 MiB)
24/04/16 16:41:23.352 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 75.3 KiB, free: 911.3 MiB)
24/04/16 16:41:23.352 dag-scheduler-event-loop INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1535
24/04/16 16:41:23.352 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[215] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 16:41:23.352 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
24/04/16 16:41:23.359 dispatcher-event-loop-1 WARN TaskSetManager: Stage 58 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:41:23.359 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 69) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 16:41:23.360 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO Executor: Running task 0.0 in stage 58.0 (TID 69)
24/04/16 16:41:23.369 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:41:23.552 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_67_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 16:41:23.627 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO CodeGenerator: Code generated in 136.6455 ms
24/04/16 16:41:23.764 Executor task launch worker for task 0.0 in stage 58.0 (TID 69) INFO Executor: Finished task 0.0 in stage 58.0 (TID 69). 5618 bytes result sent to driver
24/04/16 16:41:23.765 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 69) in 412 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:41:23.765 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
24/04/16 16:41:23.765 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 58 (collect at utils.scala:26) finished in 0,422 s
24/04/16 16:41:23.766 dag-scheduler-event-loop INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:41:23.766 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
24/04/16 16:41:23.766 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 43 finished: collect at utils.scala:26, took 0,425327 s
24/04/16 16:41:24.580 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 16:41:24.580 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 16:41:24.580 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 16:41:24.580 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 16:41:24.580 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 16:41:24.580 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 16:41:24.616 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.5598 ms
24/04/16 16:41:24.629 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 2.7068 ms
24/04/16 16:41:24.629 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 2.9985 ms
24/04/16 16:55:05.789 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 222 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 16
24/04/16 16:55:05.789 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 44 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:55:05.789 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 59 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:55:05.789 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:55:05.789 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:55:05.789 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[222] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:55:05.789 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 129.6 KiB, free 909.2 MiB)
24/04/16 16:55:05.804 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 909.1 MiB)
24/04/16 16:55:05.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 33.9 KiB, free: 911.3 MiB)
24/04/16 16:55:05.804 dag-scheduler-event-loop INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1535
24/04/16 16:55:05.804 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[222] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:55:05.804 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0
24/04/16 16:55:05.851 dispatcher-event-loop-1 WARN TaskSetManager: Stage 59 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:55:05.851 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 70) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:55:05.851 Executor task launch worker for task 0.0 in stage 59.0 (TID 70) INFO Executor: Running task 0.0 in stage 59.0 (TID 70)
24/04/16 16:55:05.867 Executor task launch worker for task 0.0 in stage 59.0 (TID 70) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:55:05.961 Executor task launch worker for task 0.0 in stage 59.0 (TID 70) INFO Executor: Finished task 0.0 in stage 59.0 (TID 70). 2395 bytes result sent to driver
24/04/16 16:55:05.961 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 70) in 157 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:55:05.961 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
24/04/16 16:55:05.961 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 59 (count at NativeMethodAccessorImpl.java:0) finished in 0,172 s
24/04/16 16:55:05.961 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:55:05.961 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:55:05.961 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 16:55:05.961 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:55:05.976 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 16:55:05.992 dag-scheduler-event-loop INFO DAGScheduler: Got job 45 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:55:05.992 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 61 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:55:05.992 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
24/04/16 16:55:05.992 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:55:05.992 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[225] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:55:05.992 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 12.1 KiB, free 909.1 MiB)
24/04/16 16:55:05.992 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 909.1 MiB)
24/04/16 16:55:05.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.8 KiB, free: 911.3 MiB)
24/04/16 16:55:05.992 dag-scheduler-event-loop INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1535
24/04/16 16:55:05.992 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[225] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:55:05.992 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
24/04/16 16:55:05.992 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 71) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 16:55:05.992 Executor task launch worker for task 0.0 in stage 61.0 (TID 71) INFO Executor: Running task 0.0 in stage 61.0 (TID 71)
24/04/16 16:55:05.992 Executor task launch worker for task 0.0 in stage 61.0 (TID 71) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:55:05.992 Executor task launch worker for task 0.0 in stage 61.0 (TID 71) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:55:05.992 Executor task launch worker for task 0.0 in stage 61.0 (TID 71) INFO Executor: Finished task 0.0 in stage 61.0 (TID 71). 3909 bytes result sent to driver
24/04/16 16:55:05.992 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 71) in 0 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:55:05.992 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
24/04/16 16:55:05.992 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 61 (count at NativeMethodAccessorImpl.java:0) finished in 0,000 s
24/04/16 16:55:06.008 dag-scheduler-event-loop INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:55:06.008 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
24/04/16 16:55:06.008 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 45 finished: count at NativeMethodAccessorImpl.java:0, took 0,012899 s
24/04/16 16:55:06.253 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 232 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 17
24/04/16 16:55:06.253 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 46 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:55:06.253 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 62 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:55:06.253 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 16:55:06.253 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:55:06.253 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[232] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:55:06.253 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 129.6 KiB, free 909.0 MiB)
24/04/16 16:55:06.253 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 908.9 MiB)
24/04/16 16:55:06.253 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 33.9 KiB, free: 911.3 MiB)
24/04/16 16:55:06.253 dag-scheduler-event-loop INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1535
24/04/16 16:55:06.253 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[232] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:55:06.253 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
24/04/16 16:55:06.269 dispatcher-event-loop-1 WARN TaskSetManager: Stage 62 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 16:55:06.269 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 72) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 16:55:06.269 Executor task launch worker for task 0.0 in stage 62.0 (TID 72) INFO Executor: Running task 0.0 in stage 62.0 (TID 72)
24/04/16 16:55:06.269 Executor task launch worker for task 0.0 in stage 62.0 (TID 72) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 16:55:06.341 Executor task launch worker for task 0.0 in stage 62.0 (TID 72) INFO Executor: Finished task 0.0 in stage 62.0 (TID 72). 2395 bytes result sent to driver
24/04/16 16:55:06.341 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 72) in 88 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:55:06.341 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
24/04/16 16:55:06.341 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 62 (count at NativeMethodAccessorImpl.java:0) finished in 0,088 s
24/04/16 16:55:06.341 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 16:55:06.341 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 16:55:06.341 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 16:55:06.341 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 16:55:06.356 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO DAGScheduler: Got job 47 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 64 (count at NativeMethodAccessorImpl.java:0)
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[235] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 12.1 KiB, free 908.9 MiB)
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 908.9 MiB)
24/04/16 16:55:06.356 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.8 KiB, free: 911.3 MiB)
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1535
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[235] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
24/04/16 16:55:06.356 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 73) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 16:55:06.356 Executor task launch worker for task 0.0 in stage 64.0 (TID 73) INFO Executor: Running task 0.0 in stage 64.0 (TID 73)
24/04/16 16:55:06.356 Executor task launch worker for task 0.0 in stage 64.0 (TID 73) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 16:55:06.356 Executor task launch worker for task 0.0 in stage 64.0 (TID 73) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 16:55:06.356 Executor task launch worker for task 0.0 in stage 64.0 (TID 73) INFO Executor: Finished task 0.0 in stage 64.0 (TID 73). 3866 bytes result sent to driver
24/04/16 16:55:06.356 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 73) in 0 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 16:55:06.356 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 64 (count at NativeMethodAccessorImpl.java:0) finished in 0,000 s
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 16:55:06.356 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
24/04/16 16:55:06.356 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 47 finished: count at NativeMethodAccessorImpl.java:0, took 0,009434 s
24/04/16 17:01:04.928 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_70_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.8 KiB, free: 911.3 MiB)
24/04/16 17:01:04.928 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_71_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 33.9 KiB, free: 911.3 MiB)
24/04/16 17:01:04.928 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_72_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.8 KiB, free: 911.3 MiB)
24/04/16 17:01:04.959 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 242 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 18
24/04/16 17:01:04.959 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 48 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 17:01:04.959 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 65 (count at NativeMethodAccessorImpl.java:0)
24/04/16 17:01:04.959 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:01:04.959 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:04.959 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[242] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 17:01:04.959 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 129.6 KiB, free 909.0 MiB)
24/04/16 17:01:04.959 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 909.0 MiB)
24/04/16 17:01:04.959 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 33.9 KiB, free: 911.3 MiB)
24/04/16 17:01:04.959 dag-scheduler-event-loop INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:04.959 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[242] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 17:01:04.959 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
24/04/16 17:01:04.975 dispatcher-event-loop-1 WARN TaskSetManager: Stage 65 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:01:04.975 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 74) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 17:01:04.975 Executor task launch worker for task 0.0 in stage 65.0 (TID 74) INFO Executor: Running task 0.0 in stage 65.0 (TID 74)
24/04/16 17:01:04.990 Executor task launch worker for task 0.0 in stage 65.0 (TID 74) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:01:05.053 Executor task launch worker for task 0.0 in stage 65.0 (TID 74) INFO Executor: Finished task 0.0 in stage 65.0 (TID 74). 2395 bytes result sent to driver
24/04/16 17:01:05.053 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 74) in 78 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:01:05.053 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
24/04/16 17:01:05.053 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 65 (count at NativeMethodAccessorImpl.java:0) finished in 0,094 s
24/04/16 17:01:05.053 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 17:01:05.053 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 17:01:05.053 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 17:01:05.053 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 17:01:05.084 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 17:01:05.085 dag-scheduler-event-loop INFO DAGScheduler: Got job 49 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 17:01:05.085 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 67 (count at NativeMethodAccessorImpl.java:0)
24/04/16 17:01:05.085 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
24/04/16 17:01:05.085 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:05.085 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[245] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 17:01:05.087 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 12.1 KiB, free 908.9 MiB)
24/04/16 17:01:05.088 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 908.9 MiB)
24/04/16 17:01:05.089 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.8 KiB, free: 911.3 MiB)
24/04/16 17:01:05.089 dag-scheduler-event-loop INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:05.090 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[245] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 17:01:05.090 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0
24/04/16 17:01:05.091 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 75) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 17:01:05.091 Executor task launch worker for task 0.0 in stage 67.0 (TID 75) INFO Executor: Running task 0.0 in stage 67.0 (TID 75)
24/04/16 17:01:05.093 Executor task launch worker for task 0.0 in stage 67.0 (TID 75) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:01:05.093 Executor task launch worker for task 0.0 in stage 67.0 (TID 75) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:01:05.096 Executor task launch worker for task 0.0 in stage 67.0 (TID 75) INFO Executor: Finished task 0.0 in stage 67.0 (TID 75). 3909 bytes result sent to driver
24/04/16 17:01:05.096 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 75) in 6 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:01:05.097 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
24/04/16 17:01:05.097 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 67 (count at NativeMethodAccessorImpl.java:0) finished in 0,011 s
24/04/16 17:01:05.097 dag-scheduler-event-loop INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:01:05.097 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
24/04/16 17:01:05.097 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 49 finished: count at NativeMethodAccessorImpl.java:0, took 0,012935 s
24/04/16 17:01:05.312 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 252 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 19
24/04/16 17:01:05.312 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 50 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 17:01:05.312 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 68 (count at NativeMethodAccessorImpl.java:0)
24/04/16 17:01:05.312 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:01:05.312 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:05.312 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[252] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 17:01:05.312 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 129.6 KiB, free 908.8 MiB)
24/04/16 17:01:05.312 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 908.8 MiB)
24/04/16 17:01:05.312 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 33.9 KiB, free: 911.2 MiB)
24/04/16 17:01:05.312 dag-scheduler-event-loop INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:05.312 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[252] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 17:01:05.312 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
24/04/16 17:01:05.328 dispatcher-event-loop-1 WARN TaskSetManager: Stage 68 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:01:05.328 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 76) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818691 bytes) 
24/04/16 17:01:05.328 Executor task launch worker for task 0.0 in stage 68.0 (TID 76) INFO Executor: Running task 0.0 in stage 68.0 (TID 76)
24/04/16 17:01:05.343 Executor task launch worker for task 0.0 in stage 68.0 (TID 76) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:01:05.400 Executor task launch worker for task 0.0 in stage 68.0 (TID 76) INFO Executor: Finished task 0.0 in stage 68.0 (TID 76). 2395 bytes result sent to driver
24/04/16 17:01:05.416 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 76) in 104 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:01:05.416 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
24/04/16 17:01:05.416 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 68 (count at NativeMethodAccessorImpl.java:0) finished in 0,104 s
24/04/16 17:01:05.416 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 17:01:05.416 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 17:01:05.416 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 17:01:05.416 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 17:01:05.431 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO DAGScheduler: Got job 51 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 70 (count at NativeMethodAccessorImpl.java:0)
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 69)
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[255] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 12.1 KiB, free 908.8 MiB)
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 908.8 MiB)
24/04/16 17:01:05.431 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.8 KiB, free: 911.2 MiB)
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[255] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
24/04/16 17:01:05.431 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 77) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 17:01:05.431 Executor task launch worker for task 0.0 in stage 70.0 (TID 77) INFO Executor: Running task 0.0 in stage 70.0 (TID 77)
24/04/16 17:01:05.431 Executor task launch worker for task 0.0 in stage 70.0 (TID 77) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:01:05.431 Executor task launch worker for task 0.0 in stage 70.0 (TID 77) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:01:05.431 Executor task launch worker for task 0.0 in stage 70.0 (TID 77) INFO Executor: Finished task 0.0 in stage 70.0 (TID 77). 3909 bytes result sent to driver
24/04/16 17:01:05.431 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 77) in 0 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:01:05.431 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 70 (count at NativeMethodAccessorImpl.java:0) finished in 0,000 s
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:01:05.431 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished
24/04/16 17:01:05.431 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 51 finished: count at NativeMethodAccessorImpl.java:0, took 0,009302 s
24/04/16 17:01:05.661 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_74_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.8 KiB, free: 911.2 MiB)
24/04/16 17:01:05.664 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_76_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.8 KiB, free: 911.2 MiB)
24/04/16 17:01:05.667 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_73_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 33.9 KiB, free: 911.3 MiB)
24/04/16 17:01:05.671 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_75_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 33.9 KiB, free: 911.3 MiB)
24/04/16 17:01:06.645 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 17:01:06.645 dag-scheduler-event-loop INFO DAGScheduler: Got job 52 (collect at utils.scala:26) with 1 output partitions
24/04/16 17:01:06.645 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:26)
24/04/16 17:01:06.645 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:01:06.645 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:06.645 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[258] at collect at utils.scala:26), which has no missing parents
24/04/16 17:01:06.645 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 62.4 KiB, free 909.1 MiB)
24/04/16 17:01:06.645 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.0 MiB)
24/04/16 17:01:06.645 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:01:06.645 dag-scheduler-event-loop INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:06.645 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[258] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 17:01:06.645 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0
24/04/16 17:01:06.645 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 78) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 17:01:06.645 Executor task launch worker for task 0.0 in stage 71.0 (TID 78) INFO Executor: Running task 0.0 in stage 71.0 (TID 78)
24/04/16 17:01:06.660 Executor task launch worker for task 0.0 in stage 71.0 (TID 78) INFO Executor: Finished task 0.0 in stage 71.0 (TID 78). 1387 bytes result sent to driver
24/04/16 17:01:06.660 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 78) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:01:06.660 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
24/04/16 17:01:06.660 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 71 (collect at utils.scala:26) finished in 0,015 s
24/04/16 17:01:06.660 dag-scheduler-event-loop INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:01:06.660 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished
24/04/16 17:01:06.660 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 52 finished: collect at utils.scala:26, took 0,021724 s
24/04/16 17:01:10.202 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 17:01:10.202 dag-scheduler-event-loop INFO DAGScheduler: Got job 53 (collect at utils.scala:26) with 1 output partitions
24/04/16 17:01:10.202 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 72 (collect at utils.scala:26)
24/04/16 17:01:10.202 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:01:10.202 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:10.202 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[261] at collect at utils.scala:26), which has no missing parents
24/04/16 17:01:10.214 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 62.4 KiB, free 909.0 MiB)
24/04/16 17:01:10.215 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.0 MiB)
24/04/16 17:01:10.215 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:01:10.215 dag-scheduler-event-loop INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:10.216 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[261] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 17:01:10.216 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
24/04/16 17:01:10.216 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 79) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 17:01:10.216 Executor task launch worker for task 0.0 in stage 72.0 (TID 79) INFO Executor: Running task 0.0 in stage 72.0 (TID 79)
24/04/16 17:01:10.230 Executor task launch worker for task 0.0 in stage 72.0 (TID 79) INFO Executor: Finished task 0.0 in stage 72.0 (TID 79). 1387 bytes result sent to driver
24/04/16 17:01:10.230 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 79) in 14 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:01:10.230 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
24/04/16 17:01:10.231 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 72 (collect at utils.scala:26) finished in 0,028 s
24/04/16 17:01:10.231 dag-scheduler-event-loop INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:01:10.231 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
24/04/16 17:01:10.231 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 53 finished: collect at utils.scala:26, took 0,019089 s
24/04/16 17:01:27.262 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_77_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:01:27.262 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_78_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:01:27.355 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 17:01:27.355 dag-scheduler-event-loop INFO DAGScheduler: Got job 54 (collect at utils.scala:26) with 1 output partitions
24/04/16 17:01:27.355 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 73 (collect at utils.scala:26)
24/04/16 17:01:27.355 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:01:27.355 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:27.355 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[264] at collect at utils.scala:26), which has no missing parents
24/04/16 17:01:27.355 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 62.4 KiB, free 909.1 MiB)
24/04/16 17:01:27.355 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.0 MiB)
24/04/16 17:01:27.355 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:01:27.355 dag-scheduler-event-loop INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:27.355 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[264] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 17:01:27.355 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0
24/04/16 17:01:27.355 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 80) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 17:01:27.355 Executor task launch worker for task 0.0 in stage 73.0 (TID 80) INFO Executor: Running task 0.0 in stage 73.0 (TID 80)
24/04/16 17:01:27.371 Executor task launch worker for task 0.0 in stage 73.0 (TID 80) INFO Executor: Finished task 0.0 in stage 73.0 (TID 80). 1387 bytes result sent to driver
24/04/16 17:01:27.371 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 80) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:01:27.371 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
24/04/16 17:01:27.371 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 73 (collect at utils.scala:26) finished in 0,016 s
24/04/16 17:01:27.371 dag-scheduler-event-loop INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:01:27.371 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
24/04/16 17:01:27.371 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 54 finished: collect at utils.scala:26, took 0,021997 s
24/04/16 17:01:30.246 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 17:01:30.246 dag-scheduler-event-loop INFO DAGScheduler: Got job 55 (collect at utils.scala:26) with 1 output partitions
24/04/16 17:01:30.246 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:26)
24/04/16 17:01:30.246 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:01:30.246 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:30.246 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[267] at collect at utils.scala:26), which has no missing parents
24/04/16 17:01:30.246 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 62.4 KiB, free 909.0 MiB)
24/04/16 17:01:30.246 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.0 MiB)
24/04/16 17:01:30.246 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:01:30.246 dag-scheduler-event-loop INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:30.246 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[267] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 17:01:30.246 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
24/04/16 17:01:30.261 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 81) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 17:01:30.261 Executor task launch worker for task 0.0 in stage 74.0 (TID 81) INFO Executor: Running task 0.0 in stage 74.0 (TID 81)
24/04/16 17:01:30.277 Executor task launch worker for task 0.0 in stage 74.0 (TID 81) INFO Executor: Finished task 0.0 in stage 74.0 (TID 81). 1430 bytes result sent to driver
24/04/16 17:01:30.277 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 81) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:01:30.277 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
24/04/16 17:01:30.277 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 74 (collect at utils.scala:26) finished in 0,031 s
24/04/16 17:01:30.277 dag-scheduler-event-loop INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:01:30.277 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
24/04/16 17:01:30.277 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 55 finished: collect at utils.scala:26, took 0,022585 s
24/04/16 17:01:35.384 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_79_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:01:35.384 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_80_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:01:36.315 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 17:01:36.315 dag-scheduler-event-loop INFO DAGScheduler: Got job 56 (collect at utils.scala:26) with 1 output partitions
24/04/16 17:01:36.315 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:26)
24/04/16 17:01:36.315 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:01:36.315 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:36.315 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[270] at collect at utils.scala:26), which has no missing parents
24/04/16 17:01:36.315 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 62.4 KiB, free 909.1 MiB)
24/04/16 17:01:36.315 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.0 MiB)
24/04/16 17:01:36.315 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:01:36.315 dag-scheduler-event-loop INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:36.315 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[270] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 17:01:36.315 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0
24/04/16 17:01:36.315 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 82) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 17:01:36.315 Executor task launch worker for task 0.0 in stage 75.0 (TID 82) INFO Executor: Running task 0.0 in stage 75.0 (TID 82)
24/04/16 17:01:36.331 Executor task launch worker for task 0.0 in stage 75.0 (TID 82) INFO Executor: Finished task 0.0 in stage 75.0 (TID 82). 1387 bytes result sent to driver
24/04/16 17:01:36.331 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 82) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:01:36.331 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
24/04/16 17:01:36.331 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 75 (collect at utils.scala:26) finished in 0,016 s
24/04/16 17:01:36.331 dag-scheduler-event-loop INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:01:36.331 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished
24/04/16 17:01:36.331 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 56 finished: collect at utils.scala:26, took 0,019155 s
24/04/16 17:01:39.670 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_81_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:01:39.700 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.0774 ms
24/04/16 17:01:39.715 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.996 ms
24/04/16 17:01:39.730 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 285 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 20
24/04/16 17:01:39.731 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 57 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/16 17:01:39.731 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 76 (count at NativeMethodAccessorImpl.java:0)
24/04/16 17:01:39.731 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:01:39.731 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:39.731 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[285] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 17:01:39.742 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 226.3 KiB, free 908.9 MiB)
24/04/16 17:01:39.744 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 57.1 KiB, free 908.8 MiB)
24/04/16 17:01:39.745 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 57.1 KiB, free: 911.2 MiB)
24/04/16 17:01:39.745 dag-scheduler-event-loop INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:39.745 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[285] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:01:39.745 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 76.0 with 2 tasks resource profile 0
24/04/16 17:01:39.753 dispatcher-event-loop-1 WARN TaskSetManager: Stage 76 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:01:39.753 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 83) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 17:01:39.753 Executor task launch worker for task 0.0 in stage 76.0 (TID 83) INFO Executor: Running task 0.0 in stage 76.0 (TID 83)
24/04/16 17:01:39.762 Executor task launch worker for task 0.0 in stage 76.0 (TID 83) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:01:39.825 Executor task launch worker for task 0.0 in stage 76.0 (TID 83) INFO Executor: Finished task 0.0 in stage 76.0 (TID 83). 3011 bytes result sent to driver
24/04/16 17:01:39.825 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 84) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 17:01:39.825 Executor task launch worker for task 1.0 in stage 76.0 (TID 84) INFO Executor: Running task 1.0 in stage 76.0 (TID 84)
24/04/16 17:01:39.825 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 83) in 79 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:01:39.840 Executor task launch worker for task 1.0 in stage 76.0 (TID 84) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:01:39.903 Executor task launch worker for task 1.0 in stage 76.0 (TID 84) INFO Executor: Finished task 1.0 in stage 76.0 (TID 84). 3011 bytes result sent to driver
24/04/16 17:01:39.903 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 84) in 78 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:01:39.903 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
24/04/16 17:01:39.903 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 76 (count at NativeMethodAccessorImpl.java:0) finished in 0,171 s
24/04/16 17:01:39.903 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 17:01:39.903 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 17:01:39.903 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 17:01:39.903 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 17:01:39.922 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 17:01:39.922 dag-scheduler-event-loop INFO DAGScheduler: Got job 58 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 17:01:39.922 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 78 (count at NativeMethodAccessorImpl.java:0)
24/04/16 17:01:39.922 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
24/04/16 17:01:39.922 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:39.922 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[288] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 17:01:39.922 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 12.1 KiB, free 908.8 MiB)
24/04/16 17:01:39.922 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 908.8 MiB)
24/04/16 17:01:39.922 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.8 KiB, free: 911.2 MiB)
24/04/16 17:01:39.922 dag-scheduler-event-loop INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:39.922 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[288] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 17:01:39.922 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0
24/04/16 17:01:39.922 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 85) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 17:01:39.934 Executor task launch worker for task 0.0 in stage 78.0 (TID 85) INFO Executor: Running task 0.0 in stage 78.0 (TID 85)
24/04/16 17:01:39.935 Executor task launch worker for task 0.0 in stage 78.0 (TID 85) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:01:39.935 Executor task launch worker for task 0.0 in stage 78.0 (TID 85) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:01:39.937 Executor task launch worker for task 0.0 in stage 78.0 (TID 85) INFO Executor: Finished task 0.0 in stage 78.0 (TID 85). 3866 bytes result sent to driver
24/04/16 17:01:39.937 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 85) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:01:39.937 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
24/04/16 17:01:39.937 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 78 (count at NativeMethodAccessorImpl.java:0) finished in 0,015 s
24/04/16 17:01:39.937 dag-scheduler-event-loop INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:01:39.937 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished
24/04/16 17:01:39.937 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 58 finished: count at NativeMethodAccessorImpl.java:0, took 0,009691 s
24/04/16 17:01:40.226 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_83_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.8 KiB, free: 911.2 MiB)
24/04/16 17:01:40.226 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_82_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 57.1 KiB, free: 911.3 MiB)
24/04/16 17:01:40.288 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 3.4595 ms
24/04/16 17:01:40.304 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.1406 ms
24/04/16 17:01:40.304 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 303 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 21
24/04/16 17:01:40.304 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 59 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
24/04/16 17:01:40.304 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 79 (count at NativeMethodAccessorImpl.java:0)
24/04/16 17:01:40.304 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:01:40.304 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:40.304 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[303] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 17:01:40.319 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 226.3 KiB, free 908.9 MiB)
24/04/16 17:01:40.319 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 57.2 KiB, free 908.8 MiB)
24/04/16 17:01:40.319 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 57.2 KiB, free: 911.2 MiB)
24/04/16 17:01:40.319 dag-scheduler-event-loop INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:40.319 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[303] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:01:40.319 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 79.0 with 2 tasks resource profile 0
24/04/16 17:01:40.335 dispatcher-event-loop-1 WARN TaskSetManager: Stage 79 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:01:40.335 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 86) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 17:01:40.335 Executor task launch worker for task 0.0 in stage 79.0 (TID 86) INFO Executor: Running task 0.0 in stage 79.0 (TID 86)
24/04/16 17:01:40.335 Executor task launch worker for task 0.0 in stage 79.0 (TID 86) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:01:40.444 Executor task launch worker for task 0.0 in stage 79.0 (TID 86) INFO Executor: Finished task 0.0 in stage 79.0 (TID 86). 3011 bytes result sent to driver
24/04/16 17:01:40.460 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 87) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818800 bytes) 
24/04/16 17:01:40.460 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 86) in 141 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:01:40.460 Executor task launch worker for task 1.0 in stage 79.0 (TID 87) INFO Executor: Running task 1.0 in stage 79.0 (TID 87)
24/04/16 17:01:40.460 Executor task launch worker for task 1.0 in stage 79.0 (TID 87) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:01:40.538 Executor task launch worker for task 1.0 in stage 79.0 (TID 87) INFO Executor: Finished task 1.0 in stage 79.0 (TID 87). 3011 bytes result sent to driver
24/04/16 17:01:40.538 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 87) in 94 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:01:40.538 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
24/04/16 17:01:40.538 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 79 (count at NativeMethodAccessorImpl.java:0) finished in 0,219 s
24/04/16 17:01:40.538 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 17:01:40.538 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 17:01:40.538 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 17:01:40.538 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 17:01:40.554 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/16 17:01:40.554 dag-scheduler-event-loop INFO DAGScheduler: Got job 60 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/16 17:01:40.554 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 81 (count at NativeMethodAccessorImpl.java:0)
24/04/16 17:01:40.554 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
24/04/16 17:01:40.554 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:01:40.554 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[306] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/16 17:01:40.554 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 12.1 KiB, free 908.8 MiB)
24/04/16 17:01:40.554 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 908.8 MiB)
24/04/16 17:01:40.554 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.8 KiB, free: 911.2 MiB)
24/04/16 17:01:40.554 dag-scheduler-event-loop INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1535
24/04/16 17:01:40.554 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[306] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/16 17:01:40.554 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0
24/04/16 17:01:40.554 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 88) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 17:01:40.554 Executor task launch worker for task 0.0 in stage 81.0 (TID 88) INFO Executor: Running task 0.0 in stage 81.0 (TID 88)
24/04/16 17:01:40.554 Executor task launch worker for task 0.0 in stage 81.0 (TID 88) INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:01:40.554 Executor task launch worker for task 0.0 in stage 81.0 (TID 88) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:01:40.569 Executor task launch worker for task 0.0 in stage 81.0 (TID 88) INFO Executor: Finished task 0.0 in stage 81.0 (TID 88). 3866 bytes result sent to driver
24/04/16 17:01:40.569 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 88) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:01:40.569 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
24/04/16 17:01:40.569 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 81 (count at NativeMethodAccessorImpl.java:0) finished in 0,015 s
24/04/16 17:01:40.569 dag-scheduler-event-loop INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:01:40.569 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
24/04/16 17:01:40.569 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 60 finished: count at NativeMethodAccessorImpl.java:0, took 0,009846 s
24/04/16 17:06:50.847 nioEventLoopGroup-2-2 INFO Instrumentation: [afc91b96] training finished
24/04/16 17:06:51.019 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_84_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 57.2 KiB, free: 911.3 MiB)
24/04/16 17:06:51.019 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_85_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.8 KiB, free: 911.3 MiB)
24/04/16 17:06:51.148 nioEventLoopGroup-2-2 INFO Instrumentation: [504fbb68] training finished
24/04/16 17:06:51.489 nioEventLoopGroup-2-2 INFO Instrumentation: [d521b0fb] Stage class: RandomForestRegressor
24/04/16 17:06:51.489 nioEventLoopGroup-2-2 INFO Instrumentation: [d521b0fb] Stage uid: random_forest__21d6cb96_0366_4b0d_b8bf_1480fe8d4eaf
24/04/16 17:06:51.489 nioEventLoopGroup-2-2 INFO Instrumentation: [d521b0fb] training: numPartitions=2 storageLevel=StorageLevel(1 replicas)
24/04/16 17:06:51.489 nioEventLoopGroup-2-2 INFO Instrumentation: [d521b0fb] {"subsamplingRate":1.0,"impurity":"variance","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"numTrees":20}
24/04/16 17:06:51.505 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 17:06:51.505 dag-scheduler-event-loop INFO DAGScheduler: Got job 61 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 17:06:51.505 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 82 (take at DecisionTreeMetadata.scala:119)
24/04/16 17:06:51.505 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:06:51.505 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:06:51.505 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[329] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 17:06:51.521 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 521.9 KiB, free 908.6 MiB)
24/04/16 17:06:51.521 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 117.4 KiB, free 908.5 MiB)
24/04/16 17:06:51.521 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 117.4 KiB, free: 911.2 MiB)
24/04/16 17:06:51.521 dag-scheduler-event-loop INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:51.521 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[329] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 17:06:51.521 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
24/04/16 17:06:51.521 dispatcher-event-loop-0 WARN TaskSetManager: Stage 82 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:06:51.521 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 89) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 17:06:51.536 Executor task launch worker for task 0.0 in stage 82.0 (TID 89) INFO Executor: Running task 0.0 in stage 82.0 (TID 89)
24/04/16 17:06:51.536 Executor task launch worker for task 0.0 in stage 82.0 (TID 89) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:06:51.720 Executor task launch worker for task 0.0 in stage 82.0 (TID 89) INFO CodeGenerator: Code generated in 49.7656 ms
24/04/16 17:06:51.729 Executor task launch worker for task 0.0 in stage 82.0 (TID 89) INFO Executor: Finished task 0.0 in stage 82.0 (TID 89). 1993 bytes result sent to driver
24/04/16 17:06:51.729 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 89) in 208 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:06:51.729 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
24/04/16 17:06:51.729 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 82 (take at DecisionTreeMetadata.scala:119) finished in 0,224 s
24/04/16 17:06:51.729 dag-scheduler-event-loop INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:06:51.729 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished
24/04/16 17:06:51.729 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 61 finished: take at DecisionTreeMetadata.scala:119, took 0,218848 s
24/04/16 17:06:51.729 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 17:06:51.729 dag-scheduler-event-loop INFO DAGScheduler: Got job 62 (aggregate at DecisionTreeMetadata.scala:125) with 2 output partitions
24/04/16 17:06:51.729 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 83 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 17:06:51.729 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:06:51.729 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:06:51.729 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[328] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 17:06:51.745 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 521.9 KiB, free 908.0 MiB)
24/04/16 17:06:51.745 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 117.6 KiB, free 907.9 MiB)
24/04/16 17:06:51.745 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 117.6 KiB, free: 911.1 MiB)
24/04/16 17:06:51.745 dag-scheduler-event-loop INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:51.745 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 83 (MapPartitionsRDD[328] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:51.745 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 83.0 with 2 tasks resource profile 0
24/04/16 17:06:51.761 dispatcher-event-loop-1 WARN TaskSetManager: Stage 83 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:06:51.761 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 90) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 17:06:51.761 Executor task launch worker for task 0.0 in stage 83.0 (TID 90) INFO Executor: Running task 0.0 in stage 83.0 (TID 90)
24/04/16 17:06:51.778 Executor task launch worker for task 0.0 in stage 83.0 (TID 90) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:06:52.020 Executor task launch worker for task 0.0 in stage 83.0 (TID 90) INFO Executor: Finished task 0.0 in stage 83.0 (TID 90). 2065 bytes result sent to driver
24/04/16 17:06:52.036 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 91) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818920 bytes) 
24/04/16 17:06:52.036 Executor task launch worker for task 1.0 in stage 83.0 (TID 91) INFO Executor: Running task 1.0 in stage 83.0 (TID 91)
24/04/16 17:06:52.036 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 90) in 291 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:52.065 Executor task launch worker for task 1.0 in stage 83.0 (TID 91) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:06:52.864 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_86_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 117.4 KiB, free: 911.2 MiB)
24/04/16 17:06:52.868 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 82.8 KiB, free: 911.3 MiB)
24/04/16 17:06:52.878 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 86.5 KiB, free: 911.3 MiB)
24/04/16 17:06:52.881 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_68_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 75.3 KiB, free: 911.4 MiB)
24/04/16 17:06:52.885 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_69_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 33.9 KiB, free: 911.5 MiB)
24/04/16 17:06:53.027 Executor task launch worker for task 1.0 in stage 83.0 (TID 91) INFO Executor: Finished task 1.0 in stage 83.0 (TID 91). 2151 bytes result sent to driver
24/04/16 17:06:53.027 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 91) in 1007 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:53.027 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
24/04/16 17:06:53.027 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 83 (aggregate at DecisionTreeMetadata.scala:125) finished in 1,298 s
24/04/16 17:06:53.027 dag-scheduler-event-loop INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:06:53.027 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished
24/04/16 17:06:53.027 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 62 finished: aggregate at DecisionTreeMetadata.scala:125, took 1,289193 s
24/04/16 17:06:53.043 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 17:06:53.043 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 331 (flatMap at RandomForest.scala:1039) as input to shuffle 22
24/04/16 17:06:53.043 dag-scheduler-event-loop INFO DAGScheduler: Got job 63 (collectAsMap at RandomForest.scala:1054) with 2 output partitions
24/04/16 17:06:53.043 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 85 (collectAsMap at RandomForest.scala:1054)
24/04/16 17:06:53.043 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
24/04/16 17:06:53.043 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 84)
24/04/16 17:06:53.043 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[331] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 17:06:53.043 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 531.0 KiB, free 909.5 MiB)
24/04/16 17:06:53.059 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 121.2 KiB, free 909.4 MiB)
24/04/16 17:06:53.059 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 121.2 KiB, free: 911.3 MiB)
24/04/16 17:06:53.059 dag-scheduler-event-loop INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:53.059 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[331] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:53.059 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 84.0 with 2 tasks resource profile 0
24/04/16 17:06:53.059 dispatcher-event-loop-0 WARN TaskSetManager: Stage 84 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:06:53.059 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 92) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:53.059 Executor task launch worker for task 0.0 in stage 84.0 (TID 92) INFO Executor: Running task 0.0 in stage 84.0 (TID 92)
24/04/16 17:06:53.074 Executor task launch worker for task 0.0 in stage 84.0 (TID 92) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:06:53.474 Executor task launch worker for task 0.0 in stage 84.0 (TID 92) INFO Executor: Finished task 0.0 in stage 84.0 (TID 92). 2291 bytes result sent to driver
24/04/16 17:06:53.483 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 93) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:53.483 Executor task launch worker for task 1.0 in stage 84.0 (TID 93) INFO Executor: Running task 1.0 in stage 84.0 (TID 93)
24/04/16 17:06:53.483 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 92) in 424 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:53.500 Executor task launch worker for task 1.0 in stage 84.0 (TID 93) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:06:53.961 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_87_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 117.6 KiB, free: 911.4 MiB)
24/04/16 17:06:53.992 Executor task launch worker for task 1.0 in stage 84.0 (TID 93) INFO Executor: Finished task 1.0 in stage 84.0 (TID 93). 2291 bytes result sent to driver
24/04/16 17:06:53.992 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 93) in 518 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:53.992 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
24/04/16 17:06:53.992 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 84 (flatMap at RandomForest.scala:1039) finished in 0,949 s
24/04/16 17:06:53.992 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 17:06:53.992 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 17:06:53.992 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 85)
24/04/16 17:06:53.992 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 17:06:53.992 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[333] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 17:06:53.992 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 11.9 KiB, free 910.0 MiB)
24/04/16 17:06:53.992 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 910.0 MiB)
24/04/16 17:06:53.992 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 4.5 KiB, free: 911.4 MiB)
24/04/16 17:06:53.992 dag-scheduler-event-loop INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:53.992 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 85 (MapPartitionsRDD[333] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:53.992 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 85.0 with 2 tasks resource profile 0
24/04/16 17:06:53.992 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 94) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:53.992 Executor task launch worker for task 0.0 in stage 85.0 (TID 94) INFO Executor: Running task 0.0 in stage 85.0 (TID 94)
24/04/16 17:06:53.992 Executor task launch worker for task 0.0 in stage 85.0 (TID 94) INFO ShuffleBlockFetcherIterator: Getting 2 (43.3 KiB) non-empty blocks including 2 (43.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:53.992 Executor task launch worker for task 0.0 in stage 85.0 (TID 94) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:54.008 Executor task launch worker for task 0.0 in stage 85.0 (TID 94) INFO Executor: Finished task 0.0 in stage 85.0 (TID 94). 24803 bytes result sent to driver
24/04/16 17:06:54.008 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 95) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:54.008 Executor task launch worker for task 1.0 in stage 85.0 (TID 95) INFO Executor: Running task 1.0 in stage 85.0 (TID 95)
24/04/16 17:06:54.008 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 94) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:54.008 Executor task launch worker for task 1.0 in stage 85.0 (TID 95) INFO ShuffleBlockFetcherIterator: Getting 2 (41.4 KiB) non-empty blocks including 2 (41.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:54.008 Executor task launch worker for task 1.0 in stage 85.0 (TID 95) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:54.024 Executor task launch worker for task 1.0 in stage 85.0 (TID 95) INFO Executor: Finished task 1.0 in stage 85.0 (TID 95). 23800 bytes result sent to driver
24/04/16 17:06:54.024 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 95) in 16 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:54.024 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
24/04/16 17:06:54.024 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 85 (collectAsMap at RandomForest.scala:1054) finished in 0,032 s
24/04/16 17:06:54.024 dag-scheduler-event-loop INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:06:54.024 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
24/04/16 17:06:54.024 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 63 finished: collectAsMap at RandomForest.scala:1054, took 0,988705 s
24/04/16 17:06:54.039 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 57.6 KiB, free 910.0 MiB)
24/04/16 17:06:54.039 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 910.0 MiB)
24/04/16 17:06:54.039 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 9.6 KiB, free: 911.4 MiB)
24/04/16 17:06:54.039 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 90 from broadcast at RandomForest.scala:293
24/04/16 17:06:54.044 nioEventLoopGroup-2-2 INFO Instrumentation: [d521b0fb] {"numFeatures":545}
24/04/16 17:06:54.044 nioEventLoopGroup-2-2 INFO Instrumentation: [d521b0fb] {"numClasses":0}
24/04/16 17:06:54.044 nioEventLoopGroup-2-2 INFO Instrumentation: [d521b0fb] {"numExamples":2647}
24/04/16 17:06:54.044 nioEventLoopGroup-2-2 INFO Instrumentation: [d521b0fb] {"sumOfWeights":2647.0}
24/04/16 17:06:54.044 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 16.1 KiB, free 909.9 MiB)
24/04/16 17:06:54.044 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 909.9 MiB)
24/04/16 17:06:54.044 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 10.3 KiB, free: 911.4 MiB)
24/04/16 17:06:54.044 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 91 from broadcast at RandomForest.scala:622
24/04/16 17:06:54.059 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 17:06:54.059 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 336 (mapPartitions at RandomForest.scala:644) as input to shuffle 23
24/04/16 17:06:54.059 dag-scheduler-event-loop INFO DAGScheduler: Got job 64 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 17:06:54.059 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 87 (collectAsMap at RandomForest.scala:663)
24/04/16 17:06:54.059 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)
24/04/16 17:06:54.059 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 86)
24/04/16 17:06:54.059 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[336] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 17:06:54.059 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 564.6 KiB, free 909.4 MiB)
24/04/16 17:06:54.059 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 133.7 KiB, free 909.2 MiB)
24/04/16 17:06:54.059 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 133.7 KiB, free: 911.3 MiB)
24/04/16 17:06:54.059 dag-scheduler-event-loop INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:54.059 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[336] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:54.059 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 86.0 with 2 tasks resource profile 0
24/04/16 17:06:54.075 dispatcher-event-loop-1 WARN TaskSetManager: Stage 86 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:06:54.075 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 96) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:54.075 Executor task launch worker for task 0.0 in stage 86.0 (TID 96) INFO Executor: Running task 0.0 in stage 86.0 (TID 96)
24/04/16 17:06:54.091 Executor task launch worker for task 0.0 in stage 86.0 (TID 96) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:06:54.277 Executor task launch worker for task 0.0 in stage 86.0 (TID 96) INFO MemoryStore: Block rdd_335_0 stored as values in memory (estimated size 2.9 MiB, free 906.3 MiB)
24/04/16 17:06:54.277 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_335_0 in memory on DESKTOP-LH06ASP:64589 (size: 2.9 MiB, free: 908.4 MiB)
24/04/16 17:06:54.311 Executor task launch worker for task 0.0 in stage 86.0 (TID 96) INFO Executor: Finished task 0.0 in stage 86.0 (TID 96). 2248 bytes result sent to driver
24/04/16 17:06:54.311 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 97) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:54.311 Executor task launch worker for task 1.0 in stage 86.0 (TID 97) INFO Executor: Running task 1.0 in stage 86.0 (TID 97)
24/04/16 17:06:54.311 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 96) in 252 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:54.328 Executor task launch worker for task 1.0 in stage 86.0 (TID 97) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:06:54.377 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_89_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 4.5 KiB, free: 908.4 MiB)
24/04/16 17:06:54.533 Executor task launch worker for task 1.0 in stage 86.0 (TID 97) INFO MemoryStore: Block rdd_335_1 stored as values in memory (estimated size 2.7 MiB, free 903.6 MiB)
24/04/16 17:06:54.533 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_335_1 in memory on DESKTOP-LH06ASP:64589 (size: 2.7 MiB, free: 905.7 MiB)
24/04/16 17:06:54.564 Executor task launch worker for task 1.0 in stage 86.0 (TID 97) INFO Executor: Finished task 1.0 in stage 86.0 (TID 97). 2291 bytes result sent to driver
24/04/16 17:06:54.564 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 97) in 253 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:54.564 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
24/04/16 17:06:54.564 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 86 (mapPartitions at RandomForest.scala:644) finished in 0,505 s
24/04/16 17:06:54.564 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 17:06:54.564 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 17:06:54.564 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 87)
24/04/16 17:06:54.564 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 17:06:54.564 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[338] at map at RandomForest.scala:663), which has no missing parents
24/04/16 17:06:54.564 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 7.4 KiB, free 903.6 MiB)
24/04/16 17:06:54.564 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 903.6 MiB)
24/04/16 17:06:54.564 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 3.8 KiB, free: 905.7 MiB)
24/04/16 17:06:54.564 dag-scheduler-event-loop INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:54.564 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 87 (MapPartitionsRDD[338] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:54.564 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 87.0 with 2 tasks resource profile 0
24/04/16 17:06:54.564 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 98) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:54.564 Executor task launch worker for task 0.0 in stage 87.0 (TID 98) INFO Executor: Running task 0.0 in stage 87.0 (TID 98)
24/04/16 17:06:54.564 Executor task launch worker for task 0.0 in stage 87.0 (TID 98) INFO ShuffleBlockFetcherIterator: Getting 2 (136.0 KiB) non-empty blocks including 2 (136.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:54.564 Executor task launch worker for task 0.0 in stage 87.0 (TID 98) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:54.564 Executor task launch worker for task 0.0 in stage 87.0 (TID 98) INFO Executor: Finished task 0.0 in stage 87.0 (TID 98). 4184 bytes result sent to driver
24/04/16 17:06:54.580 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 99) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:54.580 Executor task launch worker for task 1.0 in stage 87.0 (TID 99) INFO Executor: Running task 1.0 in stage 87.0 (TID 99)
24/04/16 17:06:54.580 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 98) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:54.580 Executor task launch worker for task 1.0 in stage 87.0 (TID 99) INFO ShuffleBlockFetcherIterator: Getting 2 (136.0 KiB) non-empty blocks including 2 (136.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:54.580 Executor task launch worker for task 1.0 in stage 87.0 (TID 99) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:54.580 Executor task launch worker for task 1.0 in stage 87.0 (TID 99) INFO Executor: Finished task 1.0 in stage 87.0 (TID 99). 4210 bytes result sent to driver
24/04/16 17:06:54.580 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 99) in 0 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:54.580 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
24/04/16 17:06:54.580 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 87 (collectAsMap at RandomForest.scala:663) finished in 0,016 s
24/04/16 17:06:54.580 dag-scheduler-event-loop INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:06:54.580 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished
24/04/16 17:06:54.580 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 64 finished: collectAsMap at RandomForest.scala:663, took 0,529245 s
24/04/16 17:06:54.580 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(91) (from destroy at RandomForest.scala:674)
24/04/16 17:06:54.580 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_91_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 10.3 KiB, free: 905.7 MiB)
24/04/16 17:06:54.580 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 32.6 KiB, free 903.6 MiB)
24/04/16 17:06:54.580 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 903.6 MiB)
24/04/16 17:06:54.580 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 20.3 KiB, free: 905.6 MiB)
24/04/16 17:06:54.580 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 94 from broadcast at RandomForest.scala:622
24/04/16 17:06:54.596 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 17:06:54.596 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 339 (mapPartitions at RandomForest.scala:644) as input to shuffle 24
24/04/16 17:06:54.596 dag-scheduler-event-loop INFO DAGScheduler: Got job 65 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 17:06:54.596 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 89 (collectAsMap at RandomForest.scala:663)
24/04/16 17:06:54.596 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
24/04/16 17:06:54.596 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 88)
24/04/16 17:06:54.596 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 88 (MapPartitionsRDD[339] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 17:06:54.611 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 585.6 KiB, free 903.0 MiB)
24/04/16 17:06:54.611 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 146.9 KiB, free 902.9 MiB)
24/04/16 17:06:54.611 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 146.9 KiB, free: 905.5 MiB)
24/04/16 17:06:54.611 dag-scheduler-event-loop INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:54.611 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[339] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:54.611 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 88.0 with 2 tasks resource profile 0
24/04/16 17:06:54.611 dispatcher-event-loop-1 WARN TaskSetManager: Stage 88 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:06:54.611 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 100) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:54.611 Executor task launch worker for task 0.0 in stage 88.0 (TID 100) INFO Executor: Running task 0.0 in stage 88.0 (TID 100)
24/04/16 17:06:54.628 Executor task launch worker for task 0.0 in stage 88.0 (TID 100) INFO BlockManager: Found block rdd_335_0 locally
24/04/16 17:06:54.659 Executor task launch worker for task 0.0 in stage 88.0 (TID 100) INFO Executor: Finished task 0.0 in stage 88.0 (TID 100). 2248 bytes result sent to driver
24/04/16 17:06:54.659 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 101) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:54.675 Executor task launch worker for task 1.0 in stage 88.0 (TID 101) INFO Executor: Running task 1.0 in stage 88.0 (TID 101)
24/04/16 17:06:54.675 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 100) in 64 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:54.675 Executor task launch worker for task 1.0 in stage 88.0 (TID 101) INFO BlockManager: Found block rdd_335_1 locally
24/04/16 17:06:54.706 Executor task launch worker for task 1.0 in stage 88.0 (TID 101) INFO Executor: Finished task 1.0 in stage 88.0 (TID 101). 2248 bytes result sent to driver
24/04/16 17:06:54.706 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 101) in 47 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:54.706 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
24/04/16 17:06:54.706 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 88 (mapPartitions at RandomForest.scala:644) finished in 0,110 s
24/04/16 17:06:54.706 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 17:06:54.706 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 17:06:54.706 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 89)
24/04/16 17:06:54.706 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 17:06:54.706 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[341] at map at RandomForest.scala:663), which has no missing parents
24/04/16 17:06:54.706 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 11.1 KiB, free 902.9 MiB)
24/04/16 17:06:54.706 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 902.9 MiB)
24/04/16 17:06:54.706 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.2 KiB, free: 905.5 MiB)
24/04/16 17:06:54.722 dag-scheduler-event-loop INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:54.722 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 89 (MapPartitionsRDD[341] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:54.722 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 89.0 with 2 tasks resource profile 0
24/04/16 17:06:54.722 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 102) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:54.722 Executor task launch worker for task 0.0 in stage 89.0 (TID 102) INFO Executor: Running task 0.0 in stage 89.0 (TID 102)
24/04/16 17:06:54.722 Executor task launch worker for task 0.0 in stage 89.0 (TID 102) INFO ShuffleBlockFetcherIterator: Getting 2 (241.0 KiB) non-empty blocks including 2 (241.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:54.722 Executor task launch worker for task 0.0 in stage 89.0 (TID 102) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:54.722 Executor task launch worker for task 0.0 in stage 89.0 (TID 102) INFO Executor: Finished task 0.0 in stage 89.0 (TID 102). 6268 bytes result sent to driver
24/04/16 17:06:54.722 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 103) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:54.722 Executor task launch worker for task 1.0 in stage 89.0 (TID 103) INFO Executor: Running task 1.0 in stage 89.0 (TID 103)
24/04/16 17:06:54.722 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 102) in 0 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:54.722 Executor task launch worker for task 1.0 in stage 89.0 (TID 103) INFO ShuffleBlockFetcherIterator: Getting 2 (188.5 KiB) non-empty blocks including 2 (188.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:54.722 Executor task launch worker for task 1.0 in stage 89.0 (TID 103) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:54.737 Executor task launch worker for task 1.0 in stage 89.0 (TID 103) INFO Executor: Finished task 1.0 in stage 89.0 (TID 103). 6294 bytes result sent to driver
24/04/16 17:06:54.737 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 103) in 15 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:54.737 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
24/04/16 17:06:54.737 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 89 (collectAsMap at RandomForest.scala:663) finished in 0,031 s
24/04/16 17:06:54.737 dag-scheduler-event-loop INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:06:54.737 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished
24/04/16 17:06:54.737 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 65 finished: collectAsMap at RandomForest.scala:663, took 0,141958 s
24/04/16 17:06:54.737 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(94) (from destroy at RandomForest.scala:674)
24/04/16 17:06:54.737 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_94_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 20.3 KiB, free: 905.5 MiB)
24/04/16 17:06:54.737 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 60.4 KiB, free 902.8 MiB)
24/04/16 17:06:54.737 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 902.8 MiB)
24/04/16 17:06:54.737 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 37.3 KiB, free: 905.5 MiB)
24/04/16 17:06:54.737 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 97 from broadcast at RandomForest.scala:622
24/04/16 17:06:54.753 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 17:06:54.753 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 342 (mapPartitions at RandomForest.scala:644) as input to shuffle 25
24/04/16 17:06:54.753 dag-scheduler-event-loop INFO DAGScheduler: Got job 66 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 17:06:54.753 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 91 (collectAsMap at RandomForest.scala:663)
24/04/16 17:06:54.753 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
24/04/16 17:06:54.753 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 90)
24/04/16 17:06:54.753 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[342] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 17:06:54.768 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 621.3 KiB, free 902.8 MiB)
24/04/16 17:06:54.768 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_95_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 146.9 KiB, free: 905.6 MiB)
24/04/16 17:06:54.784 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 167.8 KiB, free 902.8 MiB)
24/04/16 17:06:54.784 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 167.8 KiB, free: 905.5 MiB)
24/04/16 17:06:54.784 dag-scheduler-event-loop INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:54.784 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[342] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:54.784 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 90.0 with 2 tasks resource profile 0
24/04/16 17:06:54.784 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_93_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 3.8 KiB, free: 905.5 MiB)
24/04/16 17:06:54.794 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_96_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.2 KiB, free: 905.5 MiB)
24/04/16 17:06:54.799 dispatcher-event-loop-1 WARN TaskSetManager: Stage 90 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:06:54.799 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 104) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:54.799 Executor task launch worker for task 0.0 in stage 90.0 (TID 104) INFO Executor: Running task 0.0 in stage 90.0 (TID 104)
24/04/16 17:06:54.811 Executor task launch worker for task 0.0 in stage 90.0 (TID 104) INFO BlockManager: Found block rdd_335_0 locally
24/04/16 17:06:54.842 Executor task launch worker for task 0.0 in stage 90.0 (TID 104) INFO Executor: Finished task 0.0 in stage 90.0 (TID 104). 2248 bytes result sent to driver
24/04/16 17:06:54.842 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 105) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:54.858 Executor task launch worker for task 1.0 in stage 90.0 (TID 105) INFO Executor: Running task 1.0 in stage 90.0 (TID 105)
24/04/16 17:06:54.858 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 104) in 74 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:54.858 Executor task launch worker for task 1.0 in stage 90.0 (TID 105) INFO BlockManager: Found block rdd_335_1 locally
24/04/16 17:06:54.905 Executor task launch worker for task 1.0 in stage 90.0 (TID 105) INFO Executor: Finished task 1.0 in stage 90.0 (TID 105). 2248 bytes result sent to driver
24/04/16 17:06:54.905 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 105) in 63 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:54.905 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
24/04/16 17:06:54.905 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 90 (mapPartitions at RandomForest.scala:644) finished in 0,152 s
24/04/16 17:06:54.905 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 17:06:54.905 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 17:06:54.905 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 91)
24/04/16 17:06:54.905 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 17:06:54.905 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[344] at map at RandomForest.scala:663), which has no missing parents
24/04/16 17:06:54.905 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 14.4 KiB, free 902.8 MiB)
24/04/16 17:06:54.905 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 902.8 MiB)
24/04/16 17:06:54.905 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 6.3 KiB, free: 905.5 MiB)
24/04/16 17:06:54.905 dag-scheduler-event-loop INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:54.905 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 91 (MapPartitionsRDD[344] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:54.905 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 91.0 with 2 tasks resource profile 0
24/04/16 17:06:54.905 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 106) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:54.905 Executor task launch worker for task 0.0 in stage 91.0 (TID 106) INFO Executor: Running task 0.0 in stage 91.0 (TID 106)
24/04/16 17:06:54.905 Executor task launch worker for task 0.0 in stage 91.0 (TID 106) INFO ShuffleBlockFetcherIterator: Getting 2 (354.5 KiB) non-empty blocks including 2 (354.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:54.905 Executor task launch worker for task 0.0 in stage 91.0 (TID 106) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:54.920 Executor task launch worker for task 0.0 in stage 91.0 (TID 106) INFO Executor: Finished task 0.0 in stage 91.0 (TID 106). 9856 bytes result sent to driver
24/04/16 17:06:54.920 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 107) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:54.920 Executor task launch worker for task 1.0 in stage 91.0 (TID 107) INFO Executor: Running task 1.0 in stage 91.0 (TID 107)
24/04/16 17:06:54.920 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 106) in 15 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:54.920 Executor task launch worker for task 1.0 in stage 91.0 (TID 107) INFO ShuffleBlockFetcherIterator: Getting 2 (322.2 KiB) non-empty blocks including 2 (322.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:54.920 Executor task launch worker for task 1.0 in stage 91.0 (TID 107) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:54.936 Executor task launch worker for task 1.0 in stage 91.0 (TID 107) INFO Executor: Finished task 1.0 in stage 91.0 (TID 107). 9843 bytes result sent to driver
24/04/16 17:06:54.936 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 107) in 16 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:54.936 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
24/04/16 17:06:54.936 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 91 (collectAsMap at RandomForest.scala:663) finished in 0,031 s
24/04/16 17:06:54.936 dag-scheduler-event-loop INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:06:54.936 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished
24/04/16 17:06:54.936 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 66 finished: collectAsMap at RandomForest.scala:663, took 0,179251 s
24/04/16 17:06:54.936 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(97) (from destroy at RandomForest.scala:674)
24/04/16 17:06:54.936 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_97_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 37.3 KiB, free: 905.5 MiB)
24/04/16 17:06:54.936 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 73.3 KiB, free 902.8 MiB)
24/04/16 17:06:54.936 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 45.7 KiB, free 902.7 MiB)
24/04/16 17:06:54.936 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 45.7 KiB, free: 905.5 MiB)
24/04/16 17:06:54.936 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 100 from broadcast at RandomForest.scala:622
24/04/16 17:06:54.951 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 17:06:54.951 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 345 (mapPartitions at RandomForest.scala:644) as input to shuffle 26
24/04/16 17:06:54.951 dag-scheduler-event-loop INFO DAGScheduler: Got job 67 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 17:06:54.951 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 93 (collectAsMap at RandomForest.scala:663)
24/04/16 17:06:54.951 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)
24/04/16 17:06:54.951 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 92)
24/04/16 17:06:54.951 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[345] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 17:06:54.967 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 652.6 KiB, free 902.1 MiB)
24/04/16 17:06:54.967 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 182.1 KiB, free 901.9 MiB)
24/04/16 17:06:54.967 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 182.1 KiB, free: 905.3 MiB)
24/04/16 17:06:54.967 dag-scheduler-event-loop INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:54.967 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[345] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:54.967 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 92.0 with 2 tasks resource profile 0
24/04/16 17:06:54.967 dispatcher-event-loop-1 WARN TaskSetManager: Stage 92 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:06:54.967 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 108) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:54.967 Executor task launch worker for task 0.0 in stage 92.0 (TID 108) INFO Executor: Running task 0.0 in stage 92.0 (TID 108)
24/04/16 17:06:54.983 Executor task launch worker for task 0.0 in stage 92.0 (TID 108) INFO BlockManager: Found block rdd_335_0 locally
24/04/16 17:06:55.030 Executor task launch worker for task 0.0 in stage 92.0 (TID 108) INFO Executor: Finished task 0.0 in stage 92.0 (TID 108). 2248 bytes result sent to driver
24/04/16 17:06:55.030 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 109) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:55.030 Executor task launch worker for task 1.0 in stage 92.0 (TID 109) INFO Executor: Running task 1.0 in stage 92.0 (TID 109)
24/04/16 17:06:55.030 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 108) in 63 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:55.045 Executor task launch worker for task 1.0 in stage 92.0 (TID 109) INFO BlockManager: Found block rdd_335_1 locally
24/04/16 17:06:55.076 Executor task launch worker for task 1.0 in stage 92.0 (TID 109) INFO Executor: Finished task 1.0 in stage 92.0 (TID 109). 2248 bytes result sent to driver
24/04/16 17:06:55.092 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 109) in 62 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:55.092 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
24/04/16 17:06:55.092 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 92 (mapPartitions at RandomForest.scala:644) finished in 0,141 s
24/04/16 17:06:55.092 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 17:06:55.092 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 17:06:55.092 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 93)
24/04/16 17:06:55.092 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 17:06:55.092 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[347] at map at RandomForest.scala:663), which has no missing parents
24/04/16 17:06:55.092 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 16.0 KiB, free 901.9 MiB)
24/04/16 17:06:55.092 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 901.9 MiB)
24/04/16 17:06:55.092 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 6.8 KiB, free: 905.3 MiB)
24/04/16 17:06:55.092 dag-scheduler-event-loop INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:55.092 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 93 (MapPartitionsRDD[347] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:55.092 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 93.0 with 2 tasks resource profile 0
24/04/16 17:06:55.092 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 110) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:55.092 Executor task launch worker for task 0.0 in stage 93.0 (TID 110) INFO Executor: Running task 0.0 in stage 93.0 (TID 110)
24/04/16 17:06:55.092 Executor task launch worker for task 0.0 in stage 93.0 (TID 110) INFO ShuffleBlockFetcherIterator: Getting 2 (407.6 KiB) non-empty blocks including 2 (407.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:55.092 Executor task launch worker for task 0.0 in stage 93.0 (TID 110) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:55.108 Executor task launch worker for task 0.0 in stage 93.0 (TID 110) INFO Executor: Finished task 0.0 in stage 93.0 (TID 110). 11507 bytes result sent to driver
24/04/16 17:06:55.108 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 111) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:55.108 Executor task launch worker for task 1.0 in stage 93.0 (TID 111) INFO Executor: Running task 1.0 in stage 93.0 (TID 111)
24/04/16 17:06:55.108 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 110) in 16 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:55.108 Executor task launch worker for task 1.0 in stage 93.0 (TID 111) INFO ShuffleBlockFetcherIterator: Getting 2 (389.9 KiB) non-empty blocks including 2 (389.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:55.108 Executor task launch worker for task 1.0 in stage 93.0 (TID 111) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:55.123 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_101_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 182.1 KiB, free: 905.5 MiB)
24/04/16 17:06:55.139 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_98_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 167.8 KiB, free: 905.6 MiB)
24/04/16 17:06:55.139 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_99_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 6.3 KiB, free: 905.6 MiB)
24/04/16 17:06:55.139 Executor task launch worker for task 1.0 in stage 93.0 (TID 111) INFO Executor: Finished task 1.0 in stage 93.0 (TID 111). 11520 bytes result sent to driver
24/04/16 17:06:55.139 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 111) in 31 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:55.139 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
24/04/16 17:06:55.139 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 93 (collectAsMap at RandomForest.scala:663) finished in 0,047 s
24/04/16 17:06:55.139 dag-scheduler-event-loop INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:06:55.139 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished
24/04/16 17:06:55.139 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 67 finished: collectAsMap at RandomForest.scala:663, took 0,181975 s
24/04/16 17:06:55.139 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(100) (from destroy at RandomForest.scala:674)
24/04/16 17:06:55.139 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_100_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 45.7 KiB, free: 905.7 MiB)
24/04/16 17:06:55.139 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 79.9 KiB, free 903.5 MiB)
24/04/16 17:06:55.139 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 49.5 KiB, free 903.5 MiB)
24/04/16 17:06:55.139 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 49.5 KiB, free: 905.6 MiB)
24/04/16 17:06:55.139 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 103 from broadcast at RandomForest.scala:622
24/04/16 17:06:55.155 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 17:06:55.155 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 348 (mapPartitions at RandomForest.scala:644) as input to shuffle 27
24/04/16 17:06:55.155 dag-scheduler-event-loop INFO DAGScheduler: Got job 68 (collectAsMap at RandomForest.scala:663) with 2 output partitions
24/04/16 17:06:55.155 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 95 (collectAsMap at RandomForest.scala:663)
24/04/16 17:06:55.155 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)
24/04/16 17:06:55.155 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 94)
24/04/16 17:06:55.155 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[348] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 17:06:55.170 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 682.1 KiB, free 902.8 MiB)
24/04/16 17:06:55.170 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 192.6 KiB, free 902.6 MiB)
24/04/16 17:06:55.170 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 192.6 KiB, free: 905.4 MiB)
24/04/16 17:06:55.170 dag-scheduler-event-loop INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:55.170 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[348] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:55.170 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 94.0 with 2 tasks resource profile 0
24/04/16 17:06:55.170 dispatcher-event-loop-1 WARN TaskSetManager: Stage 94 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:06:55.170 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 112) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:55.170 Executor task launch worker for task 0.0 in stage 94.0 (TID 112) INFO Executor: Running task 0.0 in stage 94.0 (TID 112)
24/04/16 17:06:55.194 Executor task launch worker for task 0.0 in stage 94.0 (TID 112) INFO BlockManager: Found block rdd_335_0 locally
24/04/16 17:06:55.291 Executor task launch worker for task 0.0 in stage 94.0 (TID 112) INFO Executor: Finished task 0.0 in stage 94.0 (TID 112). 2248 bytes result sent to driver
24/04/16 17:06:55.291 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 113) (DESKTOP-LH06ASP, executor driver, partition 1, PROCESS_LOCAL, 9818909 bytes) 
24/04/16 17:06:55.291 Executor task launch worker for task 1.0 in stage 94.0 (TID 113) INFO Executor: Running task 1.0 in stage 94.0 (TID 113)
24/04/16 17:06:55.291 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 112) in 121 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:55.314 Executor task launch worker for task 1.0 in stage 94.0 (TID 113) INFO BlockManager: Found block rdd_335_1 locally
24/04/16 17:06:55.354 Executor task launch worker for task 1.0 in stage 94.0 (TID 113) INFO Executor: Finished task 1.0 in stage 94.0 (TID 113). 2248 bytes result sent to driver
24/04/16 17:06:55.354 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 113) in 63 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:55.354 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
24/04/16 17:06:55.354 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 94 (mapPartitions at RandomForest.scala:644) finished in 0,199 s
24/04/16 17:06:55.355 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 17:06:55.355 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 17:06:55.355 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 95)
24/04/16 17:06:55.355 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 17:06:55.355 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[350] at map at RandomForest.scala:663), which has no missing parents
24/04/16 17:06:55.356 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 16.8 KiB, free 902.6 MiB)
24/04/16 17:06:55.356 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 902.6 MiB)
24/04/16 17:06:55.357 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 7.0 KiB, free: 905.4 MiB)
24/04/16 17:06:55.357 dag-scheduler-event-loop INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:55.357 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 95 (MapPartitionsRDD[350] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1))
24/04/16 17:06:55.357 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 95.0 with 2 tasks resource profile 0
24/04/16 17:06:55.358 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 114) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:55.358 Executor task launch worker for task 0.0 in stage 95.0 (TID 114) INFO Executor: Running task 0.0 in stage 95.0 (TID 114)
24/04/16 17:06:55.359 Executor task launch worker for task 0.0 in stage 95.0 (TID 114) INFO ShuffleBlockFetcherIterator: Getting 2 (407.6 KiB) non-empty blocks including 2 (407.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:55.359 Executor task launch worker for task 0.0 in stage 95.0 (TID 114) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:55.375 Executor task launch worker for task 0.0 in stage 95.0 (TID 114) INFO Executor: Finished task 0.0 in stage 95.0 (TID 114). 12315 bytes result sent to driver
24/04/16 17:06:55.375 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 115) (DESKTOP-LH06ASP, executor driver, partition 1, NODE_LOCAL, 7181 bytes) 
24/04/16 17:06:55.375 Executor task launch worker for task 1.0 in stage 95.0 (TID 115) INFO Executor: Running task 1.0 in stage 95.0 (TID 115)
24/04/16 17:06:55.375 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 114) in 17 ms on DESKTOP-LH06ASP (executor driver) (1/2)
24/04/16 17:06:55.375 Executor task launch worker for task 1.0 in stage 95.0 (TID 115) INFO ShuffleBlockFetcherIterator: Getting 2 (428.9 KiB) non-empty blocks including 2 (428.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 17:06:55.375 Executor task launch worker for task 1.0 in stage 95.0 (TID 115) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 17:06:55.391 Executor task launch worker for task 1.0 in stage 95.0 (TID 115) INFO Executor: Finished task 1.0 in stage 95.0 (TID 115). 12203 bytes result sent to driver
24/04/16 17:06:55.391 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 115) in 16 ms on DESKTOP-LH06ASP (executor driver) (2/2)
24/04/16 17:06:55.391 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
24/04/16 17:06:55.391 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 95 (collectAsMap at RandomForest.scala:663) finished in 0,036 s
24/04/16 17:06:55.391 dag-scheduler-event-loop INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:06:55.391 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 95: Stage finished
24/04/16 17:06:55.391 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 68 finished: collectAsMap at RandomForest.scala:663, took 0,238940 s
24/04/16 17:06:55.391 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(103) (from destroy at RandomForest.scala:674)
24/04/16 17:06:55.391 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 17:06:55.391 nioEventLoopGroup-2-2 INFO RandomForest:   init: 9.44E-5
  total: 1.3598937
  findBestSplits: 1.3492103
  chooseSplits: 1.3482343
24/04/16 17:06:55.391 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_103_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 49.5 KiB, free: 905.5 MiB)
24/04/16 17:06:55.391 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 335 from persistence list
24/04/16 17:06:55.391 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(90) (from destroy at RandomForest.scala:305)
24/04/16 17:06:55.391 block-manager-storage-async-thread-pool-246 INFO BlockManager: Removing RDD 335
24/04/16 17:06:55.406 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_90_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 9.6 KiB, free: 911.1 MiB)
24/04/16 17:06:55.406 nioEventLoopGroup-2-2 INFO Instrumentation: [d521b0fb] {"numFeatures":545}
24/04/16 17:06:55.406 nioEventLoopGroup-2-2 INFO Instrumentation: [d521b0fb] training finished
24/04/16 17:06:55.406 nioEventLoopGroup-2-2 INFO Instrumentation: [493ad163] training finished
24/04/16 17:06:56.017 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_104_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 192.6 KiB, free: 911.3 MiB)
24/04/16 17:06:56.023 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_105_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 7.0 KiB, free: 911.3 MiB)
24/04/16 17:06:56.027 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_102_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 6.8 KiB, free: 911.3 MiB)
24/04/16 17:06:56.043 nioEventLoopGroup-2-2 INFO Instrumentation: [d6f189a9] training finished
24/04/16 17:06:57.121 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 17:06:57.121 dag-scheduler-event-loop INFO DAGScheduler: Got job 69 (collect at utils.scala:26) with 1 output partitions
24/04/16 17:06:57.122 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 96 (collect at utils.scala:26)
24/04/16 17:06:57.122 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:06:57.122 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:06:57.122 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[353] at collect at utils.scala:26), which has no missing parents
24/04/16 17:06:57.123 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 62.5 KiB, free 909.3 MiB)
24/04/16 17:06:57.124 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 909.3 MiB)
24/04/16 17:06:57.125 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:06:57.125 dag-scheduler-event-loop INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1535
24/04/16 17:06:57.125 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[353] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 17:06:57.125 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0
24/04/16 17:06:57.126 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 116) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 17:06:57.126 Executor task launch worker for task 0.0 in stage 96.0 (TID 116) INFO Executor: Running task 0.0 in stage 96.0 (TID 116)
24/04/16 17:06:57.139 Executor task launch worker for task 0.0 in stage 96.0 (TID 116) INFO Executor: Finished task 0.0 in stage 96.0 (TID 116). 1387 bytes result sent to driver
24/04/16 17:06:57.140 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 116) in 14 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:06:57.140 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
24/04/16 17:06:57.140 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 96 (collect at utils.scala:26) finished in 0,018 s
24/04/16 17:06:57.140 dag-scheduler-event-loop INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:06:57.140 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 96: Stage finished
24/04/16 17:06:57.140 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 69 finished: collect at utils.scala:26, took 0,019168 s
24/04/16 17:06:59.591 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_106_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:06:59.741 nioEventLoopGroup-2-2 INFO Instrumentation: [a4e80fb5] training finished
24/04/16 17:06:59.788 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 479.2 KiB, free 908.9 MiB)
24/04/16 17:06:59.788 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 40.2 KiB, free 908.8 MiB)
24/04/16 17:06:59.788 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 40.2 KiB, free: 911.3 MiB)
24/04/16 17:06:59.788 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 107 from broadcast at RandomForestRegressor.scala:238
24/04/16 17:06:59.835 nioEventLoopGroup-2-2 INFO Instrumentation: [ca400d4b] training finished
24/04/16 17:07:00.873 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 17:07:00.874 dag-scheduler-event-loop INFO DAGScheduler: Got job 70 (collect at utils.scala:26) with 1 output partitions
24/04/16 17:07:00.874 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 97 (collect at utils.scala:26)
24/04/16 17:07:00.874 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:07:00.874 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:07:00.874 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[356] at collect at utils.scala:26), which has no missing parents
24/04/16 17:07:00.876 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 62.6 KiB, free 908.8 MiB)
24/04/16 17:07:00.877 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 908.8 MiB)
24/04/16 17:07:00.877 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:07:00.878 dag-scheduler-event-loop INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1535
24/04/16 17:07:00.878 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[356] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 17:07:00.878 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0
24/04/16 17:07:00.878 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 117) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 17:07:00.879 Executor task launch worker for task 0.0 in stage 97.0 (TID 117) INFO Executor: Running task 0.0 in stage 97.0 (TID 117)
24/04/16 17:07:00.895 Executor task launch worker for task 0.0 in stage 97.0 (TID 117) INFO Executor: Finished task 0.0 in stage 97.0 (TID 117). 1430 bytes result sent to driver
24/04/16 17:07:00.895 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 117) in 17 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:07:00.895 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
24/04/16 17:07:00.895 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 97 (collect at utils.scala:26) finished in 0,021 s
24/04/16 17:07:00.895 dag-scheduler-event-loop INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:07:00.895 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished
24/04/16 17:07:00.895 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 70 finished: collect at utils.scala:26, took 0,023849 s
24/04/16 17:07:03.202 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_108_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.3 MiB)
24/04/16 17:07:05.373 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 17:07:05.373 dag-scheduler-event-loop INFO DAGScheduler: Got job 71 (collect at utils.scala:26) with 1 output partitions
24/04/16 17:07:05.373 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 98 (collect at utils.scala:26)
24/04/16 17:07:05.373 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:07:05.373 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:07:05.373 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[364] at collect at utils.scala:26), which has no missing parents
24/04/16 17:07:05.373 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 373.1 KiB, free 908.5 MiB)
24/04/16 17:07:05.373 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 75.3 KiB, free 908.4 MiB)
24/04/16 17:07:05.373 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 75.3 KiB, free: 911.2 MiB)
24/04/16 17:07:05.373 dag-scheduler-event-loop INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1535
24/04/16 17:07:05.373 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[364] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 17:07:05.373 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0
24/04/16 17:07:05.388 dispatcher-event-loop-0 WARN TaskSetManager: Stage 98 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:07:05.388 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 118) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 17:07:05.388 Executor task launch worker for task 0.0 in stage 98.0 (TID 118) INFO Executor: Running task 0.0 in stage 98.0 (TID 118)
24/04/16 17:07:05.388 Executor task launch worker for task 0.0 in stage 98.0 (TID 118) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:07:05.535 Executor task launch worker for task 0.0 in stage 98.0 (TID 118) INFO CodeGenerator: Code generated in 57.8238 ms
24/04/16 17:07:05.622 Executor task launch worker for task 0.0 in stage 98.0 (TID 118) INFO Executor: Finished task 0.0 in stage 98.0 (TID 118). 6354 bytes result sent to driver
24/04/16 17:07:05.622 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 118) in 249 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:07:05.622 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
24/04/16 17:07:05.622 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 98 (collect at utils.scala:26) finished in 0,249 s
24/04/16 17:07:05.622 dag-scheduler-event-loop INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:07:05.622 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished
24/04/16 17:07:05.622 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 71 finished: collect at utils.scala:26, took 0,250019 s
24/04/16 17:07:11.711 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 17:07:11.712 dag-scheduler-event-loop INFO DAGScheduler: Got job 72 (collect at utils.scala:26) with 1 output partitions
24/04/16 17:07:11.712 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 99 (collect at utils.scala:26)
24/04/16 17:07:11.712 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:07:11.712 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:07:11.712 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[372] at collect at utils.scala:26), which has no missing parents
24/04/16 17:07:11.717 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 373.1 KiB, free 908.0 MiB)
24/04/16 17:07:11.719 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 75.3 KiB, free 908.0 MiB)
24/04/16 17:07:11.719 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 75.3 KiB, free: 911.1 MiB)
24/04/16 17:07:11.719 dag-scheduler-event-loop INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1535
24/04/16 17:07:11.719 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[372] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 17:07:11.719 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0
24/04/16 17:07:11.719 dispatcher-event-loop-1 WARN TaskSetManager: Stage 99 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:07:11.719 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 119) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 17:07:11.719 Executor task launch worker for task 0.0 in stage 99.0 (TID 119) INFO Executor: Running task 0.0 in stage 99.0 (TID 119)
24/04/16 17:07:11.734 Executor task launch worker for task 0.0 in stage 99.0 (TID 119) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:07:11.852 Executor task launch worker for task 0.0 in stage 99.0 (TID 119) INFO Executor: Finished task 0.0 in stage 99.0 (TID 119). 6354 bytes result sent to driver
24/04/16 17:07:11.852 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 119) in 133 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:07:11.852 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
24/04/16 17:07:11.852 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 99 (collect at utils.scala:26) finished in 0,140 s
24/04/16 17:07:11.852 dag-scheduler-event-loop INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:07:11.852 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished
24/04/16 17:07:11.852 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 72 finished: collect at utils.scala:26, took 0,152991 s
24/04/16 17:09:37.002 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_110_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 75.3 KiB, free: 911.2 MiB)
24/04/16 17:09:37.002 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_109_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 75.3 KiB, free: 911.3 MiB)
24/04/16 17:09:37.002 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_92_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 133.7 KiB, free: 911.4 MiB)
24/04/16 17:09:37.002 block-manager-storage-async-thread-pool-286 INFO BlockManager: Removing RDD 335
24/04/16 17:09:37.002 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_88_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 121.2 KiB, free: 911.5 MiB)
24/04/16 17:39:17.028 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 17:39:17.032 dag-scheduler-event-loop INFO DAGScheduler: Got job 73 (collect at utils.scala:26) with 1 output partitions
24/04/16 17:39:17.032 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 100 (collect at utils.scala:26)
24/04/16 17:39:17.032 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 17:39:17.033 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 17:39:17.033 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[378] at collect at utils.scala:26), which has no missing parents
24/04/16 17:39:17.041 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 123.2 KiB, free 910.0 MiB)
24/04/16 17:39:17.047 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 910.0 MiB)
24/04/16 17:39:17.048 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 17:39:17.048 dag-scheduler-event-loop INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1535
24/04/16 17:39:17.049 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[378] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 17:39:17.050 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
24/04/16 17:39:17.109 dispatcher-event-loop-1 WARN TaskSetManager: Stage 100 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 17:39:17.109 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 120) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 17:39:17.112 Executor task launch worker for task 0.0 in stage 100.0 (TID 120) INFO Executor: Running task 0.0 in stage 100.0 (TID 120)
24/04/16 17:39:17.155 Executor task launch worker for task 0.0 in stage 100.0 (TID 120) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 17:39:17.461 Executor task launch worker for task 0.0 in stage 100.0 (TID 120) INFO Executor: Finished task 0.0 in stage 100.0 (TID 120). 245201 bytes result sent to driver
24/04/16 17:39:17.465 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 120) in 413 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 17:39:17.466 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
24/04/16 17:39:17.466 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 100 (collect at utils.scala:26) finished in 0,432 s
24/04/16 17:39:17.466 dag-scheduler-event-loop INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 17:39:17.466 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 100: Stage finished
24/04/16 17:39:17.466 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 73 finished: collect at utils.scala:26, took 0,437473 s
24/04/16 17:39:17.916 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_111_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 18:05:57.187 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:05:57.187 dag-scheduler-event-loop INFO DAGScheduler: Got job 74 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:05:57.187 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 101 (collect at utils.scala:26)
24/04/16 18:05:57.187 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:05:57.187 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:05:57.187 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[384] at collect at utils.scala:26), which has no missing parents
24/04/16 18:05:57.187 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 123.2 KiB, free 910.0 MiB)
24/04/16 18:05:57.187 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 910.0 MiB)
24/04/16 18:05:57.187 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 18:05:57.187 dag-scheduler-event-loop INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1535
24/04/16 18:05:57.187 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[384] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:05:57.187 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks resource profile 0
24/04/16 18:05:57.202 dispatcher-event-loop-0 WARN TaskSetManager: Stage 101 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:05:57.202 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 121) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 18:05:57.202 Executor task launch worker for task 0.0 in stage 101.0 (TID 121) INFO Executor: Running task 0.0 in stage 101.0 (TID 121)
24/04/16 18:05:57.222 Executor task launch worker for task 0.0 in stage 101.0 (TID 121) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 18:05:57.333 Executor task launch worker for task 0.0 in stage 101.0 (TID 121) INFO Executor: Finished task 0.0 in stage 101.0 (TID 121). 245115 bytes result sent to driver
24/04/16 18:05:57.333 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 121) in 146 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:05:57.333 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
24/04/16 18:05:57.333 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 101 (collect at utils.scala:26) finished in 0,146 s
24/04/16 18:05:57.333 dag-scheduler-event-loop INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:05:57.333 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 101: Stage finished
24/04/16 18:05:57.333 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 74 finished: collect at utils.scala:26, took 0,145686 s
24/04/16 18:09:37.476 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_112_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 18:14:58.954 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 18:14:58.954 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 18:14:58.967 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 18:14:58.967 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 18:14:58.969 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 18:14:58.969 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 18:14:59.063 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:14:59.063 dag-scheduler-event-loop INFO DAGScheduler: Got job 75 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:14:59.063 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 102 (collect at utils.scala:26)
24/04/16 18:14:59.064 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:14:59.064 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:14:59.064 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[387] at collect at utils.scala:26), which has no missing parents
24/04/16 18:14:59.065 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 7.1 KiB, free 910.2 MiB)
24/04/16 18:14:59.067 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 910.2 MiB)
24/04/16 18:14:59.067 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 3.7 KiB, free: 911.5 MiB)
24/04/16 18:14:59.067 dag-scheduler-event-loop INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1535
24/04/16 18:14:59.068 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[387] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:14:59.068 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0
24/04/16 18:14:59.069 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 122) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9497 bytes) 
24/04/16 18:14:59.070 Executor task launch worker for task 0.0 in stage 102.0 (TID 122) INFO Executor: Running task 0.0 in stage 102.0 (TID 122)
24/04/16 18:14:59.075 Executor task launch worker for task 0.0 in stage 102.0 (TID 122) INFO Executor: Finished task 0.0 in stage 102.0 (TID 122). 2244 bytes result sent to driver
24/04/16 18:14:59.076 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 122) in 7 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:14:59.076 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
24/04/16 18:14:59.076 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 102 (collect at utils.scala:26) finished in 0,012 s
24/04/16 18:14:59.077 dag-scheduler-event-loop INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:14:59.077 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 102: Stage finished
24/04/16 18:14:59.077 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 75 finished: collect at utils.scala:26, took 0,014078 s
24/04/16 18:14:59.092 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 14.6809 ms
24/04/16 18:15:13.077 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 18:15:13.077 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 18:15:13.083 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 18:15:13.084 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 18:15:13.087 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 18:15:13.088 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 18:15:13.149 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:15:13.149 dag-scheduler-event-loop INFO DAGScheduler: Got job 76 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:15:13.149 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 103 (collect at utils.scala:26)
24/04/16 18:15:13.159 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:15:13.159 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:15:13.160 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[390] at collect at utils.scala:26), which has no missing parents
24/04/16 18:15:13.160 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 7.1 KiB, free 910.1 MiB)
24/04/16 18:15:13.160 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 910.1 MiB)
24/04/16 18:15:13.160 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 3.7 KiB, free: 911.5 MiB)
24/04/16 18:15:13.160 dag-scheduler-event-loop INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1535
24/04/16 18:15:13.160 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[390] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:15:13.160 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0
24/04/16 18:15:13.160 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 123) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9497 bytes) 
24/04/16 18:15:13.168 Executor task launch worker for task 0.0 in stage 103.0 (TID 123) INFO Executor: Running task 0.0 in stage 103.0 (TID 123)
24/04/16 18:15:13.168 Executor task launch worker for task 0.0 in stage 103.0 (TID 123) INFO Executor: Finished task 0.0 in stage 103.0 (TID 123). 2244 bytes result sent to driver
24/04/16 18:15:13.168 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 123) in 8 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:15:13.176 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
24/04/16 18:15:13.176 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 103 (collect at utils.scala:26) finished in 0,016 s
24/04/16 18:15:13.176 dag-scheduler-event-loop INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:15:13.176 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
24/04/16 18:15:13.178 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 76 finished: collect at utils.scala:26, took 0,019312 s
24/04/16 18:17:43.232 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:17:43.232 dag-scheduler-event-loop INFO DAGScheduler: Got job 77 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:17:43.232 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 104 (collect at utils.scala:26)
24/04/16 18:17:43.232 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:17:43.232 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:17:43.232 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[396] at collect at utils.scala:26), which has no missing parents
24/04/16 18:17:43.237 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 123.2 KiB, free 910.0 MiB)
24/04/16 18:17:43.237 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 910.0 MiB)
24/04/16 18:17:43.237 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 18:17:43.237 dag-scheduler-event-loop INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1535
24/04/16 18:17:43.237 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[396] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:17:43.237 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks resource profile 0
24/04/16 18:17:43.253 dispatcher-event-loop-1 WARN TaskSetManager: Stage 104 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:17:43.253 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 124) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 18:17:43.256 Executor task launch worker for task 0.0 in stage 104.0 (TID 124) INFO Executor: Running task 0.0 in stage 104.0 (TID 124)
24/04/16 18:17:43.266 Executor task launch worker for task 0.0 in stage 104.0 (TID 124) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 18:17:43.373 Executor task launch worker for task 0.0 in stage 104.0 (TID 124) INFO Executor: Finished task 0.0 in stage 104.0 (TID 124). 245115 bytes result sent to driver
24/04/16 18:17:43.374 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 124) in 137 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:17:43.374 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
24/04/16 18:17:43.375 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 104 (collect at utils.scala:26) finished in 0,143 s
24/04/16 18:17:43.375 dag-scheduler-event-loop INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:17:43.375 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 104: Stage finished
24/04/16 18:17:43.375 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 77 finished: collect at utils.scala:26, took 0,141026 s
24/04/16 18:17:43.690 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_115_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 31.0 KiB, free: 911.5 MiB)
24/04/16 18:17:43.693 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_113_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 3.7 KiB, free: 911.5 MiB)
24/04/16 18:17:43.697 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_114_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 3.7 KiB, free: 911.5 MiB)
24/04/16 18:21:11.128 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 18:21:11.131 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 18:21:11.132 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 18:21:11.132 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 18:21:11.137 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 18:21:11.139 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 18:21:11.202 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:21:11.202 dag-scheduler-event-loop INFO DAGScheduler: Got job 78 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:21:11.202 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 105 (collect at utils.scala:26)
24/04/16 18:21:11.202 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:21:11.202 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:21:11.202 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[399] at collect at utils.scala:26), which has no missing parents
24/04/16 18:21:11.202 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 7.1 KiB, free 910.2 MiB)
24/04/16 18:21:11.218 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 910.2 MiB)
24/04/16 18:21:11.218 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 3.7 KiB, free: 911.5 MiB)
24/04/16 18:21:11.218 dag-scheduler-event-loop INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1535
24/04/16 18:21:11.218 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[399] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:21:11.218 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0
24/04/16 18:21:11.220 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 125) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9497 bytes) 
24/04/16 18:21:11.221 Executor task launch worker for task 0.0 in stage 105.0 (TID 125) INFO Executor: Running task 0.0 in stage 105.0 (TID 125)
24/04/16 18:21:11.226 Executor task launch worker for task 0.0 in stage 105.0 (TID 125) INFO Executor: Finished task 0.0 in stage 105.0 (TID 125). 2244 bytes result sent to driver
24/04/16 18:21:11.229 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 125) in 9 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:21:11.229 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
24/04/16 18:21:11.232 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 105 (collect at utils.scala:26) finished in 0,030 s
24/04/16 18:21:11.232 dag-scheduler-event-loop INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:21:11.232 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
24/04/16 18:21:11.233 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 78 finished: collect at utils.scala:26, took 0,019856 s
24/04/16 18:21:12.668 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_116_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 3.7 KiB, free: 911.5 MiB)
24/04/16 18:21:19.672 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:21:19.672 dag-scheduler-event-loop INFO DAGScheduler: Got job 79 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:21:19.672 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 106 (collect at utils.scala:26)
24/04/16 18:21:19.672 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:21:19.672 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:21:19.672 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[403] at collect at utils.scala:26), which has no missing parents
24/04/16 18:21:19.679 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 62.4 KiB, free 910.1 MiB)
24/04/16 18:21:19.679 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.1 MiB)
24/04/16 18:21:19.679 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 18:21:19.679 dag-scheduler-event-loop INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1535
24/04/16 18:21:19.679 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[403] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:21:19.679 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
24/04/16 18:21:19.684 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 126) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 18:21:19.685 Executor task launch worker for task 0.0 in stage 106.0 (TID 126) INFO Executor: Running task 0.0 in stage 106.0 (TID 126)
24/04/16 18:21:19.703 Executor task launch worker for task 0.0 in stage 106.0 (TID 126) INFO Executor: Finished task 0.0 in stage 106.0 (TID 126). 1387 bytes result sent to driver
24/04/16 18:21:19.703 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 126) in 19 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:21:19.703 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
24/04/16 18:21:19.703 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 106 (collect at utils.scala:26) finished in 0,024 s
24/04/16 18:21:19.703 dag-scheduler-event-loop INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:21:19.703 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished
24/04/16 18:21:19.714 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 79 finished: collect at utils.scala:26, took 0,036544 s
24/04/16 18:21:24.313 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:21:24.324 dag-scheduler-event-loop INFO DAGScheduler: Got job 80 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:21:24.324 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 107 (collect at utils.scala:26)
24/04/16 18:21:24.324 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:21:24.324 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:21:24.324 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[406] at collect at utils.scala:26), which has no missing parents
24/04/16 18:21:24.326 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 62.4 KiB, free 910.0 MiB)
24/04/16 18:21:24.327 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 910.0 MiB)
24/04/16 18:21:24.327 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 18:21:24.328 dag-scheduler-event-loop INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1535
24/04/16 18:21:24.328 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[406] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:21:24.328 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0
24/04/16 18:21:24.329 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 127) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 18:21:24.329 Executor task launch worker for task 0.0 in stage 107.0 (TID 127) INFO Executor: Running task 0.0 in stage 107.0 (TID 127)
24/04/16 18:21:24.349 Executor task launch worker for task 0.0 in stage 107.0 (TID 127) INFO Executor: Finished task 0.0 in stage 107.0 (TID 127). 1430 bytes result sent to driver
24/04/16 18:21:24.349 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 127) in 20 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:21:24.349 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
24/04/16 18:21:24.349 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 107 (collect at utils.scala:26) finished in 0,025 s
24/04/16 18:21:24.349 dag-scheduler-event-loop INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:21:24.349 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 107: Stage finished
24/04/16 18:21:24.349 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 80 finished: collect at utils.scala:26, took 0,028520 s
24/04/16 18:21:27.316 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 18:21:27.316 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 18:21:27.316 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
24/04/16 18:21:27.316 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_database: default	
24/04/16 18:21:27.326 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
24/04/16 18:21:27.326 nioEventLoopGroup-2-2 INFO audit: ugi=pedro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
24/04/16 18:22:49.271 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_118_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 18:22:49.274 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_117_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 911.5 MiB)
24/04/16 18:22:50.357 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 414 (collect at StringIndexer.scala:204) as input to shuffle 28
24/04/16 18:22:50.357 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 81 (collect at StringIndexer.scala:204) with 1 output partitions
24/04/16 18:22:50.357 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 108 (collect at StringIndexer.scala:204)
24/04/16 18:22:50.357 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:22:50.357 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:22:50.357 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[414] at collect at StringIndexer.scala:204), which has no missing parents
24/04/16 18:22:50.426 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 112.1 KiB, free 910.1 MiB)
24/04/16 18:22:50.426 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 910.0 MiB)
24/04/16 18:22:50.426 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 30.0 KiB, free: 911.5 MiB)
24/04/16 18:22:50.426 dag-scheduler-event-loop INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:50.426 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[414] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:50.426 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks resource profile 0
24/04/16 18:22:50.444 dispatcher-event-loop-1 WARN TaskSetManager: Stage 108 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:22:50.444 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 128) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:22:50.447 Executor task launch worker for task 0.0 in stage 108.0 (TID 128) INFO Executor: Running task 0.0 in stage 108.0 (TID 128)
24/04/16 18:22:50.583 Executor task launch worker for task 0.0 in stage 108.0 (TID 128) INFO CodeGenerator: Code generated in 61.246 ms
24/04/16 18:22:51.123 Executor task launch worker for task 0.0 in stage 108.0 (TID 128) INFO MemoryStore: Block rdd_409_0 stored as values in memory (estimated size 10.5 MiB, free 899.5 MiB)
24/04/16 18:22:51.123 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_409_0 in memory on DESKTOP-LH06ASP:64589 (size: 10.5 MiB, free: 901.0 MiB)
24/04/16 18:22:51.129 Executor task launch worker for task 0.0 in stage 108.0 (TID 128) INFO CodeGenerator: Code generated in 9.743 ms
24/04/16 18:22:51.161 Executor task launch worker for task 0.0 in stage 108.0 (TID 128) INFO CodeGenerator: Code generated in 3.7184 ms
24/04/16 18:22:51.178 Executor task launch worker for task 0.0 in stage 108.0 (TID 128) INFO CodeGenerator: Code generated in 4.0935 ms
24/04/16 18:22:51.186 Executor task launch worker for task 0.0 in stage 108.0 (TID 128) INFO CodeGenerator: Code generated in 5.0433 ms
24/04/16 18:22:51.194 Executor task launch worker for task 0.0 in stage 108.0 (TID 128) INFO CodeGenerator: Code generated in 5.1753 ms
24/04/16 18:22:51.267 Executor task launch worker for task 0.0 in stage 108.0 (TID 128) INFO CodeGenerator: Code generated in 23.0815 ms
24/04/16 18:22:51.840 Executor task launch worker for task 0.0 in stage 108.0 (TID 128) INFO Executor: Finished task 0.0 in stage 108.0 (TID 128). 2078 bytes result sent to driver
24/04/16 18:22:51.845 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 128) in 1419 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:51.845 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
24/04/16 18:22:51.845 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 108 (collect at StringIndexer.scala:204) finished in 1,482 s
24/04/16 18:22:51.845 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:22:51.845 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:22:51.845 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 18:22:51.845 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:22:51.901 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
24/04/16 18:22:51.901 dag-scheduler-event-loop INFO DAGScheduler: Got job 82 (collect at StringIndexer.scala:204) with 1 output partitions
24/04/16 18:22:51.902 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 110 (collect at StringIndexer.scala:204)
24/04/16 18:22:51.902 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 109)
24/04/16 18:22:51.902 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:22:51.902 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[417] at collect at StringIndexer.scala:204), which has no missing parents
24/04/16 18:22:51.905 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 117.4 KiB, free 899.4 MiB)
24/04/16 18:22:51.905 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 32.1 KiB, free 899.4 MiB)
24/04/16 18:22:51.905 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 32.1 KiB, free: 901.0 MiB)
24/04/16 18:22:51.905 dag-scheduler-event-loop INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:51.905 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[417] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:51.905 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0
24/04/16 18:22:51.913 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 129) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 18:22:51.913 Executor task launch worker for task 0.0 in stage 110.0 (TID 129) INFO Executor: Running task 0.0 in stage 110.0 (TID 129)
24/04/16 18:22:51.923 Executor task launch worker for task 0.0 in stage 110.0 (TID 129) INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:22:51.923 Executor task launch worker for task 0.0 in stage 110.0 (TID 129) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:22:51.939 Executor task launch worker for task 0.0 in stage 110.0 (TID 129) INFO CodeGenerator: Code generated in 13.5605 ms
24/04/16 18:22:52.012 Executor task launch worker for task 0.0 in stage 110.0 (TID 129) INFO Executor: Finished task 0.0 in stage 110.0 (TID 129). 4782 bytes result sent to driver
24/04/16 18:22:52.012 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 129) in 99 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:52.012 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
24/04/16 18:22:52.012 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 110 (collect at StringIndexer.scala:204) finished in 0,110 s
24/04/16 18:22:52.012 dag-scheduler-event-loop INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:22:52.012 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 110: Stage finished
24/04/16 18:22:52.012 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 82 finished: collect at StringIndexer.scala:204, took 0,124922 s
24/04/16 18:22:52.060 nioEventLoopGroup-2-2 INFO Instrumentation: [83bede12] training finished
24/04/16 18:22:52.372 nioEventLoopGroup-2-2 INFO Instrumentation: [d8b96fbd] training finished
24/04/16 18:22:52.440 nioEventLoopGroup-2-2 INFO Instrumentation: [029e9023] Stage class: RandomForestClassifier
24/04/16 18:22:52.440 nioEventLoopGroup-2-2 INFO Instrumentation: [029e9023] Stage uid: random_forest__c3d5bf59_879e_488d_96ff_7892edcbcd07
24/04/16 18:22:52.654 nioEventLoopGroup-2-2 INFO Instrumentation: [029e9023] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
24/04/16 18:22:52.895 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 37.6152 ms
24/04/16 18:22:52.996 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_120_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 32.1 KiB, free: 901.0 MiB)
24/04/16 18:22:53.000 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_119_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 30.0 KiB, free: 901.0 MiB)
24/04/16 18:22:53.023 nioEventLoopGroup-2-2 INFO Instrumentation: [029e9023] {"subsamplingRate":1.0,"impurity":"gini","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"rawPredictionCol":"rawPrediction","probabilityCol":"probability","numTrees":20}
24/04/16 18:22:53.118 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 18:22:53.118 dag-scheduler-event-loop INFO DAGScheduler: Got job 83 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 18:22:53.118 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 111 (take at DecisionTreeMetadata.scala:119)
24/04/16 18:22:53.118 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:22:53.118 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:22:53.119 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[436] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 18:22:53.125 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 276.7 KiB, free 899.4 MiB)
24/04/16 18:22:53.127 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 80.2 KiB, free 899.3 MiB)
24/04/16 18:22:53.128 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 80.2 KiB, free: 900.9 MiB)
24/04/16 18:22:53.128 dag-scheduler-event-loop INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:53.128 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[436] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:53.128 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks resource profile 0
24/04/16 18:22:53.130 dispatcher-event-loop-1 WARN TaskSetManager: Stage 111 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:22:53.130 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 130) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097240 bytes) 
24/04/16 18:22:53.130 Executor task launch worker for task 0.0 in stage 111.0 (TID 130) INFO Executor: Running task 0.0 in stage 111.0 (TID 130)
24/04/16 18:22:53.163 Executor task launch worker for task 0.0 in stage 111.0 (TID 130) INFO BlockManager: Found block rdd_409_0 locally
24/04/16 18:22:53.237 Executor task launch worker for task 0.0 in stage 111.0 (TID 130) INFO CodeGenerator: Code generated in 68.5712 ms
24/04/16 18:22:53.317 Executor task launch worker for task 0.0 in stage 111.0 (TID 130) INFO CodeGenerator: Code generated in 51.656 ms
24/04/16 18:22:53.336 Executor task launch worker for task 0.0 in stage 111.0 (TID 130) INFO CodeGenerator: Code generated in 4.2393 ms
24/04/16 18:22:53.336 Executor task launch worker for task 0.0 in stage 111.0 (TID 130) INFO Executor: 1 block locks were not released by task 0.0 in stage 111.0 (TID 130)
[rdd_409_0]
24/04/16 18:22:53.336 Executor task launch worker for task 0.0 in stage 111.0 (TID 130) INFO Executor: Finished task 0.0 in stage 111.0 (TID 130). 1359 bytes result sent to driver
24/04/16 18:22:53.336 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 130) in 206 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:53.336 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
24/04/16 18:22:53.336 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 111 (take at DecisionTreeMetadata.scala:119) finished in 0,217 s
24/04/16 18:22:53.336 dag-scheduler-event-loop INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:22:53.336 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished
24/04/16 18:22:53.336 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 83 finished: take at DecisionTreeMetadata.scala:119, took 0,225138 s
24/04/16 18:22:53.351 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 18:22:53.351 dag-scheduler-event-loop INFO DAGScheduler: Got job 84 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions
24/04/16 18:22:53.351 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 112 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 18:22:53.351 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:22:53.351 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:22:53.351 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[435] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 18:22:53.355 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 276.8 KiB, free 899.0 MiB)
24/04/16 18:22:53.355 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 80.4 KiB, free 899.0 MiB)
24/04/16 18:22:53.355 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 80.4 KiB, free: 900.9 MiB)
24/04/16 18:22:53.355 dag-scheduler-event-loop INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:53.355 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[435] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:53.355 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks resource profile 0
24/04/16 18:22:53.365 dispatcher-event-loop-0 WARN TaskSetManager: Stage 112 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:22:53.365 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 131) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097240 bytes) 
24/04/16 18:22:53.365 Executor task launch worker for task 0.0 in stage 112.0 (TID 131) INFO Executor: Running task 0.0 in stage 112.0 (TID 131)
24/04/16 18:22:53.381 Executor task launch worker for task 0.0 in stage 112.0 (TID 131) INFO BlockManager: Found block rdd_409_0 locally
24/04/16 18:22:53.740 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_121_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 80.2 KiB, free: 900.9 MiB)
24/04/16 18:22:53.806 Executor task launch worker for task 0.0 in stage 112.0 (TID 131) INFO Executor: Finished task 0.0 in stage 112.0 (TID 131). 1517 bytes result sent to driver
24/04/16 18:22:53.806 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 131) in 444 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:53.806 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
24/04/16 18:22:53.807 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 112 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,456 s
24/04/16 18:22:53.807 dag-scheduler-event-loop INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:22:53.807 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 112: Stage finished
24/04/16 18:22:53.807 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 84 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,456088 s
24/04/16 18:22:53.844 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 18:22:53.845 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 438 (flatMap at RandomForest.scala:1039) as input to shuffle 29
24/04/16 18:22:53.846 dag-scheduler-event-loop INFO DAGScheduler: Got job 85 (collectAsMap at RandomForest.scala:1054) with 1 output partitions
24/04/16 18:22:53.846 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 114 (collectAsMap at RandomForest.scala:1054)
24/04/16 18:22:53.846 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)
24/04/16 18:22:53.846 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 113)
24/04/16 18:22:53.846 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 113 (MapPartitionsRDD[438] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 18:22:53.854 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 285.8 KiB, free 899.0 MiB)
24/04/16 18:22:53.856 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 83.9 KiB, free 899.0 MiB)
24/04/16 18:22:53.856 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 83.9 KiB, free: 900.9 MiB)
24/04/16 18:22:53.856 dag-scheduler-event-loop INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:53.857 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 113 (MapPartitionsRDD[438] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:53.857 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks resource profile 0
24/04/16 18:22:53.864 dispatcher-event-loop-1 WARN TaskSetManager: Stage 113 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:22:53.865 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 132) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:22:53.865 Executor task launch worker for task 0.0 in stage 113.0 (TID 132) INFO Executor: Running task 0.0 in stage 113.0 (TID 132)
24/04/16 18:22:53.878 Executor task launch worker for task 0.0 in stage 113.0 (TID 132) INFO BlockManager: Found block rdd_409_0 locally
24/04/16 18:22:54.531 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_122_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 80.4 KiB, free: 900.9 MiB)
24/04/16 18:22:54.708 Executor task launch worker for task 0.0 in stage 113.0 (TID 132) INFO Executor: Finished task 0.0 in stage 113.0 (TID 132). 1785 bytes result sent to driver
24/04/16 18:22:54.709 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 132) in 851 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:54.709 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
24/04/16 18:22:54.710 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 113 (flatMap at RandomForest.scala:1039) finished in 0,863 s
24/04/16 18:22:54.710 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:22:54.710 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:22:54.710 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 114)
24/04/16 18:22:54.711 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:22:54.711 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[440] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 18:22:54.712 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 11.9 KiB, free 899.3 MiB)
24/04/16 18:22:54.712 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 899.3 MiB)
24/04/16 18:22:54.713 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 4.5 KiB, free: 900.9 MiB)
24/04/16 18:22:54.713 dag-scheduler-event-loop INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:54.713 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[440] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:54.713 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks resource profile 0
24/04/16 18:22:54.715 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 133) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:22:54.715 Executor task launch worker for task 0.0 in stage 114.0 (TID 133) INFO Executor: Running task 0.0 in stage 114.0 (TID 133)
24/04/16 18:22:54.718 Executor task launch worker for task 0.0 in stage 114.0 (TID 133) INFO ShuffleBlockFetcherIterator: Getting 1 (1737.8 KiB) non-empty blocks including 1 (1737.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:22:54.718 Executor task launch worker for task 0.0 in stage 114.0 (TID 133) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:22:54.952 Executor task launch worker for task 0.0 in stage 114.0 (TID 133) INFO Executor: Finished task 0.0 in stage 114.0 (TID 133). 265155 bytes result sent to driver
24/04/16 18:22:54.958 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 133) in 244 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:54.958 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
24/04/16 18:22:54.958 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 114 (collectAsMap at RandomForest.scala:1054) finished in 0,247 s
24/04/16 18:22:54.958 dag-scheduler-event-loop INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:22:54.958 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 114: Stage finished
24/04/16 18:22:54.959 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 85 finished: collectAsMap at RandomForest.scala:1054, took 1,114594 s
24/04/16 18:22:54.969 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 360.4 KiB, free 898.9 MiB)
24/04/16 18:22:54.970 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 93.2 KiB, free 898.8 MiB)
24/04/16 18:22:54.970 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 93.2 KiB, free: 900.9 MiB)
24/04/16 18:22:54.976 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 125 from broadcast at RandomForest.scala:293
24/04/16 18:22:54.980 nioEventLoopGroup-2-2 INFO Instrumentation: [029e9023] {"numFeatures":545}
24/04/16 18:22:54.980 nioEventLoopGroup-2-2 INFO Instrumentation: [029e9023] {"numClasses":2}
24/04/16 18:22:54.980 nioEventLoopGroup-2-2 INFO Instrumentation: [029e9023] {"numExamples":2698}
24/04/16 18:22:54.980 nioEventLoopGroup-2-2 INFO Instrumentation: [029e9023] {"sumOfWeights":2698.0}
24/04/16 18:22:54.981 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 3.8 KiB, free 898.8 MiB)
24/04/16 18:22:54.982 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 1966.0 B, free 898.8 MiB)
24/04/16 18:22:54.982 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 1966.0 B, free: 900.8 MiB)
24/04/16 18:22:54.982 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 126 from broadcast at RandomForest.scala:622
24/04/16 18:22:55.017 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 18:22:55.017 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 443 (mapPartitions at RandomForest.scala:644) as input to shuffle 30
24/04/16 18:22:55.017 dag-scheduler-event-loop INFO DAGScheduler: Got job 86 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 18:22:55.017 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 116 (collectAsMap at RandomForest.scala:663)
24/04/16 18:22:55.017 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 115)
24/04/16 18:22:55.017 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 115)
24/04/16 18:22:55.020 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[443] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 18:22:55.029 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 401.4 KiB, free 898.4 MiB)
24/04/16 18:22:55.036 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 147.4 KiB, free 898.3 MiB)
24/04/16 18:22:55.036 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 147.4 KiB, free: 900.7 MiB)
24/04/16 18:22:55.038 dag-scheduler-event-loop INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:55.038 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[443] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:55.038 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks resource profile 0
24/04/16 18:22:55.047 dispatcher-event-loop-0 WARN TaskSetManager: Stage 115 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:22:55.047 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 134) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:22:55.047 Executor task launch worker for task 0.0 in stage 115.0 (TID 134) INFO Executor: Running task 0.0 in stage 115.0 (TID 134)
24/04/16 18:22:55.055 Executor task launch worker for task 0.0 in stage 115.0 (TID 134) INFO BlockManager: Found block rdd_409_0 locally
24/04/16 18:22:55.400 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_124_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 4.5 KiB, free: 900.7 MiB)
24/04/16 18:22:55.403 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_123_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 83.9 KiB, free: 900.8 MiB)
24/04/16 18:22:55.552 Executor task launch worker for task 0.0 in stage 115.0 (TID 134) INFO MemoryStore: Block rdd_442_0 stored as values in memory (estimated size 5.9 MiB, free 892.8 MiB)
24/04/16 18:22:55.552 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_442_0 in memory on DESKTOP-LH06ASP:64589 (size: 5.9 MiB, free: 894.9 MiB)
24/04/16 18:22:55.630 Executor task launch worker for task 0.0 in stage 115.0 (TID 134) INFO Executor: Finished task 0.0 in stage 115.0 (TID 134). 1742 bytes result sent to driver
24/04/16 18:22:55.630 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 134) in 592 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:55.630 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
24/04/16 18:22:55.630 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 115 (mapPartitions at RandomForest.scala:644) finished in 0,610 s
24/04/16 18:22:55.630 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:22:55.630 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:22:55.630 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 116)
24/04/16 18:22:55.630 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:22:55.635 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[445] at map at RandomForest.scala:663), which has no missing parents
24/04/16 18:22:55.636 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 7.4 KiB, free 892.8 MiB)
24/04/16 18:22:55.638 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 892.8 MiB)
24/04/16 18:22:55.638 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 3.8 KiB, free: 894.9 MiB)
24/04/16 18:22:55.638 dag-scheduler-event-loop INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:55.638 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[445] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:55.638 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks resource profile 0
24/04/16 18:22:55.639 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 135) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:22:55.639 Executor task launch worker for task 0.0 in stage 116.0 (TID 135) INFO Executor: Running task 0.0 in stage 116.0 (TID 135)
24/04/16 18:22:55.639 Executor task launch worker for task 0.0 in stage 116.0 (TID 135) INFO ShuffleBlockFetcherIterator: Getting 1 (74.8 KiB) non-empty blocks including 1 (74.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:22:55.639 Executor task launch worker for task 0.0 in stage 116.0 (TID 135) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:22:55.672 Executor task launch worker for task 0.0 in stage 116.0 (TID 135) INFO Executor: Finished task 0.0 in stage 116.0 (TID 135). 5932 bytes result sent to driver
24/04/16 18:22:55.672 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 135) in 34 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:55.672 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
24/04/16 18:22:55.672 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 116 (collectAsMap at RandomForest.scala:663) finished in 0,037 s
24/04/16 18:22:55.672 dag-scheduler-event-loop INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:22:55.678 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 116: Stage finished
24/04/16 18:22:55.678 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 86 finished: collectAsMap at RandomForest.scala:663, took 0,660296 s
24/04/16 18:22:55.678 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(126) (from destroy at RandomForest.scala:674)
24/04/16 18:22:55.680 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_126_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 1966.0 B, free: 894.9 MiB)
24/04/16 18:22:55.680 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 8.0 KiB, free 892.8 MiB)
24/04/16 18:22:55.682 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 892.8 MiB)
24/04/16 18:22:55.683 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 3.3 KiB, free: 894.9 MiB)
24/04/16 18:22:55.683 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 129 from broadcast at RandomForest.scala:622
24/04/16 18:22:55.694 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 18:22:55.694 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 446 (mapPartitions at RandomForest.scala:644) as input to shuffle 31
24/04/16 18:22:55.694 dag-scheduler-event-loop INFO DAGScheduler: Got job 87 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 18:22:55.704 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 118 (collectAsMap at RandomForest.scala:663)
24/04/16 18:22:55.704 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117)
24/04/16 18:22:55.704 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 117)
24/04/16 18:22:55.704 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 117 (MapPartitionsRDD[446] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 18:22:55.710 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 409.6 KiB, free 892.4 MiB)
24/04/16 18:22:55.710 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 151.3 KiB, free 892.3 MiB)
24/04/16 18:22:55.710 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 151.3 KiB, free: 894.8 MiB)
24/04/16 18:22:55.710 dag-scheduler-event-loop INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:55.710 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 117 (MapPartitionsRDD[446] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:55.710 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0
24/04/16 18:22:55.728 dispatcher-event-loop-0 WARN TaskSetManager: Stage 117 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:22:55.728 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 136) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:22:55.728 Executor task launch worker for task 0.0 in stage 117.0 (TID 136) INFO Executor: Running task 0.0 in stage 117.0 (TID 136)
24/04/16 18:22:55.741 Executor task launch worker for task 0.0 in stage 117.0 (TID 136) INFO BlockManager: Found block rdd_442_0 locally
24/04/16 18:22:55.792 Executor task launch worker for task 0.0 in stage 117.0 (TID 136) INFO Executor: Finished task 0.0 in stage 117.0 (TID 136). 1742 bytes result sent to driver
24/04/16 18:22:55.792 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 136) in 82 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:55.792 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
24/04/16 18:22:55.792 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 117 (mapPartitions at RandomForest.scala:644) finished in 0,088 s
24/04/16 18:22:55.792 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:22:55.792 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:22:55.792 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 118)
24/04/16 18:22:55.792 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:22:55.792 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[448] at map at RandomForest.scala:663), which has no missing parents
24/04/16 18:22:55.797 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 10.8 KiB, free 892.2 MiB)
24/04/16 18:22:55.797 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 892.2 MiB)
24/04/16 18:22:55.797 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.1 KiB, free: 894.8 MiB)
24/04/16 18:22:55.797 dag-scheduler-event-loop INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:55.797 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[448] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:55.797 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks resource profile 0
24/04/16 18:22:55.799 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 137) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:22:55.799 Executor task launch worker for task 0.0 in stage 118.0 (TID 137) INFO Executor: Running task 0.0 in stage 118.0 (TID 137)
24/04/16 18:22:55.801 Executor task launch worker for task 0.0 in stage 118.0 (TID 137) INFO ShuffleBlockFetcherIterator: Getting 1 (109.5 KiB) non-empty blocks including 1 (109.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:22:55.801 Executor task launch worker for task 0.0 in stage 118.0 (TID 137) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:22:55.821 Executor task launch worker for task 0.0 in stage 118.0 (TID 137) INFO Executor: Finished task 0.0 in stage 118.0 (TID 137). 9498 bytes result sent to driver
24/04/16 18:22:55.821 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 137) in 22 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:55.821 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
24/04/16 18:22:55.821 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 118 (collectAsMap at RandomForest.scala:663) finished in 0,029 s
24/04/16 18:22:55.821 dag-scheduler-event-loop INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:22:55.821 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 118: Stage finished
24/04/16 18:22:55.821 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 87 finished: collectAsMap at RandomForest.scala:663, took 0,120094 s
24/04/16 18:22:55.824 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(129) (from destroy at RandomForest.scala:674)
24/04/16 18:22:55.824 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_129_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 3.3 KiB, free: 894.8 MiB)
24/04/16 18:22:55.826 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 15.7 KiB, free 892.2 MiB)
24/04/16 18:22:55.826 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 892.2 MiB)
24/04/16 18:22:55.826 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 6.0 KiB, free: 894.8 MiB)
24/04/16 18:22:55.826 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 132 from broadcast at RandomForest.scala:622
24/04/16 18:22:55.853 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 18:22:55.853 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 449 (mapPartitions at RandomForest.scala:644) as input to shuffle 32
24/04/16 18:22:55.853 dag-scheduler-event-loop INFO DAGScheduler: Got job 88 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 18:22:55.853 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 120 (collectAsMap at RandomForest.scala:663)
24/04/16 18:22:55.853 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 119)
24/04/16 18:22:55.853 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 119)
24/04/16 18:22:55.853 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[449] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 18:22:55.873 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 424.1 KiB, free 891.8 MiB)
24/04/16 18:22:55.875 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 158.3 KiB, free 891.7 MiB)
24/04/16 18:22:55.875 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 158.3 KiB, free: 894.6 MiB)
24/04/16 18:22:55.875 dag-scheduler-event-loop INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:55.877 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[449] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:55.877 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks resource profile 0
24/04/16 18:22:55.886 dispatcher-event-loop-0 WARN TaskSetManager: Stage 119 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:22:55.887 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 138) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:22:55.887 Executor task launch worker for task 0.0 in stage 119.0 (TID 138) INFO Executor: Running task 0.0 in stage 119.0 (TID 138)
24/04/16 18:22:55.900 Executor task launch worker for task 0.0 in stage 119.0 (TID 138) INFO BlockManager: Found block rdd_442_0 locally
24/04/16 18:22:55.985 Executor task launch worker for task 0.0 in stage 119.0 (TID 138) INFO Executor: Finished task 0.0 in stage 119.0 (TID 138). 1699 bytes result sent to driver
24/04/16 18:22:55.985 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 138) in 108 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:55.985 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
24/04/16 18:22:55.985 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 119 (mapPartitions at RandomForest.scala:644) finished in 0,132 s
24/04/16 18:22:55.985 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:22:55.985 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:22:55.985 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 120)
24/04/16 18:22:55.985 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:22:55.998 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[451] at map at RandomForest.scala:663), which has no missing parents
24/04/16 18:22:55.999 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 14.3 KiB, free 891.6 MiB)
24/04/16 18:22:56.001 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 891.6 MiB)
24/04/16 18:22:56.002 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 6.2 KiB, free: 894.6 MiB)
24/04/16 18:22:56.002 dag-scheduler-event-loop INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:56.004 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[451] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:56.004 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks resource profile 0
24/04/16 18:22:56.004 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 139) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:22:56.004 Executor task launch worker for task 0.0 in stage 120.0 (TID 139) INFO Executor: Running task 0.0 in stage 120.0 (TID 139)
24/04/16 18:22:56.008 Executor task launch worker for task 0.0 in stage 120.0 (TID 139) INFO ShuffleBlockFetcherIterator: Getting 1 (145.8 KiB) non-empty blocks including 1 (145.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:22:56.008 Executor task launch worker for task 0.0 in stage 120.0 (TID 139) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:22:56.096 Executor task launch worker for task 0.0 in stage 120.0 (TID 139) INFO Executor: Finished task 0.0 in stage 120.0 (TID 139). 16609 bytes result sent to driver
24/04/16 18:22:56.096 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 139) in 92 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:56.096 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
24/04/16 18:22:56.096 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 120 (collectAsMap at RandomForest.scala:663) finished in 0,097 s
24/04/16 18:22:56.096 dag-scheduler-event-loop INFO DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:22:56.096 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 120: Stage finished
24/04/16 18:22:56.096 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 88 finished: collectAsMap at RandomForest.scala:663, took 0,241307 s
24/04/16 18:22:56.108 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(132) (from destroy at RandomForest.scala:674)
24/04/16 18:22:56.112 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_132_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 6.0 KiB, free: 894.6 MiB)
24/04/16 18:22:56.118 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 25.3 KiB, free 891.6 MiB)
24/04/16 18:22:56.118 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 891.6 MiB)
24/04/16 18:22:56.118 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 9.5 KiB, free: 894.6 MiB)
24/04/16 18:22:56.118 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 135 from broadcast at RandomForest.scala:622
24/04/16 18:22:56.160 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 18:22:56.162 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 452 (mapPartitions at RandomForest.scala:644) as input to shuffle 33
24/04/16 18:22:56.162 dag-scheduler-event-loop INFO DAGScheduler: Got job 89 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 18:22:56.162 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 122 (collectAsMap at RandomForest.scala:663)
24/04/16 18:22:56.162 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121)
24/04/16 18:22:56.162 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 121)
24/04/16 18:22:56.162 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[452] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 18:22:56.179 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 449.0 KiB, free 891.2 MiB)
24/04/16 18:22:56.179 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 168.3 KiB, free 891.0 MiB)
24/04/16 18:22:56.179 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 168.3 KiB, free: 894.4 MiB)
24/04/16 18:22:56.179 dag-scheduler-event-loop INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:56.179 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[452] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:56.179 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks resource profile 0
24/04/16 18:22:56.243 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_134_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 6.2 KiB, free: 894.4 MiB)
24/04/16 18:22:56.249 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_131_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.1 KiB, free: 894.5 MiB)
24/04/16 18:22:56.249 dispatcher-event-loop-0 WARN TaskSetManager: Stage 121 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:22:56.252 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 140) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:22:56.252 Executor task launch worker for task 0.0 in stage 121.0 (TID 140) INFO Executor: Running task 0.0 in stage 121.0 (TID 140)
24/04/16 18:22:56.257 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_127_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 147.4 KiB, free: 894.6 MiB)
24/04/16 18:22:56.263 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_128_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 3.8 KiB, free: 894.6 MiB)
24/04/16 18:22:56.270 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_130_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 151.3 KiB, free: 894.7 MiB)
24/04/16 18:22:56.270 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_133_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 158.3 KiB, free: 894.9 MiB)
24/04/16 18:22:56.283 Executor task launch worker for task 0.0 in stage 121.0 (TID 140) INFO BlockManager: Found block rdd_442_0 locally
24/04/16 18:22:56.391 Executor task launch worker for task 0.0 in stage 121.0 (TID 140) INFO Executor: Finished task 0.0 in stage 121.0 (TID 140). 1742 bytes result sent to driver
24/04/16 18:22:56.392 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 140) in 206 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:56.392 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
24/04/16 18:22:56.392 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 121 (mapPartitions at RandomForest.scala:644) finished in 0,230 s
24/04/16 18:22:56.393 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:22:56.393 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:22:56.393 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 122)
24/04/16 18:22:56.393 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:22:56.393 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[454] at map at RandomForest.scala:663), which has no missing parents
24/04/16 18:22:56.395 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 18.6 KiB, free 892.7 MiB)
24/04/16 18:22:56.395 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 892.7 MiB)
24/04/16 18:22:56.395 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 7.4 KiB, free: 894.9 MiB)
24/04/16 18:22:56.395 dag-scheduler-event-loop INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:56.399 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[454] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:56.399 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks resource profile 0
24/04/16 18:22:56.399 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 141) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:22:56.399 Executor task launch worker for task 0.0 in stage 122.0 (TID 141) INFO Executor: Running task 0.0 in stage 122.0 (TID 141)
24/04/16 18:22:56.402 Executor task launch worker for task 0.0 in stage 122.0 (TID 141) INFO ShuffleBlockFetcherIterator: Getting 1 (194.1 KiB) non-empty blocks including 1 (194.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:22:56.404 Executor task launch worker for task 0.0 in stage 122.0 (TID 141) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:22:56.489 Executor task launch worker for task 0.0 in stage 122.0 (TID 141) INFO Executor: Finished task 0.0 in stage 122.0 (TID 141). 25556 bytes result sent to driver
24/04/16 18:22:56.489 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 141) in 90 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:56.489 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
24/04/16 18:22:56.489 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 122 (collectAsMap at RandomForest.scala:663) finished in 0,096 s
24/04/16 18:22:56.489 dag-scheduler-event-loop INFO DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:22:56.489 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 122: Stage finished
24/04/16 18:22:56.489 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 89 finished: collectAsMap at RandomForest.scala:663, took 0,334961 s
24/04/16 18:22:56.489 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(135) (from destroy at RandomForest.scala:674)
24/04/16 18:22:56.489 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_135_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 9.5 KiB, free: 894.9 MiB)
24/04/16 18:22:56.500 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 34.4 KiB, free 892.7 MiB)
24/04/16 18:22:56.503 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 892.7 MiB)
24/04/16 18:22:56.503 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 13.0 KiB, free: 894.9 MiB)
24/04/16 18:22:56.503 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 138 from broadcast at RandomForest.scala:622
24/04/16 18:22:56.521 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 18:22:56.521 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 455 (mapPartitions at RandomForest.scala:644) as input to shuffle 34
24/04/16 18:22:56.521 dag-scheduler-event-loop INFO DAGScheduler: Got job 90 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 18:22:56.521 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 124 (collectAsMap at RandomForest.scala:663)
24/04/16 18:22:56.521 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 123)
24/04/16 18:22:56.521 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 123)
24/04/16 18:22:56.521 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 123 (MapPartitionsRDD[455] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 18:22:56.527 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 485.5 KiB, free 892.2 MiB)
24/04/16 18:22:56.536 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 182.0 KiB, free 892.0 MiB)
24/04/16 18:22:56.536 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 182.0 KiB, free: 894.7 MiB)
24/04/16 18:22:56.536 dag-scheduler-event-loop INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:56.536 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 123 (MapPartitionsRDD[455] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:56.536 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 123.0 with 1 tasks resource profile 0
24/04/16 18:22:56.541 dispatcher-event-loop-0 WARN TaskSetManager: Stage 123 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:22:56.541 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 142) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:22:56.541 Executor task launch worker for task 0.0 in stage 123.0 (TID 142) INFO Executor: Running task 0.0 in stage 123.0 (TID 142)
24/04/16 18:22:56.554 Executor task launch worker for task 0.0 in stage 123.0 (TID 142) INFO BlockManager: Found block rdd_442_0 locally
24/04/16 18:22:56.651 Executor task launch worker for task 0.0 in stage 123.0 (TID 142) INFO Executor: Finished task 0.0 in stage 123.0 (TID 142). 1742 bytes result sent to driver
24/04/16 18:22:56.651 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 142) in 115 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:56.651 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
24/04/16 18:22:56.653 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 123 (mapPartitions at RandomForest.scala:644) finished in 0,132 s
24/04/16 18:22:56.653 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:22:56.653 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:22:56.653 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 124)
24/04/16 18:22:56.653 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:22:56.653 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 124 (MapPartitionsRDD[457] at map at RandomForest.scala:663), which has no missing parents
24/04/16 18:22:56.655 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 22.9 KiB, free 892.0 MiB)
24/04/16 18:22:56.657 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 892.0 MiB)
24/04/16 18:22:56.657 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 8.5 KiB, free: 894.7 MiB)
24/04/16 18:22:56.657 dag-scheduler-event-loop INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:56.659 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 124 (MapPartitionsRDD[457] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:56.659 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks resource profile 0
24/04/16 18:22:56.659 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 143) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:22:56.659 Executor task launch worker for task 0.0 in stage 124.0 (TID 143) INFO Executor: Running task 0.0 in stage 124.0 (TID 143)
24/04/16 18:22:56.659 Executor task launch worker for task 0.0 in stage 124.0 (TID 143) INFO ShuffleBlockFetcherIterator: Getting 1 (213.5 KiB) non-empty blocks including 1 (213.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:22:56.659 Executor task launch worker for task 0.0 in stage 124.0 (TID 143) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:22:56.792 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_136_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 168.3 KiB, free: 894.9 MiB)
24/04/16 18:22:56.808 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_137_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 7.4 KiB, free: 894.9 MiB)
24/04/16 18:22:56.811 Executor task launch worker for task 0.0 in stage 124.0 (TID 143) INFO Executor: Finished task 0.0 in stage 124.0 (TID 143). 34310 bytes result sent to driver
24/04/16 18:22:56.813 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 143) in 154 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:22:56.813 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
24/04/16 18:22:56.813 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 124 (collectAsMap at RandomForest.scala:663) finished in 0,160 s
24/04/16 18:22:56.813 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_139_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 182.0 KiB, free: 895.1 MiB)
24/04/16 18:22:56.813 dag-scheduler-event-loop INFO DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:22:56.813 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 124: Stage finished
24/04/16 18:22:56.817 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 90 finished: collectAsMap at RandomForest.scala:663, took 0,292470 s
24/04/16 18:22:56.817 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(138) (from destroy at RandomForest.scala:674)
24/04/16 18:22:56.817 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 18:22:56.821 nioEventLoopGroup-2-2 INFO RandomForest:   init: 6.66E-5
  total: 1.8396049
  findBestSplits: 1.8245287
  chooseSplits: 1.822143
24/04/16 18:22:56.821 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_138_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 13.0 KiB, free: 895.1 MiB)
24/04/16 18:22:56.847 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 442 from persistence list
24/04/16 18:22:56.847 block-manager-storage-async-thread-pool-418 INFO BlockManager: Removing RDD 442
24/04/16 18:22:56.847 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(125) (from destroy at RandomForest.scala:305)
24/04/16 18:22:56.853 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_125_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 93.2 KiB, free: 901.0 MiB)
24/04/16 18:22:56.858 nioEventLoopGroup-2-2 INFO Instrumentation: [029e9023] {"numClasses":2}
24/04/16 18:22:56.858 nioEventLoopGroup-2-2 INFO Instrumentation: [029e9023] {"numFeatures":545}
24/04/16 18:22:57.270 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.8499 ms
24/04/16 18:22:57.441 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.53 ms
24/04/16 18:22:57.471 nioEventLoopGroup-2-2 INFO Instrumentation: [029e9023] training finished
24/04/16 18:22:57.472 nioEventLoopGroup-2-2 INFO Instrumentation: [96be7730] training finished
24/04/16 18:22:58.509 nioEventLoopGroup-2-2 INFO Instrumentation: [2952a2ff] training finished
24/04/16 18:22:58.607 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_140_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 8.5 KiB, free: 901.0 MiB)
24/04/16 18:22:58.609 block-manager-storage-async-thread-pool-333 INFO BlockManager: Removing RDD 442
24/04/16 18:22:59.980 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:22:59.980 dag-scheduler-event-loop INFO DAGScheduler: Got job 91 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:22:59.980 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 125 (collect at utils.scala:26)
24/04/16 18:22:59.980 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:22:59.980 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:22:59.980 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[479] at collect at utils.scala:26), which has no missing parents
24/04/16 18:22:59.980 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 62.5 KiB, free 899.6 MiB)
24/04/16 18:22:59.980 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 899.6 MiB)
24/04/16 18:22:59.980 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 901.0 MiB)
24/04/16 18:22:59.980 dag-scheduler-event-loop INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1535
24/04/16 18:22:59.980 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[479] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:22:59.980 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 125.0 with 1 tasks resource profile 0
24/04/16 18:22:59.980 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 144) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 18:22:59.980 Executor task launch worker for task 0.0 in stage 125.0 (TID 144) INFO Executor: Running task 0.0 in stage 125.0 (TID 144)
24/04/16 18:23:00.003 Executor task launch worker for task 0.0 in stage 125.0 (TID 144) INFO Executor: Finished task 0.0 in stage 125.0 (TID 144). 1430 bytes result sent to driver
24/04/16 18:23:00.003 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 144) in 23 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:00.003 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
24/04/16 18:23:00.009 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 125 (collect at utils.scala:26) finished in 0,023 s
24/04/16 18:23:00.009 dag-scheduler-event-loop INFO DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:00.009 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 125: Stage finished
24/04/16 18:23:00.009 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 91 finished: collect at utils.scala:26, took 0,025763 s
24/04/16 18:23:04.175 nioEventLoopGroup-2-2 INFO Instrumentation: [54680015] training finished
24/04/16 18:23:05.465 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_141_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 901.0 MiB)
24/04/16 18:23:05.616 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:23:05.616 dag-scheduler-event-loop INFO DAGScheduler: Got job 92 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:23:05.616 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 126 (collect at utils.scala:26)
24/04/16 18:23:05.616 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:23:05.616 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:23:05.616 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[482] at collect at utils.scala:26), which has no missing parents
24/04/16 18:23:05.620 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 62.5 KiB, free 899.6 MiB)
24/04/16 18:23:05.620 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 899.6 MiB)
24/04/16 18:23:05.620 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 901.0 MiB)
24/04/16 18:23:05.620 dag-scheduler-event-loop INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:05.620 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[482] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:05.620 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0
24/04/16 18:23:05.620 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 145) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 18:23:05.624 Executor task launch worker for task 0.0 in stage 126.0 (TID 145) INFO Executor: Running task 0.0 in stage 126.0 (TID 145)
24/04/16 18:23:05.640 Executor task launch worker for task 0.0 in stage 126.0 (TID 145) INFO Executor: Finished task 0.0 in stage 126.0 (TID 145). 1430 bytes result sent to driver
24/04/16 18:23:05.640 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 145) in 20 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:05.640 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
24/04/16 18:23:05.640 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 126 (collect at utils.scala:26) finished in 0,024 s
24/04/16 18:23:05.640 dag-scheduler-event-loop INFO DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:05.640 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished
24/04/16 18:23:05.640 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 92 finished: collect at utils.scala:26, took 0,029400 s
24/04/16 18:23:10.257 nioEventLoopGroup-2-2 INFO Instrumentation: [96eef452] training finished
24/04/16 18:23:19.767 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 487 (collect at StringIndexer.scala:204) as input to shuffle 35
24/04/16 18:23:19.767 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 93 (collect at StringIndexer.scala:204) with 1 output partitions
24/04/16 18:23:19.768 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 127 (collect at StringIndexer.scala:204)
24/04/16 18:23:19.768 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:23:19.768 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:23:19.768 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 127 (MapPartitionsRDD[487] at collect at StringIndexer.scala:204), which has no missing parents
24/04/16 18:23:19.778 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 112.1 KiB, free 899.5 MiB)
24/04/16 18:23:19.779 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 899.4 MiB)
24/04/16 18:23:19.780 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 30.0 KiB, free: 901.0 MiB)
24/04/16 18:23:19.780 dag-scheduler-event-loop INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:19.780 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 127 (MapPartitionsRDD[487] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:19.780 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks resource profile 0
24/04/16 18:23:19.789 dispatcher-event-loop-0 WARN TaskSetManager: Stage 127 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:23:19.789 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 146) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:23:19.789 Executor task launch worker for task 0.0 in stage 127.0 (TID 146) INFO Executor: Running task 0.0 in stage 127.0 (TID 146)
24/04/16 18:23:19.802 Executor task launch worker for task 0.0 in stage 127.0 (TID 146) INFO BlockManager: Found block rdd_409_0 locally
24/04/16 18:23:19.847 Executor task launch worker for task 0.0 in stage 127.0 (TID 146) INFO Executor: Finished task 0.0 in stage 127.0 (TID 146). 2121 bytes result sent to driver
24/04/16 18:23:19.848 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 146) in 67 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:19.848 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
24/04/16 18:23:19.848 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 127 (collect at StringIndexer.scala:204) finished in 0,080 s
24/04/16 18:23:19.849 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:23:19.849 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:23:19.849 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
24/04/16 18:23:19.849 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:23:19.866 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
24/04/16 18:23:19.867 dag-scheduler-event-loop INFO DAGScheduler: Got job 94 (collect at StringIndexer.scala:204) with 1 output partitions
24/04/16 18:23:19.867 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 129 (collect at StringIndexer.scala:204)
24/04/16 18:23:19.867 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 128)
24/04/16 18:23:19.867 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:23:19.867 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[490] at collect at StringIndexer.scala:204), which has no missing parents
24/04/16 18:23:19.870 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 117.4 KiB, free 899.3 MiB)
24/04/16 18:23:19.871 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 32.1 KiB, free 899.3 MiB)
24/04/16 18:23:19.871 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 32.1 KiB, free: 901.0 MiB)
24/04/16 18:23:19.871 dag-scheduler-event-loop INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:19.871 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[490] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:19.871 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0
24/04/16 18:23:19.873 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 147) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7363 bytes) 
24/04/16 18:23:19.873 Executor task launch worker for task 0.0 in stage 129.0 (TID 147) INFO Executor: Running task 0.0 in stage 129.0 (TID 147)
24/04/16 18:23:19.932 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_143_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 30.0 KiB, free: 901.0 MiB)
24/04/16 18:23:19.935 Executor task launch worker for task 0.0 in stage 129.0 (TID 147) INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:23:19.935 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_142_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 901.0 MiB)
24/04/16 18:23:19.935 Executor task launch worker for task 0.0 in stage 129.0 (TID 147) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:23:19.957 Executor task launch worker for task 0.0 in stage 129.0 (TID 147) INFO Executor: Finished task 0.0 in stage 129.0 (TID 147). 4825 bytes result sent to driver
24/04/16 18:23:19.958 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 147) in 85 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:19.958 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
24/04/16 18:23:19.958 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 129 (collect at StringIndexer.scala:204) finished in 0,090 s
24/04/16 18:23:19.958 dag-scheduler-event-loop INFO DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:19.958 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished
24/04/16 18:23:19.959 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 94 finished: collect at StringIndexer.scala:204, took 0,092348 s
24/04/16 18:23:19.991 nioEventLoopGroup-2-2 INFO Instrumentation: [b78bfeba] training finished
24/04/16 18:23:20.316 nioEventLoopGroup-2-2 INFO Instrumentation: [b5e6b03e] training finished
24/04/16 18:23:20.374 nioEventLoopGroup-2-2 INFO Instrumentation: [a673a979] Stage class: RandomForestClassifier
24/04/16 18:23:20.374 nioEventLoopGroup-2-2 INFO Instrumentation: [a673a979] Stage uid: random_forest__7733ed99_c411_4a0f_9b27_04ec20e94686
24/04/16 18:23:20.543 nioEventLoopGroup-2-2 INFO Instrumentation: [a673a979] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
24/04/16 18:23:20.680 nioEventLoopGroup-2-2 INFO Instrumentation: [a673a979] {"subsamplingRate":1.0,"impurity":"gini","featuresCol":"features","maxDepth":5,"minInstancesPerNode":1,"featureSubsetStrategy":"auto","checkpointInterval":10,"minInfoGain":0.0,"cacheNodeIds":false,"labelCol":"label","predictionCol":"prediction","maxMemoryInMB":256,"maxBins":32,"rawPredictionCol":"rawPrediction","probabilityCol":"probability","numTrees":20}
24/04/16 18:23:20.706 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
24/04/16 18:23:20.706 dag-scheduler-event-loop INFO DAGScheduler: Got job 95 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
24/04/16 18:23:20.706 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 130 (take at DecisionTreeMetadata.scala:119)
24/04/16 18:23:20.706 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:23:20.707 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:23:20.707 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[509] at map at DecisionTreeMetadata.scala:119), which has no missing parents
24/04/16 18:23:20.713 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 276.7 KiB, free 899.2 MiB)
24/04/16 18:23:20.715 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 80.2 KiB, free 899.2 MiB)
24/04/16 18:23:20.715 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 80.2 KiB, free: 900.9 MiB)
24/04/16 18:23:20.716 dag-scheduler-event-loop INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:20.716 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[509] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:20.716 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0
24/04/16 18:23:20.725 dispatcher-event-loop-0 WARN TaskSetManager: Stage 130 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:23:20.725 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 148) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097240 bytes) 
24/04/16 18:23:20.726 Executor task launch worker for task 0.0 in stage 130.0 (TID 148) INFO Executor: Running task 0.0 in stage 130.0 (TID 148)
24/04/16 18:23:20.738 Executor task launch worker for task 0.0 in stage 130.0 (TID 148) INFO BlockManager: Found block rdd_409_0 locally
24/04/16 18:23:20.836 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_144_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 32.1 KiB, free: 900.9 MiB)
24/04/16 18:23:20.844 Executor task launch worker for task 0.0 in stage 130.0 (TID 148) INFO Executor: 1 block locks were not released by task 0.0 in stage 130.0 (TID 148)
[rdd_409_0]
24/04/16 18:23:20.844 Executor task launch worker for task 0.0 in stage 130.0 (TID 148) INFO Executor: Finished task 0.0 in stage 130.0 (TID 148). 1402 bytes result sent to driver
24/04/16 18:23:20.844 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 148) in 127 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:20.844 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
24/04/16 18:23:20.844 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 130 (take at DecisionTreeMetadata.scala:119) finished in 0,136 s
24/04/16 18:23:20.844 dag-scheduler-event-loop INFO DAGScheduler: Job 95 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:20.844 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 130: Stage finished
24/04/16 18:23:20.844 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 95 finished: take at DecisionTreeMetadata.scala:119, took 0,141444 s
24/04/16 18:23:20.844 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
24/04/16 18:23:20.856 dag-scheduler-event-loop INFO DAGScheduler: Got job 96 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions
24/04/16 18:23:20.856 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 131 (aggregate at DecisionTreeMetadata.scala:125)
24/04/16 18:23:20.856 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:23:20.856 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:23:20.856 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[508] at retag at RandomForest.scala:274), which has no missing parents
24/04/16 18:23:20.856 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 276.8 KiB, free 899.0 MiB)
24/04/16 18:23:20.856 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 80.4 KiB, free 899.0 MiB)
24/04/16 18:23:20.856 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 80.4 KiB, free: 900.9 MiB)
24/04/16 18:23:20.856 dag-scheduler-event-loop INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:20.856 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[508] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:20.856 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks resource profile 0
24/04/16 18:23:20.871 dispatcher-event-loop-1 WARN TaskSetManager: Stage 131 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:23:20.871 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 149) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097240 bytes) 
24/04/16 18:23:20.871 Executor task launch worker for task 0.0 in stage 131.0 (TID 149) INFO Executor: Running task 0.0 in stage 131.0 (TID 149)
24/04/16 18:23:20.871 Executor task launch worker for task 0.0 in stage 131.0 (TID 149) INFO BlockManager: Found block rdd_409_0 locally
24/04/16 18:23:21.188 Executor task launch worker for task 0.0 in stage 131.0 (TID 149) INFO Executor: Finished task 0.0 in stage 131.0 (TID 149). 1474 bytes result sent to driver
24/04/16 18:23:21.193 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 149) in 332 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:21.193 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
24/04/16 18:23:21.193 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 131 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,337 s
24/04/16 18:23:21.193 dag-scheduler-event-loop INFO DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:21.193 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 131: Stage finished
24/04/16 18:23:21.193 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 96 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,338996 s
24/04/16 18:23:21.204 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
24/04/16 18:23:21.219 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 511 (flatMap at RandomForest.scala:1039) as input to shuffle 36
24/04/16 18:23:21.219 dag-scheduler-event-loop INFO DAGScheduler: Got job 97 (collectAsMap at RandomForest.scala:1054) with 1 output partitions
24/04/16 18:23:21.219 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 133 (collectAsMap at RandomForest.scala:1054)
24/04/16 18:23:21.219 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132)
24/04/16 18:23:21.219 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 132)
24/04/16 18:23:21.219 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 132 (MapPartitionsRDD[511] at flatMap at RandomForest.scala:1039), which has no missing parents
24/04/16 18:23:21.223 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 285.8 KiB, free 898.7 MiB)
24/04/16 18:23:21.223 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 83.9 KiB, free 898.6 MiB)
24/04/16 18:23:21.223 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 83.9 KiB, free: 900.8 MiB)
24/04/16 18:23:21.223 dag-scheduler-event-loop INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:21.223 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 132 (MapPartitionsRDD[511] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:21.223 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 132.0 with 1 tasks resource profile 0
24/04/16 18:23:21.235 dispatcher-event-loop-0 WARN TaskSetManager: Stage 132 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:23:21.235 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 150) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:23:21.235 Executor task launch worker for task 0.0 in stage 132.0 (TID 150) INFO Executor: Running task 0.0 in stage 132.0 (TID 150)
24/04/16 18:23:21.251 Executor task launch worker for task 0.0 in stage 132.0 (TID 150) INFO BlockManager: Found block rdd_409_0 locally
24/04/16 18:23:21.416 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_145_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 80.2 KiB, free: 900.9 MiB)
24/04/16 18:23:21.419 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_146_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 80.4 KiB, free: 900.9 MiB)
24/04/16 18:23:21.759 Executor task launch worker for task 0.0 in stage 132.0 (TID 150) INFO Executor: Finished task 0.0 in stage 132.0 (TID 150). 1742 bytes result sent to driver
24/04/16 18:23:21.761 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 150) in 538 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:21.761 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
24/04/16 18:23:21.761 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 132 (flatMap at RandomForest.scala:1039) finished in 0,542 s
24/04/16 18:23:21.761 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:23:21.761 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:23:21.761 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 133)
24/04/16 18:23:21.761 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:23:21.761 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[513] at map at RandomForest.scala:1054), which has no missing parents
24/04/16 18:23:21.761 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 11.9 KiB, free 899.3 MiB)
24/04/16 18:23:21.763 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 899.3 MiB)
24/04/16 18:23:21.764 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 4.5 KiB, free: 900.9 MiB)
24/04/16 18:23:21.764 dag-scheduler-event-loop INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:21.764 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[513] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:21.764 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0
24/04/16 18:23:21.764 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 151) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:23:21.764 Executor task launch worker for task 0.0 in stage 133.0 (TID 151) INFO Executor: Running task 0.0 in stage 133.0 (TID 151)
24/04/16 18:23:21.766 Executor task launch worker for task 0.0 in stage 133.0 (TID 151) INFO ShuffleBlockFetcherIterator: Getting 1 (1737.8 KiB) non-empty blocks including 1 (1737.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:23:21.766 Executor task launch worker for task 0.0 in stage 133.0 (TID 151) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:23:21.868 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_147_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 83.9 KiB, free: 901.0 MiB)
24/04/16 18:23:21.972 Executor task launch worker for task 0.0 in stage 133.0 (TID 151) INFO Executor: Finished task 0.0 in stage 133.0 (TID 151). 265198 bytes result sent to driver
24/04/16 18:23:21.988 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 151) in 224 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:21.988 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
24/04/16 18:23:21.988 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 133 (collectAsMap at RandomForest.scala:1054) finished in 0,227 s
24/04/16 18:23:21.988 dag-scheduler-event-loop INFO DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:21.988 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished
24/04/16 18:23:21.988 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 97 finished: collectAsMap at RandomForest.scala:1054, took 0,771869 s
24/04/16 18:23:21.988 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 360.4 KiB, free 899.3 MiB)
24/04/16 18:23:22.003 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 93.2 KiB, free 899.2 MiB)
24/04/16 18:23:22.003 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 93.2 KiB, free: 900.9 MiB)
24/04/16 18:23:22.009 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 149 from broadcast at RandomForest.scala:293
24/04/16 18:23:22.012 nioEventLoopGroup-2-2 INFO Instrumentation: [a673a979] {"numFeatures":545}
24/04/16 18:23:22.012 nioEventLoopGroup-2-2 INFO Instrumentation: [a673a979] {"numClasses":2}
24/04/16 18:23:22.012 nioEventLoopGroup-2-2 INFO Instrumentation: [a673a979] {"numExamples":2698}
24/04/16 18:23:22.012 nioEventLoopGroup-2-2 INFO Instrumentation: [a673a979] {"sumOfWeights":2698.0}
24/04/16 18:23:22.012 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 3.8 KiB, free 899.2 MiB)
24/04/16 18:23:22.014 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 1966.0 B, free 899.2 MiB)
24/04/16 18:23:22.014 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 1966.0 B, free: 900.9 MiB)
24/04/16 18:23:22.014 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 150 from broadcast at RandomForest.scala:622
24/04/16 18:23:22.037 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 18:23:22.037 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 516 (mapPartitions at RandomForest.scala:644) as input to shuffle 37
24/04/16 18:23:22.037 dag-scheduler-event-loop INFO DAGScheduler: Got job 98 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 18:23:22.037 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 135 (collectAsMap at RandomForest.scala:663)
24/04/16 18:23:22.037 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 134)
24/04/16 18:23:22.037 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 134)
24/04/16 18:23:22.037 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 134 (MapPartitionsRDD[516] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 18:23:22.051 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 401.4 KiB, free 898.8 MiB)
24/04/16 18:23:22.051 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 147.4 KiB, free 898.7 MiB)
24/04/16 18:23:22.051 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 147.4 KiB, free: 900.8 MiB)
24/04/16 18:23:22.051 dag-scheduler-event-loop INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:22.051 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 134 (MapPartitionsRDD[516] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:22.051 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks resource profile 0
24/04/16 18:23:22.067 dispatcher-event-loop-0 WARN TaskSetManager: Stage 134 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:23:22.067 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 152) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:23:22.067 Executor task launch worker for task 0.0 in stage 134.0 (TID 152) INFO Executor: Running task 0.0 in stage 134.0 (TID 152)
24/04/16 18:23:22.094 Executor task launch worker for task 0.0 in stage 134.0 (TID 152) INFO BlockManager: Found block rdd_409_0 locally
24/04/16 18:23:22.433 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_148_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 4.5 KiB, free: 900.8 MiB)
24/04/16 18:23:22.511 Executor task launch worker for task 0.0 in stage 134.0 (TID 152) INFO MemoryStore: Block rdd_515_0 stored as values in memory (estimated size 5.9 MiB, free 892.8 MiB)
24/04/16 18:23:22.511 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_515_0 in memory on DESKTOP-LH06ASP:64589 (size: 5.9 MiB, free: 894.9 MiB)
24/04/16 18:23:22.561 Executor task launch worker for task 0.0 in stage 134.0 (TID 152) INFO Executor: Finished task 0.0 in stage 134.0 (TID 152). 1785 bytes result sent to driver
24/04/16 18:23:22.561 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 152) in 510 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:22.561 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
24/04/16 18:23:22.561 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 134 (mapPartitions at RandomForest.scala:644) finished in 0,524 s
24/04/16 18:23:22.561 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:23:22.561 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:23:22.561 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 135)
24/04/16 18:23:22.561 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:23:22.561 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[518] at map at RandomForest.scala:663), which has no missing parents
24/04/16 18:23:22.564 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 7.4 KiB, free 892.8 MiB)
24/04/16 18:23:22.566 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 892.8 MiB)
24/04/16 18:23:22.566 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 3.8 KiB, free: 894.9 MiB)
24/04/16 18:23:22.566 dag-scheduler-event-loop INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:22.566 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[518] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:22.566 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 135.0 with 1 tasks resource profile 0
24/04/16 18:23:22.566 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 153) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:23:22.566 Executor task launch worker for task 0.0 in stage 135.0 (TID 153) INFO Executor: Running task 0.0 in stage 135.0 (TID 153)
24/04/16 18:23:22.573 Executor task launch worker for task 0.0 in stage 135.0 (TID 153) INFO ShuffleBlockFetcherIterator: Getting 1 (74.8 KiB) non-empty blocks including 1 (74.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:23:22.573 Executor task launch worker for task 0.0 in stage 135.0 (TID 153) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:23:22.593 Executor task launch worker for task 0.0 in stage 135.0 (TID 153) INFO Executor: Finished task 0.0 in stage 135.0 (TID 153). 5889 bytes result sent to driver
24/04/16 18:23:22.593 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 153) in 27 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:22.593 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
24/04/16 18:23:22.593 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 135 (collectAsMap at RandomForest.scala:663) finished in 0,029 s
24/04/16 18:23:22.593 dag-scheduler-event-loop INFO DAGScheduler: Job 98 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:22.593 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 135: Stage finished
24/04/16 18:23:22.593 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 98 finished: collectAsMap at RandomForest.scala:663, took 0,549588 s
24/04/16 18:23:22.593 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(150) (from destroy at RandomForest.scala:674)
24/04/16 18:23:22.593 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_150_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 1966.0 B, free: 894.9 MiB)
24/04/16 18:23:22.593 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 8.0 KiB, free 892.8 MiB)
24/04/16 18:23:22.593 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 892.8 MiB)
24/04/16 18:23:22.593 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 3.3 KiB, free: 894.9 MiB)
24/04/16 18:23:22.593 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 153 from broadcast at RandomForest.scala:622
24/04/16 18:23:22.626 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 18:23:22.626 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 519 (mapPartitions at RandomForest.scala:644) as input to shuffle 38
24/04/16 18:23:22.626 dag-scheduler-event-loop INFO DAGScheduler: Got job 99 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 18:23:22.626 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 137 (collectAsMap at RandomForest.scala:663)
24/04/16 18:23:22.626 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 136)
24/04/16 18:23:22.626 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 136)
24/04/16 18:23:22.626 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 136 (MapPartitionsRDD[519] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 18:23:22.636 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 409.6 KiB, free 892.4 MiB)
24/04/16 18:23:22.636 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 151.3 KiB, free 892.3 MiB)
24/04/16 18:23:22.636 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 151.3 KiB, free: 894.8 MiB)
24/04/16 18:23:22.636 dag-scheduler-event-loop INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:22.636 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 136 (MapPartitionsRDD[519] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:22.636 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0
24/04/16 18:23:22.653 dispatcher-event-loop-0 WARN TaskSetManager: Stage 136 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:23:22.653 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 154) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:23:22.653 Executor task launch worker for task 0.0 in stage 136.0 (TID 154) INFO Executor: Running task 0.0 in stage 136.0 (TID 154)
24/04/16 18:23:22.676 Executor task launch worker for task 0.0 in stage 136.0 (TID 154) INFO BlockManager: Found block rdd_515_0 locally
24/04/16 18:23:22.727 Executor task launch worker for task 0.0 in stage 136.0 (TID 154) INFO Executor: Finished task 0.0 in stage 136.0 (TID 154). 1742 bytes result sent to driver
24/04/16 18:23:22.727 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 154) in 91 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:22.727 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
24/04/16 18:23:22.727 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 136 (mapPartitions at RandomForest.scala:644) finished in 0,101 s
24/04/16 18:23:22.727 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:23:22.727 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:23:22.727 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 137)
24/04/16 18:23:22.727 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:23:22.727 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[521] at map at RandomForest.scala:663), which has no missing parents
24/04/16 18:23:22.727 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 10.8 KiB, free 892.2 MiB)
24/04/16 18:23:22.732 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 892.2 MiB)
24/04/16 18:23:22.732 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 5.1 KiB, free: 894.8 MiB)
24/04/16 18:23:22.732 dag-scheduler-event-loop INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:22.732 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 137 (MapPartitionsRDD[521] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:22.732 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 137.0 with 1 tasks resource profile 0
24/04/16 18:23:22.732 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 155) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:23:22.732 Executor task launch worker for task 0.0 in stage 137.0 (TID 155) INFO Executor: Running task 0.0 in stage 137.0 (TID 155)
24/04/16 18:23:22.732 Executor task launch worker for task 0.0 in stage 137.0 (TID 155) INFO ShuffleBlockFetcherIterator: Getting 1 (109.5 KiB) non-empty blocks including 1 (109.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:23:22.732 Executor task launch worker for task 0.0 in stage 137.0 (TID 155) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:23:22.766 Executor task launch worker for task 0.0 in stage 137.0 (TID 155) INFO Executor: Finished task 0.0 in stage 137.0 (TID 155). 9541 bytes result sent to driver
24/04/16 18:23:22.766 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 155) in 34 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:22.775 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
24/04/16 18:23:22.775 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 137 (collectAsMap at RandomForest.scala:663) finished in 0,048 s
24/04/16 18:23:22.776 dag-scheduler-event-loop INFO DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:22.776 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished
24/04/16 18:23:22.776 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 99 finished: collectAsMap at RandomForest.scala:663, took 0,145671 s
24/04/16 18:23:22.776 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(153) (from destroy at RandomForest.scala:674)
24/04/16 18:23:22.776 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_153_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 3.3 KiB, free: 894.8 MiB)
24/04/16 18:23:22.780 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 15.7 KiB, free 892.2 MiB)
24/04/16 18:23:22.780 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 892.2 MiB)
24/04/16 18:23:22.780 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 6.0 KiB, free: 894.8 MiB)
24/04/16 18:23:22.780 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 156 from broadcast at RandomForest.scala:622
24/04/16 18:23:22.812 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 18:23:22.812 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 522 (mapPartitions at RandomForest.scala:644) as input to shuffle 39
24/04/16 18:23:22.812 dag-scheduler-event-loop INFO DAGScheduler: Got job 100 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 18:23:22.812 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 139 (collectAsMap at RandomForest.scala:663)
24/04/16 18:23:22.812 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 138)
24/04/16 18:23:22.812 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 138)
24/04/16 18:23:22.812 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 138 (MapPartitionsRDD[522] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 18:23:22.812 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 424.1 KiB, free 891.8 MiB)
24/04/16 18:23:22.829 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 158.3 KiB, free 891.7 MiB)
24/04/16 18:23:22.829 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 158.3 KiB, free: 894.6 MiB)
24/04/16 18:23:22.829 dag-scheduler-event-loop INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:22.829 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 138 (MapPartitionsRDD[522] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:22.829 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks resource profile 0
24/04/16 18:23:22.834 dispatcher-event-loop-0 WARN TaskSetManager: Stage 138 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:23:22.834 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 156) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:23:22.844 Executor task launch worker for task 0.0 in stage 138.0 (TID 156) INFO Executor: Running task 0.0 in stage 138.0 (TID 156)
24/04/16 18:23:22.862 Executor task launch worker for task 0.0 in stage 138.0 (TID 156) INFO BlockManager: Found block rdd_515_0 locally
24/04/16 18:23:22.941 Executor task launch worker for task 0.0 in stage 138.0 (TID 156) INFO Executor: Finished task 0.0 in stage 138.0 (TID 156). 1742 bytes result sent to driver
24/04/16 18:23:22.943 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 156) in 114 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:22.943 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
24/04/16 18:23:22.943 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 138 (mapPartitions at RandomForest.scala:644) finished in 0,131 s
24/04/16 18:23:22.943 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:23:22.943 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:23:22.943 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 139)
24/04/16 18:23:22.943 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:23:22.945 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[524] at map at RandomForest.scala:663), which has no missing parents
24/04/16 18:23:22.947 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 14.3 KiB, free 891.6 MiB)
24/04/16 18:23:22.949 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 891.6 MiB)
24/04/16 18:23:22.949 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 6.2 KiB, free: 894.6 MiB)
24/04/16 18:23:22.949 dag-scheduler-event-loop INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:22.951 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[524] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:22.951 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks resource profile 0
24/04/16 18:23:22.952 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 157) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:23:22.952 Executor task launch worker for task 0.0 in stage 139.0 (TID 157) INFO Executor: Running task 0.0 in stage 139.0 (TID 157)
24/04/16 18:23:22.959 Executor task launch worker for task 0.0 in stage 139.0 (TID 157) INFO ShuffleBlockFetcherIterator: Getting 1 (145.8 KiB) non-empty blocks including 1 (145.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:23:22.959 Executor task launch worker for task 0.0 in stage 139.0 (TID 157) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:23:23.105 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_157_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 158.3 KiB, free: 894.8 MiB)
24/04/16 18:23:23.107 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_154_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 151.3 KiB, free: 894.9 MiB)
24/04/16 18:23:23.109 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_155_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 5.1 KiB, free: 894.9 MiB)
24/04/16 18:23:23.111 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_152_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 3.8 KiB, free: 894.9 MiB)
24/04/16 18:23:23.114 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_151_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 147.4 KiB, free: 895.1 MiB)
24/04/16 18:23:23.127 Executor task launch worker for task 0.0 in stage 139.0 (TID 157) INFO Executor: Finished task 0.0 in stage 139.0 (TID 157). 16652 bytes result sent to driver
24/04/16 18:23:23.127 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 157) in 175 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:23.127 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
24/04/16 18:23:23.127 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 139 (collectAsMap at RandomForest.scala:663) finished in 0,182 s
24/04/16 18:23:23.127 dag-scheduler-event-loop INFO DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:23.127 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 139: Stage finished
24/04/16 18:23:23.129 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 100 finished: collectAsMap at RandomForest.scala:663, took 0,315508 s
24/04/16 18:23:23.129 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(156) (from destroy at RandomForest.scala:674)
24/04/16 18:23:23.129 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_156_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 6.0 KiB, free: 895.1 MiB)
24/04/16 18:23:23.131 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 25.3 KiB, free 893.3 MiB)
24/04/16 18:23:23.131 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 893.3 MiB)
24/04/16 18:23:23.131 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 9.5 KiB, free: 895.1 MiB)
24/04/16 18:23:23.131 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 159 from broadcast at RandomForest.scala:622
24/04/16 18:23:23.147 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 18:23:23.147 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 525 (mapPartitions at RandomForest.scala:644) as input to shuffle 40
24/04/16 18:23:23.147 dag-scheduler-event-loop INFO DAGScheduler: Got job 101 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 18:23:23.147 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 141 (collectAsMap at RandomForest.scala:663)
24/04/16 18:23:23.147 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 140)
24/04/16 18:23:23.147 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 140)
24/04/16 18:23:23.147 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 140 (MapPartitionsRDD[525] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 18:23:23.162 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 449.0 KiB, free 892.9 MiB)
24/04/16 18:23:23.169 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 168.2 KiB, free 892.7 MiB)
24/04/16 18:23:23.169 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 168.2 KiB, free: 894.9 MiB)
24/04/16 18:23:23.169 dag-scheduler-event-loop INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:23.169 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 140 (MapPartitionsRDD[525] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:23.169 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 140.0 with 1 tasks resource profile 0
24/04/16 18:23:23.177 dispatcher-event-loop-0 WARN TaskSetManager: Stage 140 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:23:23.177 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 158) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:23:23.177 Executor task launch worker for task 0.0 in stage 140.0 (TID 158) INFO Executor: Running task 0.0 in stage 140.0 (TID 158)
24/04/16 18:23:23.193 Executor task launch worker for task 0.0 in stage 140.0 (TID 158) INFO BlockManager: Found block rdd_515_0 locally
24/04/16 18:23:23.245 Executor task launch worker for task 0.0 in stage 140.0 (TID 158) INFO Executor: Finished task 0.0 in stage 140.0 (TID 158). 1699 bytes result sent to driver
24/04/16 18:23:23.245 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 158) in 76 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:23.245 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
24/04/16 18:23:23.245 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 140 (mapPartitions at RandomForest.scala:644) finished in 0,098 s
24/04/16 18:23:23.245 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:23:23.245 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:23:23.245 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 141)
24/04/16 18:23:23.245 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:23:23.245 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[527] at map at RandomForest.scala:663), which has no missing parents
24/04/16 18:23:23.249 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 18.6 KiB, free 892.7 MiB)
24/04/16 18:23:23.251 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 892.7 MiB)
24/04/16 18:23:23.251 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 7.4 KiB, free: 894.9 MiB)
24/04/16 18:23:23.251 dag-scheduler-event-loop INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:23.251 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[527] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:23.251 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 141.0 with 1 tasks resource profile 0
24/04/16 18:23:23.253 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 159) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:23:23.253 Executor task launch worker for task 0.0 in stage 141.0 (TID 159) INFO Executor: Running task 0.0 in stage 141.0 (TID 159)
24/04/16 18:23:23.253 Executor task launch worker for task 0.0 in stage 141.0 (TID 159) INFO ShuffleBlockFetcherIterator: Getting 1 (194.1 KiB) non-empty blocks including 1 (194.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:23:23.253 Executor task launch worker for task 0.0 in stage 141.0 (TID 159) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:23:23.328 Executor task launch worker for task 0.0 in stage 141.0 (TID 159) INFO Executor: Finished task 0.0 in stage 141.0 (TID 159). 25556 bytes result sent to driver
24/04/16 18:23:23.328 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 159) in 75 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:23.328 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
24/04/16 18:23:23.328 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 141 (collectAsMap at RandomForest.scala:663) finished in 0,079 s
24/04/16 18:23:23.328 dag-scheduler-event-loop INFO DAGScheduler: Job 101 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:23.328 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 141: Stage finished
24/04/16 18:23:23.328 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 101 finished: collectAsMap at RandomForest.scala:663, took 0,177978 s
24/04/16 18:23:23.328 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(159) (from destroy at RandomForest.scala:674)
24/04/16 18:23:23.336 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_159_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 9.5 KiB, free: 894.9 MiB)
24/04/16 18:23:23.337 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 34.4 KiB, free 892.7 MiB)
24/04/16 18:23:23.341 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 892.7 MiB)
24/04/16 18:23:23.341 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 13.0 KiB, free: 894.9 MiB)
24/04/16 18:23:23.341 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 162 from broadcast at RandomForest.scala:622
24/04/16 18:23:23.352 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
24/04/16 18:23:23.352 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 528 (mapPartitions at RandomForest.scala:644) as input to shuffle 41
24/04/16 18:23:23.352 dag-scheduler-event-loop INFO DAGScheduler: Got job 102 (collectAsMap at RandomForest.scala:663) with 1 output partitions
24/04/16 18:23:23.352 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 143 (collectAsMap at RandomForest.scala:663)
24/04/16 18:23:23.352 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 142)
24/04/16 18:23:23.352 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List(ShuffleMapStage 142)
24/04/16 18:23:23.352 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 142 (MapPartitionsRDD[528] at mapPartitions at RandomForest.scala:644), which has no missing parents
24/04/16 18:23:23.367 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 485.5 KiB, free 892.2 MiB)
24/04/16 18:23:23.367 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 182.0 KiB, free 892.0 MiB)
24/04/16 18:23:23.367 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 182.0 KiB, free: 894.7 MiB)
24/04/16 18:23:23.367 dag-scheduler-event-loop INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:23.367 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 142 (MapPartitionsRDD[528] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:23.367 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 142.0 with 1 tasks resource profile 0
24/04/16 18:23:23.383 dispatcher-event-loop-0 WARN TaskSetManager: Stage 142 contains a task of very large size (11813 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:23:23.383 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 160) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 12097229 bytes) 
24/04/16 18:23:23.383 Executor task launch worker for task 0.0 in stage 142.0 (TID 160) INFO Executor: Running task 0.0 in stage 142.0 (TID 160)
24/04/16 18:23:23.409 Executor task launch worker for task 0.0 in stage 142.0 (TID 160) INFO BlockManager: Found block rdd_515_0 locally
24/04/16 18:23:23.486 Executor task launch worker for task 0.0 in stage 142.0 (TID 160) INFO Executor: Finished task 0.0 in stage 142.0 (TID 160). 1742 bytes result sent to driver
24/04/16 18:23:23.486 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 160) in 119 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:23.486 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
24/04/16 18:23:23.486 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 142 (mapPartitions at RandomForest.scala:644) finished in 0,134 s
24/04/16 18:23:23.486 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
24/04/16 18:23:23.486 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
24/04/16 18:23:23.486 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set(ResultStage 143)
24/04/16 18:23:23.486 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
24/04/16 18:23:23.486 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[530] at map at RandomForest.scala:663), which has no missing parents
24/04/16 18:23:23.486 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 22.9 KiB, free 892.0 MiB)
24/04/16 18:23:23.486 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 8.5 KiB, free 892.0 MiB)
24/04/16 18:23:23.486 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 8.5 KiB, free: 894.7 MiB)
24/04/16 18:23:23.486 dag-scheduler-event-loop INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:23.486 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 143 (MapPartitionsRDD[530] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:23.486 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 143.0 with 1 tasks resource profile 0
24/04/16 18:23:23.486 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 161) (DESKTOP-LH06ASP, executor driver, partition 0, NODE_LOCAL, 7181 bytes) 
24/04/16 18:23:23.486 Executor task launch worker for task 0.0 in stage 143.0 (TID 161) INFO Executor: Running task 0.0 in stage 143.0 (TID 161)
24/04/16 18:23:23.495 Executor task launch worker for task 0.0 in stage 143.0 (TID 161) INFO ShuffleBlockFetcherIterator: Getting 1 (213.5 KiB) non-empty blocks including 1 (213.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
24/04/16 18:23:23.495 Executor task launch worker for task 0.0 in stage 143.0 (TID 161) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/04/16 18:23:23.534 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_158_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 6.2 KiB, free: 894.7 MiB)
24/04/16 18:23:23.536 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_161_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 7.4 KiB, free: 894.7 MiB)
24/04/16 18:23:23.536 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_163_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 182.0 KiB, free: 894.9 MiB)
24/04/16 18:23:23.539 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_160_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 168.2 KiB, free: 895.1 MiB)
24/04/16 18:23:23.622 Executor task launch worker for task 0.0 in stage 143.0 (TID 161) INFO Executor: Finished task 0.0 in stage 143.0 (TID 161). 34267 bytes result sent to driver
24/04/16 18:23:23.622 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 161) in 136 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:23.622 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
24/04/16 18:23:23.622 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 143 (collectAsMap at RandomForest.scala:663) finished in 0,136 s
24/04/16 18:23:23.622 dag-scheduler-event-loop INFO DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:23.622 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 143: Stage finished
24/04/16 18:23:23.622 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 102 finished: collectAsMap at RandomForest.scala:663, took 0,268726 s
24/04/16 18:23:23.622 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(162) (from destroy at RandomForest.scala:674)
24/04/16 18:23:23.622 nioEventLoopGroup-2-2 INFO RandomForest: Internal timing for DecisionTree:
24/04/16 18:23:23.622 nioEventLoopGroup-2-2 INFO RandomForest:   init: 6.66E-5
  total: 1.6208082
  findBestSplits: 1.6107746
  chooseSplits: 1.6065449
24/04/16 18:23:23.622 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_162_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 13.0 KiB, free: 895.1 MiB)
24/04/16 18:23:23.633 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 515 from persistence list
24/04/16 18:23:23.633 block-manager-storage-async-thread-pool-333 INFO BlockManager: Removing RDD 515
24/04/16 18:23:23.633 nioEventLoopGroup-2-2 INFO TorrentBroadcast: Destroying Broadcast(149) (from destroy at RandomForest.scala:305)
24/04/16 18:23:23.636 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_149_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 93.2 KiB, free: 901.0 MiB)
24/04/16 18:23:23.638 nioEventLoopGroup-2-2 INFO Instrumentation: [a673a979] {"numClasses":2}
24/04/16 18:23:23.638 nioEventLoopGroup-2-2 INFO Instrumentation: [a673a979] {"numFeatures":545}
24/04/16 18:23:24.067 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_164_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 8.5 KiB, free: 901.0 MiB)
24/04/16 18:23:24.067 block-manager-storage-async-thread-pool-352 INFO BlockManager: Removing RDD 515
24/04/16 18:23:24.109 nioEventLoopGroup-2-2 INFO Instrumentation: [a673a979] training finished
24/04/16 18:23:24.109 nioEventLoopGroup-2-2 INFO Instrumentation: [5c8983d5] training finished
24/04/16 18:23:24.910 nioEventLoopGroup-2-2 INFO Instrumentation: [25ddbf53] training finished
24/04/16 18:23:26.531 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:23:26.531 dag-scheduler-event-loop INFO DAGScheduler: Got job 103 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:23:26.531 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 144 (collect at utils.scala:26)
24/04/16 18:23:26.531 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:23:26.531 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:23:26.531 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[552] at collect at utils.scala:26), which has no missing parents
24/04/16 18:23:26.534 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 62.5 KiB, free 899.6 MiB)
24/04/16 18:23:26.534 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 899.6 MiB)
24/04/16 18:23:26.534 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 901.0 MiB)
24/04/16 18:23:26.534 dag-scheduler-event-loop INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:26.534 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[552] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:26.534 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 144.0 with 1 tasks resource profile 0
24/04/16 18:23:26.534 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 162) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 18:23:26.537 Executor task launch worker for task 0.0 in stage 144.0 (TID 162) INFO Executor: Running task 0.0 in stage 144.0 (TID 162)
24/04/16 18:23:26.558 Executor task launch worker for task 0.0 in stage 144.0 (TID 162) INFO Executor: Finished task 0.0 in stage 144.0 (TID 162). 1430 bytes result sent to driver
24/04/16 18:23:26.558 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 162) in 24 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:26.558 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
24/04/16 18:23:26.558 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 144 (collect at utils.scala:26) finished in 0,027 s
24/04/16 18:23:26.558 dag-scheduler-event-loop INFO DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:26.565 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 144: Stage finished
24/04/16 18:23:26.565 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 103 finished: collect at utils.scala:26, took 0,033132 s
24/04/16 18:23:26.642 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_165_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 901.0 MiB)
24/04/16 18:23:30.738 nioEventLoopGroup-2-2 INFO Instrumentation: [8db687a0] training finished
24/04/16 18:23:32.483 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:23:32.483 dag-scheduler-event-loop INFO DAGScheduler: Got job 104 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:23:32.483 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 145 (collect at utils.scala:26)
24/04/16 18:23:32.483 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:23:32.483 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:23:32.483 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[555] at collect at utils.scala:26), which has no missing parents
24/04/16 18:23:32.487 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 62.5 KiB, free 899.6 MiB)
24/04/16 18:23:32.488 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 899.6 MiB)
24/04/16 18:23:32.488 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.7 KiB, free: 901.0 MiB)
24/04/16 18:23:32.488 dag-scheduler-event-loop INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:32.489 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[555] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:32.489 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 145.0 with 1 tasks resource profile 0
24/04/16 18:23:32.489 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 163) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 18:23:32.490 Executor task launch worker for task 0.0 in stage 145.0 (TID 163) INFO Executor: Running task 0.0 in stage 145.0 (TID 163)
24/04/16 18:23:32.586 Executor task launch worker for task 0.0 in stage 145.0 (TID 163) INFO Executor: Finished task 0.0 in stage 145.0 (TID 163). 1473 bytes result sent to driver
24/04/16 18:23:32.587 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 163) in 98 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:32.587 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
24/04/16 18:23:32.588 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 145 (collect at utils.scala:26) finished in 0,104 s
24/04/16 18:23:32.588 dag-scheduler-event-loop INFO DAGScheduler: Job 104 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:32.588 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 145: Stage finished
24/04/16 18:23:32.588 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 104 finished: collect at utils.scala:26, took 0,105225 s
24/04/16 18:23:37.103 nioEventLoopGroup-2-2 INFO Instrumentation: [91a42027] training finished
24/04/16 18:23:48.772 nioEventLoopGroup-2-2 WARN StringIndexerModel: Input column class does not exist during transformation. Skip StringIndexerModel for this column.
24/04/16 18:23:48.788 nioEventLoopGroup-2-2 INFO Instrumentation: [c529e7e3] training finished
24/04/16 18:23:48.967 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_166_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.7 KiB, free: 901.0 MiB)
24/04/16 18:23:49.080 nioEventLoopGroup-2-2 INFO Instrumentation: [2ee6d712] training finished
24/04/16 18:23:50.578 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:23:50.578 dag-scheduler-event-loop INFO DAGScheduler: Got job 105 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:23:50.578 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 146 (collect at utils.scala:26)
24/04/16 18:23:50.578 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:23:50.578 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:23:50.578 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 146 (MapPartitionsRDD[558] at collect at utils.scala:26), which has no missing parents
24/04/16 18:23:50.590 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 62.8 KiB, free 899.6 MiB)
24/04/16 18:23:50.592 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 899.6 MiB)
24/04/16 18:23:50.592 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.8 KiB, free: 901.0 MiB)
24/04/16 18:23:50.592 dag-scheduler-event-loop INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:50.592 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 146 (MapPartitionsRDD[558] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:50.592 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 146.0 with 1 tasks resource profile 0
24/04/16 18:23:50.592 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 164) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 18:23:50.592 Executor task launch worker for task 0.0 in stage 146.0 (TID 164) INFO Executor: Running task 0.0 in stage 146.0 (TID 164)
24/04/16 18:23:50.626 Executor task launch worker for task 0.0 in stage 146.0 (TID 164) INFO CodeGenerator: Code generated in 16.0489 ms
24/04/16 18:23:50.626 Executor task launch worker for task 0.0 in stage 146.0 (TID 164) INFO Executor: Finished task 0.0 in stage 146.0 (TID 164). 1430 bytes result sent to driver
24/04/16 18:23:50.626 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 164) in 34 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:50.626 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
24/04/16 18:23:50.626 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 146 (collect at utils.scala:26) finished in 0,048 s
24/04/16 18:23:50.626 dag-scheduler-event-loop INFO DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:50.626 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 146: Stage finished
24/04/16 18:23:50.626 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 105 finished: collect at utils.scala:26, took 0,045897 s
24/04/16 18:23:50.749 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 69.9048 ms
24/04/16 18:23:54.524 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_167_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.8 KiB, free: 901.0 MiB)
24/04/16 18:23:56.074 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:23:56.074 dag-scheduler-event-loop INFO DAGScheduler: Got job 106 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:23:56.074 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 147 (collect at utils.scala:26)
24/04/16 18:23:56.074 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:23:56.074 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:23:56.074 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[561] at collect at utils.scala:26), which has no missing parents
24/04/16 18:23:56.084 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 63.0 KiB, free 899.6 MiB)
24/04/16 18:23:56.084 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 12.8 KiB, free 899.6 MiB)
24/04/16 18:23:56.084 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 12.8 KiB, free: 901.0 MiB)
24/04/16 18:23:56.084 dag-scheduler-event-loop INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1535
24/04/16 18:23:56.084 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[561] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:23:56.084 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 147.0 with 1 tasks resource profile 0
24/04/16 18:23:56.084 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 165) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 7571 bytes) 
24/04/16 18:23:56.086 Executor task launch worker for task 0.0 in stage 147.0 (TID 165) INFO Executor: Running task 0.0 in stage 147.0 (TID 165)
24/04/16 18:23:56.122 Executor task launch worker for task 0.0 in stage 147.0 (TID 165) INFO CodeGenerator: Code generated in 24.2284 ms
24/04/16 18:23:56.137 Executor task launch worker for task 0.0 in stage 147.0 (TID 165) INFO Executor: Finished task 0.0 in stage 147.0 (TID 165). 1430 bytes result sent to driver
24/04/16 18:23:56.137 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 165) in 53 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:23:56.137 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
24/04/16 18:23:56.139 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 147 (collect at utils.scala:26) finished in 0,065 s
24/04/16 18:23:56.139 dag-scheduler-event-loop INFO DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:23:56.139 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 147: Stage finished
24/04/16 18:23:56.139 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 106 finished: collect at utils.scala:26, took 0,058282 s
24/04/16 18:23:56.248 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 57.5554 ms
24/04/16 18:24:00.008 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.7302 ms
24/04/16 18:24:00.107 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_168_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 12.8 KiB, free: 901.0 MiB)
24/04/16 18:24:00.121 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:24:00.121 dag-scheduler-event-loop INFO DAGScheduler: Got job 107 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:24:00.121 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 148 (collect at utils.scala:26)
24/04/16 18:24:00.121 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:24:00.121 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:24:00.121 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[569] at collect at utils.scala:26), which has no missing parents
24/04/16 18:24:00.135 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 488.3 KiB, free 899.2 MiB)
24/04/16 18:24:00.135 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 119.7 KiB, free 899.1 MiB)
24/04/16 18:24:00.135 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 119.7 KiB, free: 900.9 MiB)
24/04/16 18:24:00.135 dag-scheduler-event-loop INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1535
24/04/16 18:24:00.135 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[569] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:24:00.135 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks resource profile 0
24/04/16 18:24:00.150 dispatcher-event-loop-0 WARN TaskSetManager: Stage 148 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:24:00.150 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 166) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 18:24:00.150 Executor task launch worker for task 0.0 in stage 148.0 (TID 166) INFO Executor: Running task 0.0 in stage 148.0 (TID 166)
24/04/16 18:24:00.197 Executor task launch worker for task 0.0 in stage 148.0 (TID 166) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 18:24:00.575 Executor task launch worker for task 0.0 in stage 148.0 (TID 166) INFO CodeGenerator: Code generated in 91.4227 ms
24/04/16 18:24:00.727 Executor task launch worker for task 0.0 in stage 148.0 (TID 166) INFO Executor: Finished task 0.0 in stage 148.0 (TID 166). 2355 bytes result sent to driver
24/04/16 18:24:00.727 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 166) in 592 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:24:00.727 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
24/04/16 18:24:00.727 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 148 (collect at utils.scala:26) finished in 0,606 s
24/04/16 18:24:00.727 dag-scheduler-event-loop INFO DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:24:00.727 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 148: Stage finished
24/04/16 18:24:00.727 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 107 finished: collect at utils.scala:26, took 0,601934 s
24/04/16 18:24:32.979 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_169_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 119.7 KiB, free: 901.0 MiB)
24/04/16 18:24:32.982 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
24/04/16 18:24:32.982 dag-scheduler-event-loop INFO DAGScheduler: Got job 108 (collect at utils.scala:26) with 1 output partitions
24/04/16 18:24:32.982 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 149 (collect at utils.scala:26)
24/04/16 18:24:32.982 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
24/04/16 18:24:32.982 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
24/04/16 18:24:32.982 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[577] at collect at utils.scala:26), which has no missing parents
24/04/16 18:24:32.995 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 488.3 KiB, free 899.2 MiB)
24/04/16 18:24:32.995 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 119.7 KiB, free 899.1 MiB)
24/04/16 18:24:33.007 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on DESKTOP-LH06ASP:64589 (size: 119.7 KiB, free: 900.9 MiB)
24/04/16 18:24:33.007 dag-scheduler-event-loop INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1535
24/04/16 18:24:33.007 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[577] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
24/04/16 18:24:33.007 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 149.0 with 1 tasks resource profile 0
24/04/16 18:24:33.011 dispatcher-event-loop-0 WARN TaskSetManager: Stage 149 contains a task of very large size (9588 KiB). The maximum recommended task size is 1000 KiB.
24/04/16 18:24:33.011 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 167) (DESKTOP-LH06ASP, executor driver, partition 0, PROCESS_LOCAL, 9818702 bytes) 
24/04/16 18:24:33.011 Executor task launch worker for task 0.0 in stage 149.0 (TID 167) INFO Executor: Running task 0.0 in stage 149.0 (TID 167)
24/04/16 18:24:33.039 Executor task launch worker for task 0.0 in stage 149.0 (TID 167) INFO BlockManager: Found block rdd_13_0 locally
24/04/16 18:24:33.310 Executor task launch worker for task 0.0 in stage 149.0 (TID 167) INFO Executor: Finished task 0.0 in stage 149.0 (TID 167). 2355 bytes result sent to driver
24/04/16 18:24:33.310 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 167) in 301 ms on DESKTOP-LH06ASP (executor driver) (1/1)
24/04/16 18:24:33.310 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
24/04/16 18:24:33.311 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 149 (collect at utils.scala:26) finished in 0,329 s
24/04/16 18:24:33.311 dag-scheduler-event-loop INFO DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/16 18:24:33.311 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 149: Stage finished
24/04/16 18:24:33.311 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 108 finished: collect at utils.scala:26, took 0,323172 s
24/04/16 18:39:38.355 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_170_piece0 on DESKTOP-LH06ASP:64589 in memory (size: 119.7 KiB, free: 901.0 MiB)
24/04/16 19:31:41.624 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
24/04/16 19:31:41.628 shutdown-hook-0 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/16 19:31:41.705 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-LH06ASP:4040
24/04/16 19:31:41.774 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/16 19:31:42.291 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
24/04/16 19:31:42.291 shutdown-hook-0 INFO BlockManager: BlockManager stopped
24/04/16 19:31:42.303 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/16 19:31:42.313 dispatcher-event-loop-0 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/16 19:31:42.329 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-45b0042a-6e74-47da-a1b0-d100da5302ea\userFiles-ffb43f20-c1da-4fa8-b223-eea17f6823a1
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-45b0042a-6e74-47da-a1b0-d100da5302ea\userFiles-ffb43f20-c1da-4fa8-b223-eea17f6823a1\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2175)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1509)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2175)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2081)
	at org.apache.spark.SparkContext.$anonfun$new$31(SparkContext.scala:664)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/16 19:31:42.343 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
24/04/16 19:31:42.343 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
24/04/16 19:31:42.345 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\Temp\spark-889dca85-a9a7-4990-b3cd-24da6132f547
24/04/16 19:31:42.351 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-45b0042a-6e74-47da-a1b0-d100da5302ea
24/04/16 19:31:42.364 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-45b0042a-6e74-47da-a1b0-d100da5302ea
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-45b0042a-6e74-47da-a1b0-d100da5302ea\userFiles-ffb43f20-c1da-4fa8-b223-eea17f6823a1\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
24/04/16 19:31:42.366 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-45b0042a-6e74-47da-a1b0-d100da5302ea\userFiles-ffb43f20-c1da-4fa8-b223-eea17f6823a1
24/04/16 19:31:42.373 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-45b0042a-6e74-47da-a1b0-d100da5302ea\userFiles-ffb43f20-c1da-4fa8-b223-eea17f6823a1
java.io.IOException: Failed to delete: C:\Users\pedro\AppData\Local\spark\spark-3.4.2-bin-hadoop3\tmp\local\spark-45b0042a-6e74-47da-a1b0-d100da5302ea\userFiles-ffb43f20-c1da-4fa8-b223-eea17f6823a1\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:150)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:133)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:121)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1231)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
