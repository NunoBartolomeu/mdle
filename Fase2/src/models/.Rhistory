# Compute SVD for Pima dataset
pima_svd <- svd(scale(pima_encoded[, -ncol(pima_encoded)]))
# Compute SVD for Lisbon dataset
lisbon_svd <- svd(scale(lisbon_encoded[, -c(1, 2, 22, 23, 24)]))
# Plot singular values for Pima dataset
plot(pima_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Pima Dataset")
# Plot singular values for Lisbon dataset
plot(lisbon_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Lisbon Dataset")
# Determine a proporção acumulada da variância explicada por cada componente
cumulative_variance_svd_pima <- cumsum(pima_svd$d^2 / sum(pima_svd$d^2))
cumulative_variance_svd_lisbon <- cumsum(lisbon_svd$d^2 / sum(lisbon_svd$d^2))
# Encontre o número de componentes que explicam pelo menos 90% da variância
k_svd_pima <- which(cumulative_variance_svd_pima >= 0.9)[1]
k_svd_lisbon <- which(cumulative_variance_svd_lisbon >= 0.9)[1]
# Retenha o número selecionado de componentes
selected_svd_pcs_pima <- pima_svd$u[, 1:k_svd_pima] %*% diag(pima_svd$d[1:k_svd_pima])
selected_svd_pcs_lisbon <- lisbon_svd$u[, 1:k_svd_lisbon] %*% diag(lisbon_svd$d[1:k_svd_lisbon])
# Mostrar os componentes selecionados no terminal
ncol(selected_svd_pcs_pima)
ncol(selected_svd_pcs_lisbon)
set.seed(123)
# Set the working directory to the 'src' directory
# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path ))
#########################AUXILIAR FUNCTIONS###################################################
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
#Calculate the mean of column Active.Energy..kWh.
mean_energy <- mean(df$Active.Energy..kWh., na.rm = TRUE)
#Creates the new column
df$Active.Energy.Class <- ifelse(df$Active.Energy..kWh. > mean_energy, "High", "Low")
#Transforms the new column to factor
df$Active.Energy.Class <- as.factor(df$Active.Energy.Class)
################Decision Trees################################################################
df_clean <- na.omit(df)
#########################AUXILIAR FUNCTIONS###################################################
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
train_index <- sample(1:nrow(df), size = 0.65 * nrow(df))
df_train <- df[train_index, ]
df_test <- df[-train_index, ]
# Train Random Forest model
rf_model <- randomForest(Active.Energy.Class ~ ., data = df_train_clean, ntree = 10)
library(dplyr)
library(rpart)
library(sparklyr)
library(caret)
library(randomForest) #Implements Random Forest
library(class) #Implements KNN
library(e1071) #Implements SVM
# Train Random Forest model
rf_model <- randomForest(Active.Energy.Class ~ ., data = df_train_clean, ntree = 10)
# Train Random Forest model
rf_model <- randomForest(Active.Energy.Class ~ ., data = df_train, ntree = 10)
# Remover linhas com valores ausentes
df_train_clean <- na.omit(df_train)
# Train Random Forest model
rf_model <- randomForest(Active.Energy.Class ~ ., data = df_train_clean, ntree = 10)
predictions <- predict(rf_model, newdata = df_test)
############################################################################################
confusion_matrix <- confusionMatrix(predictions, df_test$Active.Energy.Class)
print(confusion_matrix)
df <- subset(df, select = -c(datetime, Date, Hour))
numeric_cols <- sapply(df, is.numeric)
numeric_cols["Active.Energy.Class"] <- FALSE # Não normalizar a coluna alvo
df[numeric_cols] <- as.data.frame(lapply(df[numeric_cols], normalize))
train_index <- sample(1:nrow(df), size = 0.7 * nrow(df))
df_train <- df[train_index, ]
df_test <- df[-train_index, ]
# Separate features and labels
features <- names(df)[!names(df) %in% c("Active.Energy.Class")]
train_features <- df_train[, features]
train_labels <- df_train$Active.Energy.Class
test_features <- df_test[, features]
test_labels <- df_test$Active.Energy.Class
# Verificar valores ausentes nos dados de treino
anyNA(train_features)
anyNA(test_features)
anyNA(train_labels)
anyNA(test_labels)
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
#Calculate the mean of column Active.Energy..kWh.
mean_energy <- mean(df$Active.Energy..kWh., na.rm = TRUE)
#Creates the new column
df$Active.Energy.Class <- ifelse(df$Active.Energy..kWh. > mean_energy, "High", "Low")
#Transforms the new column to factor
df$Active.Energy.Class <- as.factor(df$Active.Energy.Class)
df <- na.omit(df)
df <- subset(df, select = -c(datetime, Date, Hour))
numeric_cols <- sapply(df, is.numeric)
numeric_cols["Active.Energy.Class"] <- FALSE # Não normalizar a coluna alvo
df[numeric_cols] <- as.data.frame(lapply(df[numeric_cols], normalize))
train_index <- sample(1:nrow(df), size = 0.7 * nrow(df))
df_train <- df[train_index, ]
df_test <- df[-train_index, ]
# Separate features and labels
features <- names(df)[!names(df) %in% c("Active.Energy.Class")]
train_features <- df_train[, features]
train_labels <- df_train$Active.Energy.Class
test_features <- df_test[, features]
test_labels <- df_test$Active.Energy.Class
# Verificar valores ausentes nos dados de treino
anyNA(train_features)
anyNA(test_features)
anyNA(train_labels)
anyNA(test_labels)
#Define number of neighbours
k <- 3
#Train the model
predictions <- knn(train = train_features, test = test_features, cl = train_labels, k = k)
############################################################################################
confusion_matrix <- confusionMatrix(predictions, df_test$Active.Energy.Class)
print(confusion_matrix)
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
#Calculate the mean of column Active.Energy..kWh.
mean_energy <- mean(df$Active.Energy..kWh., na.rm = TRUE)
#Creates the new column
df$Active.Energy.Class <- ifelse(df$Active.Energy..kWh. > mean_energy, "High", "Low")
#Transforms the new column to factor
df$Active.Energy.Class <- as.factor(df$Active.Energy.Class)
#############################################################################################
################SVM##########################################################################
train_index <- sample(1:nrow(df), size = 0.7 * nrow(df))
df_train <- df[train_index, ]
df_test <- df[-train_index, ]
# Separar as características e os rótulos
train_features <- df_train[, features]
train_labels <- df_train$Active.Energy.Class
test_features <- df_test[, features]
test_labels <- df_test$Active.Energy.Class
# Treinar o modelo SVM
svm_model <- svm(train_features, train_labels, kernel = "radial")
############################################################################################
confusion_matrix <- confusionMatrix(predictions, df_test$Active.Energy.Class)
confusion_matrix <- confusionMatrix(predictions, test_labels)
str(predictions)
str(test_labels)
nrow(predictions)
ncol(predictions)
length(predictions)
length(test_labels)
cat("Comprimento de train_features:", nrow(train_features), "\n")
cat("Comprimento de train_labels:", length(train_labels), "\n")
cat("Comprimento de test_features:", nrow(test_features), "\n")
cat("Comprimento de test_labels:", length(test_labels), "\n")
library(dplyr)
library(rpart)
library(sparklyr)
library(caret)
library(randomForest) #Implements Random Forest
library(class) #Implements KNN
library(e1071) #Implements SVM
set.seed(123)
# Set the working directory to the 'src' directory
# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path ))
################# Spark setup ################
spark_disconnect_all() #just preventive code
sc <- spark_connect('local', version = '3.4.2', hadoop_version = '3', config = list())
#########################AUXILIAR FUNCTIONS###################################################
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
df <- spark_read_csv("../../mdle_data/out/merged_dataset.csv")
df <- spark_read_csv(sc, "../../mdle_data/out/merged_dataset.csv")
#Calculate the mean of column Active.Energy..kWh.
mean_energy <- mean(df$Active.Energy..kWh., na.rm = TRUE)
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
df_spark <- copy_to(sc, df, overwrite = TRUE)
set.seed(123)
# Set the working directory to the 'src' directory
# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path ))
################# Spark setup ################
spark_disconnect_all() #just preventive code
sc <- spark_connect('local', version = '3.4.2', hadoop_version = '3', config = list())
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
df_spark <- copy_to(sc, df, overwrite = TRUE)
mean_energy <- df_spark %>%
summarize(mean_energy = mean(Active.Energy..kWh., na.rm = TRUE)) %>%
collect() %>%
pull(mean_energy)
mean_energy <- df_spark %>%
summarize(mean_energy = mean(Active_Energy_kWh_, na.rm = TRUE)) %>%
collect() %>%
pull(mean_energy)
df_spark <- df_spark %>%
mutate(Active.Energy.Class = ifelse(Active_Energy_kWh_ > mean_energy, "High", "Low"))
# Coletar o DataFrame de volta para R
df_collected <- df_spark %>% collect()
# Transformar a coluna em fator
df_collected$Active.Energy.Class <- as.factor(df_collected$Active.Energy.Class)
df_spark <- copy_to(sc, df, overwrite = TRUE)
mean_energy <- df_spark %>%
summarise(mean_energy = mean(Active.Energy..kWh., na.rm = TRUE)) %>%
collect() %>%
.$mean_energy
mean_energy <- df_spark %>%
summarise(mean_energy = mean(Active_Energy_kWh_, na.rm = TRUE)) %>%
collect() %>%
.$mean_energy
df_spark <- df_spark %>%
mutate(Active.Energy.Class = ifelse(Active_Energy_kWh_ > mean_energy, "High", "Low"))
# Transformar a coluna em fator
df_collected$Active.Energy.Class <- as.factor(df_collected$Active.Energy.Class)
df_spark %>% glimpse()
################Random Forrest###############################################################
#With Spark
df_collected <- df_collected %>% filter(!is.na())
################Random Forrest###############################################################
#With Spark
df_collected <- df_collected %>% filter(!is.na(Active_Energy_kWh_))
#Prepare the data
df_spark <- df_spark %>% sdf_random_split(training = 0.65, test = 0.35, seed = 1234)
df_train <- df_spark$training
df_test <- df_spark$test
View(df_spark)
#Train the model
rf_model <- df_train %>%
ml_random_forest(Active.Energy.Class ~ ., type = "classification", ntree = 10)
View(df_train)
#Train the Random Forest model
rf_model <- df_train %>%
ml_random_forest(`Active.Energy.Class` ~ ., type = "classification", num_trees = 10)
names(df_spark)
schema(df_spark)
schema(df_train)
# Converts the column
df_train <- df_train %>%
ft_string_indexer(input_col = "Active.Energy.Class", output_col = "label")
#Prepare the data
df_spark <- df_collected %>% sdf_random_split(training = 0.65, test = 0.35, seed = 1234)
df_spark <- copy_to(sc, df, overwrite = TRUE)
mean_energy <- df_spark %>%
summarise(mean_energy = mean(Active_Energy_kWh_, na.rm = TRUE)) %>%
collect() %>%
.$mean_energy
df_spark <- df_spark %>%
mutate(Active.Energy.Class = ifelse(Active_Energy_kWh_ > mean_energy, "High", "Low"))
# Coletar o DataFrame de volta para R
df_collected <- df_spark %>% collect()
# Transformar a coluna em fator
df_collected$Active.Energy.Class <- as.factor(df_collected$Active.Energy.Class)
schema(df_spark)
head(df_spark)
View(df_spark)
################Random Forrest###############################################################
#With Spark
df_collected <- df_collected %>% filter(!is.na(Active_Energy_kWh_))
#Prepare the data
df_spark <- df_spark %>% sdf_random_split(training = 0.65, test = 0.35, seed = 1234)
df_train <- df_spark$training
df_test <- df_spark$test
# Converts the column
df_train <- df_train %>%
ft_string_indexer(input_col = "Active.Energy.Class", output_col = "label")
sdf_schema(df_train)
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
df_spark <- copy_to(sc, df, overwrite = TRUE)
mean_energy <- df_spark %>%
summarise(mean_energy = mean(Active_Energy_kWh_, na.rm = TRUE)) %>%
collect() %>%
.$mean_energy
df_spark <- df_spark %>%
mutate(Label = ifelse(Active_Energy_kWh_ > mean_energy, "High", "Low"))
# Coletar o DataFrame de volta para R
df_collected <- df_spark %>% collect()
# Transformar a coluna em fator
df_collected$Label <- as.factor(df_collected$Label)
sdf_schema(df_collected)
################Random Forrest###############################################################
#With Spark
df_collected <- df_collected %>% filter(!is.na(Active_Energy_kWh_))
#Prepare the data
df_spark <- df_spark %>% sdf_random_split(training = 0.65, test = 0.35, seed = 1234)
df_train <- df_spark$training
df_test <- df_spark$test
# Trains the Random Forest
rf_model <- df_train %>%
ml_random_forest(Label ~ ., type = "classification", num_trees = 10)
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
df_spark <- copy_to(sc, df, overwrite = TRUE)
mean_energy <- df_spark %>%
summarise(mean_energy = mean(Active_Energy_kWh_, na.rm = TRUE)) %>%
collect() %>%
.$mean_energy
df_spark <- df_spark %>%
mutate(Label = ifelse(Active_Energy_kWh_ > mean_energy, "High", "Low"))
# Coletar o DataFrame de volta para R
df_collected <- df_spark %>% collect()
# Transformar a coluna em fator
df_collected$Label <- as.factor(df_collected$Label)
################Random Forrest###############################################################
#With Spark
df_collected <- df_collected %>% filter(!is.na(Active_Energy_kWh_))
#Prepare the data
df_spark <- df_spark %>% sdf_random_split(training = 0.65, test = 0.35, seed = 1234)
df_train <- df_spark$training
df_test <- df_spark$test
# Trains the Random Forest
rf_model <- df_train %>%
ml_random_forest(Label ~ ., type = "classification", num_trees = 10)
sparklyr::spark_last_error()
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
df_spark <- copy_to(sc, df, overwrite = TRUE)
df_spark <- df_spark %>%
select(where(~ !is.character(.)))
mean_energy <- df_spark %>%
summarise(mean_energy = mean(Active_Energy_kWh_, na.rm = TRUE)) %>%
collect() %>%
.$mean_energy
df_spark <- df_spark %>%
mutate(Label = ifelse(Active_Energy_kWh_ > mean_energy, "High", "Low"))
# Coletar o DataFrame de volta para R
df_collected <- df_spark %>% collect()
# Transformar a coluna em fator
df_collected$Label <- as.factor(df_collected$Label)
################Random Forrest###############################################################
#With Spark
df_collected <- df_collected %>% filter(!is.na(Active_Energy_kWh_))
#Prepare the data
df_spark <- df_spark %>% sdf_random_split(training = 0.65, test = 0.35, seed = 1234)
df_train <- df_spark$training
df_test <- df_spark$test
# Trains the Random Forest
rf_model <- df_train %>%
ml_random_forest(Label ~ ., type = "classification", num_trees = 10)
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
df_spark <- copy_to(sc, df, overwrite = TRUE)
df_spark <- df_spark %>%
select(where(~ !is.character(.)))
mean_energy <- df_spark %>%
summarise(mean_energy = mean(Active_Energy_kWh_, na.rm = TRUE)) %>%
collect() %>%
.$mean_energy
df_spark <- df_spark %>%
mutate(Label = ifelse(Active_Energy_kWh_ > mean_energy, "High", "Low"))
# Coletar o DataFrame de volta para R
df_collected <- df_spark %>% collect()
# Transformar a coluna em fator
df_collected$Label <- as.factor(df_collected$Label)
################Random Forrest###############################################################
#With Spark
df_collected <- df_collected %>% sdf_na_drop()
################Random Forrest###############################################################
#With Spark
df_collected <- df_collected %>% na.omit()
#Prepare the data
df_spark <- df_spark %>% sdf_random_split(training = 0.65, test = 0.35, seed = 1234)
df_train <- df_spark$training
df_test <- df_spark$test
# Trains the Random Forest
rf_model <- df_train %>%
ml_random_forest(Label ~ ., type = "classification", num_trees = 10)
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
df_spark <- copy_to(sc, df, overwrite = TRUE)
################# Spark setup ################
spark_disconnect_all() #just preventive code
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
#Calculate the mean of column Active.Energy..kWh.
mean_energy <- mean(df$Active.Energy..kWh., na.rm = TRUE)
#Creates the new column
df$Active.Energy.Class <- ifelse(df$Active.Energy..kWh. > mean_energy, "High", "Low")
#Transforms the new column to factor
df$Active.Energy.Class <- as.factor(df$Active.Energy.Class)
#Without Spark
df <- na.omit(df)
#train_index <- sample(1:nrow(df), size = 0.7 * nrow(df))
train_index <- sample(2, nrow(df), replace = TRUE, prob = c(0.7,0.3))
df_train <- df[train_index==1, ]
df_test <- df[-train_index==2, ]
# Train Random Forest model
rf_model <- randomForest(Active.Energy.Class ~ ., data = df_train)
predictions <- predict(rf_model, newdata = df_test)
confusion_matrix <- confusionMatrix(predictions, df_test)
confusion_matrix <- confusionMatrix(predictions, df_test$Active.Energy.Class)
print(confusion_matrix)
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
#Calculate the mean of column Active.Energy..kWh.
mean_energy <- mean(df$Active.Energy..kWh., na.rm = TRUE)
#Creates the new column
df$Active.Energy.Class <- ifelse(df$Active.Energy..kWh. > mean_energy, "High", "Low")
#Transforms the new column to factor
df$Active.Energy.Class <- as.factor(df$Active.Energy.Class)
#Without Spark
df <- na.omit(df)
str(df)
#train_index <- sample(1:nrow(df), size = 0.7 * nrow(df))
train_index <- sample(2, nrow(df), replace = TRUE, prob = c(0.7,0.3))
head(train_index)
length(train_index)
str(train_index)
df_train <- df[train_index==1, ]
df_test <- df[train_index==2, ]
# Train Random Forest model
rf_model <- randomForest(Active.Energy.Class ~ ., data = df_train)
predictions <- predict(rf_model, newdata = df_test)
confusion_matrix <- confusionMatrix(predictions, df_test$Active.Energy.Class)
print(confusion_matrix)
library(pROC) #ROC Curve
probabilities <- predict(rf_model, newdata = df_test, type = "prob")
#Calcules the ROC curve
roc_curve <- roc(df_test$Active.Energy.Class, probabilities[, 2])
plot(roc_curve, col = "blue", main = "Curva ROC para o Modelo Random Forest")
abline(a = 0, b = 1, lty = 2, col = "red")
roc_curves <- lapply(unique(predictions_cv$Resample), function(resample) {
resample_data <- predictions_cv[predictions_cv$Resample == resample, ]
roc(resample_data$obs, resample_data$yes)  # 'yes' é a classe positiva
})
formula <- Active.Energy.Class ~ .
train_control <- trainControl(method = "cv", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary, savePredictions = TRUE)
rf_model_cv <- train(formula, data = df, method = "rf", trControl = train_control, metric = "ROC")
df <- na.omit(df)
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
#Calculate the mean of column Active.Energy..kWh.
mean_energy <- mean(df$Active.Energy..kWh., na.rm = TRUE)
#Creates the new column
df$Active.Energy.Class <- ifelse(df$Active.Energy..kWh. > mean_energy, "High", "Low")
#Transforms the new column to factor
df$Active.Energy.Class <- as.factor(df$Active.Energy.Class)
df <- na.omit(df)
df <- subset(df, select = -c(datetime, Date, Hour))
numeric_cols <- sapply(df, is.numeric)
numeric_cols
#Don't normalize
numeric_cols["Active.Energy.Class", "Zip.Code"] <- FALSE
numeric_cols["Zip.Code"] <- FALSE
#Don't normalize
numeric_cols["Active.Energy.Class"] <- FALSE
df[numeric_cols] <- as.data.frame(lapply(df[numeric_cols], normalize))
return ((x - min(x)) / (max(x) - min(x)))
#########################AUXILIAR FUNCTIONS###################################################
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
train_index <- sample(2, nrow(df), replace = TRUE, prob = c(0.7,0.3))
df_train <- df[train_index==1, ]
df_test <- df[train_index==2, ]
# Separate features and labels
features <- names(df)[!names(df) %in% c("Active.Energy.Class")]
train_features <- df_train[, features]
train_labels <- df_train$Active.Energy.Class
test_features <- df_test[, features]
test_labels <- df_test$Active.Energy.Class
# Verificar valores ausentes nos dados de treino
anyNA(train_features)
anyNA(test_features)
anyNA(train_labels)
anyNA(test_labels)
#Define number of neighbours
k <- 3
#Train the model
predictions <- knn(train = train_features, test = test_features, cl = train_labels, k = k)
confusion_matrix <- confusionMatrix(predictions, df_test$Active.Energy.Class)
print(confusion_matrix)
confusion_matrix <- confusionMatrix(predictions, test_labels)
print(confusion_matrix)
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
#Calculate the mean of column Active.Energy..kWh.
mean_energy <- mean(df$Active.Energy..kWh., na.rm = TRUE)
#Creates the new column
df$Active.Energy.Class <- ifelse(df$Active.Energy..kWh. > mean_energy, "High", "Low")
#Transforms the new column to factor
df$Active.Energy.Class <- as.factor(df$Active.Energy.Class)
#############################################################################################
################SVM##########################################################################
train_index <- sample(1:nrow(df), size = 0.7 * nrow(df))
df_train <- df[train_index, ]
df_test <- df[-train_index, ]
# Separar as características e os rótulos
train_features <- df_train[, features]
train_labels <- df_train$Active.Energy.Class
test_features <- df_test[, features]
test_labels <- df_test$Active.Energy.Class
# Treinar o modelo SVM
svm_model <- svm(train_features, train_labels, kernel = "radial")
predictions <- predict(svm_model, test_features)
confusion_matrix <- confusionMatrix(predictions, test_labels)
length(predictions)
length(test_labels)
length(test_features)
str(test_features)
df <- read.csv("../../mdle_data/out/merged_dataset.csv")
#Calculate the mean of column Active.Energy..kWh.
mean_energy <- mean(df$Active.Energy..kWh., na.rm = TRUE)
#Creates the new column
df$Active.Energy.Class <- ifelse(df$Active.Energy..kWh. > mean_energy, "High", "Low")
#Transforms the new column to factor
df$Active.Energy.Class <- as.factor(df$Active.Energy.Class)
#############################################################################################
################SMV##########################################################################
df <- na.omit(df)
df <- subset(df, select = -c(datetime, Date, Hour))
train_index <- sample(1:nrow(df), size = 0.7 * nrow(df))
df_train <- df[train_index, ]
df_test <- df[-train_index, ]
# Separar as características e os rótulos
train_features <- df_train[, features]
train_labels <- df_train$Active.Energy.Class
test_features <- df_test[, features]
test_labels <- df_test$Active.Energy.Class
# Treinar o modelo SVM
svm_model <- svm(train_features, train_labels, kernel = "radial")
predictions <- predict(svm_model, test_features)
confusion_matrix <- confusionMatrix(predictions, test_labels)
print(confusion_matrix)
