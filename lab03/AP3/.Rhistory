# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance_pima <- cumsum(pima_pca$sdev^2 / sum(pima_pca$sdev^2))
cumulative_variance_lisbon <- cumsum(lisbon_pca$sdev^2 / sum(lisbon_pca$sdev^2))
# Find the number of components that explain at least 90% of the variance
k_pima <- which(cumulative_variance_pima >= 0.9)[1]
k_lisbon <- which(cumulative_variance_lisbon >= 0.95)[1]
# Retain the selected number of components
selected_pcs_pima <- pima_pca$x[, 1:k_pima]
selected_pcs_lisbon <- lisbon_pca$x[, 1:k_lisbon]
# Show selected components in terminal
ncol(selected_pcs_pima)
ncol(selected_pcs_lisbon)
#Feature Reduction
#Ex a) PCA decomposition
# Load necessary libraries
library(dplyr)
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
lisbon_encoded <- lisbon %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Remove constant columns
lisbon_encoded <- lisbon_encoded[, -which(sapply(lisbon_encoded, function(x) length(unique(x))) == 1)]
# Perform PCA
pima_pca <- prcomp(pima_encoded[, -ncol(pima_encoded)], center = TRUE, scale. = TRUE)
lisbon_pca <- prcomp(lisbon_encoded[, -c(1, 2, 22, 23, 24)], center = TRUE, scale. = TRUE)
# Compute eigenvalues
pima_eigenvalues <- (pima_pca$sdev)^2
lisbon_eigenvalues <- (lisbon_pca$sdev)^2
# Sort eigenvalues in decreasing order
pima_eigenvalues <- sort(pima_eigenvalues, decreasing = TRUE)
lisbon_eigenvalues <- sort(lisbon_eigenvalues, decreasing = TRUE)
# Plot the eigenvalues
plot(pima_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Pima Dataset")
plot(lisbon_eigenvalues, type = "b", xlab = "Principal Component", ylab = "Eigenvalue", main = "Eigenvalues - Lisbon Dataset")
# Determine the cumulative proportion of variance explained by each component
cumulative_variance_pima <- cumsum(pima_pca$sdev^2 / sum(pima_pca$sdev^2))
cumulative_variance_lisbon <- cumsum(lisbon_pca$sdev^2 / sum(lisbon_pca$sdev^2))
# Find the number of components that explain at least 90% of the variance
k_pima <- which(cumulative_variance_pima >= 0.9)[1]
k_lisbon <- which(cumulative_variance_lisbon >= 0.9)[1]
# Retain the selected number of components
selected_pcs_pima <- pima_pca$x[, 1:k_pima]
selected_pcs_lisbon <- lisbon_pca$x[, 1:k_lisbon]
# Show selected components in terminal
ncol(selected_pcs_pima)
ncol(selected_pcs_lisbon)
#Ex b
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Function to handle missing or infinite values
handle_missing_infinite <- function(data) {
for (col in names(data)){
data[[col]][is.infinite(data[[col]])] <- NA
data[[col]][is.nan(data[[col]])] <- NA
}
data <- na.omit(data)
return(data)
}
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Apply the function to handle missing or infinite values
lisbon_encoded <- handle_missing_infinite(lisbon_encoded)
# Compute SVD for Pima dataset
pima_svd <- svd(scale(pima_encoded[, -ncol(pima_encoded)]))
# Compute SVD for Lisbon dataset
lisbon_svd <- svd(scale(lisbon_encoded[, -c(1, 2, 22, 23, 24)]))
# Plot singular values for Pima dataset
plot(pima_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Pima Dataset")
# Plot singular values for Lisbon dataset
plot(lisbon_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Lisbon Dataset")
# Determine a proporção acumulada da variância explicada por cada componente
cumulative_variance_svd_pima <- cumsum(pima_svd$d^2 / sum(pima_svd$d^2))
cumulative_variance_svd_lisbon <- cumsum(lisbon_svd$d^2 / sum(lisbon_svd$d^2))
# Encontre o número de componentes que explicam pelo menos 90% da variância
k_svd_pima <- which(cumulative_variance_svd_pima >= 0.9)[1]
k_svd_lisbon <- which(cumulative_variance_svd_lisbon >= 0.9)[1]
# Retenha o número selecionado de componentes
selected_svd_pcs_pima <- pima_svd$u[, 1:k_svd_pima] %*% diag(pima_svd$d[1:k_svd_pima])
selected_svd_pcs_lisbon <- lisbon_svd$u[, 1:k_svd_lisbon] %*% diag(lisbon_svd$d[1:k_svd_lisbon])
# Mostrar os componentes selecionados no terminal
selected_svd_pcs_pima
selected_svd_pcs_lisbon
#Ex b
# Load datasets
pima <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/pima.csv")
lisbon <- read.csv("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab02/Lisbon_ 2023-01-01_2023-01-31.csv")
# Function to handle missing or infinite values
handle_missing_infinite <- function(data) {
for (col in names(data)){
data[[col]][is.infinite(data[[col]])] <- NA
data[[col]][is.nan(data[[col]])] <- NA
}
data <- na.omit(data)
return(data)
}
# Encode categorical variables
pima_encoded <- pima %>%
mutate(across(where(is.character), as.factor)) %>%
mutate(across(where(is.factor), as.integer))
# Apply the function to handle missing or infinite values
lisbon_encoded <- handle_missing_infinite(lisbon_encoded)
# Compute SVD for Pima dataset
pima_svd <- svd(scale(pima_encoded[, -ncol(pima_encoded)]))
# Compute SVD for Lisbon dataset
lisbon_svd <- svd(scale(lisbon_encoded[, -c(1, 2, 22, 23, 24)]))
# Plot singular values for Pima dataset
plot(pima_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Pima Dataset")
# Plot singular values for Lisbon dataset
plot(lisbon_svd$d, type = "b", xlab = "Singular Value", ylab = "Value", main = "Singular Values - Lisbon Dataset")
# Determine a proporção acumulada da variância explicada por cada componente
cumulative_variance_svd_pima <- cumsum(pima_svd$d^2 / sum(pima_svd$d^2))
cumulative_variance_svd_lisbon <- cumsum(lisbon_svd$d^2 / sum(lisbon_svd$d^2))
# Encontre o número de componentes que explicam pelo menos 90% da variância
k_svd_pima <- which(cumulative_variance_svd_pima >= 0.9)[1]
k_svd_lisbon <- which(cumulative_variance_svd_lisbon >= 0.9)[1]
# Retenha o número selecionado de componentes
selected_svd_pcs_pima <- pima_svd$u[, 1:k_svd_pima] %*% diag(pima_svd$d[1:k_svd_pima])
selected_svd_pcs_lisbon <- lisbon_svd$u[, 1:k_svd_lisbon] %*% diag(lisbon_svd$d[1:k_svd_lisbon])
# Mostrar os componentes selecionados no terminal
ncol(selected_svd_pcs_pima)
ncol(selected_svd_pcs_lisbon)
################# Preparation ################
library(dplyr) #data manipulation
library(sparklyr) #spark
library(smotefamily) #For SMOTE sampling
library(data.table) #To be used when possible, as a more performant data.frame
library(e1071)
library(caret)
setwd("C:/Users/pedro/Desktop/Mestrado/MDLE/lab/lab03/AP3")
if(!exists("printConfusionMatrix", mode="function"))
source("helperfunctions.R")
################# Spark setup ################
spark_disconnect_all() #just preventive code
sc <- spark_connect('local', version = '3.4.2', hadoop_version = '3', config = list())
################# Load data ################
basepath <- "../data"
tr.data <- c("train_data_25.csv","train_data_30.csv") #The data to use
labels<- c("train_labels_25.csv","train_labels_30.csv") #the lables for the data
fun1 <- function(i) { #read CSV data
read.csv(paste(basepath,"train",i,sep = "/"), header=FALSE,stringsAsFactors = FALSE)
}
fun2 <- function(i) { #read and transpose CSV data
read.csv(paste(basepath,"train",i,sep = "/"), header=FALSE,stringsAsFactors = FALSE) %>% t %>% as.data.table
}
df<-do.call(rbind, lapply(tr.data, fun1 )) #bind csv together
df.l<-do.call(rbind, lapply(labels, fun2 )) #bind class together
names(df.l) <-c("CLASS") #rename dependent variable
df.local<- cbind(df.l,df) #bind them together
df <- copy_to(sc, df.local)
################# G2 #######################
#Glimpse of the data set
#TODO
sdf <- sdf_schema(df)
head(df)
actual_rows <- nrow(spark_dataframe(df))
actual_cols <- ncol(spark_dataframe(df))
stopifnot(
actual_rows==546,
actual_cols==2190)
################# G3 #######################
#Feature Selection
idx <- c(1,2,5,6,9,10,11,14,16,17,19,21,24,25,26,31,32,33,34,35,41,44,49,50,54)
#TODO
df.sel <- df %>% select(all_of(idx))
head(df.sel)
################# G4 #######################
#Generating train and test data
set.seed(123)
df.split <- df %>% sdf_random_split(training = 2/3, testing = 1/3)
df.train <- df.split$training
df.test <-  df.split$testing
#TODO Baseline
# Collect the data from Spark DataFrame to local R environment
train_data_local <- collect(df.train)
test_data_local <- collect(df.test)
# Use the table function to determine the number of instances for each class
train_class_counts <- table(train_data_local$CLASS)
test_class_counts <- table(test_data_local$CLASS)
# Display the class counts
print("Train Data Class Counts:")
print(train_class_counts)
print("Test Data Class Counts:")
print(test_class_counts)
random_forest_model <- ml_random_forest(df.train, formula = ("CLASS ~ ."))
# Make predictions on the test data using the trained model
predictions <- ml_predict(random_forest_model, df.test)
mdle.printConfusionMatrix(predictions, "Random Forest Baseline")
################# G5 #######################
num_pos_instances <- df.train %>%
filter(CLASS == 1) %>%
sdf_nrow() %>%
as.integer()
num_neg_instances <- df.train %>%
filter(CLASS == 0) %>%
sdf_nrow() %>%
as.integer()
# Determine the minimum number of instances for balanced sampling
min_instances <- min(num_pos_instances, num_neg_instances)
# Undersample the positive and negative classes
df.pos.train <- df.train %>%
filter(CLASS == 1) %>%
sdf_sample(fraction = min_instances / num_pos_instances)
df.neg.train <- df.train %>%
filter(CLASS == 0) %>%
sdf_sample(fraction = min_instances / num_neg_instances)
# Combine the undersampled dataframes
df.train_balanced <- sdf_bind_rows(df.pos.train, df.neg.train)
# Check the number of instances for each class after undersampling
num_instances_class_0 <- df.train_balanced %>%
filter(CLASS == 0) %>%
sdf_nrow() %>%
as.integer()
num_instances_class_1 <- df.train_balanced %>%
filter(CLASS == 1) %>%
sdf_nrow() %>%
as.integer()
cat("Number of instances for CLASS=0 after undersampling:", num_instances_class_0, "\n")
cat("Number of instances for CLASS=1 after undersampling:", num_instances_class_1, "\n")
random_forest_model <- ml_random_forest(df.train_balanced, formula = ("CLASS ~ ."))
# Make predictions on the test data using the trained model
predictions <- ml_predict(random_forest_model, df.test)
# Print confusion matrix and performance metrics
mdle.printConfusionMatrix(predictions, "Random Forest Undersampling")
# Check the number of instances for each class in the training set
num_instances_class_0 <- df_train_local %>%
filter(CLASS == 0) %>%
nrow()
num_instances_class_0 <- df.train %>%
filter(CLASS == 0) %>%
nrow()
num_instances_class_1 <- df.train %>%
filter(CLASS == 1) %>%
nrow()
# Determine the value of k for SMOTE based on the number of instances in the minority class
k <- min(5, num_instances_class_1)  # Adjust 5 as needed based on your dataset
if (num_instances_class_1 < k) {
warning("Number of instances in the minority class is too low for SMOTE oversampling.")
} else {
# Apply SMOTE oversampling
df.smote_local <- SMOTE(df_train_local, "CLASS", K = k)
# Convert oversampled data back to Spark DataFrame
df.smote <- copy_to(sc, df.smote_local)
# Check the number of instances for each class after oversampling
num_instances_class_0_oversampled <- df.smote %>%
filter(CLASS == 0) %>%
sdf_nrow() %>%
as.integer()
num_instances_class_1_oversampled <- df.smote %>%
filter(CLASS == 1) %>%
sdf_nrow() %>%
as.integer()
cat("Number of instances for CLASS=0 after oversampling:", num_instances_class_0_oversampled, "\n")
cat("Number of instances for CLASS=1 after oversampling:", num_instances_class_1_oversampled, "\n")
}
num_instances_class_1
k
num_instances_class_0 <- df.train %>%
filter(CLASS == 0) %>%
nrow()
num_instances_class_1 <- df.train %>%
filter(CLASS == 1) %>%
nrow()
num_instances_class_1
help("nrow")
#Oversampling
class(df.train)
# Check the number of instances for each class in the training set
num_instances_class_0 <- spark_dataframe(df.train) %>%
filter(CLASS == 0) %>%
nrow()
# Check the number of instances for each class in the training set
num_instances_class_0 <- df.train %>%
filter(CLASS == 0) %>%
spark_dataframe() %>%
nrow()
num_instances_class_1 <- df.train %>%
filter(CLASS == 1) %>%
spark_dataframe() %>%
nrow()
num_instances_class_1
# Count the number of instances for each class in the training set
num_instances_class_0 <- df.train %>%
filter(CLASS == 0) %>%
sdf_nrow() %>%
as.integer()
num_instances_class_1 <- df.train %>%
filter(CLASS == 1) %>%
sdf_nrow() %>%
as.integer()
# Determine the class with fewer instances
min_instances <- min(num_instances_class_0, num_instances_class_1)
# Perform random oversampling for both classes
df.pos.oversampled <- df.train %>%
filter(CLASS == 1) %>%
sdf_sample(n = min_instances, replace = TRUE)
num_instances_class_0
num_instances_class_1
# Perform random oversampling for both classes
df.pos.oversampled <- df.train %>%
filter(CLASS == 1) %>%
sdf_sample_frac(size = min_instances / num_instances_class_1, replace = TRUE)
# Perform random oversampling for both classes
df.pos.oversampled <- df.train %>%
filter(CLASS == 1)
df.neg.oversampled <- df.train %>%
filter(CLASS == 0)
# Sample the positive class to match the number of instances in the negative class
if (num_instances_class_1 < num_instances_class_0) {
df.pos.oversampled <- df.pos.oversampled %>%
sdf_sample(size = num_instances_class_0 - num_instances_class_1, replace = TRUE)
} else if (num_instances_class_0 < num_instances_class_1) {
df.neg.oversampled <- df.neg.oversampled %>%
sdf_sample(size = num_instances_class_1 - num_instances_class_0, replace = TRUE)
}
#Oversampling
num_pos_instances <- df.train %>%
filter(CLASS == 1) %>%
sdf_nrow() %>%
as.integer()
num_neg_instances <- df.train %>%
filter(CLASS == 0) %>%
sdf_nrow() %>%
as.integer()
# Determine the minimum number of instances for balanced sampling
max_instances <- max(num_pos_instances, num_neg_instances)
# Undersample the positive and negative classes
df.pos.train <- df.train %>%
filter(CLASS == 1) %>%
sdf_sample(fraction = max_instances / num_pos_instances)
df.neg.train <- df.train %>%
filter(CLASS == 0) %>%
sdf_sample(fraction = max_instances / num_neg_instances)
# Combine the undersampled dataframes
df.train_balanced <- sdf_bind_rows(df.pos.train, df.neg.train)
# Check the number of instances for each class after undersampling
num_instances_class_0 <- df.train_balanced %>%
filter(CLASS == 0) %>%
sdf_nrow() %>%
as.integer()
num_instances_class_1 <- df.train_balanced %>%
filter(CLASS == 1) %>%
sdf_nrow() %>%
as.integer()
cat("Number of instances for CLASS=0 after undersampling:", num_instances_class_0, "\n")
cat("Number of instances for CLASS=1 after undersampling:", num_instances_class_1, "\n")
random_forest_model <- ml_random_forest(df.train_balanced, formula = ("CLASS ~ ."))
# Make predictions on the test data using the trained model
predictions <- ml_predict(random_forest_model, df.test)
# Print confusion matrix and performance metrics
mdle.printConfusionMatrix(predictions, "Random Forest Undersampling")
# Print confusion matrix and performance metrics
mdle.printConfusionMatrix(predictions, "Random Forest Oversampling")
help("BSMOTE")
??BSMOTE
df.train_widthout_class <- df[, -ncol(df)]
#############################################################################################
#BSMOTE
class(df.train)
# Convert tbl_spark to regular R data frame
df <- as.data.frame(df.train)
# Extract features (exclude the class label)
features <- df[, -ncol(df)]
print(features)
# Extract features (exclude the class label)
features <- df[, -1]  # Exclude the first column, assuming "CLASS" is the first column
# Print features
print(features)
# Extract the class labels
labels <- df[[ncol(df)]]
# Apply Borderline-SMOTE sampling using BLSMOTE
# Set the values for K, C, and method parameters
K <- 5  # Number of nearest neighbors to consider
C <- 6  # Number of nearest neighbors to consider when identifying borderline samples
method <- "both"  # Borderline samples from both classes will be oversampled
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(features, labels, K = K, C = C, method = method)
remove.packages("smotefamily")
# Install the package and its dependencies
install.packages("smotefamily", dependencies = TRUE)
install.packages("smotefamily", dependencies = TRUE)
library(smotefamily)
# Apply Borderline-SMOTE sampling using BLSMOTE
# Set the values for K, C, and method parameters
K <- 5  # Number of nearest neighbors to consider
C <- 6  # Number of nearest neighbors to consider when identifying borderline samples
method <- "both"  # Borderline samples from both classes will be oversampled
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(features, labels, K = K, C = C, method = method)
# Define the kncount function
kncount <- function(knear_D, sizeP) {
sum(knear_D <= sizeP)
}
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(features, labels, K = K, C = C, method = method)
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(features, labels, K = K, C = C, method = "type1")
class(labels)
class(features)
labels <- as.factor(labels)
class(labels)
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(features, labels, K = K, C = C, method = "type1")
help("kncount")
??kncount
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(X = features, target = labels, K = K, C = C, dupSize= 0, method = "type1")
df
# Print features
print(features)
labels
oversampled_data <- BLSMOTE(X = features, target = labels, K = 5, C = 6, dupSize= 0, method = "type1")
class(labels)
class(features)
labels <- as.vector(labels)
class(labels)
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(X = features, target = labels, K = 5, C = 6, dupSize= 0, method = "type1")
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(X = features, target = labels, method = "type1")
ncol(features)
table(labels)
labels
table(labels)
# Extract the class labels
labels <- df[0]
labels
table(labels)
# Extract the class labels
labels <- df[-1]
labels
table(labels)
labels <- df$CLASS
labels
table(labels)
labels <- as.vector(labels)
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(X = features, target = labels, method = "type1")
labels <- df$CLASS
labels
table(labels)
# Apply Borderline-SMOTE sampling using BLSMOTE
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(X = features, target = labels, method = "type1")
df <- as.data.frame(df.train)
# Extract features (exclude the class label)
features <- df[, -1]  # Exclude the first column, assuming "CLASS" is the first column
# Extract the class labels
labels <- df$CLASS
# Apply Borderline-SMOTE sampling using BLSMOTE
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(X = features, target = labels, method = "both")
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(X = features, target = labels, method = "type1")
# Combine oversampled features and labels into a new data frame
oversampled_df <- data.frame(oversampled_data$features, Class = oversampled_data$labels)
random_forest_model <- ml_random_forest(oversampled_df, formula = ("CLASS ~ ."))
spark_df <- sdf_copy_to(sc, oversampled_df, name = "oversampled_df_spark")
spark_df <- sdf_copy_to(sc, oversampled_df)
help("sdf_copy_to")
#BSMOTE
# Convert tbl_spark to regular R data frame
df <- as.data.frame(df.train)
# Extract features (exclude the class label)
features <- df[, -1]  # Exclude the first column, assuming "CLASS" is the first column
# Extract the class labels
labels <- df$CLASS
# Apply Borderline-SMOTE sampling using BLSMOTE
# Apply BLSMOTE oversampling
oversampled_data <- BLSMOTE(X = features, target = labels, method = "type1")
# Combine oversampled features and labels into a new data frame
oversampled_df <- data.frame(oversampled_data$features, Class = oversampled_data$labels)
class(oversampled_df)
class(oversampled_data)
class(oversampled_data)
# Combine oversampled features and labels into a new data frame
oversampled_df <- data.frame(oversampled_data)
# Combine oversampled features and labels into a new data frame
oversampled_df <- data.frame(oversampled_data$data)
class(oversampled_df)
spark_df <- sdf_copy_to(sc, oversampled_df)
random_forest_model <- ml_random_forest(spark_df, formula = ("CLASS ~ ."))
random_forest_model <- ml_random_forest(spark_df, formula = ("class ~ ."))
random_forest_model <- ml_random_forest(spark_df, formula = ("class ~ ."))
predictions <- ml_predict(random_forest_model, df.test)
# Print confusion matrix and performance metrics
mdle.printConfusionMatrix(predictions, "Random Forest Oversampling")
mdle.printConfusionMatrix(predictions, "Random Forest BLSMOTE")
################# Spark cleanup ################
spark_disconnect(sc)
